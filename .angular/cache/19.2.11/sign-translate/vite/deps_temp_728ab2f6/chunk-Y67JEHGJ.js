import {
  __async,
  __commonJS,
  __esm,
  __export,
  __toESM
} from "./chunk-H7FQKYJT.js";

// node_modules/@tensorflow/tfjs-core/dist/backends/backend.js
function notYetImplemented(kernelName) {
  throw new Error(`'${kernelName}' not yet implemented or not found in the registry. This kernel may not be supported by the tfjs backend you have chosen`);
}
var EPSILON_FLOAT32, EPSILON_FLOAT16, DataStorage, KernelBackend;
var init_backend = __esm({
  "node_modules/@tensorflow/tfjs-core/dist/backends/backend.js"() {
    EPSILON_FLOAT32 = 1e-7;
    EPSILON_FLOAT16 = 1e-4;
    DataStorage = class {
      constructor(backend2, dataMover) {
        this.backend = backend2;
        this.dataMover = dataMover;
        this.data = /* @__PURE__ */ new WeakMap();
        this.dataIdsCount = 0;
      }
      get(dataId) {
        if (!this.data.has(dataId)) {
          this.dataMover.moveData(this.backend, dataId);
        }
        return this.data.get(dataId);
      }
      set(dataId, value) {
        this.dataIdsCount++;
        this.data.set(dataId, value);
      }
      has(dataId) {
        return this.data.has(dataId);
      }
      delete(dataId) {
        this.dataIdsCount--;
        return this.data.delete(dataId);
      }
      numDataIds() {
        return this.dataIdsCount;
      }
    };
    KernelBackend = class {
      refCount(dataId) {
        return notYetImplemented("refCount");
      }
      incRef(dataId) {
        return notYetImplemented("incRef");
      }
      timerAvailable() {
        return true;
      }
      time(f) {
        return notYetImplemented("time");
      }
      read(dataId) {
        return notYetImplemented("read");
      }
      readSync(dataId) {
        return notYetImplemented("readSync");
      }
      readToGPU(dataId, options) {
        return notYetImplemented("readToGPU");
      }
      numDataIds() {
        return notYetImplemented("numDataIds");
      }
      disposeData(dataId, force) {
        return notYetImplemented("disposeData");
      }
      write(values, shape, dtype) {
        return notYetImplemented("write");
      }
      move(dataId, values, shape, dtype, refCount) {
        return notYetImplemented("move");
      }
      createTensorFromGPUData(values, shape, dtype) {
        return notYetImplemented("createTensorFromGPUData");
      }
      memory() {
        return notYetImplemented("memory");
      }
      /** Returns the highest precision for floats in bits (e.g. 16 or 32) */
      floatPrecision() {
        return notYetImplemented("floatPrecision");
      }
      /** Returns the smallest representable number.  */
      epsilon() {
        return this.floatPrecision() === 32 ? EPSILON_FLOAT32 : EPSILON_FLOAT16;
      }
      dispose() {
        return notYetImplemented("dispose");
      }
    };
  }
});

// node_modules/@tensorflow/tfjs-core/dist/util_base.js
function shuffle(array) {
  let counter = array.length;
  let index = 0;
  while (counter > 0) {
    index = Math.random() * counter | 0;
    counter--;
    swap(array, counter, index);
  }
}
function shuffleCombo(array, array2) {
  if (array.length !== array2.length) {
    throw new Error(`Array sizes must match to be shuffled together First array length was ${array.length}Second array length was ${array2.length}`);
  }
  let counter = array.length;
  let index = 0;
  while (counter > 0) {
    index = Math.random() * counter | 0;
    counter--;
    swap(array, counter, index);
    swap(array2, counter, index);
  }
}
function clamp(min2, x, max2) {
  return Math.max(min2, Math.min(x, max2));
}
function nearestLargerEven(val) {
  return val % 2 === 0 ? val : val + 1;
}
function swap(object, left, right) {
  const temp = object[left];
  object[left] = object[right];
  object[right] = temp;
}
function sum(arr) {
  let sum3 = 0;
  for (let i = 0; i < arr.length; i++) {
    sum3 += arr[i];
  }
  return sum3;
}
function randUniform(a, b) {
  const r = Math.random();
  return b * r + (1 - r) * a;
}
function distSquared(a, b) {
  let result = 0;
  for (let i = 0; i < a.length; i++) {
    const diff = Number(a[i]) - Number(b[i]);
    result += diff * diff;
  }
  return result;
}
function assert(expr, msg) {
  if (!expr) {
    throw new Error(typeof msg === "string" ? msg : msg());
  }
}
function assertShapesMatch(shapeA, shapeB, errorMessagePrefix = "") {
  assert(arraysEqual(shapeA, shapeB), () => errorMessagePrefix + ` Shapes ${shapeA} and ${shapeB} must match`);
}
function assertNonNull(a) {
  assert(a != null, () => `The input to the tensor constructor must be a non-null value.`);
}
function sizeFromShape(shape) {
  if (shape.length === 0) {
    return 1;
  }
  let size = shape[0];
  for (let i = 1; i < shape.length; i++) {
    size *= shape[i];
  }
  return size;
}
function isScalarShape(shape) {
  return shape.length === 0;
}
function arraysEqualWithNull(n1, n2) {
  if (n1 === n2) {
    return true;
  }
  if (n1 == null || n2 == null) {
    return false;
  }
  if (n1.length !== n2.length) {
    return false;
  }
  for (let i = 0; i < n1.length; i++) {
    if (n1[i] !== null && n2[i] !== null && n1[i] !== n2[i]) {
      return false;
    }
  }
  return true;
}
function arraysEqual(n1, n2) {
  if (n1 === n2) {
    return true;
  }
  if (n1 == null || n2 == null) {
    return false;
  }
  if (n1.length !== n2.length) {
    return false;
  }
  for (let i = 0; i < n1.length; i++) {
    if (n1[i] !== n2[i]) {
      return false;
    }
  }
  return true;
}
function isInt(a) {
  return a % 1 === 0;
}
function tanh(x) {
  if (Math.tanh != null) {
    return Math.tanh(x);
  }
  if (x === Infinity) {
    return 1;
  } else if (x === -Infinity) {
    return -1;
  } else {
    const e2x = Math.exp(2 * x);
    return (e2x - 1) / (e2x + 1);
  }
}
function sizeToSquarishShape(size) {
  const width = Math.ceil(Math.sqrt(size));
  return [width, Math.ceil(size / width)];
}
function createShuffledIndices(n) {
  const shuffledIndices = new Uint32Array(n);
  for (let i = 0; i < n; ++i) {
    shuffledIndices[i] = i;
  }
  shuffle(shuffledIndices);
  return shuffledIndices;
}
function rightPad(a, size) {
  if (size <= a.length) {
    return a;
  }
  return a + " ".repeat(size - a.length);
}
function repeatedTry(checkFn, delayFn = (counter) => 0, maxCounter, scheduleFn) {
  return new Promise((resolve, reject) => {
    let tryCount = 0;
    const tryFn = () => {
      if (checkFn()) {
        resolve();
        return;
      }
      tryCount++;
      const nextBackoff = delayFn(tryCount);
      if (maxCounter != null && tryCount >= maxCounter) {
        reject();
        return;
      }
      if (scheduleFn != null) {
        scheduleFn(tryFn, nextBackoff);
      } else {
        setTimeout(tryFn, nextBackoff);
      }
    };
    tryFn();
  });
}
function inferFromImplicitShape(shape, size) {
  let shapeProd = 1;
  let implicitIdx = -1;
  for (let i = 0; i < shape.length; ++i) {
    if (shape[i] >= 0) {
      shapeProd *= shape[i];
    } else if (shape[i] === -1) {
      if (implicitIdx !== -1) {
        throw Error(`Shapes can only have 1 implicit size. Found -1 at dim ${implicitIdx} and dim ${i}`);
      }
      implicitIdx = i;
    } else if (shape[i] < 0) {
      throw Error(`Shapes can not be < 0. Found ${shape[i]} at dim ${i}`);
    }
  }
  if (implicitIdx === -1) {
    if (size > 0 && size !== shapeProd) {
      throw Error(`Size(${size}) must match the product of shape ${shape}`);
    }
    return shape;
  }
  if (shapeProd === 0) {
    throw Error(`Cannot infer the missing size in [${shape}] when there are 0 elements`);
  }
  if (size % shapeProd !== 0) {
    throw Error(`The implicit shape can't be a fractional number. Got ${size} / ${shapeProd}`);
  }
  const newShape = shape.slice();
  newShape[implicitIdx] = size / shapeProd;
  return newShape;
}
function parseAxisParam(axis, shape) {
  const rank = shape.length;
  axis = axis == null ? shape.map((s, i) => i) : [].concat(axis);
  assert(axis.every((ax) => ax >= -rank && ax < rank), () => `All values in axis param must be in range [-${rank}, ${rank}) but got axis ${axis}`);
  assert(axis.every((ax) => isInt(ax)), () => `All values in axis param must be integers but got axis ${axis}`);
  return axis.map((a) => a < 0 ? rank + a : a);
}
function squeezeShape(shape, axis) {
  const newShape = [];
  const keptDims = [];
  const isEmptyArray = axis != null && Array.isArray(axis) && axis.length === 0;
  const axes = axis == null || isEmptyArray ? null : parseAxisParam(axis, shape).sort();
  let j = 0;
  for (let i = 0; i < shape.length; ++i) {
    if (axes != null) {
      if (axes[j] === i && shape[i] !== 1) {
        throw new Error(`Can't squeeze axis ${i} since its dim '${shape[i]}' is not 1`);
      }
      if ((axes[j] == null || axes[j] > i) && shape[i] === 1) {
        newShape.push(shape[i]);
        keptDims.push(i);
      }
      if (axes[j] <= i) {
        j++;
      }
    }
    if (shape[i] !== 1) {
      newShape.push(shape[i]);
      keptDims.push(i);
    }
  }
  return {
    newShape,
    keptDims
  };
}
function getTypedArrayFromDType(dtype, size) {
  return getArrayFromDType(dtype, size);
}
function getArrayFromDType(dtype, size) {
  let values = null;
  if (dtype == null || dtype === "float32") {
    values = new Float32Array(size);
  } else if (dtype === "int32") {
    values = new Int32Array(size);
  } else if (dtype === "bool") {
    values = new Uint8Array(size);
  } else if (dtype === "string") {
    values = new Array(size);
  } else {
    throw new Error(`Unknown data type ${dtype}`);
  }
  return values;
}
function checkConversionForErrors(vals, dtype) {
  for (let i = 0; i < vals.length; i++) {
    const num = vals[i];
    if (isNaN(num) || !isFinite(num)) {
      throw Error(`A tensor of type ${dtype} being uploaded contains ${num}.`);
    }
  }
}
function isValidDtype(dtype) {
  return dtype === "bool" || dtype === "complex64" || dtype === "float32" || dtype === "int32" || dtype === "string";
}
function hasEncodingLoss(oldType, newType) {
  if (newType === "complex64") {
    return false;
  }
  if (newType === "float32" && oldType !== "complex64") {
    return false;
  }
  if (newType === "int32" && oldType !== "float32" && oldType !== "complex64") {
    return false;
  }
  if (newType === "bool" && oldType === "bool") {
    return false;
  }
  return true;
}
function bytesPerElement(dtype) {
  if (dtype === "float32" || dtype === "int32") {
    return 4;
  } else if (dtype === "complex64") {
    return 8;
  } else if (dtype === "bool") {
    return 1;
  } else {
    throw new Error(`Unknown dtype ${dtype}`);
  }
}
function bytesFromStringArray(arr) {
  if (arr == null) {
    return 0;
  }
  let bytes = 0;
  arr.forEach((x) => bytes += x.length);
  return bytes;
}
function isString(value) {
  return typeof value === "string" || value instanceof String;
}
function isBoolean(value) {
  return typeof value === "boolean";
}
function isNumber(value) {
  return typeof value === "number";
}
function inferDtype(values) {
  if (Array.isArray(values)) {
    return inferDtype(values[0]);
  }
  if (values instanceof Float32Array) {
    return "float32";
  } else if (values instanceof Int32Array || values instanceof Uint8Array || values instanceof Uint8ClampedArray) {
    return "int32";
  } else if (isNumber(values)) {
    return "float32";
  } else if (isString(values)) {
    return "string";
  } else if (isBoolean(values)) {
    return "bool";
  }
  return "float32";
}
function isFunction(f) {
  return !!(f && f.constructor && f.call && f.apply);
}
function nearestDivisor(size, start) {
  for (let i = start; i < size; ++i) {
    if (size % i === 0) {
      return i;
    }
  }
  return size;
}
function computeStrides(shape) {
  const rank = shape.length;
  if (rank < 2) {
    return [];
  }
  const strides = new Array(rank - 1);
  strides[rank - 2] = shape[rank - 1];
  for (let i = rank - 3; i >= 0; --i) {
    strides[i] = strides[i + 1] * shape[i + 1];
  }
  return strides;
}
function createNestedArray(offset, shape, a, isComplex = false) {
  const ret = new Array();
  if (shape.length === 1) {
    const d = shape[0] * (isComplex ? 2 : 1);
    for (let i = 0; i < d; i++) {
      ret[i] = a[offset + i];
    }
  } else {
    const d = shape[0];
    const rest = shape.slice(1);
    const len = rest.reduce((acc, c) => acc * c) * (isComplex ? 2 : 1);
    for (let i = 0; i < d; i++) {
      ret[i] = createNestedArray(offset + i * len, rest, a, isComplex);
    }
  }
  return ret;
}
function toNestedArray(shape, a, isComplex = false) {
  if (shape.length === 0) {
    return a[0];
  }
  const size = shape.reduce((acc, c) => acc * c) * (isComplex ? 2 : 1);
  if (size === 0) {
    return [];
  }
  if (size !== a.length) {
    throw new Error(`[${shape}] does not match the input size ${a.length}${isComplex ? " for a complex tensor" : ""}.`);
  }
  return createNestedArray(0, shape, a, isComplex);
}
function convertBackendValuesAndArrayBuffer(data, dtype) {
  if (Array.isArray(data)) {
    return data;
  }
  if (dtype === "float32") {
    return data instanceof Float32Array ? data : new Float32Array(data);
  } else if (dtype === "int32") {
    return data instanceof Int32Array ? data : new Int32Array(data);
  } else if (dtype === "bool" || dtype === "string") {
    return Uint8Array.from(new Int32Array(data));
  } else {
    throw new Error(`Unknown dtype ${dtype}`);
  }
}
function makeOnesTypedArray(size, dtype) {
  const array = makeZerosTypedArray(size, dtype);
  for (let i = 0; i < array.length; i++) {
    array[i] = 1;
  }
  return array;
}
function makeZerosTypedArray(size, dtype) {
  if (dtype == null || dtype === "float32" || dtype === "complex64") {
    return new Float32Array(size);
  } else if (dtype === "int32") {
    return new Int32Array(size);
  } else if (dtype === "bool") {
    return new Uint8Array(size);
  } else {
    throw new Error(`Unknown data type ${dtype}`);
  }
}
function makeZerosNestedTypedArray(shape, dtype) {
  const size = shape.reduce((prev, curr) => prev * curr, 1);
  if (dtype == null || dtype === "float32") {
    return toNestedArray(shape, new Float32Array(size));
  } else if (dtype === "int32") {
    return toNestedArray(shape, new Int32Array(size));
  } else if (dtype === "bool") {
    return toNestedArray(shape, new Uint8Array(size));
  } else {
    throw new Error(`Unknown data type ${dtype}`);
  }
}
function assertNonNegativeIntegerDimensions(shape) {
  shape.forEach((dimSize) => {
    assert(Number.isInteger(dimSize) && dimSize >= 0, () => `Tensor must have a shape comprised of positive integers but got shape [${shape}].`);
  });
}
function locToIndex(locs, rank, strides) {
  if (rank === 0) {
    return 0;
  } else if (rank === 1) {
    return locs[0];
  }
  let index = locs[locs.length - 1];
  for (let i = 0; i < locs.length - 1; ++i) {
    index += strides[i] * locs[i];
  }
  return index;
}
function indexToLoc(index, rank, strides) {
  if (rank === 0) {
    return [];
  } else if (rank === 1) {
    return [index];
  }
  const locs = new Array(rank);
  for (let i = 0; i < locs.length - 1; ++i) {
    locs[i] = Math.floor(index / strides[i]);
    index -= locs[i] * strides[i];
  }
  locs[locs.length - 1] = index;
  return locs;
}
function isPromise(object) {
  return object && object.then && typeof object.then === "function";
}
var init_util_base = __esm({
  "node_modules/@tensorflow/tfjs-core/dist/util_base.js"() {
  }
});

// node_modules/@tensorflow/tfjs-core/dist/environment.js
function getQueryParams(queryString) {
  const params = {};
  queryString.replace(/[?&]([^=?&]+)(?:=([^&]*))?/g, (s, ...t) => {
    decodeParam(params, t[0], t[1]);
    return t.join("=");
  });
  return params;
}
function decodeParam(params, name, value) {
  params[decodeURIComponent(name)] = decodeURIComponent(value || "");
}
function parseValue(flagName, value) {
  const lowerCaseValue = value.toLowerCase();
  if (lowerCaseValue === "true" || lowerCaseValue === "false") {
    return lowerCaseValue === "true";
  } else if (`${+lowerCaseValue}` === lowerCaseValue) {
    return +lowerCaseValue;
  } else {
    return value;
  }
}
function env() {
  return ENV;
}
function setEnvironmentGlobal(environment) {
  ENV = environment;
}
var TENSORFLOWJS_FLAGS_PREFIX, Environment, ENV;
var init_environment = __esm({
  "node_modules/@tensorflow/tfjs-core/dist/environment.js"() {
    init_util_base();
    TENSORFLOWJS_FLAGS_PREFIX = "tfjsflags";
    Environment = class {
      // tslint:disable-next-line: no-any
      constructor(global2) {
        this.global = global2;
        this.flags = {};
        this.flagRegistry = {};
        this.urlFlags = {};
        this.getQueryParams = getQueryParams;
        this.populateURLFlags();
      }
      setPlatform(platformName, platform) {
        if (this.platform != null) {
          if (!(env().getBool("IS_TEST") || env().getBool("PROD"))) {
            console.warn(`Platform ${this.platformName} has already been set. Overwriting the platform with ${platformName}.`);
          }
        }
        this.platformName = platformName;
        this.platform = platform;
      }
      registerFlag(flagName, evaluationFn, setHook) {
        this.flagRegistry[flagName] = {
          evaluationFn,
          setHook
        };
        if (this.urlFlags[flagName] != null) {
          const flagValue = this.urlFlags[flagName];
          if (!(env().getBool("IS_TEST") || env().getBool("PROD"))) {
            console.warn(`Setting feature override from URL ${flagName}: ${flagValue}.`);
          }
          this.set(flagName, flagValue);
        }
      }
      getAsync(flagName) {
        return __async(this, null, function* () {
          if (flagName in this.flags) {
            return this.flags[flagName];
          }
          this.flags[flagName] = yield this.evaluateFlag(flagName);
          return this.flags[flagName];
        });
      }
      get(flagName) {
        if (flagName in this.flags) {
          return this.flags[flagName];
        }
        const flagValue = this.evaluateFlag(flagName);
        if (isPromise(flagValue)) {
          throw new Error(`Flag ${flagName} cannot be synchronously evaluated. Please use getAsync() instead.`);
        }
        this.flags[flagName] = flagValue;
        return this.flags[flagName];
      }
      getNumber(flagName) {
        return this.get(flagName);
      }
      getBool(flagName) {
        return this.get(flagName);
      }
      getString(flagName) {
        return this.get(flagName);
      }
      getFlags() {
        return this.flags;
      }
      // For backwards compatibility.
      get features() {
        return this.flags;
      }
      set(flagName, value) {
        if (this.flagRegistry[flagName] == null) {
          throw new Error(`Cannot set flag ${flagName} as it has not been registered.`);
        }
        this.flags[flagName] = value;
        if (this.flagRegistry[flagName].setHook != null) {
          this.flagRegistry[flagName].setHook(value);
        }
      }
      evaluateFlag(flagName) {
        if (this.flagRegistry[flagName] == null) {
          throw new Error(`Cannot evaluate flag '${flagName}': no evaluation function found.`);
        }
        return this.flagRegistry[flagName].evaluationFn();
      }
      setFlags(flags) {
        this.flags = Object.assign({}, flags);
      }
      reset() {
        this.flags = {};
        this.urlFlags = {};
        this.populateURLFlags();
      }
      populateURLFlags() {
        if (typeof this.global === "undefined" || typeof this.global.location === "undefined" || typeof this.global.location.search === "undefined") {
          return;
        }
        const urlParams = this.getQueryParams(this.global.location.search);
        if (TENSORFLOWJS_FLAGS_PREFIX in urlParams) {
          const keyValues = urlParams[TENSORFLOWJS_FLAGS_PREFIX].split(",");
          keyValues.forEach((keyValue) => {
            const [key, value] = keyValue.split(":");
            this.urlFlags[key] = parseValue(key, value);
          });
        }
      }
    };
    ENV = null;
  }
});

// node_modules/@tensorflow/tfjs-core/dist/kernel_names.js
var Abs, Acos, Acosh, Add, AddN, All, Any, ArgMax, ArgMin, Asin, Asinh, Atan, Atanh, Atan2, AvgPool, AvgPoolGrad, AvgPool3D, AvgPool3DGrad, BatchMatMul, BatchToSpaceND, Bincount, BitwiseAnd, BroadcastTo, BroadcastArgs, Cast, Ceil, ClipByValue, Complex, ComplexAbs, Concat, Conv2D, Conv2DBackpropFilter, Conv2DBackpropInput, Conv3D, Conv3DBackpropFilterV2, Conv3DBackpropInputV2, Cos, Cosh, Cumprod, Cumsum, CropAndResize, DenseBincount, DepthToSpace, DepthwiseConv2dNative, DepthwiseConv2dNativeBackpropFilter, DepthwiseConv2dNativeBackpropInput, Diag, Dilation2D, Dilation2DBackpropInput, Dilation2DBackpropFilter, Draw, RealDiv, Einsum, Elu, EluGrad, Erf, Equal, Exp, ExpandDims, Expm1, FFT, Fill, FlipLeftRight, Floor, FloorDiv, FusedBatchNorm, GatherV2, GatherNd, Greater, GreaterEqual, Identity, IFFT, Imag, IsFinite, IsInf, IsNan, LeakyRelu, Less, LessEqual, LinSpace, Log, Log1p, LogicalAnd, LogicalNot, LogicalOr, LogicalXor, LogSoftmax, LowerBound, LRN, LRNGrad, MatrixBandPart, Max, Maximum, MaxPool, MaxPoolGrad, MaxPool3D, MaxPool3DGrad, MaxPoolWithArgmax, Mean, Min, Minimum, MirrorPad, Mod, Multinomial, Multiply, Neg, NotEqual, NonMaxSuppressionV3, NonMaxSuppressionV4, NonMaxSuppressionV5, OnesLike, OneHot, Pack, PadV2, Pool, Pow, Prelu, Prod, RaggedGather, RaggedRange, RaggedTensorToTensor, Range, Real, Reciprocal, Relu, Reshape, ResizeNearestNeighbor, ResizeNearestNeighborGrad, ResizeBilinear, ResizeBilinearGrad, Relu6, Reverse, Round, Rsqrt, ScatterNd, TensorScatterUpdate, SearchSorted, Select, Selu, Slice, Sin, Sinh, Sign, Sigmoid, Softplus, Sqrt, Sum, SpaceToBatchND, SplitV, Softmax, SparseFillEmptyRows, SparseReshape, SparseSegmentMean, SparseSegmentSum, SparseToDense, SquaredDifference, Square, StaticRegexReplace, StridedSlice, StringNGrams, StringSplit, StringToHashBucketFast, Sub, Tan, Tanh, Tile, TopK, Transform, Transpose, Unique, Unpack, UnsortedSegmentSum, UpperBound, ZerosLike, Step, FromPixels, RotateWithOffset, _FusedMatMul, FusedConv2D, FusedDepthwiseConv2D;
var init_kernel_names = __esm({
  "node_modules/@tensorflow/tfjs-core/dist/kernel_names.js"() {
    Abs = "Abs";
    Acos = "Acos";
    Acosh = "Acosh";
    Add = "Add";
    AddN = "AddN";
    All = "All";
    Any = "Any";
    ArgMax = "ArgMax";
    ArgMin = "ArgMin";
    Asin = "Asin";
    Asinh = "Asinh";
    Atan = "Atan";
    Atanh = "Atanh";
    Atan2 = "Atan2";
    AvgPool = "AvgPool";
    AvgPoolGrad = "AvgPoolGrad";
    AvgPool3D = "AvgPool3D";
    AvgPool3DGrad = "AvgPool3DGrad";
    BatchMatMul = "BatchMatMul";
    BatchToSpaceND = "BatchToSpaceND";
    Bincount = "Bincount";
    BitwiseAnd = "BitwiseAnd";
    BroadcastTo = "BroadcastTo";
    BroadcastArgs = "BroadcastArgs";
    Cast = "Cast";
    Ceil = "Ceil";
    ClipByValue = "ClipByValue";
    Complex = "Complex";
    ComplexAbs = "ComplexAbs";
    Concat = "Concat";
    Conv2D = "Conv2D";
    Conv2DBackpropFilter = "Conv2DBackpropFilter";
    Conv2DBackpropInput = "Conv2DBackpropInput";
    Conv3D = "Conv3D";
    Conv3DBackpropFilterV2 = "Conv3DBackpropFilterV2";
    Conv3DBackpropInputV2 = "Conv3DBackpropInputV2";
    Cos = "Cos";
    Cosh = "Cosh";
    Cumprod = "Cumprod";
    Cumsum = "Cumsum";
    CropAndResize = "CropAndResize";
    DenseBincount = "DenseBincount";
    DepthToSpace = "DepthToSpace";
    DepthwiseConv2dNative = "DepthwiseConv2dNative";
    DepthwiseConv2dNativeBackpropFilter = "DepthwiseConv2dNativeBackpropFilter";
    DepthwiseConv2dNativeBackpropInput = "DepthwiseConv2dNativeBackpropInput";
    Diag = "Diag";
    Dilation2D = "Dilation2D";
    Dilation2DBackpropInput = "Dilation2DBackpropInput";
    Dilation2DBackpropFilter = "Dilation2DBackpropFilter";
    Draw = "Draw";
    RealDiv = "RealDiv";
    Einsum = "Einsum";
    Elu = "Elu";
    EluGrad = "EluGrad";
    Erf = "Erf";
    Equal = "Equal";
    Exp = "Exp";
    ExpandDims = "ExpandDims";
    Expm1 = "Expm1";
    FFT = "FFT";
    Fill = "Fill";
    FlipLeftRight = "FlipLeftRight";
    Floor = "Floor";
    FloorDiv = "FloorDiv";
    FusedBatchNorm = "FusedBatchNorm";
    GatherV2 = "GatherV2";
    GatherNd = "GatherNd";
    Greater = "Greater";
    GreaterEqual = "GreaterEqual";
    Identity = "Identity";
    IFFT = "IFFT";
    Imag = "Imag";
    IsFinite = "IsFinite";
    IsInf = "IsInf";
    IsNan = "IsNan";
    LeakyRelu = "LeakyRelu";
    Less = "Less";
    LessEqual = "LessEqual";
    LinSpace = "LinSpace";
    Log = "Log";
    Log1p = "Log1p";
    LogicalAnd = "LogicalAnd";
    LogicalNot = "LogicalNot";
    LogicalOr = "LogicalOr";
    LogicalXor = "LogicalXor";
    LogSoftmax = "LogSoftmax";
    LowerBound = "LowerBound";
    LRN = "LRN";
    LRNGrad = "LRNGrad";
    MatrixBandPart = "MatrixBandPart";
    Max = "Max";
    Maximum = "Maximum";
    MaxPool = "MaxPool";
    MaxPoolGrad = "MaxPoolGrad";
    MaxPool3D = "MaxPool3D";
    MaxPool3DGrad = "MaxPool3DGrad";
    MaxPoolWithArgmax = "MaxPoolWithArgmax";
    Mean = "Mean";
    Min = "Min";
    Minimum = "Minimum";
    MirrorPad = "MirrorPad";
    Mod = "Mod";
    Multinomial = "Multinomial";
    Multiply = "Multiply";
    Neg = "Neg";
    NotEqual = "NotEqual";
    NonMaxSuppressionV3 = "NonMaxSuppressionV3";
    NonMaxSuppressionV4 = "NonMaxSuppressionV4";
    NonMaxSuppressionV5 = "NonMaxSuppressionV5";
    OnesLike = "OnesLike";
    OneHot = "OneHot";
    Pack = "Pack";
    PadV2 = "PadV2";
    Pool = "Pool";
    Pow = "Pow";
    Prelu = "Prelu";
    Prod = "Prod";
    RaggedGather = "RaggedGather";
    RaggedRange = "RaggedRange";
    RaggedTensorToTensor = "RaggedTensorToTensor";
    Range = "Range";
    Real = "Real";
    Reciprocal = "Reciprocal";
    Relu = "Relu";
    Reshape = "Reshape";
    ResizeNearestNeighbor = "ResizeNearestNeighbor";
    ResizeNearestNeighborGrad = "ResizeNearestNeighborGrad";
    ResizeBilinear = "ResizeBilinear";
    ResizeBilinearGrad = "ResizeBilinearGrad";
    Relu6 = "Relu6";
    Reverse = "Reverse";
    Round = "Round";
    Rsqrt = "Rsqrt";
    ScatterNd = "ScatterNd";
    TensorScatterUpdate = "TensorScatterUpdate";
    SearchSorted = "SearchSorted";
    Select = "Select";
    Selu = "Selu";
    Slice = "Slice";
    Sin = "Sin";
    Sinh = "Sinh";
    Sign = "Sign";
    Sigmoid = "Sigmoid";
    Softplus = "Softplus";
    Sqrt = "Sqrt";
    Sum = "Sum";
    SpaceToBatchND = "SpaceToBatchND";
    SplitV = "SplitV";
    Softmax = "Softmax";
    SparseFillEmptyRows = "SparseFillEmptyRows";
    SparseReshape = "SparseReshape";
    SparseSegmentMean = "SparseSegmentMean";
    SparseSegmentSum = "SparseSegmentSum";
    SparseToDense = "SparseToDense";
    SquaredDifference = "SquaredDifference";
    Square = "Square";
    StaticRegexReplace = "StaticRegexReplace";
    StridedSlice = "StridedSlice";
    StringNGrams = "StringNGrams";
    StringSplit = "StringSplit";
    StringToHashBucketFast = "StringToHashBucketFast";
    Sub = "Sub";
    Tan = "Tan";
    Tanh = "Tanh";
    Tile = "Tile";
    TopK = "TopK";
    Transform = "Transform";
    Transpose = "Transpose";
    Unique = "Unique";
    Unpack = "Unpack";
    UnsortedSegmentSum = "UnsortedSegmentSum";
    UpperBound = "UpperBound";
    ZerosLike = "ZerosLike";
    Step = "Step";
    FromPixels = "FromPixels";
    RotateWithOffset = "RotateWithOffset";
    _FusedMatMul = "_FusedMatMul";
    FusedConv2D = "FusedConv2D";
    FusedDepthwiseConv2D = "FusedDepthwiseConv2D";
  }
});

// node_modules/@tensorflow/tfjs-core/dist/global_util.js
function getGlobalNamespace() {
  if (globalNameSpace == null) {
    let ns;
    if (typeof window !== "undefined") {
      ns = window;
    } else if (typeof global !== "undefined") {
      ns = global;
    } else if (typeof process !== "undefined") {
      ns = process;
    } else if (typeof self !== "undefined") {
      ns = self;
    } else {
      throw new Error("Could not find a global object");
    }
    globalNameSpace = ns;
  }
  return globalNameSpace;
}
function getGlobalMap() {
  const ns = getGlobalNamespace();
  if (ns._tfGlobals == null) {
    ns._tfGlobals = /* @__PURE__ */ new Map();
  }
  return ns._tfGlobals;
}
function getGlobal(key, init) {
  const globalMap = getGlobalMap();
  if (globalMap.has(key)) {
    return globalMap.get(key);
  } else {
    const singleton = init();
    globalMap.set(key, singleton);
    return globalMap.get(key);
  }
}
var globalNameSpace;
var init_global_util = __esm({
  "node_modules/@tensorflow/tfjs-core/dist/global_util.js"() {
  }
});

// node_modules/@tensorflow/tfjs-core/dist/log.js
function warn(...msg) {
  if (!(env().getBool("IS_TEST") || env().getBool("PROD"))) {
    console.warn(...msg);
  }
}
function log(...msg) {
  if (!(env().getBool("IS_TEST") || env().getBool("PROD"))) {
    console.log(...msg);
  }
}
var init_log = __esm({
  "node_modules/@tensorflow/tfjs-core/dist/log.js"() {
    init_environment();
  }
});

// node_modules/@tensorflow/tfjs-core/dist/kernel_registry.js
function getKernel(kernelName, backendName) {
  const key = makeKey(kernelName, backendName);
  return kernelRegistry.get(key);
}
function getGradient(kernelName) {
  return gradRegistry.get(kernelName);
}
function getKernelsForBackend(backendName) {
  const it = kernelRegistry.entries();
  const result = [];
  while (true) {
    const {
      done,
      value
    } = it.next();
    if (done) {
      break;
    }
    const [key, config] = value;
    const [backend2] = key.split("_");
    if (backend2 === backendName) {
      result.push(config);
    }
  }
  return result;
}
function registerKernel(config) {
  const {
    kernelName,
    backendName
  } = config;
  const key = makeKey(kernelName, backendName);
  if (kernelRegistry.has(key)) {
    warn(`The kernel '${kernelName}' for backend '${backendName}' is already registered`);
  }
  kernelRegistry.set(key, config);
}
function registerGradient(config) {
  const {
    kernelName
  } = config;
  if (gradRegistry.has(kernelName)) {
    if (env().getBool("DEBUG")) {
      warn(`Overriding the gradient for '${kernelName}'`);
    }
  }
  gradRegistry.set(kernelName, config);
}
function unregisterKernel(kernelName, backendName) {
  const key = makeKey(kernelName, backendName);
  if (!kernelRegistry.has(key)) {
    throw new Error(`The kernel '${kernelName}' for backend '${backendName}' is not registered`);
  }
  kernelRegistry.delete(key);
}
function unregisterGradient(kernelName) {
  if (!gradRegistry.has(kernelName)) {
    throw new Error(`The gradient '${kernelName}' for backend is not registered`);
  }
  gradRegistry.delete(kernelName);
}
function copyRegisteredKernels(registeredBackendName, newBackendName) {
  const kernels = getKernelsForBackend(registeredBackendName);
  kernels.forEach((kernelConfig) => {
    const newKernelConfig = Object.assign({}, kernelConfig, {
      backendName: newBackendName
    });
    registerKernel(newKernelConfig);
  });
}
function makeKey(kernelName, backendName) {
  return `${backendName}_${kernelName}`;
}
var kernelRegistry, gradRegistry;
var init_kernel_registry = __esm({
  "node_modules/@tensorflow/tfjs-core/dist/kernel_registry.js"() {
    init_environment();
    init_global_util();
    init_log();
    kernelRegistry = getGlobal("kernelRegistry", () => /* @__PURE__ */ new Map());
    gradRegistry = getGlobal("gradRegistry", () => /* @__PURE__ */ new Map());
  }
});

// node_modules/@tensorflow/tfjs-core/dist/platforms/is_typed_array_browser.js
function isTypedArrayBrowser(a) {
  return a instanceof Float32Array || a instanceof Int32Array || a instanceof Uint8Array || a instanceof Uint8ClampedArray;
}
var init_is_typed_array_browser = __esm({
  "node_modules/@tensorflow/tfjs-core/dist/platforms/is_typed_array_browser.js"() {
  }
});

// node_modules/long/src/long.js
var require_long = __commonJS({
  "node_modules/long/src/long.js"(exports, module) {
    module.exports = Long2;
    var wasm = null;
    try {
      wasm = new WebAssembly.Instance(new WebAssembly.Module(new Uint8Array([0, 97, 115, 109, 1, 0, 0, 0, 1, 13, 2, 96, 0, 1, 127, 96, 4, 127, 127, 127, 127, 1, 127, 3, 7, 6, 0, 1, 1, 1, 1, 1, 6, 6, 1, 127, 1, 65, 0, 11, 7, 50, 6, 3, 109, 117, 108, 0, 1, 5, 100, 105, 118, 95, 115, 0, 2, 5, 100, 105, 118, 95, 117, 0, 3, 5, 114, 101, 109, 95, 115, 0, 4, 5, 114, 101, 109, 95, 117, 0, 5, 8, 103, 101, 116, 95, 104, 105, 103, 104, 0, 0, 10, 191, 1, 6, 4, 0, 35, 0, 11, 36, 1, 1, 126, 32, 0, 173, 32, 1, 173, 66, 32, 134, 132, 32, 2, 173, 32, 3, 173, 66, 32, 134, 132, 126, 34, 4, 66, 32, 135, 167, 36, 0, 32, 4, 167, 11, 36, 1, 1, 126, 32, 0, 173, 32, 1, 173, 66, 32, 134, 132, 32, 2, 173, 32, 3, 173, 66, 32, 134, 132, 127, 34, 4, 66, 32, 135, 167, 36, 0, 32, 4, 167, 11, 36, 1, 1, 126, 32, 0, 173, 32, 1, 173, 66, 32, 134, 132, 32, 2, 173, 32, 3, 173, 66, 32, 134, 132, 128, 34, 4, 66, 32, 135, 167, 36, 0, 32, 4, 167, 11, 36, 1, 1, 126, 32, 0, 173, 32, 1, 173, 66, 32, 134, 132, 32, 2, 173, 32, 3, 173, 66, 32, 134, 132, 129, 34, 4, 66, 32, 135, 167, 36, 0, 32, 4, 167, 11, 36, 1, 1, 126, 32, 0, 173, 32, 1, 173, 66, 32, 134, 132, 32, 2, 173, 32, 3, 173, 66, 32, 134, 132, 130, 34, 4, 66, 32, 135, 167, 36, 0, 32, 4, 167, 11])), {}).exports;
    } catch (e) {
    }
    function Long2(low, high, unsigned) {
      this.low = low | 0;
      this.high = high | 0;
      this.unsigned = !!unsigned;
    }
    Long2.prototype.__isLong__;
    Object.defineProperty(Long2.prototype, "__isLong__", {
      value: true
    });
    function isLong(obj) {
      return (obj && obj["__isLong__"]) === true;
    }
    Long2.isLong = isLong;
    var INT_CACHE = {};
    var UINT_CACHE = {};
    function fromInt(value, unsigned) {
      var obj, cachedObj, cache;
      if (unsigned) {
        value >>>= 0;
        if (cache = 0 <= value && value < 256) {
          cachedObj = UINT_CACHE[value];
          if (cachedObj) return cachedObj;
        }
        obj = fromBits(value, (value | 0) < 0 ? -1 : 0, true);
        if (cache) UINT_CACHE[value] = obj;
        return obj;
      } else {
        value |= 0;
        if (cache = -128 <= value && value < 128) {
          cachedObj = INT_CACHE[value];
          if (cachedObj) return cachedObj;
        }
        obj = fromBits(value, value < 0 ? -1 : 0, false);
        if (cache) INT_CACHE[value] = obj;
        return obj;
      }
    }
    Long2.fromInt = fromInt;
    function fromNumber(value, unsigned) {
      if (isNaN(value)) return unsigned ? UZERO : ZERO;
      if (unsigned) {
        if (value < 0) return UZERO;
        if (value >= TWO_PWR_64_DBL) return MAX_UNSIGNED_VALUE;
      } else {
        if (value <= -TWO_PWR_63_DBL) return MIN_VALUE;
        if (value + 1 >= TWO_PWR_63_DBL) return MAX_VALUE;
      }
      if (value < 0) return fromNumber(-value, unsigned).neg();
      return fromBits(value % TWO_PWR_32_DBL | 0, value / TWO_PWR_32_DBL | 0, unsigned);
    }
    Long2.fromNumber = fromNumber;
    function fromBits(lowBits, highBits, unsigned) {
      return new Long2(lowBits, highBits, unsigned);
    }
    Long2.fromBits = fromBits;
    var pow_dbl = Math.pow;
    function fromString(str, unsigned, radix) {
      if (str.length === 0) throw Error("empty string");
      if (str === "NaN" || str === "Infinity" || str === "+Infinity" || str === "-Infinity") return ZERO;
      if (typeof unsigned === "number") {
        radix = unsigned, unsigned = false;
      } else {
        unsigned = !!unsigned;
      }
      radix = radix || 10;
      if (radix < 2 || 36 < radix) throw RangeError("radix");
      var p;
      if ((p = str.indexOf("-")) > 0) throw Error("interior hyphen");
      else if (p === 0) {
        return fromString(str.substring(1), unsigned, radix).neg();
      }
      var radixToPower = fromNumber(pow_dbl(radix, 8));
      var result = ZERO;
      for (var i = 0; i < str.length; i += 8) {
        var size = Math.min(8, str.length - i), value = parseInt(str.substring(i, i + size), radix);
        if (size < 8) {
          var power = fromNumber(pow_dbl(radix, size));
          result = result.mul(power).add(fromNumber(value));
        } else {
          result = result.mul(radixToPower);
          result = result.add(fromNumber(value));
        }
      }
      result.unsigned = unsigned;
      return result;
    }
    Long2.fromString = fromString;
    function fromValue(val, unsigned) {
      if (typeof val === "number") return fromNumber(val, unsigned);
      if (typeof val === "string") return fromString(val, unsigned);
      return fromBits(val.low, val.high, typeof unsigned === "boolean" ? unsigned : val.unsigned);
    }
    Long2.fromValue = fromValue;
    var TWO_PWR_16_DBL = 1 << 16;
    var TWO_PWR_24_DBL = 1 << 24;
    var TWO_PWR_32_DBL = TWO_PWR_16_DBL * TWO_PWR_16_DBL;
    var TWO_PWR_64_DBL = TWO_PWR_32_DBL * TWO_PWR_32_DBL;
    var TWO_PWR_63_DBL = TWO_PWR_64_DBL / 2;
    var TWO_PWR_24 = fromInt(TWO_PWR_24_DBL);
    var ZERO = fromInt(0);
    Long2.ZERO = ZERO;
    var UZERO = fromInt(0, true);
    Long2.UZERO = UZERO;
    var ONE = fromInt(1);
    Long2.ONE = ONE;
    var UONE = fromInt(1, true);
    Long2.UONE = UONE;
    var NEG_ONE = fromInt(-1);
    Long2.NEG_ONE = NEG_ONE;
    var MAX_VALUE = fromBits(4294967295 | 0, 2147483647 | 0, false);
    Long2.MAX_VALUE = MAX_VALUE;
    var MAX_UNSIGNED_VALUE = fromBits(4294967295 | 0, 4294967295 | 0, true);
    Long2.MAX_UNSIGNED_VALUE = MAX_UNSIGNED_VALUE;
    var MIN_VALUE = fromBits(0, 2147483648 | 0, false);
    Long2.MIN_VALUE = MIN_VALUE;
    var LongPrototype = Long2.prototype;
    LongPrototype.toInt = function toInt() {
      return this.unsigned ? this.low >>> 0 : this.low;
    };
    LongPrototype.toNumber = function toNumber() {
      if (this.unsigned) return (this.high >>> 0) * TWO_PWR_32_DBL + (this.low >>> 0);
      return this.high * TWO_PWR_32_DBL + (this.low >>> 0);
    };
    LongPrototype.toString = function toString(radix) {
      radix = radix || 10;
      if (radix < 2 || 36 < radix) throw RangeError("radix");
      if (this.isZero()) return "0";
      if (this.isNegative()) {
        if (this.eq(MIN_VALUE)) {
          var radixLong = fromNumber(radix), div2 = this.div(radixLong), rem1 = div2.mul(radixLong).sub(this);
          return div2.toString(radix) + rem1.toInt().toString(radix);
        } else return "-" + this.neg().toString(radix);
      }
      var radixToPower = fromNumber(pow_dbl(radix, 6), this.unsigned), rem = this;
      var result = "";
      while (true) {
        var remDiv = rem.div(radixToPower), intval = rem.sub(remDiv.mul(radixToPower)).toInt() >>> 0, digits = intval.toString(radix);
        rem = remDiv;
        if (rem.isZero()) return digits + result;
        else {
          while (digits.length < 6) digits = "0" + digits;
          result = "" + digits + result;
        }
      }
    };
    LongPrototype.getHighBits = function getHighBits() {
      return this.high;
    };
    LongPrototype.getHighBitsUnsigned = function getHighBitsUnsigned() {
      return this.high >>> 0;
    };
    LongPrototype.getLowBits = function getLowBits() {
      return this.low;
    };
    LongPrototype.getLowBitsUnsigned = function getLowBitsUnsigned() {
      return this.low >>> 0;
    };
    LongPrototype.getNumBitsAbs = function getNumBitsAbs() {
      if (this.isNegative())
        return this.eq(MIN_VALUE) ? 64 : this.neg().getNumBitsAbs();
      var val = this.high != 0 ? this.high : this.low;
      for (var bit = 31; bit > 0; bit--) if ((val & 1 << bit) != 0) break;
      return this.high != 0 ? bit + 33 : bit + 1;
    };
    LongPrototype.isZero = function isZero() {
      return this.high === 0 && this.low === 0;
    };
    LongPrototype.eqz = LongPrototype.isZero;
    LongPrototype.isNegative = function isNegative() {
      return !this.unsigned && this.high < 0;
    };
    LongPrototype.isPositive = function isPositive() {
      return this.unsigned || this.high >= 0;
    };
    LongPrototype.isOdd = function isOdd() {
      return (this.low & 1) === 1;
    };
    LongPrototype.isEven = function isEven() {
      return (this.low & 1) === 0;
    };
    LongPrototype.equals = function equals(other) {
      if (!isLong(other)) other = fromValue(other);
      if (this.unsigned !== other.unsigned && this.high >>> 31 === 1 && other.high >>> 31 === 1) return false;
      return this.high === other.high && this.low === other.low;
    };
    LongPrototype.eq = LongPrototype.equals;
    LongPrototype.notEquals = function notEquals(other) {
      return !this.eq(
        /* validates */
        other
      );
    };
    LongPrototype.neq = LongPrototype.notEquals;
    LongPrototype.ne = LongPrototype.notEquals;
    LongPrototype.lessThan = function lessThan(other) {
      return this.comp(
        /* validates */
        other
      ) < 0;
    };
    LongPrototype.lt = LongPrototype.lessThan;
    LongPrototype.lessThanOrEqual = function lessThanOrEqual(other) {
      return this.comp(
        /* validates */
        other
      ) <= 0;
    };
    LongPrototype.lte = LongPrototype.lessThanOrEqual;
    LongPrototype.le = LongPrototype.lessThanOrEqual;
    LongPrototype.greaterThan = function greaterThan(other) {
      return this.comp(
        /* validates */
        other
      ) > 0;
    };
    LongPrototype.gt = LongPrototype.greaterThan;
    LongPrototype.greaterThanOrEqual = function greaterThanOrEqual(other) {
      return this.comp(
        /* validates */
        other
      ) >= 0;
    };
    LongPrototype.gte = LongPrototype.greaterThanOrEqual;
    LongPrototype.ge = LongPrototype.greaterThanOrEqual;
    LongPrototype.compare = function compare(other) {
      if (!isLong(other)) other = fromValue(other);
      if (this.eq(other)) return 0;
      var thisNeg = this.isNegative(), otherNeg = other.isNegative();
      if (thisNeg && !otherNeg) return -1;
      if (!thisNeg && otherNeg) return 1;
      if (!this.unsigned) return this.sub(other).isNegative() ? -1 : 1;
      return other.high >>> 0 > this.high >>> 0 || other.high === this.high && other.low >>> 0 > this.low >>> 0 ? -1 : 1;
    };
    LongPrototype.comp = LongPrototype.compare;
    LongPrototype.negate = function negate() {
      if (!this.unsigned && this.eq(MIN_VALUE)) return MIN_VALUE;
      return this.not().add(ONE);
    };
    LongPrototype.neg = LongPrototype.negate;
    LongPrototype.add = function add4(addend) {
      if (!isLong(addend)) addend = fromValue(addend);
      var a48 = this.high >>> 16;
      var a32 = this.high & 65535;
      var a16 = this.low >>> 16;
      var a00 = this.low & 65535;
      var b48 = addend.high >>> 16;
      var b32 = addend.high & 65535;
      var b16 = addend.low >>> 16;
      var b00 = addend.low & 65535;
      var c48 = 0, c32 = 0, c16 = 0, c00 = 0;
      c00 += a00 + b00;
      c16 += c00 >>> 16;
      c00 &= 65535;
      c16 += a16 + b16;
      c32 += c16 >>> 16;
      c16 &= 65535;
      c32 += a32 + b32;
      c48 += c32 >>> 16;
      c32 &= 65535;
      c48 += a48 + b48;
      c48 &= 65535;
      return fromBits(c16 << 16 | c00, c48 << 16 | c32, this.unsigned);
    };
    LongPrototype.subtract = function subtract(subtrahend) {
      if (!isLong(subtrahend)) subtrahend = fromValue(subtrahend);
      return this.add(subtrahend.neg());
    };
    LongPrototype.sub = LongPrototype.subtract;
    LongPrototype.multiply = function multiply2(multiplier) {
      if (this.isZero()) return ZERO;
      if (!isLong(multiplier)) multiplier = fromValue(multiplier);
      if (wasm) {
        var low = wasm.mul(this.low, this.high, multiplier.low, multiplier.high);
        return fromBits(low, wasm.get_high(), this.unsigned);
      }
      if (multiplier.isZero()) return ZERO;
      if (this.eq(MIN_VALUE)) return multiplier.isOdd() ? MIN_VALUE : ZERO;
      if (multiplier.eq(MIN_VALUE)) return this.isOdd() ? MIN_VALUE : ZERO;
      if (this.isNegative()) {
        if (multiplier.isNegative()) return this.neg().mul(multiplier.neg());
        else return this.neg().mul(multiplier).neg();
      } else if (multiplier.isNegative()) return this.mul(multiplier.neg()).neg();
      if (this.lt(TWO_PWR_24) && multiplier.lt(TWO_PWR_24)) return fromNumber(this.toNumber() * multiplier.toNumber(), this.unsigned);
      var a48 = this.high >>> 16;
      var a32 = this.high & 65535;
      var a16 = this.low >>> 16;
      var a00 = this.low & 65535;
      var b48 = multiplier.high >>> 16;
      var b32 = multiplier.high & 65535;
      var b16 = multiplier.low >>> 16;
      var b00 = multiplier.low & 65535;
      var c48 = 0, c32 = 0, c16 = 0, c00 = 0;
      c00 += a00 * b00;
      c16 += c00 >>> 16;
      c00 &= 65535;
      c16 += a16 * b00;
      c32 += c16 >>> 16;
      c16 &= 65535;
      c16 += a00 * b16;
      c32 += c16 >>> 16;
      c16 &= 65535;
      c32 += a32 * b00;
      c48 += c32 >>> 16;
      c32 &= 65535;
      c32 += a16 * b16;
      c48 += c32 >>> 16;
      c32 &= 65535;
      c32 += a00 * b32;
      c48 += c32 >>> 16;
      c32 &= 65535;
      c48 += a48 * b00 + a32 * b16 + a16 * b32 + a00 * b48;
      c48 &= 65535;
      return fromBits(c16 << 16 | c00, c48 << 16 | c32, this.unsigned);
    };
    LongPrototype.mul = LongPrototype.multiply;
    LongPrototype.divide = function divide(divisor) {
      if (!isLong(divisor)) divisor = fromValue(divisor);
      if (divisor.isZero()) throw Error("division by zero");
      if (wasm) {
        if (!this.unsigned && this.high === -2147483648 && divisor.low === -1 && divisor.high === -1) {
          return this;
        }
        var low = (this.unsigned ? wasm.div_u : wasm.div_s)(this.low, this.high, divisor.low, divisor.high);
        return fromBits(low, wasm.get_high(), this.unsigned);
      }
      if (this.isZero()) return this.unsigned ? UZERO : ZERO;
      var approx, rem, res;
      if (!this.unsigned) {
        if (this.eq(MIN_VALUE)) {
          if (divisor.eq(ONE) || divisor.eq(NEG_ONE)) return MIN_VALUE;
          else if (divisor.eq(MIN_VALUE)) return ONE;
          else {
            var halfThis = this.shr(1);
            approx = halfThis.div(divisor).shl(1);
            if (approx.eq(ZERO)) {
              return divisor.isNegative() ? ONE : NEG_ONE;
            } else {
              rem = this.sub(divisor.mul(approx));
              res = approx.add(rem.div(divisor));
              return res;
            }
          }
        } else if (divisor.eq(MIN_VALUE)) return this.unsigned ? UZERO : ZERO;
        if (this.isNegative()) {
          if (divisor.isNegative()) return this.neg().div(divisor.neg());
          return this.neg().div(divisor).neg();
        } else if (divisor.isNegative()) return this.div(divisor.neg()).neg();
        res = ZERO;
      } else {
        if (!divisor.unsigned) divisor = divisor.toUnsigned();
        if (divisor.gt(this)) return UZERO;
        if (divisor.gt(this.shru(1)))
          return UONE;
        res = UZERO;
      }
      rem = this;
      while (rem.gte(divisor)) {
        approx = Math.max(1, Math.floor(rem.toNumber() / divisor.toNumber()));
        var log22 = Math.ceil(Math.log(approx) / Math.LN2), delta = log22 <= 48 ? 1 : pow_dbl(2, log22 - 48), approxRes = fromNumber(approx), approxRem = approxRes.mul(divisor);
        while (approxRem.isNegative() || approxRem.gt(rem)) {
          approx -= delta;
          approxRes = fromNumber(approx, this.unsigned);
          approxRem = approxRes.mul(divisor);
        }
        if (approxRes.isZero()) approxRes = ONE;
        res = res.add(approxRes);
        rem = rem.sub(approxRem);
      }
      return res;
    };
    LongPrototype.div = LongPrototype.divide;
    LongPrototype.modulo = function modulo(divisor) {
      if (!isLong(divisor)) divisor = fromValue(divisor);
      if (wasm) {
        var low = (this.unsigned ? wasm.rem_u : wasm.rem_s)(this.low, this.high, divisor.low, divisor.high);
        return fromBits(low, wasm.get_high(), this.unsigned);
      }
      return this.sub(this.div(divisor).mul(divisor));
    };
    LongPrototype.mod = LongPrototype.modulo;
    LongPrototype.rem = LongPrototype.modulo;
    LongPrototype.not = function not() {
      return fromBits(~this.low, ~this.high, this.unsigned);
    };
    LongPrototype.and = function and(other) {
      if (!isLong(other)) other = fromValue(other);
      return fromBits(this.low & other.low, this.high & other.high, this.unsigned);
    };
    LongPrototype.or = function or(other) {
      if (!isLong(other)) other = fromValue(other);
      return fromBits(this.low | other.low, this.high | other.high, this.unsigned);
    };
    LongPrototype.xor = function xor(other) {
      if (!isLong(other)) other = fromValue(other);
      return fromBits(this.low ^ other.low, this.high ^ other.high, this.unsigned);
    };
    LongPrototype.shiftLeft = function shiftLeft(numBits) {
      if (isLong(numBits)) numBits = numBits.toInt();
      if ((numBits &= 63) === 0) return this;
      else if (numBits < 32) return fromBits(this.low << numBits, this.high << numBits | this.low >>> 32 - numBits, this.unsigned);
      else return fromBits(0, this.low << numBits - 32, this.unsigned);
    };
    LongPrototype.shl = LongPrototype.shiftLeft;
    LongPrototype.shiftRight = function shiftRight(numBits) {
      if (isLong(numBits)) numBits = numBits.toInt();
      if ((numBits &= 63) === 0) return this;
      else if (numBits < 32) return fromBits(this.low >>> numBits | this.high << 32 - numBits, this.high >> numBits, this.unsigned);
      else return fromBits(this.high >> numBits - 32, this.high >= 0 ? 0 : -1, this.unsigned);
    };
    LongPrototype.shr = LongPrototype.shiftRight;
    LongPrototype.shiftRightUnsigned = function shiftRightUnsigned(numBits) {
      if (isLong(numBits)) numBits = numBits.toInt();
      numBits &= 63;
      if (numBits === 0) return this;
      else {
        var high = this.high;
        if (numBits < 32) {
          var low = this.low;
          return fromBits(low >>> numBits | high << 32 - numBits, high >>> numBits, this.unsigned);
        } else if (numBits === 32) return fromBits(high, 0, this.unsigned);
        else return fromBits(high >>> numBits - 32, 0, this.unsigned);
      }
    };
    LongPrototype.shru = LongPrototype.shiftRightUnsigned;
    LongPrototype.shr_u = LongPrototype.shiftRightUnsigned;
    LongPrototype.toSigned = function toSigned() {
      if (!this.unsigned) return this;
      return fromBits(this.low, this.high, false);
    };
    LongPrototype.toUnsigned = function toUnsigned() {
      if (this.unsigned) return this;
      return fromBits(this.low, this.high, true);
    };
    LongPrototype.toBytes = function toBytes(le) {
      return le ? this.toBytesLE() : this.toBytesBE();
    };
    LongPrototype.toBytesLE = function toBytesLE() {
      var hi = this.high, lo = this.low;
      return [lo & 255, lo >>> 8 & 255, lo >>> 16 & 255, lo >>> 24, hi & 255, hi >>> 8 & 255, hi >>> 16 & 255, hi >>> 24];
    };
    LongPrototype.toBytesBE = function toBytesBE() {
      var hi = this.high, lo = this.low;
      return [hi >>> 24, hi >>> 16 & 255, hi >>> 8 & 255, hi & 255, lo >>> 24, lo >>> 16 & 255, lo >>> 8 & 255, lo & 255];
    };
    Long2.fromBytes = function fromBytes(bytes, unsigned, le) {
      return le ? Long2.fromBytesLE(bytes, unsigned) : Long2.fromBytesBE(bytes, unsigned);
    };
    Long2.fromBytesLE = function fromBytesLE(bytes, unsigned) {
      return new Long2(bytes[0] | bytes[1] << 8 | bytes[2] << 16 | bytes[3] << 24, bytes[4] | bytes[5] << 8 | bytes[6] << 16 | bytes[7] << 24, unsigned);
    };
    Long2.fromBytesBE = function fromBytesBE(bytes, unsigned) {
      return new Long2(bytes[4] << 24 | bytes[5] << 16 | bytes[6] << 8 | bytes[7], bytes[0] << 24 | bytes[1] << 16 | bytes[2] << 8 | bytes[3], unsigned);
    };
  }
});

// node_modules/@tensorflow/tfjs-core/dist/hash_util.js
function hexToLong(hex) {
  return Long.fromString(hex, true, 16);
}
function shiftMix(val) {
  return val.xor(val.shru(47));
}
function fetch2(s, offset, numBytes) {
  const bytes = s.slice(offset, offset + numBytes);
  return Long.fromBytes(Array.from(bytes), true, true);
}
function fetch64(s, offset) {
  return fetch2(s, offset, 8);
}
function fetch32(s, offset) {
  return fetch2(s, offset, 4);
}
function rotate64(val, shift) {
  return shift === 0 ? val : val.shru(shift).or(val.shl(64 - shift));
}
function hashLen16(u, v, mul2 = hexToLong("9ddfea08eb382d69")) {
  let a = u.xor(v).mul(mul2);
  a = a.xor(a.shru(47));
  let b = v.xor(a).mul(mul2);
  b = b.xor(b.shru(47));
  b = b.mul(mul2);
  return b;
}
function weakHashLen32WithSeeds(w, x, y, z, a, b) {
  a = a.add(w);
  b = rotate64(b.add(a).add(z), 21);
  const c = a;
  a = a.add(x);
  a = a.add(y);
  b = b.add(rotate64(a, 44));
  return [a.add(z), b.add(c)];
}
function weakHashLen32WithSeedsStr(s, offset, a, b) {
  return weakHashLen32WithSeeds(fetch64(s, offset), fetch64(s, offset + 8), fetch64(s, offset + 16), fetch64(s, offset + 24), a, b);
}
function hashLen0to16(s, len = s.length) {
  if (len >= 8) {
    const mul2 = k2.add(len * 2);
    const a = fetch64(s, 0).add(k2);
    const b = fetch64(s, len - 8);
    const c = rotate64(b, 37).mul(mul2).add(a);
    const d = rotate64(a, 25).add(b).mul(mul2);
    return hashLen16(c, d, mul2);
  }
  if (len >= 4) {
    const mul2 = k2.add(len * 2);
    const a = fetch32(s, 0);
    return hashLen16(a.shl(3).add(len), fetch32(s, len - 4), mul2);
  }
  if (len > 0) {
    const a = s[0];
    const b = s[len >> 1];
    const c = s[len - 1];
    const y = a + (b << 8);
    const z = len + (c << 2);
    return shiftMix(k2.mul(y).xor(k0.mul(z))).mul(k2);
  }
  return k2;
}
function hashLen17to32(s, len = s.length) {
  const mul2 = k2.add(len * 2);
  const a = fetch64(s, 0).mul(k1);
  const b = fetch64(s, 8);
  const c = fetch64(s, len - 8).mul(mul2);
  const d = fetch64(s, len - 16).mul(k2);
  return hashLen16(rotate64(a.add(b), 43).add(rotate64(c, 30)).add(d), a.add(rotate64(b.add(k2), 18)).add(c), mul2);
}
function hashLen33to64(s, len = s.length) {
  const mul2 = k2.add(len * 2);
  const a = fetch64(s, 0).mul(k2);
  const b = fetch64(s, 8);
  const c = fetch64(s, len - 8).mul(mul2);
  const d = fetch64(s, len - 16).mul(k2);
  const y = rotate64(a.add(b), 43).add(rotate64(c, 30)).add(d);
  const z = hashLen16(y, a.add(rotate64(b.add(k2), 18)).add(c), mul2);
  const e = fetch64(s, 16).mul(mul2);
  const f = fetch64(s, 24);
  const g = y.add(fetch64(s, len - 32)).mul(mul2);
  const h = z.add(fetch64(s, len - 24)).mul(mul2);
  return hashLen16(rotate64(e.add(f), 43).add(rotate64(g, 30)).add(h), e.add(rotate64(f.add(a), 18)).add(g), mul2);
}
function fingerPrint64(s, len = s.length) {
  const seed = Long.fromNumber(81, true);
  if (len <= 32) {
    if (len <= 16) {
      return hashLen0to16(s, len);
    } else {
      return hashLen17to32(s, len);
    }
  } else if (len <= 64) {
    return hashLen33to64(s, len);
  }
  let x = seed;
  let y = seed.mul(k1).add(113);
  let z = shiftMix(y.mul(k2).add(113)).mul(k2);
  let v = [Long.UZERO, Long.UZERO];
  let w = [Long.UZERO, Long.UZERO];
  x = x.mul(k2).add(fetch64(s, 0));
  let offset = 0;
  const end = (len - 1 >> 6) * 64;
  const last64 = end + (len - 1 & 63) - 63;
  do {
    x = rotate64(x.add(y).add(v[0]).add(fetch64(s, offset + 8)), 37).mul(k1);
    y = rotate64(y.add(v[1]).add(fetch64(s, offset + 48)), 42).mul(k1);
    x = x.xor(w[1]);
    y = y.add(v[0]).add(fetch64(s, offset + 40));
    z = rotate64(z.add(w[0]), 33).mul(k1);
    v = weakHashLen32WithSeedsStr(s, offset, v[1].mul(k1), x.add(w[0]));
    w = weakHashLen32WithSeedsStr(s, offset + 32, z.add(w[1]), y.add(fetch64(s, offset + 16)));
    [z, x] = [x, z];
    offset += 64;
  } while (offset !== end);
  const mul2 = k1.add(z.and(255).shl(1));
  offset = last64;
  w[0] = w[0].add(len - 1 & 63);
  v[0] = v[0].add(w[0]);
  w[0] = w[0].add(v[0]);
  x = rotate64(x.add(y).add(v[0]).add(fetch64(s, offset + 8)), 37).mul(mul2);
  y = rotate64(y.add(v[1]).add(fetch64(s, offset + 48)), 42).mul(mul2);
  x = x.xor(w[1].mul(9));
  y = y.add(v[0].mul(9).add(fetch64(s, offset + 40)));
  z = rotate64(z.add(w[0]), 33).mul(mul2);
  v = weakHashLen32WithSeedsStr(s, offset, v[1].mul(mul2), x.add(w[0]));
  w = weakHashLen32WithSeedsStr(s, offset + 32, z.add(w[1]), y.add(fetch64(s, offset + 16)));
  [z, x] = [x, z];
  return hashLen16(hashLen16(v[0], w[0], mul2).add(shiftMix(y).mul(k0)).add(z), hashLen16(v[1], w[1], mul2).add(x), mul2);
}
var LongExports, Long, k0, k1, k2;
var init_hash_util = __esm({
  "node_modules/@tensorflow/tfjs-core/dist/hash_util.js"() {
    LongExports = __toESM(require_long());
    Long = // tslint:disable-next-line
    LongExports.default || LongExports;
    k0 = hexToLong("c3a5c85c97cb3127");
    k1 = hexToLong("b492b66fbe98f273");
    k2 = hexToLong("9ae16a3b2f90404f");
  }
});

// node_modules/@tensorflow/tfjs-core/dist/util.js
var util_exports = {};
__export(util_exports, {
  arraysEqual: () => arraysEqual,
  arraysEqualWithNull: () => arraysEqualWithNull,
  assert: () => assert,
  assertNonNegativeIntegerDimensions: () => assertNonNegativeIntegerDimensions,
  assertNonNull: () => assertNonNull,
  assertShapesMatch: () => assertShapesMatch,
  bytesFromStringArray: () => bytesFromStringArray,
  bytesPerElement: () => bytesPerElement,
  checkConversionForErrors: () => checkConversionForErrors,
  clamp: () => clamp,
  computeStrides: () => computeStrides,
  convertBackendValuesAndArrayBuffer: () => convertBackendValuesAndArrayBuffer,
  createScalarValue: () => createScalarValue,
  createShuffledIndices: () => createShuffledIndices,
  decodeString: () => decodeString,
  distSquared: () => distSquared,
  encodeString: () => encodeString,
  fetch: () => fetch3,
  fingerPrint64: () => fingerPrint64,
  flatten: () => flatten,
  getArrayFromDType: () => getArrayFromDType,
  getTypedArrayFromDType: () => getTypedArrayFromDType,
  hasEncodingLoss: () => hasEncodingLoss,
  hexToLong: () => hexToLong,
  indexToLoc: () => indexToLoc,
  inferDtype: () => inferDtype,
  inferFromImplicitShape: () => inferFromImplicitShape,
  isBoolean: () => isBoolean,
  isFunction: () => isFunction,
  isInt: () => isInt,
  isNumber: () => isNumber,
  isPromise: () => isPromise,
  isScalarShape: () => isScalarShape,
  isString: () => isString,
  isTypedArray: () => isTypedArray,
  isValidDtype: () => isValidDtype,
  locToIndex: () => locToIndex,
  makeOnesTypedArray: () => makeOnesTypedArray,
  makeZerosNestedTypedArray: () => makeZerosNestedTypedArray,
  makeZerosTypedArray: () => makeZerosTypedArray,
  nearestDivisor: () => nearestDivisor,
  nearestLargerEven: () => nearestLargerEven,
  now: () => now,
  parseAxisParam: () => parseAxisParam,
  randUniform: () => randUniform,
  repeatedTry: () => repeatedTry,
  rightPad: () => rightPad,
  shuffle: () => shuffle,
  shuffleCombo: () => shuffleCombo,
  sizeFromShape: () => sizeFromShape,
  sizeToSquarishShape: () => sizeToSquarishShape,
  squeezeShape: () => squeezeShape,
  sum: () => sum,
  swap: () => swap,
  tanh: () => tanh,
  toNestedArray: () => toNestedArray,
  toTypedArray: () => toTypedArray
});
function createScalarValue(value, dtype) {
  if (dtype === "string") {
    return encodeString(value);
  }
  return toTypedArray([value], dtype);
}
function noConversionNeeded(a, dtype) {
  return a instanceof Float32Array && dtype === "float32" || a instanceof Int32Array && dtype === "int32" || a instanceof Uint8Array && dtype === "bool";
}
function toTypedArray(a, dtype) {
  if (dtype === "string") {
    throw new Error("Cannot convert a string[] to a TypedArray");
  }
  if (Array.isArray(a)) {
    a = flatten(a);
  }
  if (env().getBool("DEBUG")) {
    checkConversionForErrors(a, dtype);
  }
  if (noConversionNeeded(a, dtype)) {
    return a;
  }
  if (dtype == null || dtype === "float32" || dtype === "complex64") {
    return new Float32Array(a);
  } else if (dtype === "int32") {
    return new Int32Array(a);
  } else if (dtype === "bool") {
    const bool = new Uint8Array(a.length);
    for (let i = 0; i < bool.length; ++i) {
      if (Math.round(a[i]) !== 0) {
        bool[i] = 1;
      }
    }
    return bool;
  } else {
    throw new Error(`Unknown data type ${dtype}`);
  }
}
function now() {
  return env().platform.now();
}
function fetch3(path, requestInits) {
  return env().platform.fetch(path, requestInits);
}
function encodeString(s, encoding = "utf-8") {
  encoding = encoding || "utf-8";
  return env().platform.encode(s, encoding);
}
function decodeString(bytes, encoding = "utf-8") {
  encoding = encoding || "utf-8";
  return env().platform.decode(bytes, encoding);
}
function isTypedArray(a) {
  if (env().platform.isTypedArray != null) {
    return env().platform.isTypedArray(a);
  } else {
    return isTypedArrayBrowser(a);
  }
}
function flatten(arr, result = [], skipTypedArray = false) {
  if (result == null) {
    result = [];
  }
  if (typeof arr === "boolean" || typeof arr === "number" || typeof arr === "string" || isPromise(arr) || arr == null || isTypedArray(arr) && skipTypedArray) {
    result.push(arr);
  } else if (Array.isArray(arr) || isTypedArray(arr)) {
    for (let i = 0; i < arr.length; ++i) {
      flatten(arr[i], result, skipTypedArray);
    }
  } else {
    let maxIndex = -1;
    for (const key of Object.keys(arr)) {
      if (/^([1-9]+[0-9]*|0)$/.test(key)) {
        maxIndex = Math.max(maxIndex, Number(key));
      }
    }
    for (let i = 0; i <= maxIndex; i++) {
      flatten(arr[i], result, skipTypedArray);
    }
  }
  return result;
}
var init_util = __esm({
  "node_modules/@tensorflow/tfjs-core/dist/util.js"() {
    init_environment();
    init_is_typed_array_browser();
    init_util_base();
    init_util_base();
    init_hash_util();
  }
});

// node_modules/@tensorflow/tfjs-core/dist/tensor_format.js
function tensorToString(vals, shape, dtype, verbose) {
  const strides = computeStrides(shape);
  const padPerCol = computeMaxSizePerColumn(vals, shape, dtype, strides);
  const rank = shape.length;
  const valsLines = subTensorToString(vals, shape, dtype, strides, padPerCol);
  const lines = ["Tensor"];
  if (verbose) {
    lines.push(`  dtype: ${dtype}`);
    lines.push(`  rank: ${rank}`);
    lines.push(`  shape: [${shape}]`);
    lines.push(`  values:`);
  }
  lines.push(valsLines.map((l) => "    " + l).join("\n"));
  return lines.join("\n");
}
function computeMaxSizePerColumn(vals, shape, dtype, strides) {
  const n = sizeFromShape(shape);
  const numCols = strides[strides.length - 1];
  const padPerCol = new Array(numCols).fill(0);
  const rank = shape.length;
  const valuesOrTuples = dtype === "complex64" ? createComplexTuples(vals) : vals;
  if (rank > 1) {
    for (let row = 0; row < n / numCols; row++) {
      const offset = row * numCols;
      for (let j = 0; j < numCols; j++) {
        padPerCol[j] = Math.max(padPerCol[j], valToString(valuesOrTuples[offset + j], 0, dtype).length);
      }
    }
  }
  return padPerCol;
}
function valToString(val, pad2, dtype) {
  let valStr;
  if (Array.isArray(val)) {
    valStr = `${parseFloat(val[0].toFixed(FORMAT_NUM_SIG_DIGITS))} + ${parseFloat(val[1].toFixed(FORMAT_NUM_SIG_DIGITS))}j`;
  } else if (isString(val)) {
    valStr = `'${val}'`;
  } else if (dtype === "bool") {
    valStr = boolNumToString(val);
  } else {
    valStr = parseFloat(val.toFixed(FORMAT_NUM_SIG_DIGITS)).toString();
  }
  return rightPad(valStr, pad2);
}
function boolNumToString(v) {
  return v === 0 ? "false" : "true";
}
function subTensorToString(vals, shape, dtype, strides, padPerCol, isLast = true) {
  const storagePerElement = dtype === "complex64" ? 2 : 1;
  const size = shape[0];
  const rank = shape.length;
  if (rank === 0) {
    if (dtype === "complex64") {
      const complexTuple = createComplexTuples(vals);
      return [valToString(complexTuple[0], 0, dtype)];
    }
    if (dtype === "bool") {
      return [boolNumToString(vals[0])];
    }
    return [vals[0].toString()];
  }
  if (rank === 1) {
    if (size > FORMAT_LIMIT_NUM_VALS) {
      const firstValsSize = FORMAT_NUM_FIRST_LAST_VALS * storagePerElement;
      let firstVals = Array.from(vals.slice(0, firstValsSize));
      let lastVals = Array.from(vals.slice((size - FORMAT_NUM_FIRST_LAST_VALS) * storagePerElement, size * storagePerElement));
      if (dtype === "complex64") {
        firstVals = createComplexTuples(firstVals);
        lastVals = createComplexTuples(lastVals);
      }
      return ["[" + firstVals.map((x, i) => valToString(x, padPerCol[i], dtype)).join(", ") + ", ..., " + lastVals.map((x, i) => valToString(x, padPerCol[size - FORMAT_NUM_FIRST_LAST_VALS + i], dtype)).join(", ") + "]"];
    }
    const displayVals = dtype === "complex64" ? createComplexTuples(vals) : Array.from(vals);
    return ["[" + displayVals.map((x, i) => valToString(x, padPerCol[i], dtype)).join(", ") + "]"];
  }
  const subshape = shape.slice(1);
  const substrides = strides.slice(1);
  const stride = strides[0] * storagePerElement;
  const lines = [];
  if (size > FORMAT_LIMIT_NUM_VALS) {
    for (let i = 0; i < FORMAT_NUM_FIRST_LAST_VALS; i++) {
      const start = i * stride;
      const end = start + stride;
      lines.push(...subTensorToString(
        vals.slice(start, end),
        subshape,
        dtype,
        substrides,
        padPerCol,
        false
        /* isLast */
      ));
    }
    lines.push("...");
    for (let i = size - FORMAT_NUM_FIRST_LAST_VALS; i < size; i++) {
      const start = i * stride;
      const end = start + stride;
      lines.push(...subTensorToString(
        vals.slice(start, end),
        subshape,
        dtype,
        substrides,
        padPerCol,
        i === size - 1
        /* isLast */
      ));
    }
  } else {
    for (let i = 0; i < size; i++) {
      const start = i * stride;
      const end = start + stride;
      lines.push(...subTensorToString(
        vals.slice(start, end),
        subshape,
        dtype,
        substrides,
        padPerCol,
        i === size - 1
        /* isLast */
      ));
    }
  }
  const sep = rank === 2 ? "," : "";
  lines[0] = "[" + (size > 0 ? lines[0] + sep : "");
  for (let i = 1; i < lines.length - 1; i++) {
    lines[i] = " " + lines[i] + sep;
  }
  let newLineSep = ",\n";
  for (let i = 2; i < rank; i++) {
    newLineSep += "\n";
  }
  lines[lines.length - 1] = " " + lines[lines.length - 1] + "]" + (isLast ? "" : newLineSep);
  return lines;
}
function createComplexTuples(vals) {
  const complexTuples = [];
  for (let i = 0; i < vals.length; i += 2) {
    complexTuples.push([vals[i], vals[i + 1]]);
  }
  return complexTuples;
}
var FORMAT_LIMIT_NUM_VALS, FORMAT_NUM_FIRST_LAST_VALS, FORMAT_NUM_SIG_DIGITS;
var init_tensor_format = __esm({
  "node_modules/@tensorflow/tfjs-core/dist/tensor_format.js"() {
    init_util();
    FORMAT_LIMIT_NUM_VALS = 20;
    FORMAT_NUM_FIRST_LAST_VALS = 3;
    FORMAT_NUM_SIG_DIGITS = 7;
  }
});

// node_modules/@tensorflow/tfjs-core/dist/tensor.js
function setTensorTracker(fn) {
  trackerFn = fn;
}
function setOpHandler(handler) {
  opHandler = handler;
}
function setDeprecationWarningFn(fn) {
  deprecationWarningFn = fn;
}
function getGlobalTensorClass() {
  return getGlobal("Tensor", () => {
    return Tensor;
  });
}
var TensorBuffer, trackerFn, opHandler, deprecationWarningFn, Tensor, Variable;
var init_tensor = __esm({
  "node_modules/@tensorflow/tfjs-core/dist/tensor.js"() {
    init_global_util();
    init_tensor_format();
    init_util();
    init_util();
    TensorBuffer = class {
      constructor(shape, dtype, values) {
        this.dtype = dtype;
        this.shape = shape.slice();
        this.size = sizeFromShape(shape);
        if (values != null) {
          const n = values.length;
          assert(n === this.size, () => `Length of values '${n}' does not match the size inferred by the shape '${this.size}'.`);
        }
        if (dtype === "complex64") {
          throw new Error(`complex64 dtype TensorBuffers are not supported. Please create a TensorBuffer for the real and imaginary parts separately and call tf.complex(real, imag).`);
        }
        this.values = values || getArrayFromDType(dtype, this.size);
        this.strides = computeStrides(shape);
      }
      /**
       * Sets a value in the buffer at a given location.
       *
       * @param value The value to set.
       * @param locs  The location indices.
       *
       * @doc {heading: 'Tensors', subheading: 'Creation'}
       */
      set(value, ...locs) {
        if (locs.length === 0) {
          locs = [0];
        }
        assert(locs.length === this.rank, () => `The number of provided coordinates (${locs.length}) must match the rank (${this.rank})`);
        const index = this.locToIndex(locs);
        this.values[index] = value;
      }
      /**
       * Returns the value in the buffer at the provided location.
       *
       * @param locs The location indices.
       *
       * @doc {heading: 'Tensors', subheading: 'Creation'}
       */
      get(...locs) {
        if (locs.length === 0) {
          locs = [0];
        }
        let i = 0;
        for (const loc of locs) {
          if (loc < 0 || loc >= this.shape[i]) {
            const msg = `Requested out of range element at ${locs}.   Buffer shape=${this.shape}`;
            throw new Error(msg);
          }
          i++;
        }
        let index = locs[locs.length - 1];
        for (let i2 = 0; i2 < locs.length - 1; ++i2) {
          index += this.strides[i2] * locs[i2];
        }
        return this.values[index];
      }
      locToIndex(locs) {
        if (this.rank === 0) {
          return 0;
        } else if (this.rank === 1) {
          return locs[0];
        }
        let index = locs[locs.length - 1];
        for (let i = 0; i < locs.length - 1; ++i) {
          index += this.strides[i] * locs[i];
        }
        return index;
      }
      indexToLoc(index) {
        if (this.rank === 0) {
          return [];
        } else if (this.rank === 1) {
          return [index];
        }
        const locs = new Array(this.shape.length);
        for (let i = 0; i < locs.length - 1; ++i) {
          locs[i] = Math.floor(index / this.strides[i]);
          index -= locs[i] * this.strides[i];
        }
        locs[locs.length - 1] = index;
        return locs;
      }
      get rank() {
        return this.shape.length;
      }
      /**
       * Creates an immutable `tf.Tensor` object from the buffer.
       *
       * @doc {heading: 'Tensors', subheading: 'Creation'}
       */
      toTensor() {
        return trackerFn().makeTensor(this.values, this.shape, this.dtype);
      }
    };
    trackerFn = null;
    opHandler = null;
    deprecationWarningFn = null;
    Tensor = class {
      constructor(shape, dtype, dataId, id) {
        this.kept = false;
        this.isDisposedInternal = false;
        this.shape = shape.slice();
        this.dtype = dtype || "float32";
        this.size = sizeFromShape(shape);
        this.strides = computeStrides(shape);
        this.dataId = dataId;
        this.id = id;
        this.rankType = this.rank < 5 ? this.rank.toString() : "higher";
      }
      get rank() {
        return this.shape.length;
      }
      /**
       * Returns a promise of `tf.TensorBuffer` that holds the underlying data.
       *
       * @doc {heading: 'Tensors', subheading: 'Classes'}
       */
      buffer() {
        return __async(this, null, function* () {
          const vals = yield this.data();
          return opHandler.buffer(this.shape, this.dtype, vals);
        });
      }
      /**
       * Returns a `tf.TensorBuffer` that holds the underlying data.
       * @doc {heading: 'Tensors', subheading: 'Classes'}
       */
      bufferSync() {
        return opHandler.buffer(this.shape, this.dtype, this.dataSync());
      }
      /**
       * Returns the tensor data as a nested array. The transfer of data is done
       * asynchronously.
       *
       * @doc {heading: 'Tensors', subheading: 'Classes'}
       */
      array() {
        return __async(this, null, function* () {
          const vals = yield this.data();
          return toNestedArray(this.shape, vals, this.dtype === "complex64");
        });
      }
      /**
       * Returns the tensor data as a nested array. The transfer of data is done
       * synchronously.
       *
       * @doc {heading: 'Tensors', subheading: 'Classes'}
       */
      arraySync() {
        return toNestedArray(this.shape, this.dataSync(), this.dtype === "complex64");
      }
      /**
       * Asynchronously downloads the values from the `tf.Tensor`. Returns a
       * promise of `TypedArray` that resolves when the computation has finished.
       *
       * @doc {heading: 'Tensors', subheading: 'Classes'}
       */
      data() {
        return __async(this, null, function* () {
          this.throwIfDisposed();
          const data = trackerFn().read(this.dataId);
          if (this.dtype === "string") {
            const bytes = yield data;
            try {
              return bytes.map((b) => decodeString(b));
            } catch (_a) {
              throw new Error("Failed to decode the string bytes into utf-8. To get the original bytes, call tensor.bytes().");
            }
          }
          return data;
        });
      }
      /**
       * Copy the tensor's data to a new GPU resource. Comparing to the `dataSync()`
       * and `data()`, this method prevents data from being downloaded to CPU.
       *
       * For WebGL backend, the data will be stored on a densely packed texture.
       * This means that the texture will use the RGBA channels to store value.
       *
       * For WebGPU backend, the data will be stored on a buffer. There is no
       * parameter, so can not use a user-defined size to create the buffer.
       *
       * @param options:
       *     For WebGL,
       *         - customTexShape: Optional. If set, will use the user defined
       *     texture shape to create the texture.
       *
       * @returns For WebGL backend, a GPUData contains the new texture and
       *     its information.
       *     {
       *        tensorRef: The tensor that is associated with this texture,
       *        texture: WebGLTexture,
       *        texShape: [number, number] // [height, width]
       *     }
       *
       *     For WebGPU backend, a GPUData contains the new buffer.
       *     {
       *        tensorRef: The tensor that is associated with this buffer,
       *        buffer: GPUBuffer,
       *     }
       *
       *     Remember to dispose the GPUData after it is used by
       *     `res.tensorRef.dispose()`.
       *
       * @doc {heading: 'Tensors', subheading: 'Classes'}
       */
      dataToGPU(options) {
        this.throwIfDisposed();
        return trackerFn().readToGPU(this.dataId, options);
      }
      /**
       * Synchronously downloads the values from the `tf.Tensor`. This blocks the
       * UI thread until the values are ready, which can cause performance issues.
       *
       * @doc {heading: 'Tensors', subheading: 'Classes'}
       */
      dataSync() {
        this.throwIfDisposed();
        const data = trackerFn().readSync(this.dataId);
        if (this.dtype === "string") {
          try {
            return data.map((b) => decodeString(b));
          } catch (_a) {
            throw new Error("Failed to decode the string bytes into utf-8. To get the original bytes, call tensor.bytes().");
          }
        }
        return data;
      }
      /** Returns the underlying bytes of the tensor's data. */
      bytes() {
        return __async(this, null, function* () {
          this.throwIfDisposed();
          const data = yield trackerFn().read(this.dataId);
          if (this.dtype === "string") {
            return data;
          } else {
            return new Uint8Array(data.buffer);
          }
        });
      }
      /**
       * Disposes `tf.Tensor` from memory.
       *
       * @doc {heading: 'Tensors', subheading: 'Classes'}
       */
      dispose() {
        if (this.isDisposed) {
          return;
        }
        if (this.kerasMask) {
          this.kerasMask.dispose();
        }
        trackerFn().disposeTensor(this);
        this.isDisposedInternal = true;
      }
      get isDisposed() {
        return this.isDisposedInternal;
      }
      throwIfDisposed() {
        if (this.isDisposed) {
          throw new Error(`Tensor is disposed.`);
        }
      }
      /**
       * Prints the `tf.Tensor`. See `tf.print` for details.
       *
       * @param verbose Whether to print verbose information about the tensor,
       *    including dtype and size.
       *
       * @doc {heading: 'Tensors', subheading: 'Classes'}
       */
      print(verbose = false) {
        return opHandler.print(this, verbose);
      }
      /**
       * Returns a copy of the tensor. See `tf.clone` for details.
       * @doc {heading: 'Tensors', subheading: 'Classes'}
       */
      clone() {
        this.throwIfDisposed();
        return opHandler.clone(this);
      }
      /**
       * Returns a human-readable description of the tensor. Useful for logging.
       *
       * @doc {heading: 'Tensors', subheading: 'Classes'}
       */
      toString(verbose = false) {
        const vals = this.dataSync();
        return tensorToString(vals, this.shape, this.dtype, verbose);
      }
      cast(dtype) {
        this.throwIfDisposed();
        return opHandler.cast(this, dtype);
      }
      variable(trainable = true, name, dtype) {
        this.throwIfDisposed();
        return trackerFn().makeVariable(this, trainable, name, dtype);
      }
    };
    Object.defineProperty(Tensor, Symbol.hasInstance, {
      value: (instance) => {
        return !!instance && instance.data != null && instance.dataSync != null && instance.throwIfDisposed != null;
      }
    });
    getGlobalTensorClass();
    Variable = class extends Tensor {
      constructor(initialValue, trainable, name, tensorId) {
        super(initialValue.shape, initialValue.dtype, initialValue.dataId, tensorId);
        this.trainable = trainable;
        this.name = name;
      }
      /**
       * Assign a new `tf.Tensor` to this variable. The new `tf.Tensor` must have
       * the same shape and dtype as the old `tf.Tensor`.
       *
       * @param newValue New tensor to be assigned to this variable.
       *
       * @doc {heading: 'Tensors', subheading: 'Classes'}
       */
      assign(newValue) {
        if (newValue.dtype !== this.dtype) {
          throw new Error(`dtype of the new value (${newValue.dtype}) and previous value (${this.dtype}) must match`);
        }
        if (!arraysEqual(newValue.shape, this.shape)) {
          throw new Error(`shape of the new value (${newValue.shape}) and previous value (${this.shape}) must match`);
        }
        trackerFn().disposeTensor(this);
        this.dataId = newValue.dataId;
        trackerFn().incRef(
          this,
          null
          /* backend */
        );
      }
      dispose() {
        trackerFn().disposeVariable(this);
        this.isDisposedInternal = true;
      }
    };
    Object.defineProperty(Variable, Symbol.hasInstance, {
      value: (instance) => {
        return instance instanceof Tensor && instance.assign != null && instance.assign instanceof Function;
      }
    });
  }
});

// node_modules/@tensorflow/tfjs-core/dist/types.js
function upcastType(typeA, typeB) {
  if (typeA === "string" || typeB === "string") {
    if (typeA === "string" && typeB === "string") {
      return "string";
    }
    throw new Error(`Can not upcast ${typeA} with ${typeB}`);
  }
  return upcastTypeMap[typeA][typeB];
}
function sumOutType(type) {
  return upcastType(type, "int32");
}
function isWebGLData(values) {
  return values != null && typeof values === "object" && "texture" in values && values.texture instanceof WebGLTexture;
}
function isWebGPUData(values) {
  return typeof GPUBuffer !== "undefined" && values != null && typeof values === "object" && "buffer" in values && values.buffer instanceof GPUBuffer;
}
var Rank, UpcastInt32AndMap, UpcastBoolAndMap, UpcastFloat32AndMap, UpcastComplex64AndMap, upcastTypeMap;
var init_types = __esm({
  "node_modules/@tensorflow/tfjs-core/dist/types.js"() {
    (function(Rank2) {
      Rank2["R0"] = "R0";
      Rank2["R1"] = "R1";
      Rank2["R2"] = "R2";
      Rank2["R3"] = "R3";
      Rank2["R4"] = "R4";
      Rank2["R5"] = "R5";
      Rank2["R6"] = "R6";
    })(Rank || (Rank = {}));
    (function(UpcastInt32AndMap2) {
      UpcastInt32AndMap2["float32"] = "float32";
      UpcastInt32AndMap2["int32"] = "int32";
      UpcastInt32AndMap2["bool"] = "int32";
      UpcastInt32AndMap2["complex64"] = "complex64";
    })(UpcastInt32AndMap || (UpcastInt32AndMap = {}));
    (function(UpcastBoolAndMap2) {
      UpcastBoolAndMap2["float32"] = "float32";
      UpcastBoolAndMap2["int32"] = "int32";
      UpcastBoolAndMap2["bool"] = "bool";
      UpcastBoolAndMap2["complex64"] = "complex64";
    })(UpcastBoolAndMap || (UpcastBoolAndMap = {}));
    (function(UpcastFloat32AndMap2) {
      UpcastFloat32AndMap2["float32"] = "float32";
      UpcastFloat32AndMap2["int32"] = "float32";
      UpcastFloat32AndMap2["bool"] = "float32";
      UpcastFloat32AndMap2["complex64"] = "complex64";
    })(UpcastFloat32AndMap || (UpcastFloat32AndMap = {}));
    (function(UpcastComplex64AndMap2) {
      UpcastComplex64AndMap2["float32"] = "complex64";
      UpcastComplex64AndMap2["int32"] = "complex64";
      UpcastComplex64AndMap2["bool"] = "complex64";
      UpcastComplex64AndMap2["complex64"] = "complex64";
    })(UpcastComplex64AndMap || (UpcastComplex64AndMap = {}));
    upcastTypeMap = {
      "float32": UpcastFloat32AndMap,
      "int32": UpcastInt32AndMap,
      "bool": UpcastBoolAndMap,
      "complex64": UpcastComplex64AndMap
    };
  }
});

// node_modules/@tensorflow/tfjs-core/dist/tensor_util.js
var tensor_util_exports = {};
__export(tensor_util_exports, {
  assertTypesMatch: () => assertTypesMatch,
  getTensorsInContainer: () => getTensorsInContainer,
  isTensorInList: () => isTensorInList,
  makeTypesMatch: () => makeTypesMatch
});
function makeTypesMatch(a, b) {
  if (a.dtype === b.dtype) {
    return [a, b];
  }
  const dtype = upcastType(a.dtype, b.dtype);
  return [a.cast(dtype), b.cast(dtype)];
}
function assertTypesMatch(a, b) {
  assert(a.dtype === b.dtype, () => `The dtypes of the first(${a.dtype}) and second(${b.dtype}) input must match`);
}
function isTensorInList(tensor2, tensorList) {
  return tensorList.some((x) => x.id === tensor2.id);
}
function getTensorsInContainer(result) {
  const list = [];
  const seen = /* @__PURE__ */ new Set();
  walkTensorContainer(result, list, seen);
  return list;
}
function walkTensorContainer(container, list, seen) {
  if (container == null) {
    return;
  }
  if (container instanceof Tensor) {
    list.push(container);
    return;
  }
  if (!isIterable(container)) {
    return;
  }
  const iterable = container;
  for (const k in iterable) {
    const val = iterable[k];
    if (!seen.has(val)) {
      seen.add(val);
      walkTensorContainer(val, list, seen);
    }
  }
}
function isIterable(obj) {
  return Array.isArray(obj) || typeof obj === "object";
}
var init_tensor_util = __esm({
  "node_modules/@tensorflow/tfjs-core/dist/tensor_util.js"() {
    init_tensor();
    init_types();
    init_util();
  }
});

// node_modules/@tensorflow/tfjs-core/dist/device_util.js
var device_util_exports = {};
__export(device_util_exports, {
  isBrowser: () => isBrowser,
  isMobile: () => isMobile,
  mockIsMobile: () => mockIsMobile
});
function _isNavigatorDefined() {
  return typeof navigator !== "undefined" && navigator != null;
}
function mockIsMobile(value) {
  isMobileMockValue = value;
}
function isMobile(nav) {
  if (isMobileMockValue !== void 0) {
    return isMobileMockValue;
  }
  if (nav || _isNavigatorDefined()) {
    if (!nav) {
      nav = navigator;
    }
    if (nav.product === "ReactNative") {
      return true;
    }
    const a = nav.userAgent || nav.vendor || // tslint:disable-next-line:no-any
    (typeof window !== "undefined" ? window.opera : "");
    if (!a) {
      const navAny = nav;
      return navAny.userAgentData && navAny.userAgentData.mobile;
    }
    return /(android|bb\d+|meego).+mobile|avantgo|bada\/|blackberry|blazer|compal|elaine|fennec|hiptop|iemobile|ip(hone|od)|iris|kindle|lge |maemo|midp|mmp|mobile.+firefox|netfront|opera m(ob|in)i|palm( os)?|phone|p(ixi|re)\/|plucker|pocket|psp|series(4|6)0|symbian|treo|up\.(browser|link)|vodafone|wap|windows ce|xda|xiino/i.test(a) || // tslint:disable-next-line:max-line-length
    /1207|6310|6590|3gso|4thp|50[1-6]i|770s|802s|a wa|abac|ac(er|oo|s\-)|ai(ko|rn)|al(av|ca|co)|amoi|an(ex|ny|yw)|aptu|ar(ch|go)|as(te|us)|attw|au(di|\-m|r |s )|avan|be(ck|ll|nq)|bi(lb|rd)|bl(ac|az)|br(e|v)w|bumb|bw\-(n|u)|c55\/|capi|ccwa|cdm\-|cell|chtm|cldc|cmd\-|co(mp|nd)|craw|da(it|ll|ng)|dbte|dc\-s|devi|dica|dmob|do(c|p)o|ds(12|\-d)|el(49|ai)|em(l2|ul)|er(ic|k0)|esl8|ez([4-7]0|os|wa|ze)|fetc|fly(\-|_)|g1 u|g560|gene|gf\-5|g\-mo|go(\.w|od)|gr(ad|un)|haie|hcit|hd\-(m|p|t)|hei\-|hi(pt|ta)|hp( i|ip)|hs\-c|ht(c(\-| |_|a|g|p|s|t)|tp)|hu(aw|tc)|i\-(20|go|ma)|i230|iac( |\-|\/)|ibro|idea|ig01|ikom|im1k|inno|ipaq|iris|ja(t|v)a|jbro|jemu|jigs|kddi|keji|kgt( |\/)|klon|kpt |kwc\-|kyo(c|k)|le(no|xi)|lg( g|\/(k|l|u)|50|54|\-[a-w])|libw|lynx|m1\-w|m3ga|m50\/|ma(te|ui|xo)|mc(01|21|ca)|m\-cr|me(rc|ri)|mi(o8|oa|ts)|mmef|mo(01|02|bi|de|do|t(\-| |o|v)|zz)|mt(50|p1|v )|mwbp|mywa|n10[0-2]|n20[2-3]|n30(0|2)|n50(0|2|5)|n7(0(0|1)|10)|ne((c|m)\-|on|tf|wf|wg|wt)|nok(6|i)|nzph|o2im|op(ti|wv)|oran|owg1|p800|pan(a|d|t)|pdxg|pg(13|\-([1-8]|c))|phil|pire|pl(ay|uc)|pn\-2|po(ck|rt|se)|prox|psio|pt\-g|qa\-a|qc(07|12|21|32|60|\-[2-7]|i\-)|qtek|r380|r600|raks|rim9|ro(ve|zo)|s55\/|sa(ge|ma|mm|ms|ny|va)|sc(01|h\-|oo|p\-)|sdk\/|se(c(\-|0|1)|47|mc|nd|ri)|sgh\-|shar|sie(\-|m)|sk\-0|sl(45|id)|sm(al|ar|b3|it|t5)|so(ft|ny)|sp(01|h\-|v\-|v )|sy(01|mb)|t2(18|50)|t6(00|10|18)|ta(gt|lk)|tcl\-|tdg\-|tel(i|m)|tim\-|t\-mo|to(pl|sh)|ts(70|m\-|m3|m5)|tx\-9|up(\.b|g1|si)|utst|v400|v750|veri|vi(rg|te)|vk(40|5[0-3]|\-v)|vm40|voda|vulc|vx(52|53|60|61|70|80|81|83|85|98)|w3c(\-| )|webc|whit|wi(g |nc|nw)|wmlb|wonu|x700|yas\-|your|zeto|zte\-/i.test(a.substr(0, 4));
  }
  return false;
}
function isBrowser() {
  return typeof window !== "undefined" && window.document != null || //@ts-ignore
  typeof WorkerGlobalScope !== "undefined";
}
var isMobileMockValue;
var init_device_util = __esm({
  "node_modules/@tensorflow/tfjs-core/dist/device_util.js"() {
  }
});

// node_modules/@tensorflow/tfjs-core/dist/profiler.js
function checkComputationForErrors(vals, dtype, kernelName) {
  if (dtype !== "float32") {
    return false;
  }
  for (let i = 0; i < vals.length; i++) {
    const num = vals[i];
    if (isNaN(num) || !isFinite(num)) {
      console.warn(`Found ${num} in the result of '${kernelName}'`);
      return true;
    }
  }
  return false;
}
var Profiler, Logger;
var init_profiler = __esm({
  "node_modules/@tensorflow/tfjs-core/dist/profiler.js"() {
    init_environment();
    init_util();
    Profiler = class {
      constructor(backendTimer, logger) {
        this.backendTimer = backendTimer;
        this.logger = logger;
        if (logger == null) {
          this.logger = new Logger();
        }
      }
      profileKernel(kernelName, inputs, f) {
        let outputs;
        const holdResultWrapperFn = () => {
          outputs = f();
        };
        let timer;
        const start = now();
        if (this.backendTimer.timerAvailable()) {
          timer = this.backendTimer.time(holdResultWrapperFn);
        } else {
          holdResultWrapperFn();
          for (const output of outputs) {
            output.dataSync();
          }
          timer = Promise.resolve({
            kernelMs: now() - start
          });
        }
        if (env().getBool("CHECK_COMPUTATION_FOR_ERRORS")) {
          for (let i = 0; i < outputs.length; i++) {
            const output = outputs[i];
            output.data().then((tensorVals) => {
              checkComputationForErrors(tensorVals, output.dtype, kernelName);
            });
          }
        }
        const kernelProfile = {
          kernelName,
          outputs,
          inputs,
          timeMs: timer.then((timing) => timing.kernelMs),
          extraInfo: timer.then((timing) => timing.getExtraProfileInfo != null ? timing.getExtraProfileInfo() : "")
        };
        return kernelProfile;
      }
      logKernelProfile(kernelProfile) {
        const {
          kernelName,
          outputs,
          timeMs,
          inputs,
          extraInfo
        } = kernelProfile;
        outputs.forEach((result) => {
          Promise.all([result.data(), timeMs, extraInfo]).then((valueContainer) => {
            this.logger.logKernelProfile(kernelName, result, valueContainer[0], valueContainer[1], inputs, valueContainer[2]);
          });
        });
      }
    };
    Logger = class {
      logKernelProfile(name, result, vals, timeMs, inputs, extraInfo) {
        const time2 = typeof timeMs === "number" ? rightPad(`${timeMs}ms`, 9) : timeMs["error"];
        const paddedName = rightPad(name, 25);
        const rank = result.rank;
        const size = result.size;
        const shape = rightPad(result.shape.toString(), 14);
        let inputShapesDescription = "";
        for (const name2 in inputs) {
          const input = inputs[name2];
          if (input != null) {
            const inputShape = input.shape || result.shape;
            const inputRank = inputShape.length;
            inputShapesDescription += `${name2}: ${inputRank}D ${inputRank > 0 ? inputShape : ""} `;
          }
        }
        console.log(`%c${paddedName}	%c${time2}	%c${rank}D ${shape}	%c${size}	%c${inputShapesDescription}	%c${extraInfo}`, "font-weight:bold", "color:red", "color:blue", "color: orange", "color: green", "color: steelblue");
      }
    };
  }
});

// node_modules/@tensorflow/tfjs-core/dist/tape.js
function getFilteredNodesXToY(tape, xs, y) {
  const tensorsFromX = {};
  const nodesFromX = {};
  for (let i = 0; i < xs.length; i++) {
    tensorsFromX[xs[i].id] = true;
  }
  for (let i = 0; i < tape.length; i++) {
    const node = tape[i];
    const nodeInputs = node.inputs;
    for (const inputName in nodeInputs) {
      const input = nodeInputs[inputName];
      let anyInputFromX = false;
      for (let j = 0; j < xs.length; j++) {
        if (tensorsFromX[input.id]) {
          node.outputs.forEach((output) => tensorsFromX[output.id] = true);
          anyInputFromX = true;
          nodesFromX[node.id] = true;
          break;
        }
      }
      if (anyInputFromX) {
        break;
      }
    }
  }
  const tensorsLeadToY = {};
  tensorsLeadToY[y.id] = true;
  const nodesToY = {};
  for (let i = tape.length - 1; i >= 0; i--) {
    const node = tape[i];
    const nodeInputs = node.inputs;
    for (let j = 0; j < node.outputs.length; j++) {
      if (tensorsLeadToY[node.outputs[j].id]) {
        for (const inputName in nodeInputs) {
          tensorsLeadToY[nodeInputs[inputName].id] = true;
          nodesToY[node.id] = true;
        }
        break;
      }
    }
  }
  const filteredTape = [];
  for (let i = 0; i < tape.length; i++) {
    const node = tape[i];
    if (nodesFromX[node.id] && nodesToY[node.id]) {
      const prunedInputs = {};
      for (const inputName in node.inputs) {
        const nodeInput = node.inputs[inputName];
        if (tensorsFromX[nodeInput.id]) {
          prunedInputs[inputName] = nodeInput;
        }
      }
      const prunedNode = Object.assign({}, node);
      prunedNode.inputs = prunedInputs;
      prunedNode.outputs = node.outputs;
      filteredTape.push(prunedNode);
    }
  }
  return filteredTape;
}
function backpropagateGradients(tensorAccumulatedGradientMap, filteredTape, tidy2, add4) {
  for (let i = filteredTape.length - 1; i >= 0; i--) {
    const node = filteredTape[i];
    const dys = [];
    node.outputs.forEach((o) => {
      const gradTensor = tensorAccumulatedGradientMap[o.id];
      if (gradTensor != null) {
        dys.push(gradTensor);
      } else {
        dys.push(null);
      }
    });
    if (node.gradient == null) {
      throw new Error(`Cannot compute gradient: gradient function not found for ${node.kernelName}.`);
    }
    const inputGradients = node.gradient(dys);
    for (const inputName in node.inputs) {
      if (!(inputName in inputGradients)) {
        throw new Error(`Cannot backprop through input ${inputName}. Available gradients found: ${Object.keys(inputGradients)}.`);
      }
      const dx = tidy2(() => inputGradients[inputName]());
      if (dx.dtype !== "float32") {
        throw new Error(`Error in gradient for op ${node.kernelName}. The gradient of input ${inputName} must have 'float32' dtype, but has '${dx.dtype}'`);
      }
      const x = node.inputs[inputName];
      if (!arraysEqual(dx.shape, x.shape)) {
        throw new Error(`Error in gradient for op ${node.kernelName}. The gradient of input '${inputName}' has shape '${dx.shape}', which does not match the shape of the input '${x.shape}'`);
      }
      if (tensorAccumulatedGradientMap[x.id] == null) {
        tensorAccumulatedGradientMap[x.id] = dx;
      } else {
        const curGradient = tensorAccumulatedGradientMap[x.id];
        tensorAccumulatedGradientMap[x.id] = add4(curGradient, dx);
        curGradient.dispose();
      }
    }
  }
}
var init_tape = __esm({
  "node_modules/@tensorflow/tfjs-core/dist/tape.js"() {
    init_util();
  }
});

// node_modules/@tensorflow/tfjs-core/dist/engine.js
function isRegisteredKernelInvocation(kernelInvocation) {
  return kernelInvocation.kernelName != null;
}
function ones(shape) {
  const values = makeOnesTypedArray(sizeFromShape(shape), "float32");
  return ENGINE.makeTensor(values, shape, "float32");
}
function getOrMakeEngine() {
  const ns = getGlobalNamespace();
  if (ns._tfengine == null) {
    const environment = new Environment(ns);
    ns._tfengine = new Engine(environment);
  }
  setEnvironmentGlobal(ns._tfengine.ENV);
  setTensorTracker(() => ns._tfengine);
  return ns._tfengine;
}
function add(a, b) {
  const inputs = {
    a,
    b
  };
  return ENGINE.runKernel(Add, inputs);
}
var EngineState, Engine, ENGINE;
var init_engine = __esm({
  "node_modules/@tensorflow/tfjs-core/dist/engine.js"() {
    init_backend();
    init_environment();
    init_global_util();
    init_kernel_names();
    init_kernel_registry();
    init_log();
    init_profiler();
    init_tape();
    init_tensor();
    init_tensor_util();
    init_util();
    init_util();
    EngineState = class {
      constructor() {
        this.registeredVariables = {};
        this.nextTapeNodeId = 0;
        this.numBytes = 0;
        this.numTensors = 0;
        this.numStringTensors = 0;
        this.numDataBuffers = 0;
        this.gradientDepth = 0;
        this.kernelDepth = 0;
        this.scopeStack = [];
        this.numDataMovesStack = [];
        this.nextScopeId = 0;
        this.tensorInfo = /* @__PURE__ */ new WeakMap();
        this.profiling = false;
        this.activeProfile = {
          newBytes: 0,
          newTensors: 0,
          peakBytes: 0,
          kernels: [],
          result: null,
          get kernelNames() {
            return Array.from(new Set(this.kernels.map((k) => k.name)));
          }
        };
      }
      dispose() {
        for (const variableName in this.registeredVariables) {
          this.registeredVariables[variableName].dispose();
        }
      }
    };
    Engine = class _Engine {
      constructor(ENV3) {
        this.ENV = ENV3;
        this.registry = {};
        this.registryFactory = {};
        this.pendingBackendInitId = 0;
        this.state = new EngineState();
      }
      ready() {
        return __async(this, null, function* () {
          if (this.pendingBackendInit != null) {
            return this.pendingBackendInit.then(() => {
            });
          }
          if (this.backendInstance != null) {
            return;
          }
          const sortedBackends = this.getSortedBackends();
          for (let i = 0; i < sortedBackends.length; i++) {
            const backendName = sortedBackends[i];
            const success = yield this.initializeBackend(backendName).success;
            if (success) {
              yield this.setBackend(backendName);
              return;
            }
          }
          throw new Error(`Could not initialize any backends, all backend initializations failed.`);
        });
      }
      get backend() {
        if (this.pendingBackendInit != null) {
          throw new Error(`Backend '${this.backendName}' has not yet been initialized. Make sure to await tf.ready() or await tf.setBackend() before calling other methods`);
        }
        if (this.backendInstance == null) {
          const {
            name,
            asyncInit
          } = this.initializeBackendsAndReturnBest();
          if (asyncInit) {
            throw new Error(`The highest priority backend '${name}' has not yet been initialized. Make sure to await tf.ready() or await tf.setBackend() before calling other methods`);
          }
          this.setBackend(name);
        }
        return this.backendInstance;
      }
      backendNames() {
        return Object.keys(this.registryFactory);
      }
      findBackend(backendName) {
        if (!(backendName in this.registry)) {
          if (backendName in this.registryFactory) {
            const {
              asyncInit
            } = this.initializeBackend(backendName);
            if (asyncInit) {
              return null;
            }
          } else {
            return null;
          }
        }
        return this.registry[backendName];
      }
      findBackendFactory(backendName) {
        if (!(backendName in this.registryFactory)) {
          return null;
        }
        return this.registryFactory[backendName].factory;
      }
      registerBackend(backendName, factory, priority = 1) {
        if (backendName in this.registryFactory) {
          warn(`${backendName} backend was already registered. Reusing existing backend factory.`);
          return false;
        }
        this.registryFactory[backendName] = {
          factory,
          priority
        };
        return true;
      }
      setBackend(backendName) {
        return __async(this, null, function* () {
          if (this.registryFactory[backendName] == null) {
            throw new Error(`Backend name '${backendName}' not found in registry`);
          }
          this.backendName = backendName;
          if (this.registry[backendName] == null) {
            this.backendInstance = null;
            const {
              success,
              asyncInit
            } = this.initializeBackend(backendName);
            const result = asyncInit ? yield success : success;
            if (!result) {
              return false;
            }
          }
          this.backendInstance = this.registry[backendName];
          this.setupRegisteredKernels();
          this.profiler = new Profiler(this.backendInstance);
          return true;
        });
      }
      setupRegisteredKernels() {
        const kernels = getKernelsForBackend(this.backendName);
        kernels.forEach((kernel) => {
          if (kernel.setupFunc != null) {
            kernel.setupFunc(this.backendInstance);
          }
        });
      }
      disposeRegisteredKernels(backendName) {
        const kernels = getKernelsForBackend(backendName);
        kernels.forEach((kernel) => {
          if (kernel.disposeFunc != null) {
            kernel.disposeFunc(this.registry[backendName]);
          }
        });
      }
      /**
       * Initializes a backend by looking up the backend name in the factory
       * registry and calling the factory method. Returns a boolean representing
       * whether the initialization of the backend succeeded. Throws an error if
       * there is no backend in the factory registry.
       */
      initializeBackend(backendName) {
        const registryFactoryEntry = this.registryFactory[backendName];
        if (registryFactoryEntry == null) {
          throw new Error(`Cannot initialize backend ${backendName}, no registration found.`);
        }
        try {
          const backend2 = registryFactoryEntry.factory();
          if (backend2 && !(backend2 instanceof KernelBackend) && typeof backend2.then === "function") {
            const promiseId = ++this.pendingBackendInitId;
            const success = backend2.then((backendInstance) => {
              if (promiseId < this.pendingBackendInitId) {
                return false;
              }
              this.registry[backendName] = backendInstance;
              this.pendingBackendInit = null;
              return true;
            }).catch((err) => {
              if (promiseId < this.pendingBackendInitId) {
                return false;
              }
              this.pendingBackendInit = null;
              warn(`Initialization of backend ${backendName} failed`);
              warn(err.stack || err.message);
              return false;
            });
            this.pendingBackendInit = success;
            return {
              success,
              asyncInit: true
            };
          } else {
            this.registry[backendName] = backend2;
            return {
              success: true,
              asyncInit: false
            };
          }
        } catch (err) {
          warn(`Initialization of backend ${backendName} failed`);
          warn(err.stack || err.message);
          return {
            success: false,
            asyncInit: false
          };
        }
      }
      removeBackend(backendName) {
        if (!(backendName in this.registryFactory)) {
          throw new Error(`${backendName} backend not found in registry`);
        }
        if (this.backendName === backendName && this.pendingBackendInit != null) {
          this.pendingBackendInitId++;
        }
        if (backendName in this.registry) {
          this.disposeRegisteredKernels(backendName);
          this.registry[backendName].dispose();
          delete this.registry[backendName];
        }
        delete this.registryFactory[backendName];
        if (this.backendName === backendName) {
          this.pendingBackendInit = null;
          this.backendName = null;
          this.backendInstance = null;
        }
      }
      getSortedBackends() {
        if (Object.keys(this.registryFactory).length === 0) {
          throw new Error("No backend found in registry.");
        }
        return Object.keys(this.registryFactory).sort((a, b) => {
          return this.registryFactory[b].priority - this.registryFactory[a].priority;
        });
      }
      initializeBackendsAndReturnBest() {
        const sortedBackends = this.getSortedBackends();
        for (let i = 0; i < sortedBackends.length; i++) {
          const backendName = sortedBackends[i];
          const {
            success,
            asyncInit
          } = this.initializeBackend(backendName);
          if (asyncInit || success) {
            return {
              name: backendName,
              asyncInit
            };
          }
        }
        throw new Error(`Could not initialize any backends, all backend initializations failed.`);
      }
      moveData(backend2, dataId) {
        const info = this.state.tensorInfo.get(dataId);
        const srcBackend = info.backend;
        const values = this.readSync(dataId);
        const refCount = srcBackend.refCount(dataId);
        srcBackend.disposeData(dataId, true);
        info.backend = backend2;
        backend2.move(dataId, values, info.shape, info.dtype, refCount);
        if (this.shouldCheckForMemLeaks()) {
          this.state.numDataMovesStack[this.state.numDataMovesStack.length - 1]++;
        }
      }
      tidy(nameOrFn, fn) {
        let name = null;
        if (fn == null) {
          if (typeof nameOrFn !== "function") {
            throw new Error("Please provide a function to tidy()");
          }
          fn = nameOrFn;
        } else {
          if (typeof nameOrFn !== "string" && !(nameOrFn instanceof String)) {
            throw new Error("When calling with two arguments, the first argument to tidy() must be a string");
          }
          if (typeof fn !== "function") {
            throw new Error("When calling with two arguments, the 2nd argument to tidy() must be a function");
          }
          name = nameOrFn;
        }
        let result;
        return this.scopedRun(() => this.startScope(name), () => this.endScope(result), () => {
          result = fn();
          if (result instanceof Promise) {
            console.error("Cannot return a Promise inside of tidy.");
          }
          return result;
        });
      }
      scopedRun(start, end, f) {
        start();
        try {
          const res = f();
          end();
          return res;
        } catch (ex) {
          end();
          throw ex;
        }
      }
      nextTensorId() {
        return _Engine.nextTensorId++;
      }
      nextVariableId() {
        return _Engine.nextVariableId++;
      }
      /**
       * This method is called instead of the public-facing tensor.clone() when
       * saving a tensor for backwards pass. It makes sure to add the clone
       * operation to the tape regardless of being called inside a kernel
       * execution.
       */
      clone(x) {
        const y = ENGINE.runKernel(Identity, {
          x
        });
        const inputs = {
          x
        };
        const grad2 = (dy) => ({
          x: () => {
            const dtype = "float32";
            const gradInputs = {
              x: dy
            };
            const attrs = {
              dtype
            };
            return ENGINE.runKernel(
              Cast,
              gradInputs,
              // tslint:disable-next-line: no-unnecessary-type-assertion
              attrs
            );
          }
        });
        const saved = [];
        this.addTapeNode(this.state.activeScope.name, inputs, [y], grad2, saved, {});
        return y;
      }
      /**
       * Execute a kernel with the given name and return the output tensor.
       *
       * @param kernelName The name of the kernel to execute.
       * @param inputs A map of input names to tensors.
       * @param attrs A map of attribute names to their values. An attribute is a
       *     primitive (non-tensor) input to the kernel.
       * @param inputsToSave A list of tensors, inputs to save for the backprop
       *     computation.
       * @param outputsToSave A list of booleans, specifying which output to save
       *     for the backprop computation. These are booleans since the output
       * tensors are not visible to the user.
       */
      runKernel(kernelName, inputs, attrs) {
        if (this.backendName == null) {
          this.backend;
        }
        const hasKernel = getKernel(kernelName, this.backendName) != null;
        if (!hasKernel) {
          throw new Error(`Kernel '${kernelName}' not registered for backend '${this.backendName}'`);
        }
        return this.runKernelFunc({
          kernelName,
          inputs,
          attrs
        });
      }
      shouldCheckForMemLeaks() {
        return this.ENV.getBool("IS_TEST");
      }
      checkKernelForMemLeak(kernelName, numDataIdsBefore, outInfos) {
        const numDataIdsAfter = this.backend.numDataIds();
        let numOutputDataIds = 0;
        outInfos.forEach((info) => {
          numOutputDataIds += info.dtype === "complex64" ? 3 : 1;
        });
        const numMoves = this.state.numDataMovesStack[this.state.numDataMovesStack.length - 1];
        const dataIdsLeaked = numDataIdsAfter - numDataIdsBefore - numOutputDataIds - numMoves;
        if (dataIdsLeaked > 0) {
          throw new Error(`Backend '${this.backendName}' has an internal memory leak (${dataIdsLeaked} data ids) after running '${kernelName}'`);
        }
      }
      /**
       * Internal helper method to execute a kernel Func
       *
       * Use `runKernel` to execute kernels from outside of engine.
       */
      runKernelFunc(kernelParams) {
        let outputs;
        let saved = [];
        const isTapeOn = this.isTapeOn();
        const startingBytecount = this.state.numBytes;
        const startingNumTensors = this.state.numTensors;
        if (this.shouldCheckForMemLeaks()) {
          this.state.numDataMovesStack.push(0);
        }
        let kernelFunc;
        if (this.backendName == null) {
          this.backend;
        }
        let out;
        const kernelOrScopeName = isRegisteredKernelInvocation(kernelParams) ? kernelParams.kernelName : this.state.activeScope != null ? this.state.activeScope.name : "";
        if (isRegisteredKernelInvocation(kernelParams)) {
          const {
            kernelName,
            inputs: inputs2,
            attrs: attrs2
          } = kernelParams;
          if (this.backendName == null) {
            this.backend;
          }
          const kernel = getKernel(kernelName, this.backendName);
          assert(kernel != null, () => `Cannot find registered kernel '${kernelName}' for backend '${this.backendName}'`);
          kernelFunc = () => {
            const numDataIdsBefore = this.backend.numDataIds();
            out = kernel.kernelFunc({
              inputs: inputs2,
              attrs: attrs2,
              backend: this.backend
            });
            const outInfos = Array.isArray(out) ? out : [out];
            if (this.shouldCheckForMemLeaks()) {
              this.checkKernelForMemLeak(kernelName, numDataIdsBefore, outInfos);
            }
            const outTensors = outInfos.map((outInfo) => {
              if (outInfo.rank != null) {
                return outInfo;
              }
              return this.makeTensorFromTensorInfo(outInfo);
            });
            if (isTapeOn) {
              const tensorsToSave = this.getTensorsForGradient(kernelName, inputs2, outTensors);
              saved = this.saveTensorsForBackwardMode(tensorsToSave);
            }
            return outTensors;
          };
        } else {
          const {
            forwardFunc
          } = kernelParams;
          const saveFunc = (tensors) => {
            if (!isTapeOn) {
              return;
            }
            saved = tensors.map((tensor2) => this.keep(this.clone(tensor2)));
          };
          kernelFunc = () => {
            const numDataIdsBefore = this.backend.numDataIds();
            out = this.tidy(() => forwardFunc(this.backend, saveFunc));
            const outs = Array.isArray(out) ? out : [out];
            if (this.shouldCheckForMemLeaks()) {
              this.checkKernelForMemLeak(kernelOrScopeName, numDataIdsBefore, outs);
            }
            return outs;
          };
        }
        const {
          inputs,
          attrs
        } = kernelParams;
        const backwardsFunc = isRegisteredKernelInvocation(kernelParams) ? null : kernelParams.backwardsFunc;
        let kernelProfile;
        this.scopedRun(
          // Stop recording to a tape when running a kernel.
          () => this.state.kernelDepth++,
          () => this.state.kernelDepth--,
          () => {
            if (!this.ENV.getBool("DEBUG") && !this.state.profiling) {
              outputs = kernelFunc();
            } else {
              kernelProfile = this.profiler.profileKernel(kernelOrScopeName, inputs, () => kernelFunc());
              if (this.ENV.getBool("DEBUG")) {
                this.profiler.logKernelProfile(kernelProfile);
              }
              outputs = kernelProfile.outputs;
            }
          }
        );
        if (isTapeOn) {
          this.addTapeNode(kernelOrScopeName, inputs, outputs, backwardsFunc, saved, attrs);
        }
        if (this.state.profiling) {
          this.state.activeProfile.kernels.push({
            name: kernelOrScopeName,
            bytesAdded: this.state.numBytes - startingBytecount,
            totalBytesSnapshot: this.state.numBytes,
            tensorsAdded: this.state.numTensors - startingNumTensors,
            totalTensorsSnapshot: this.state.numTensors,
            inputShapes: Object.keys(inputs).map((key) => inputs[key] != null ? inputs[key].shape : null),
            outputShapes: outputs.map((item) => item.shape),
            kernelTimeMs: kernelProfile.timeMs,
            extraInfo: kernelProfile.extraInfo
          });
        }
        return Array.isArray(out) ? outputs : outputs[0];
      }
      /**
       * Saves tensors used in forward mode for use in backward mode.
       *
       * @param tensors the list of tensors to save.
       */
      saveTensorsForBackwardMode(tensors) {
        const saved = tensors.map((tensor2) => this.keep(this.clone(tensor2)));
        return saved;
      }
      /**
       * Returns a list of tensors to save for a given gradient calculation.
       *
       * @param kernelName name of kernel to look up gradient for.
       * @param inputs a map of input tensors.
       * @param outputs an array of output tensors from forward mode of kernel.
       */
      getTensorsForGradient(kernelName, inputs, outputs) {
        const gradConfig = getGradient(kernelName);
        if (gradConfig != null) {
          const inputsToSave = gradConfig.inputsToSave || [];
          const outputsToSave = gradConfig.outputsToSave || [];
          let inputTensorsToSave;
          if (gradConfig.saveAllInputs) {
            assert(Array.isArray(inputs), () => "saveAllInputs is true, expected inputs to be an array.");
            inputTensorsToSave = Object.keys(inputs).map((key) => inputs[key]);
          } else {
            inputTensorsToSave = inputsToSave.map((inputName) => inputs[inputName]);
          }
          const outputTensorsToSave = outputs.filter((_, i) => outputsToSave[i]);
          return inputTensorsToSave.concat(outputTensorsToSave);
        }
        return [];
      }
      /**
       * Internal method used by public APIs for tensor creation. Makes a new
       * tensor with the provided shape, dtype and values. It always
       * creates a new data id and writes the values to the underlying backend.
       */
      makeTensor(values, shape, dtype, backend2) {
        if (values == null) {
          throw new Error("Values passed to engine.makeTensor() are null");
        }
        dtype = dtype || "float32";
        backend2 = backend2 || this.backend;
        let backendVals = values;
        if (dtype === "string" && isString(values[0])) {
          backendVals = values.map((d) => encodeString(d));
        }
        const dataId = backend2.write(backendVals, shape, dtype);
        const t = new Tensor(shape, dtype, dataId, this.nextTensorId());
        this.trackTensor(t, backend2);
        if (dtype === "string") {
          const info = this.state.tensorInfo.get(dataId);
          const newBytes = bytesFromStringArray(backendVals);
          this.state.numBytes += newBytes - info.bytes;
          info.bytes = newBytes;
        }
        return t;
      }
      /**
       * Internal method used by backends. Makes a new tensor
       * that is a wrapper around an existing data id. It doesn't create
       * a new data id, only increments the ref count used in memory tracking.
       * @deprecated
       */
      makeTensorFromDataId(dataId, shape, dtype, backend2) {
        dtype = dtype || "float32";
        const tensorInfo = {
          dataId,
          shape,
          dtype
        };
        return this.makeTensorFromTensorInfo(tensorInfo, backend2);
      }
      /**
       * Internal method used by backends. Makes a new tensor that is a wrapper
       * around an existing data id in TensorInfo. It doesn't create a new data id,
       * only increments the ref count used in memory tracking.
       */
      makeTensorFromTensorInfo(tensorInfo, backend2) {
        const {
          dataId,
          shape,
          dtype
        } = tensorInfo;
        const t = new Tensor(shape, dtype, dataId, this.nextTensorId());
        this.trackTensor(t, backend2);
        return t;
      }
      makeVariable(initialValue, trainable = true, name, dtype) {
        name = name || this.nextVariableId().toString();
        if (dtype != null && dtype !== initialValue.dtype) {
          initialValue = initialValue.cast(dtype);
        }
        const v = new Variable(initialValue, trainable, name, this.nextTensorId());
        if (this.state.registeredVariables[v.name] != null) {
          throw new Error(`Variable with name ${v.name} was already registered`);
        }
        this.state.registeredVariables[v.name] = v;
        this.incRef(v, this.backend);
        return v;
      }
      trackTensor(a, backend2) {
        this.state.numTensors++;
        if (a.dtype === "string") {
          this.state.numStringTensors++;
        }
        let bytes = 0;
        if (a.dtype !== "complex64" && a.dtype !== "string") {
          bytes = a.size * bytesPerElement(a.dtype);
        }
        this.state.numBytes += bytes;
        if (!this.state.tensorInfo.has(a.dataId)) {
          this.state.numDataBuffers++;
          this.state.tensorInfo.set(a.dataId, {
            backend: backend2 || this.backend,
            dtype: a.dtype,
            shape: a.shape,
            bytes
          });
        }
        if (!(a instanceof Variable)) {
          this.track(a);
        }
      }
      // Track the tensor by dataId and increase the refCount for the dataId in the
      // backend.
      // TODO(pyu10055): This is currently used by makeVariable method, to increase
      // refCount on the backend for the dataId. It can potentially be replaced with
      // Identity op indead of calling backend directly.
      incRef(a, backend2) {
        this.trackTensor(a, backend2);
        this.backend.incRef(a.dataId);
      }
      removeDataId(dataId, backend2) {
        if (this.state.tensorInfo.has(dataId) && this.state.tensorInfo.get(dataId).backend === backend2) {
          this.state.tensorInfo.delete(dataId);
          this.state.numDataBuffers--;
        }
      }
      disposeTensor(a) {
        if (!this.state.tensorInfo.has(a.dataId)) {
          return;
        }
        const info = this.state.tensorInfo.get(a.dataId);
        this.state.numTensors--;
        if (a.dtype === "string") {
          this.state.numStringTensors--;
          this.state.numBytes -= info.bytes;
        }
        if (a.dtype !== "complex64" && a.dtype !== "string") {
          const bytes = a.size * bytesPerElement(a.dtype);
          this.state.numBytes -= bytes;
        }
        if (info.backend.disposeData(a.dataId)) {
          this.removeDataId(a.dataId, info.backend);
        }
      }
      disposeVariables() {
        for (const varName in this.state.registeredVariables) {
          const v = this.state.registeredVariables[varName];
          this.disposeVariable(v);
        }
      }
      disposeVariable(v) {
        this.disposeTensor(v);
        if (this.state.registeredVariables[v.name] != null) {
          delete this.state.registeredVariables[v.name];
        }
      }
      memory() {
        const info = this.backend.memory();
        info.numTensors = this.state.numTensors;
        info.numDataBuffers = this.state.numDataBuffers;
        info.numBytes = this.state.numBytes;
        if (this.state.numStringTensors > 0) {
          info.unreliable = true;
          if (info.reasons == null) {
            info.reasons = [];
          }
          info.reasons.push("Memory usage by string tensors is approximate (2 bytes per character)");
        }
        return info;
      }
      profile(query) {
        return __async(this, null, function* () {
          this.state.profiling = true;
          const startBytes = this.state.numBytes;
          const startNumTensors = this.state.numTensors;
          this.state.activeProfile.kernels = [];
          this.state.activeProfile.result = yield query();
          this.state.profiling = false;
          this.state.activeProfile.peakBytes = Math.max(...this.state.activeProfile.kernels.map((d) => d.totalBytesSnapshot));
          this.state.activeProfile.newBytes = this.state.numBytes - startBytes;
          this.state.activeProfile.newTensors = this.state.numTensors - startNumTensors;
          for (const kernel of this.state.activeProfile.kernels) {
            kernel.kernelTimeMs = yield kernel.kernelTimeMs;
            kernel.extraInfo = yield kernel.extraInfo;
          }
          return this.state.activeProfile;
        });
      }
      isTapeOn() {
        return this.state.gradientDepth > 0 && this.state.kernelDepth === 0;
      }
      addTapeNode(kernelName, inputs, outputs, gradientsFunc, saved, attrs) {
        const tapeNode = {
          id: this.state.nextTapeNodeId++,
          kernelName,
          inputs,
          outputs,
          saved
        };
        const gradConfig = getGradient(kernelName);
        if (gradConfig != null) {
          gradientsFunc = gradConfig.gradFunc;
        }
        if (gradientsFunc != null) {
          tapeNode.gradient = (dys) => {
            dys = dys.map((dy, i) => {
              if (dy == null) {
                const output = outputs[i];
                const vals = makeZerosTypedArray(output.size, output.dtype);
                return this.makeTensor(vals, output.shape, output.dtype);
              }
              return dy;
            });
            return gradientsFunc(dys.length > 1 ? dys : dys[0], saved, attrs);
          };
        }
        this.state.activeTape.push(tapeNode);
      }
      keep(result) {
        result.kept = true;
        return result;
      }
      startTape() {
        if (this.state.gradientDepth === 0) {
          this.state.activeTape = [];
        }
        this.state.gradientDepth++;
      }
      endTape() {
        this.state.gradientDepth--;
      }
      /**
       * Start a scope. Use this with endScope() to achieve the same functionality
       * as scope() without the need for a function closure.
       */
      startScope(name) {
        const scopeInfo = {
          track: [],
          name: "unnamed scope",
          id: this.state.nextScopeId++
        };
        if (name) {
          scopeInfo.name = name;
        }
        this.state.scopeStack.push(scopeInfo);
        this.state.activeScope = scopeInfo;
      }
      /**
       * End a scope. Use this with startScope() to achieve the same functionality
       * as scope() without the need for a function closure.
       */
      endScope(result) {
        const tensorsToTrackInParent = getTensorsInContainer(result);
        const tensorsToTrackInParentSet = new Set(tensorsToTrackInParent.map((t) => t.id));
        for (let i = 0; i < this.state.activeScope.track.length; i++) {
          const tensor2 = this.state.activeScope.track[i];
          if (!tensor2.kept && !tensorsToTrackInParentSet.has(tensor2.id)) {
            tensor2.dispose();
          }
        }
        const oldScope = this.state.scopeStack.pop();
        this.state.activeScope = this.state.scopeStack.length === 0 ? null : this.state.scopeStack[this.state.scopeStack.length - 1];
        tensorsToTrackInParent.forEach((tensor2) => {
          if (!tensor2.kept && tensor2.scopeId === oldScope.id) {
            this.track(tensor2);
          }
        });
      }
      /**
       * Returns gradients of `f` with respect to each of the `xs`. The gradients
       * returned are of the same length as `xs`, but some might be null if `f`
       * was not a function of that `x`. It also takes optional dy to multiply the
       * gradient, which defaults to `1`.
       */
      gradients(f, xs, dy, allowNoGradients = false) {
        assert(xs.length > 0, () => "gradients() received an empty list of xs.");
        if (dy != null && dy.dtype !== "float32") {
          throw new Error(`dy must have 'float32' dtype, but has '${dy.dtype}'`);
        }
        const y = this.scopedRun(() => this.startTape(), () => this.endTape(), () => this.tidy("forward", f));
        assert(y instanceof Tensor, () => "The result y returned by f() must be a tensor.");
        const filteredTape = getFilteredNodesXToY(this.state.activeTape, xs, y);
        if (!allowNoGradients && filteredTape.length === 0 && xs.length > 0) {
          throw new Error("Cannot compute gradient of y=f(x) with respect to x. Make sure that the f you passed encloses all operations that lead from x to y.");
        }
        return this.tidy("backward", () => {
          const accumulatedGradientMap = {};
          accumulatedGradientMap[y.id] = dy == null ? ones(y.shape) : dy;
          backpropagateGradients(
            accumulatedGradientMap,
            filteredTape,
            // Pass the tidy function to avoid circular dep with `tape.ts`.
            (f2) => this.tidy(f2),
            // Pass an add function to avoide a circular dep with `tape.ts`.
            add
          );
          const grads2 = xs.map((x) => accumulatedGradientMap[x.id]);
          if (this.state.gradientDepth === 0) {
            this.state.activeTape.forEach((node) => {
              for (const tensor2 of node.saved) {
                tensor2.dispose();
              }
            });
            this.state.activeTape = null;
          }
          return {
            value: y,
            grads: grads2
          };
        });
      }
      customGrad(f) {
        assert(isFunction(f), () => "The f passed in customGrad(f) must be a function.");
        return (...inputs) => {
          assert(inputs.every((t) => t instanceof Tensor), () => "The args passed in customGrad(f)(x1, x2,...) must all be tensors");
          let res;
          const inputMap = {};
          inputs.forEach((input, i) => {
            inputMap[i] = input;
          });
          const forwardFunc = (_, save) => {
            res = f(...[...inputs, save]);
            assert(res.value instanceof Tensor, () => "The function f passed in customGrad(f) must return an object where `obj.value` is a tensor");
            assert(isFunction(res.gradFunc), () => "The function f passed in customGrad(f) must return an object where `obj.gradFunc` is a function.");
            return res.value;
          };
          const backwardsFunc = (dy, saved) => {
            const gradRes = res.gradFunc(dy, saved);
            const grads2 = Array.isArray(gradRes) ? gradRes : [gradRes];
            assert(grads2.length === inputs.length, () => "The function f passed in customGrad(f) must return an object where `obj.gradFunc` is a function that returns the same number of tensors as inputs passed to f(...).");
            assert(grads2.every((t) => t instanceof Tensor), () => "The function f passed in customGrad(f) must return an object where `obj.gradFunc` is a function that returns a list of only tensors.");
            const gradMap = {};
            grads2.forEach((grad2, i) => {
              gradMap[i] = () => grad2;
            });
            return gradMap;
          };
          return this.runKernelFunc({
            forwardFunc,
            backwardsFunc,
            inputs: inputMap
          });
        };
      }
      readSync(dataId) {
        const info = this.state.tensorInfo.get(dataId);
        return info.backend.readSync(dataId);
      }
      read(dataId) {
        const info = this.state.tensorInfo.get(dataId);
        return info.backend.read(dataId);
      }
      readToGPU(dataId, options) {
        const info = this.state.tensorInfo.get(dataId);
        return info.backend.readToGPU(dataId, options);
      }
      time(query) {
        return __async(this, null, function* () {
          const start = now();
          const timingInfo = yield this.backend.time(query);
          timingInfo.wallMs = now() - start;
          return timingInfo;
        });
      }
      /**
       * Tracks a Tensor in the current scope to be automatically cleaned up
       * when the current scope ends, and returns the value.
       *
       * @param result The Tensor to track in the current scope.
       */
      track(result) {
        if (this.state.activeScope != null) {
          result.scopeId = this.state.activeScope.id;
          this.state.activeScope.track.push(result);
        }
        return result;
      }
      get registeredVariables() {
        return this.state.registeredVariables;
      }
      /**
       * Resets the engine state. Removes all backends but does not remove
       * registered backend factories.
       */
      reset() {
        this.pendingBackendInitId++;
        this.state.dispose();
        this.ENV.reset();
        this.state = new EngineState();
        for (const backendName in this.registry) {
          this.disposeRegisteredKernels(backendName);
          this.registry[backendName].dispose();
          delete this.registry[backendName];
        }
        this.backendName = null;
        this.backendInstance = null;
        this.pendingBackendInit = null;
      }
    };
    Engine.nextTensorId = 0;
    Engine.nextVariableId = 0;
    ENGINE = getOrMakeEngine();
  }
});

// node_modules/@tensorflow/tfjs-core/dist/ops/operation.js
function op(f) {
  const keys = Object.keys(f);
  if (keys.length !== 1) {
    throw new Error(`Please provide an object with a single key (operation name) mapping to a function. Got an object with ${keys.length} keys.`);
  }
  let opName = keys[0];
  const fn = f[opName];
  if (opName.endsWith("_")) {
    opName = opName.substring(0, opName.length - 1);
  }
  opName = opName + OP_SCOPE_SUFFIX;
  const f2 = (...args) => {
    ENGINE.startScope(opName);
    try {
      const result = fn(...args);
      if (isPromise(result)) {
        console.error("Cannot return a Promise inside of tidy.");
      }
      ENGINE.endScope(result);
      return result;
    } catch (ex) {
      ENGINE.endScope(null);
      throw ex;
    }
  };
  Object.defineProperty(f2, "name", {
    value: opName,
    configurable: true
  });
  return f2;
}
var OP_SCOPE_SUFFIX;
var init_operation = __esm({
  "node_modules/@tensorflow/tfjs-core/dist/ops/operation.js"() {
    init_engine();
    init_util();
    OP_SCOPE_SUFFIX = "__op";
  }
});

// node_modules/@tensorflow/tfjs-core/dist/tensor_util_env.js
function inferShape(val, dtype) {
  let firstElem = val;
  if (isTypedArray(val)) {
    return dtype === "string" ? [] : [val.length];
  }
  if (isWebGLData(val)) {
    const usedChannels = val.channels || "RGBA";
    return [val.height, val.width * usedChannels.length];
  } else if (isWebGPUData(val)) {
    return [val.buffer.size / (dtype == null ? 4 : bytesPerElement(dtype))];
  }
  if (!Array.isArray(val)) {
    return [];
  }
  const shape = [];
  while (Array.isArray(firstElem) || isTypedArray(firstElem) && dtype !== "string") {
    shape.push(firstElem.length);
    firstElem = firstElem[0];
  }
  if (Array.isArray(val) && env().getBool("TENSORLIKE_CHECK_SHAPE_CONSISTENCY")) {
    deepAssertShapeConsistency(val, shape, []);
  }
  return shape;
}
function deepAssertShapeConsistency(val, shape, indices) {
  indices = indices || [];
  if (!Array.isArray(val) && !isTypedArray(val)) {
    assert(shape.length === 0, () => `Element arr[${indices.join("][")}] is a primitive, but should be an array/TypedArray of ${shape[0]} elements`);
    return;
  }
  assert(shape.length > 0, () => `Element arr[${indices.join("][")}] should be a primitive, but is an array of ${val.length} elements`);
  assert(val.length === shape[0], () => `Element arr[${indices.join("][")}] should have ${shape[0]} elements, but has ${val.length} elements`);
  const subShape = shape.slice(1);
  for (let i = 0; i < val.length; ++i) {
    deepAssertShapeConsistency(val[i], subShape, indices.concat(i));
  }
}
function assertDtype(expectedDtype, actualDType, argName, functionName) {
  if (expectedDtype === "string_or_numeric") {
    return;
  }
  if (expectedDtype == null) {
    throw new Error(`Expected dtype cannot be null.`);
  }
  if (expectedDtype !== "numeric" && expectedDtype !== actualDType || expectedDtype === "numeric" && actualDType === "string") {
    throw new Error(`Argument '${argName}' passed to '${functionName}' must be ${expectedDtype} tensor, but got ${actualDType} tensor`);
  }
}
function convertToTensor(x, argName, functionName, parseAsDtype = "numeric") {
  if (x instanceof getGlobalTensorClass()) {
    assertDtype(parseAsDtype, x.dtype, argName, functionName);
    return x;
  }
  let inferredDtype = inferDtype(x);
  if (inferredDtype !== "string" && ["bool", "int32", "float32"].indexOf(parseAsDtype) >= 0) {
    inferredDtype = parseAsDtype;
  }
  assertDtype(parseAsDtype, inferredDtype, argName, functionName);
  if (x == null || !isTypedArray(x) && !Array.isArray(x) && typeof x !== "number" && typeof x !== "boolean" && typeof x !== "string") {
    const type = x == null ? "null" : x.constructor.name;
    throw new Error(`Argument '${argName}' passed to '${functionName}' must be a Tensor or TensorLike, but got '${type}'`);
  }
  const inferredShape = inferShape(x, inferredDtype);
  if (!isTypedArray(x) && !Array.isArray(x)) {
    x = [x];
  }
  const skipTypedArray = true;
  const values = inferredDtype !== "string" ? toTypedArray(x, inferredDtype) : flatten(x, [], skipTypedArray);
  return ENGINE.makeTensor(values, inferredShape, inferredDtype);
}
function convertToTensorArray(arg, argName, functionName, parseAsDtype = "numeric") {
  if (!Array.isArray(arg)) {
    throw new Error(`Argument ${argName} passed to ${functionName} must be a \`Tensor[]\` or \`TensorLike[]\``);
  }
  const tensors = arg;
  return tensors.map((t, i) => convertToTensor(t, `${argName}[${i}]`, functionName, parseAsDtype));
}
var init_tensor_util_env = __esm({
  "node_modules/@tensorflow/tfjs-core/dist/tensor_util_env.js"() {
    init_engine();
    init_environment();
    init_tensor();
    init_types();
    init_util();
    init_util_base();
  }
});

// node_modules/@tensorflow/tfjs-core/dist/ops/complex.js
function complex_(real3, imag2) {
  const $real = convertToTensor(real3, "real", "complex");
  const $imag = convertToTensor(imag2, "imag", "complex");
  assertShapesMatch($real.shape, $imag.shape, `real and imag shapes, ${$real.shape} and ${$imag.shape}, must match in call to tf.complex().`);
  const inputs = {
    real: $real,
    imag: $imag
  };
  return ENGINE.runKernel(Complex, inputs);
}
var complex;
var init_complex = __esm({
  "node_modules/@tensorflow/tfjs-core/dist/ops/complex.js"() {
    init_engine();
    init_kernel_names();
    init_tensor_util_env();
    init_util();
    init_operation();
    complex = op({
      complex_
    });
  }
});

// node_modules/@tensorflow/tfjs-core/dist/ops/tensor_ops_util.js
function makeTensor(values, shape, inferredShape, dtype) {
  if (dtype == null) {
    dtype = inferDtype(values);
  } else if (dtype === "complex64") {
    throw new Error(`Cannot construct a complex64 tensor directly. Please use tf.complex(real, imag).`);
  }
  if (isWebGPUData(values) || isWebGLData(values)) {
    if (dtype !== "float32" && dtype !== "int32") {
      throw new Error(`Creating tensor from GPU data only supports 'float32'|'int32' dtype, while the dtype is ${dtype}.`);
    }
    return ENGINE.backend.createTensorFromGPUData(values, shape || inferredShape, dtype);
  }
  if (!isTypedArray(values) && !Array.isArray(values) && typeof values !== "number" && typeof values !== "boolean" && typeof values !== "string") {
    throw new Error("values passed to tensor(values) must be a number/boolean/string or an array of numbers/booleans/strings, or a TypedArray");
  }
  if (shape != null) {
    assertNonNegativeIntegerDimensions(shape);
    const providedSize = sizeFromShape(shape);
    const inferredSize = sizeFromShape(inferredShape);
    assert(providedSize === inferredSize, () => `Based on the provided shape, [${shape}], the tensor should have ${providedSize} values but has ${inferredSize}`);
    for (let i = 0; i < inferredShape.length; ++i) {
      const inferred = inferredShape[i];
      const flatDimsDontMatch = i === inferredShape.length - 1 ? inferred !== sizeFromShape(shape.slice(i)) : true;
      assert(inferredShape[i] === shape[i] || !flatDimsDontMatch, () => `Error creating a new Tensor. Inferred shape (${inferredShape}) does not match the provided shape (${shape}). `);
    }
  }
  if (!isTypedArray(values) && !Array.isArray(values)) {
    values = [values];
  }
  shape = shape || inferredShape;
  values = dtype !== "string" ? toTypedArray(values, dtype) : flatten(values, [], true);
  return ENGINE.makeTensor(values, shape, dtype);
}
var init_tensor_ops_util = __esm({
  "node_modules/@tensorflow/tfjs-core/dist/ops/tensor_ops_util.js"() {
    init_engine();
    init_types();
    init_util();
  }
});

// node_modules/@tensorflow/tfjs-core/dist/ops/tensor.js
function tensor(values, shape, dtype) {
  const inferredShape = inferShape(values, dtype);
  return makeTensor(values, shape, inferredShape, dtype);
}
var init_tensor2 = __esm({
  "node_modules/@tensorflow/tfjs-core/dist/ops/tensor.js"() {
    init_tensor_util_env();
    init_tensor_ops_util();
  }
});

// node_modules/@tensorflow/tfjs-core/dist/globals.js
function enableProdMode() {
  env().set("PROD", true);
}
function enableDebugMode() {
  env().set("DEBUG", true);
}
function disableDeprecationWarnings() {
  env().set("DEPRECATION_WARNINGS_ENABLED", false);
  console.warn(`TensorFlow.js deprecation warnings have been disabled.`);
}
function deprecationWarn(msg) {
  if (env().getBool("DEPRECATION_WARNINGS_ENABLED")) {
    console.warn(msg + " You can disable deprecation warnings with tf.disableDeprecationWarnings().");
  }
}
function disposeVariables() {
  ENGINE.disposeVariables();
}
function engine() {
  return ENGINE;
}
function memory() {
  return ENGINE.memory();
}
function profile(f) {
  return ENGINE.profile(f);
}
function tidy(nameOrFn, fn) {
  return ENGINE.tidy(nameOrFn, fn);
}
function dispose(container) {
  const tensors = getTensorsInContainer(container);
  tensors.forEach((tensor2) => tensor2.dispose());
}
function keep(result) {
  return ENGINE.keep(result);
}
function time(f) {
  return ENGINE.time(f);
}
function setBackend(backendName) {
  return ENGINE.setBackend(backendName);
}
function ready() {
  return ENGINE.ready();
}
function getBackend() {
  return ENGINE.backendName;
}
function removeBackend(name) {
  ENGINE.removeBackend(name);
}
function findBackend(name) {
  return ENGINE.findBackend(name);
}
function findBackendFactory(name) {
  return ENGINE.findBackendFactory(name);
}
function registerBackend(name, factory, priority = 1) {
  return ENGINE.registerBackend(name, factory, priority);
}
function backend() {
  return ENGINE.backend;
}
function setPlatform(platformName, platform) {
  env().setPlatform(platformName, platform);
}
var init_globals = __esm({
  "node_modules/@tensorflow/tfjs-core/dist/globals.js"() {
    init_engine();
    init_environment();
    init_tensor();
    init_tensor_util();
    setDeprecationWarningFn(deprecationWarn);
  }
});

// node_modules/@tensorflow/tfjs-core/dist/ops/buffer.js
function buffer(shape, dtype = "float32", values) {
  dtype = dtype || "float32";
  assertNonNegativeIntegerDimensions(shape);
  return new TensorBuffer(shape, dtype, values);
}
var init_buffer = __esm({
  "node_modules/@tensorflow/tfjs-core/dist/ops/buffer.js"() {
    init_tensor();
    init_util();
  }
});

// node_modules/@tensorflow/tfjs-core/dist/ops/cast.js
function cast_(x, dtype) {
  const $x = convertToTensor(x, "x", "cast");
  if (!isValidDtype(dtype)) {
    throw new Error(`Failed to cast to unknown dtype ${dtype}`);
  }
  if (dtype === "string" && $x.dtype !== "string" || dtype !== "string" && $x.dtype === "string") {
    throw new Error("Only strings can be casted to strings");
  }
  const inputs = {
    x: $x
  };
  const attrs = {
    dtype
  };
  return ENGINE.runKernel(Cast, inputs, attrs);
}
var cast;
var init_cast = __esm({
  "node_modules/@tensorflow/tfjs-core/dist/ops/cast.js"() {
    init_engine();
    init_kernel_names();
    init_tensor_util_env();
    init_util();
    init_operation();
    cast = op({
      cast_
    });
  }
});

// node_modules/@tensorflow/tfjs-core/dist/ops/clone.js
function clone_(x) {
  const $x = convertToTensor(x, "x", "clone", "string_or_numeric");
  const inputs = {
    x: $x
  };
  return ENGINE.runKernel(Identity, inputs);
}
var clone;
var init_clone = __esm({
  "node_modules/@tensorflow/tfjs-core/dist/ops/clone.js"() {
    init_engine();
    init_kernel_names();
    init_tensor_util_env();
    init_operation();
    clone = op({
      clone_
    });
  }
});

// node_modules/@tensorflow/tfjs-core/dist/ops/print.js
function print(x, verbose = false) {
  console.log(x.toString(verbose));
}
var init_print = __esm({
  "node_modules/@tensorflow/tfjs-core/dist/ops/print.js"() {
  }
});

// node_modules/@tensorflow/tfjs-core/dist/ops/add.js
function add_(a, b) {
  let $a = convertToTensor(a, "a", "add");
  let $b = convertToTensor(b, "b", "add");
  [$a, $b] = makeTypesMatch($a, $b);
  const inputs = {
    a: $a,
    b: $b
  };
  return ENGINE.runKernel(Add, inputs);
}
var add2;
var init_add = __esm({
  "node_modules/@tensorflow/tfjs-core/dist/ops/add.js"() {
    init_engine();
    init_kernel_names();
    init_tensor_util();
    init_tensor_util_env();
    init_operation();
    add2 = op({
      add_
    });
  }
});

// node_modules/@tensorflow/tfjs-core/dist/ops/floorDiv.js
function floorDiv_(a, b) {
  let $a = convertToTensor(a, "a", "floorDiv");
  let $b = convertToTensor(b, "b", "floorDiv");
  [$a, $b] = makeTypesMatch($a, $b);
  const inputs = {
    a: $a,
    b: $b
  };
  return ENGINE.runKernel(FloorDiv, inputs);
}
var floorDiv;
var init_floorDiv = __esm({
  "node_modules/@tensorflow/tfjs-core/dist/ops/floorDiv.js"() {
    init_engine();
    init_kernel_names();
    init_tensor_util();
    init_tensor_util_env();
    init_operation();
    floorDiv = op({
      floorDiv_
    });
  }
});

// node_modules/@tensorflow/tfjs-core/dist/ops/div.js
function div_(a, b) {
  let $a = convertToTensor(a, "a", "div");
  let $b = convertToTensor(b, "b", "div");
  [$a, $b] = makeTypesMatch($a, $b);
  if ($a.dtype === "int32" && $b.dtype === "int32") {
    return floorDiv($a, $b);
  }
  const inputs = {
    a: $a,
    b: $b
  };
  const attrs = {};
  return ENGINE.runKernel(RealDiv, inputs, attrs);
}
var div;
var init_div = __esm({
  "node_modules/@tensorflow/tfjs-core/dist/ops/div.js"() {
    init_engine();
    init_kernel_names();
    init_tensor_util();
    init_tensor_util_env();
    init_floorDiv();
    init_operation();
    div = op({
      div_
    });
  }
});

// node_modules/@tensorflow/tfjs-core/dist/ops/mul.js
function mul_(a, b) {
  let $a = convertToTensor(a, "a", "mul");
  let $b = convertToTensor(b, "b", "mul");
  [$a, $b] = makeTypesMatch($a, $b);
  const inputs = {
    a: $a,
    b: $b
  };
  return ENGINE.runKernel(Multiply, inputs);
}
var mul;
var init_mul = __esm({
  "node_modules/@tensorflow/tfjs-core/dist/ops/mul.js"() {
    init_engine();
    init_kernel_names();
    init_tensor_util();
    init_tensor_util_env();
    init_operation();
    mul = op({
      mul_
    });
  }
});

// node_modules/@tensorflow/tfjs-core/dist/ops/abs.js
function abs_(x) {
  const $x = convertToTensor(x, "x", "abs");
  if ($x.dtype === "complex64") {
    const inputs = {
      x: $x
    };
    return ENGINE.runKernel(ComplexAbs, inputs);
  } else {
    const inputs = {
      x: $x
    };
    return ENGINE.runKernel(Abs, inputs);
  }
}
var abs;
var init_abs = __esm({
  "node_modules/@tensorflow/tfjs-core/dist/ops/abs.js"() {
    init_engine();
    init_kernel_names();
    init_tensor_util_env();
    init_operation();
    abs = op({
      abs_
    });
  }
});

// node_modules/@tensorflow/tfjs-core/dist/ops/acos.js
function acos_(x) {
  const $x = convertToTensor(x, "x", "acos");
  const inputs = {
    x: $x
  };
  return ENGINE.runKernel(Acos, inputs);
}
var acos;
var init_acos = __esm({
  "node_modules/@tensorflow/tfjs-core/dist/ops/acos.js"() {
    init_engine();
    init_kernel_names();
    init_tensor_util_env();
    init_operation();
    acos = op({
      acos_
    });
  }
});

// node_modules/@tensorflow/tfjs-core/dist/ops/acosh.js
function acosh_(x) {
  const $x = convertToTensor(x, "x", "acosh");
  const inputs = {
    x: $x
  };
  return ENGINE.runKernel(Acosh, inputs);
}
var acosh;
var init_acosh = __esm({
  "node_modules/@tensorflow/tfjs-core/dist/ops/acosh.js"() {
    init_engine();
    init_kernel_names();
    init_tensor_util_env();
    init_operation();
    acosh = op({
      acosh_
    });
  }
});

// node_modules/@tensorflow/tfjs-core/dist/ops/add_n.js
function addN_(tensors) {
  assert(Array.isArray(tensors), () => "The argument passed to tf.addN() must be a list of tensors");
  assert(tensors.length >= 1, () => `Must pass at least one tensor to tf.addN(), but got ${tensors.length}`);
  const $tensors = tensors.map((t, i) => convertToTensor(t, `tensors${i}`, "addN"));
  const firstTensor = $tensors[0];
  $tensors.forEach((t) => {
    if (t.dtype !== firstTensor.dtype) {
      throw new Error("All tensors passed to tf.addN() must have the same dtype");
    }
  });
  $tensors.forEach((t) => {
    if (!arraysEqual(t.shape, firstTensor.shape)) {
      throw new Error("All tensors passed to tf.addN() must have the same shape");
    }
  });
  const inputs = $tensors;
  return ENGINE.runKernel(AddN, inputs);
}
var addN;
var init_add_n = __esm({
  "node_modules/@tensorflow/tfjs-core/dist/ops/add_n.js"() {
    init_engine();
    init_kernel_names();
    init_tensor_util_env();
    init_util();
    init_operation();
    addN = op({
      addN_
    });
  }
});

// node_modules/@tensorflow/tfjs-core/dist/ops/all.js
function all_(x, axis = null, keepDims = false) {
  const $x = convertToTensor(x, "x", "all", "bool");
  const inputs = {
    x: $x
  };
  const attrs = {
    axis,
    keepDims
  };
  return ENGINE.runKernel(All, inputs, attrs);
}
var all;
var init_all = __esm({
  "node_modules/@tensorflow/tfjs-core/dist/ops/all.js"() {
    init_engine();
    init_kernel_names();
    init_tensor_util_env();
    init_operation();
    all = op({
      all_
    });
  }
});

// node_modules/@tensorflow/tfjs-core/dist/ops/any.js
function any_(x, axis = null, keepDims = false) {
  const $x = convertToTensor(x, "x", "any", "bool");
  const inputs = {
    x: $x
  };
  const attrs = {
    axis,
    keepDims
  };
  return ENGINE.runKernel(Any, inputs, attrs);
}
var any;
var init_any = __esm({
  "node_modules/@tensorflow/tfjs-core/dist/ops/any.js"() {
    init_engine();
    init_kernel_names();
    init_tensor_util_env();
    init_operation();
    any = op({
      any_
    });
  }
});

// node_modules/@tensorflow/tfjs-core/dist/ops/arg_max.js
function argMax_(x, axis = 0) {
  const $x = convertToTensor(x, "x", "argMax");
  const inputs = {
    x: $x
  };
  const attrs = {
    axis
  };
  return ENGINE.runKernel(ArgMax, inputs, attrs);
}
var argMax;
var init_arg_max = __esm({
  "node_modules/@tensorflow/tfjs-core/dist/ops/arg_max.js"() {
    init_engine();
    init_kernel_names();
    init_tensor_util_env();
    init_operation();
    argMax = op({
      argMax_
    });
  }
});

// node_modules/@tensorflow/tfjs-core/dist/ops/arg_min.js
function argMin_(x, axis = 0) {
  const $x = convertToTensor(x, "x", "argMin");
  const inputs = {
    x: $x
  };
  const attrs = {
    axis
  };
  return ENGINE.runKernel(ArgMin, inputs, attrs);
}
var argMin;
var init_arg_min = __esm({
  "node_modules/@tensorflow/tfjs-core/dist/ops/arg_min.js"() {
    init_engine();
    init_kernel_names();
    init_tensor_util_env();
    init_operation();
    argMin = op({
      argMin_
    });
  }
});

// node_modules/@tensorflow/tfjs-core/dist/ops/asin.js
function asin_(x) {
  const $x = convertToTensor(x, "x", "asin");
  const inputs = {
    x: $x
  };
  return ENGINE.runKernel(Asin, inputs);
}
var asin;
var init_asin = __esm({
  "node_modules/@tensorflow/tfjs-core/dist/ops/asin.js"() {
    init_engine();
    init_kernel_names();
    init_tensor_util_env();
    init_operation();
    asin = op({
      asin_
    });
  }
});

// node_modules/@tensorflow/tfjs-core/dist/ops/asinh.js
function asinh_(x) {
  const $x = convertToTensor(x, "x", "asinh");
  const inputs = {
    x: $x
  };
  return ENGINE.runKernel(Asinh, inputs);
}
var asinh;
var init_asinh = __esm({
  "node_modules/@tensorflow/tfjs-core/dist/ops/asinh.js"() {
    init_engine();
    init_kernel_names();
    init_tensor_util_env();
    init_operation();
    asinh = op({
      asinh_
    });
  }
});

// node_modules/@tensorflow/tfjs-core/dist/ops/atan.js
function atan_(x) {
  const $x = convertToTensor(x, "x", "atan");
  const inputs = {
    x: $x
  };
  return ENGINE.runKernel(Atan, inputs);
}
var atan;
var init_atan = __esm({
  "node_modules/@tensorflow/tfjs-core/dist/ops/atan.js"() {
    init_engine();
    init_kernel_names();
    init_tensor_util_env();
    init_operation();
    atan = op({
      atan_
    });
  }
});

// node_modules/@tensorflow/tfjs-core/dist/ops/atan2.js
function atan2_(a, b) {
  let $a = convertToTensor(a, "a", "atan2");
  let $b = convertToTensor(b, "b", "atan2");
  [$a, $b] = makeTypesMatch($a, $b);
  const inputs = {
    a: $a,
    b: $b
  };
  return ENGINE.runKernel(Atan2, inputs);
}
var atan2;
var init_atan2 = __esm({
  "node_modules/@tensorflow/tfjs-core/dist/ops/atan2.js"() {
    init_engine();
    init_kernel_names();
    init_tensor_util();
    init_tensor_util_env();
    init_operation();
    atan2 = op({
      atan2_
    });
  }
});

// node_modules/@tensorflow/tfjs-core/dist/ops/atanh.js
function atanh_(x) {
  const $x = convertToTensor(x, "x", "atanh");
  const inputs = {
    x: $x
  };
  return ENGINE.runKernel(Atanh, inputs);
}
var atanh;
var init_atanh = __esm({
  "node_modules/@tensorflow/tfjs-core/dist/ops/atanh.js"() {
    init_engine();
    init_kernel_names();
    init_tensor_util_env();
    init_operation();
    atanh = op({
      atanh_
    });
  }
});

// node_modules/@tensorflow/tfjs-core/dist/ops/reshape.js
function reshape_(x, shape) {
  const $x = convertToTensor(x, "x", "reshape", "string_or_numeric");
  const inputs = {
    x: $x
  };
  const attrs = {
    shape
  };
  return ENGINE.runKernel(Reshape, inputs, attrs);
}
var reshape;
var init_reshape = __esm({
  "node_modules/@tensorflow/tfjs-core/dist/ops/reshape.js"() {
    init_engine();
    init_kernel_names();
    init_tensor_util_env();
    init_operation();
    reshape = op({
      reshape_
    });
  }
});

// node_modules/@tensorflow/tfjs-core/dist/ops/conv_util.js
function computeDilation2DInfo(inputShape, filterShape, strides, pad2, dataFormat = "NHWC", dilations) {
  const inputChannels = inputShape[3];
  const $filterShape = [...filterShape, inputChannels];
  const $dataFormat = convertConv2DDataFormat(dataFormat);
  return computeConv2DInfo(inputShape, $filterShape, strides, dilations, pad2, null, null, $dataFormat);
}
function computePool2DInfo(inShape, filterSize, strides, dilations, pad2, roundingMode, dataFormat = "channelsLast") {
  const [filterHeight, filterWidth] = parseTupleParam(filterSize);
  let filterShape;
  if (dataFormat === "channelsLast") {
    filterShape = [filterHeight, filterWidth, inShape[3], inShape[3]];
  } else if (dataFormat === "channelsFirst") {
    filterShape = [filterHeight, filterWidth, inShape[1], inShape[1]];
  } else {
    throw new Error(`Unknown dataFormat ${dataFormat}`);
  }
  return computeConv2DInfo(inShape, filterShape, strides, dilations, pad2, roundingMode, false, dataFormat);
}
function computePool3DInfo(inShape, filterSize, strides, dilations, pad2, roundingMode, dataFormat = "NDHWC") {
  const [filterDepth, filterHeight, filterWidth] = parse3TupleParam(filterSize);
  let filterShape;
  let $dataFormat;
  if (dataFormat === "NDHWC") {
    $dataFormat = "channelsLast";
    filterShape = [filterDepth, filterHeight, filterWidth, inShape[4], inShape[4]];
  } else if (dataFormat === "NCDHW") {
    $dataFormat = "channelsFirst";
    filterShape = [filterDepth, filterHeight, filterWidth, inShape[1], inShape[1]];
  } else {
    throw new Error(`Unknown dataFormat ${dataFormat}`);
  }
  return computeConv3DInfo(inShape, filterShape, strides, dilations, pad2, false, $dataFormat, roundingMode);
}
function computeConv2DInfo(inShape, filterShape, strides, dilations, pad2, roundingMode, depthwise = false, dataFormat = "channelsLast") {
  let [batchSize, inHeight, inWidth, inChannels] = [-1, -1, -1, -1];
  if (dataFormat === "channelsLast") {
    [batchSize, inHeight, inWidth, inChannels] = inShape;
  } else if (dataFormat === "channelsFirst") {
    [batchSize, inChannels, inHeight, inWidth] = inShape;
  } else {
    throw new Error(`Unknown dataFormat ${dataFormat}`);
  }
  const [filterHeight, filterWidth, , filterChannels] = filterShape;
  const [strideHeight, strideWidth] = parseTupleParam(strides);
  const [dilationHeight, dilationWidth] = parseTupleParam(dilations);
  const effectiveFilterHeight = getEffectiveFilterSize(filterHeight, dilationHeight);
  const effectiveFilterWidth = getEffectiveFilterSize(filterWidth, dilationWidth);
  const {
    padInfo,
    outHeight,
    outWidth
  } = getPadAndOutInfo(pad2, inHeight, inWidth, strideHeight, strideWidth, effectiveFilterHeight, effectiveFilterWidth, roundingMode, dataFormat);
  const outChannels = depthwise ? filterChannels * inChannels : filterChannels;
  let outShape;
  if (dataFormat === "channelsFirst") {
    outShape = [batchSize, outChannels, outHeight, outWidth];
  } else if (dataFormat === "channelsLast") {
    outShape = [batchSize, outHeight, outWidth, outChannels];
  }
  return {
    batchSize,
    dataFormat,
    inHeight,
    inWidth,
    inChannels,
    outHeight,
    outWidth,
    outChannels,
    padInfo,
    strideHeight,
    strideWidth,
    filterHeight,
    filterWidth,
    effectiveFilterHeight,
    effectiveFilterWidth,
    dilationHeight,
    dilationWidth,
    inShape,
    outShape,
    filterShape
  };
}
function computeConv3DInfo(inShape, filterShape, strides, dilations, pad2, depthwise = false, dataFormat = "channelsLast", roundingMode) {
  let [batchSize, inDepth, inHeight, inWidth, inChannels] = [-1, -1, -1, -1, -1];
  if (dataFormat === "channelsLast") {
    [batchSize, inDepth, inHeight, inWidth, inChannels] = inShape;
  } else if (dataFormat === "channelsFirst") {
    [batchSize, inChannels, inDepth, inHeight, inWidth] = inShape;
  } else {
    throw new Error(`Unknown dataFormat ${dataFormat}`);
  }
  const [filterDepth, filterHeight, filterWidth, , filterChannels] = filterShape;
  const [strideDepth, strideHeight, strideWidth] = parse3TupleParam(strides);
  const [dilationDepth, dilationHeight, dilationWidth] = parse3TupleParam(dilations);
  const effectiveFilterDepth = getEffectiveFilterSize(filterDepth, dilationDepth);
  const effectiveFilterHeight = getEffectiveFilterSize(filterHeight, dilationHeight);
  const effectiveFilterWidth = getEffectiveFilterSize(filterWidth, dilationWidth);
  const {
    padInfo,
    outDepth,
    outHeight,
    outWidth
  } = get3DPadAndOutInfo(pad2, inDepth, inHeight, inWidth, strideDepth, strideHeight, strideWidth, effectiveFilterDepth, effectiveFilterHeight, effectiveFilterWidth, roundingMode);
  const outChannels = depthwise ? filterChannels * inChannels : filterChannels;
  let outShape;
  if (dataFormat === "channelsFirst") {
    outShape = [batchSize, outChannels, outDepth, outHeight, outWidth];
  } else if (dataFormat === "channelsLast") {
    outShape = [batchSize, outDepth, outHeight, outWidth, outChannels];
  }
  return {
    batchSize,
    dataFormat,
    inDepth,
    inHeight,
    inWidth,
    inChannels,
    outDepth,
    outHeight,
    outWidth,
    outChannels,
    padInfo,
    strideDepth,
    strideHeight,
    strideWidth,
    filterDepth,
    filterHeight,
    filterWidth,
    effectiveFilterDepth,
    effectiveFilterHeight,
    effectiveFilterWidth,
    dilationDepth,
    dilationHeight,
    dilationWidth,
    inShape,
    outShape,
    filterShape
  };
}
function computeOutputShape2D(inShape, fieldSize, stride, zeroPad, roundingMode) {
  if (zeroPad == null) {
    zeroPad = computeDefaultPad(inShape, fieldSize, stride);
  }
  const inputRows = inShape[0];
  const inputCols = inShape[1];
  const outputRows = round((inputRows - fieldSize + 2 * zeroPad) / stride + 1, roundingMode);
  const outputCols = round((inputCols - fieldSize + 2 * zeroPad) / stride + 1, roundingMode);
  return [outputRows, outputCols];
}
function computeOutputShape4D(inShape, filterShape, outChannels, strides, zeroPad, roundingMode) {
  if (zeroPad == null) {
    zeroPad = computeDefaultPad(inShape, filterShape[0], strides[0]);
  }
  const outShape = [0, 0, 0, outChannels];
  for (let index = 0; index < 3; index++) {
    if (inShape[index] + 2 * zeroPad >= filterShape[index]) {
      outShape[index] = round((inShape[index] - filterShape[index] + 2 * zeroPad) / strides[index] + 1, roundingMode);
    }
  }
  return outShape;
}
function computeDefaultPad(inputShape, fieldSize, stride, dilation = 1) {
  const effectiveFieldSize = getEffectiveFilterSize(fieldSize, dilation);
  return Math.floor((inputShape[0] * (stride - 1) - stride + effectiveFieldSize) / 2);
}
function parseTupleParam(param) {
  if (typeof param === "number") {
    return [param, param, param];
  }
  if (param.length === 2) {
    return [param[0], param[1], 1];
  }
  return param;
}
function parse3TupleParam(param) {
  return typeof param === "number" ? [param, param, param] : param;
}
function getEffectiveFilterSize(filterSize, dilation) {
  if (dilation <= 1) {
    return filterSize;
  }
  return filterSize + (filterSize - 1) * (dilation - 1);
}
function getPadAndOutInfo(pad2, inHeight, inWidth, strideHeight, strideWidth, filterHeight, filterWidth, roundingMode, dataFormat) {
  let padInfo;
  let outHeight;
  let outWidth;
  if (typeof pad2 === "number") {
    const padType = pad2 === 0 ? "VALID" : "NUMBER";
    padInfo = {
      top: pad2,
      bottom: pad2,
      left: pad2,
      right: pad2,
      type: padType
    };
    const outShape = computeOutputShape2D([inHeight, inWidth], filterHeight, strideHeight, pad2, roundingMode);
    outHeight = outShape[0];
    outWidth = outShape[1];
  } else if (pad2 === "same") {
    outHeight = Math.ceil(inHeight / strideHeight);
    outWidth = Math.ceil(inWidth / strideWidth);
    const padAlongHeight = Math.max(0, (outHeight - 1) * strideHeight + filterHeight - inHeight);
    const padAlongWidth = Math.max(0, (outWidth - 1) * strideWidth + filterWidth - inWidth);
    const top = Math.floor(padAlongHeight / 2);
    const bottom = padAlongHeight - top;
    const left = Math.floor(padAlongWidth / 2);
    const right = padAlongWidth - left;
    padInfo = {
      top,
      bottom,
      left,
      right,
      type: "SAME"
    };
  } else if (pad2 === "valid") {
    padInfo = {
      top: 0,
      bottom: 0,
      left: 0,
      right: 0,
      type: "VALID"
    };
    outHeight = Math.ceil((inHeight - filterHeight + 1) / strideHeight);
    outWidth = Math.ceil((inWidth - filterWidth + 1) / strideWidth);
  } else if (typeof pad2 === "object") {
    const top = dataFormat === "channelsLast" ? pad2[1][0] : pad2[2][0];
    const bottom = dataFormat === "channelsLast" ? pad2[1][1] : pad2[2][1];
    const left = dataFormat === "channelsLast" ? pad2[2][0] : pad2[3][0];
    const right = dataFormat === "channelsLast" ? pad2[2][1] : pad2[3][1];
    const padType = top === 0 && bottom === 0 && left === 0 && right === 0 ? "VALID" : "EXPLICIT";
    padInfo = {
      top,
      bottom,
      left,
      right,
      type: padType
    };
    outHeight = round((inHeight - filterHeight + top + bottom) / strideHeight + 1, roundingMode);
    outWidth = round((inWidth - filterWidth + left + right) / strideWidth + 1, roundingMode);
  } else {
    throw Error(`Unknown padding parameter: ${pad2}`);
  }
  return {
    padInfo,
    outHeight,
    outWidth
  };
}
function get3DPadAndOutInfo(pad2, inDepth, inHeight, inWidth, strideDepth, strideHeight, strideWidth, filterDepth, filterHeight, filterWidth, roundingMode) {
  let padInfo;
  let outDepth;
  let outHeight;
  let outWidth;
  if (pad2 === "valid") {
    pad2 = 0;
  }
  if (typeof pad2 === "number") {
    const padType = pad2 === 0 ? "VALID" : "NUMBER";
    padInfo = {
      top: pad2,
      bottom: pad2,
      left: pad2,
      right: pad2,
      front: pad2,
      back: pad2,
      type: padType
    };
    const outShape = computeOutputShape4D([inDepth, inHeight, inWidth, 1], [filterDepth, filterHeight, filterWidth], 1, [strideDepth, strideHeight, strideWidth], pad2, roundingMode);
    outDepth = outShape[0];
    outHeight = outShape[1];
    outWidth = outShape[2];
  } else if (pad2 === "same") {
    outDepth = Math.ceil(inDepth / strideDepth);
    outHeight = Math.ceil(inHeight / strideHeight);
    outWidth = Math.ceil(inWidth / strideWidth);
    const padAlongDepth = (outDepth - 1) * strideDepth + filterDepth - inDepth;
    const padAlongHeight = (outHeight - 1) * strideHeight + filterHeight - inHeight;
    const padAlongWidth = (outWidth - 1) * strideWidth + filterWidth - inWidth;
    const front = Math.floor(padAlongDepth / 2);
    const back = padAlongDepth - front;
    const top = Math.floor(padAlongHeight / 2);
    const bottom = padAlongHeight - top;
    const left = Math.floor(padAlongWidth / 2);
    const right = padAlongWidth - left;
    padInfo = {
      top,
      bottom,
      left,
      right,
      front,
      back,
      type: "SAME"
    };
  } else {
    throw Error(`Unknown padding parameter: ${pad2}`);
  }
  return {
    padInfo,
    outDepth,
    outHeight,
    outWidth
  };
}
function round(value, roundingMode) {
  if (!roundingMode) {
    return Math.trunc(value);
  }
  switch (roundingMode) {
    case "round":
      return Math.round(value);
    case "ceil":
      return Math.ceil(value);
    case "floor":
      return Math.floor(value);
    default:
      throw new Error(`Unknown roundingMode ${roundingMode}`);
  }
}
function tupleValuesAreOne(param) {
  const [dimA, dimB, dimC] = parseTupleParam(param);
  return dimA === 1 && dimB === 1 && dimC === 1;
}
function eitherStridesOrDilationsAreOne(strides, dilations) {
  return tupleValuesAreOne(strides) || tupleValuesAreOne(dilations);
}
function stridesOrDilationsArePositive(values) {
  return parseTupleParam(values).every((value) => value > 0);
}
function convertConv2DDataFormat(dataFormat) {
  if (dataFormat === "NHWC") {
    return "channelsLast";
  } else if (dataFormat === "NCHW") {
    return "channelsFirst";
  } else {
    throw new Error(`Unknown dataFormat ${dataFormat}`);
  }
}
function checkPadOnDimRoundingMode(opDesc, pad2, dimRoundingMode) {
  if (dimRoundingMode != null) {
    if (typeof pad2 === "string") {
      throw Error(`Error in ${opDesc}: pad must be an integer when using dimRoundingMode ${dimRoundingMode} but got pad ${pad2}.`);
    } else if (typeof pad2 === "number") {
      assert(isInt(pad2), () => `Error in ${opDesc}: pad must be an integer when using dimRoundingMode ${dimRoundingMode} but got pad ${pad2}.`);
    } else if (typeof pad2 === "object") {
      pad2.forEach((p) => {
        p.forEach((v) => {
          assert(isInt(v), () => `Error in ${opDesc}: pad must be an integer when using dimRoundingMode ${dimRoundingMode} but got pad ${v}.`);
        });
      });
    } else {
      throw Error(`Error in ${opDesc}: Unknown padding parameter: ${pad2}`);
    }
  }
}
var init_conv_util = __esm({
  "node_modules/@tensorflow/tfjs-core/dist/ops/conv_util.js"() {
    init_util();
  }
});

// node_modules/@tensorflow/tfjs-core/dist/ops/avg_pool.js
function avgPool_(x, filterSize, strides, pad2, dimRoundingMode) {
  const $x = convertToTensor(x, "x", "avgPool", "float32");
  const dilations = 1;
  assert(eitherStridesOrDilationsAreOne(strides, dilations), () => `Error in avgPool: Either strides or dilations must be 1. Got strides ${strides} and dilations '${dilations}'`);
  let x4D = $x;
  let reshapedTo4D = false;
  if ($x.rank === 3) {
    reshapedTo4D = true;
    x4D = reshape($x, [1, $x.shape[0], $x.shape[1], $x.shape[2]]);
  }
  assert(x4D.rank === 4, () => `Error in avgPool: x must be rank 4 but got rank ${x4D.rank}.`);
  checkPadOnDimRoundingMode("avgPool", pad2, dimRoundingMode);
  const inputs = {
    x: x4D
  };
  const attrs = {
    filterSize,
    strides,
    pad: pad2,
    dimRoundingMode
  };
  let res = ENGINE.runKernel(AvgPool, inputs, attrs);
  res = cast(res, $x.dtype);
  if (reshapedTo4D) {
    return reshape(res, [res.shape[1], res.shape[2], res.shape[3]]);
  }
  return res;
}
var avgPool;
var init_avg_pool = __esm({
  "node_modules/@tensorflow/tfjs-core/dist/ops/avg_pool.js"() {
    init_engine();
    init_kernel_names();
    init_tensor_util_env();
    init_util();
    init_cast();
    init_conv_util();
    init_operation();
    init_reshape();
    avgPool = op({
      avgPool_
    });
  }
});

// node_modules/@tensorflow/tfjs-core/dist/ops/avg_pool_3d.js
function avgPool3d_(x, filterSize, strides, pad2, dimRoundingMode, dataFormat = "NDHWC") {
  const $x = convertToTensor(x, "x", "avgPool3d", "float32");
  let x5D = $x;
  let reshapedTo5D = false;
  if ($x.rank === 4) {
    reshapedTo5D = true;
    x5D = reshape($x, [1, $x.shape[0], $x.shape[1], $x.shape[2], $x.shape[3]]);
  }
  assert(x5D.rank === 5, () => `Error in avgPool3d: x must be rank 5 but got rank ${x5D.rank}.`);
  assert(dataFormat === "NDHWC", () => `Error in avgPool3d: Only NDHWC is currently supported, but got dataFormat of ${dataFormat}`);
  assert(typeof strides === "number" && strides > 0 || Array.isArray(strides) && strides[0] > 0 && strides[1] > 0 && strides[2] > 0, () => `Error in avgPool3d: Stride must be > 0, but got '${strides}'`);
  checkPadOnDimRoundingMode("avgPool3d", pad2, dimRoundingMode);
  const inputs = {
    x: x5D
  };
  const attrs = {
    filterSize,
    strides,
    pad: pad2,
    dimRoundingMode,
    dataFormat
  };
  let res = ENGINE.runKernel(AvgPool3D, inputs, attrs);
  res = cast(res, x5D.dtype);
  if (reshapedTo5D) {
    return reshape(res, [res.shape[1], res.shape[2], res.shape[3], res.shape[4]]);
  }
  return res;
}
var avgPool3d;
var init_avg_pool_3d = __esm({
  "node_modules/@tensorflow/tfjs-core/dist/ops/avg_pool_3d.js"() {
    init_engine();
    init_kernel_names();
    init_tensor_util_env();
    init_util();
    init_cast();
    init_conv_util();
    init_operation();
    init_reshape();
    avgPool3d = op({
      avgPool3d_
    });
  }
});

// node_modules/@tensorflow/tfjs-core/dist/ops/concat.js
function concat_(tensors, axis = 0) {
  assert(tensors.length >= 1, () => "Pass at least one tensor to concat");
  const $tensors = convertToTensorArray(tensors, "tensors", "concat", "string_or_numeric");
  if ($tensors[0].dtype === "complex64") {
    $tensors.forEach((tensor2) => {
      if (tensor2.dtype !== "complex64") {
        throw new Error(`Cannot concatenate complex64 tensors with a tensor
          with dtype ${tensor2.dtype}. `);
      }
    });
  }
  if ($tensors.length === 1) {
    return clone($tensors[0]);
  }
  const inputs = $tensors;
  const attr = {
    axis
  };
  return ENGINE.runKernel(Concat, inputs, attr);
}
var concat;
var init_concat = __esm({
  "node_modules/@tensorflow/tfjs-core/dist/ops/concat.js"() {
    init_engine();
    init_kernel_names();
    init_tensor_util_env();
    init_util();
    init_clone();
    init_operation();
    concat = op({
      concat_
    });
  }
});

// node_modules/@tensorflow/tfjs-core/dist/ops/mat_mul.js
function matMul_(a, b, transposeA = false, transposeB = false) {
  let $a = convertToTensor(a, "a", "matMul");
  let $b = convertToTensor(b, "b", "matMul");
  [$a, $b] = makeTypesMatch($a, $b);
  const inputs = {
    a: $a,
    b: $b
  };
  const attrs = {
    transposeA,
    transposeB
  };
  return ENGINE.runKernel(BatchMatMul, inputs, attrs);
}
var matMul;
var init_mat_mul = __esm({
  "node_modules/@tensorflow/tfjs-core/dist/ops/mat_mul.js"() {
    init_engine();
    init_kernel_names();
    init_tensor_util();
    init_tensor_util_env();
    init_operation();
    matMul = op({
      matMul_
    });
  }
});

// node_modules/@tensorflow/tfjs-core/dist/ops/sigmoid.js
function sigmoid_(x) {
  const $x = convertToTensor(x, "x", "sigmoid", "float32");
  const inputs = {
    x: $x
  };
  return ENGINE.runKernel(Sigmoid, inputs);
}
var sigmoid;
var init_sigmoid = __esm({
  "node_modules/@tensorflow/tfjs-core/dist/ops/sigmoid.js"() {
    init_engine();
    init_kernel_names();
    init_tensor_util_env();
    init_operation();
    sigmoid = op({
      sigmoid_
    });
  }
});

// node_modules/@tensorflow/tfjs-core/dist/ops/slice.js
function slice_(x, begin, size) {
  const $x = convertToTensor(x, "x", "slice", "string_or_numeric");
  if ($x.rank === 0) {
    throw new Error("Slicing scalar is not possible");
  }
  const inputs = {
    x: $x
  };
  const attrs = {
    begin,
    size
  };
  return ENGINE.runKernel(Slice, inputs, attrs);
}
var slice;
var init_slice = __esm({
  "node_modules/@tensorflow/tfjs-core/dist/ops/slice.js"() {
    init_engine();
    init_kernel_names();
    init_tensor_util_env();
    init_operation();
    slice = op({
      slice_
    });
  }
});

// node_modules/@tensorflow/tfjs-core/dist/ops/tanh.js
function tanh_(x) {
  const $x = convertToTensor(x, "x", "tanh", "float32");
  const inputs = {
    x: $x
  };
  return ENGINE.runKernel(Tanh, inputs);
}
var tanh2;
var init_tanh = __esm({
  "node_modules/@tensorflow/tfjs-core/dist/ops/tanh.js"() {
    init_engine();
    init_kernel_names();
    init_tensor_util_env();
    init_operation();
    tanh2 = op({
      tanh_
    });
  }
});

// node_modules/@tensorflow/tfjs-core/dist/ops/basic_lstm_cell.js
function basicLSTMCell_(forgetBias, lstmKernel, lstmBias, data, c, h) {
  const $forgetBias = convertToTensor(forgetBias, "forgetBias", "basicLSTMCell");
  const $lstmKernel = convertToTensor(lstmKernel, "lstmKernel", "basicLSTMCell");
  const $lstmBias = convertToTensor(lstmBias, "lstmBias", "basicLSTMCell");
  const $data = convertToTensor(data, "data", "basicLSTMCell");
  const $c = convertToTensor(c, "c", "basicLSTMCell");
  const $h = convertToTensor(h, "h", "basicLSTMCell");
  const combined = concat([$data, $h], 1);
  const weighted = matMul(combined, $lstmKernel);
  const res = add2(weighted, $lstmBias);
  const batchSize = res.shape[0];
  const sliceCols = res.shape[1] / 4;
  const sliceSize = [batchSize, sliceCols];
  const i = slice(res, [0, 0], sliceSize);
  const j = slice(res, [0, sliceCols], sliceSize);
  const f = slice(res, [0, sliceCols * 2], sliceSize);
  const o = slice(res, [0, sliceCols * 3], sliceSize);
  const newC = add2(mul(sigmoid(i), tanh2(j)), mul($c, sigmoid(add2($forgetBias, f))));
  const newH = mul(tanh2(newC), sigmoid(o));
  return [newC, newH];
}
var basicLSTMCell;
var init_basic_lstm_cell = __esm({
  "node_modules/@tensorflow/tfjs-core/dist/ops/basic_lstm_cell.js"() {
    init_tensor_util_env();
    init_add();
    init_concat();
    init_mat_mul();
    init_mul();
    init_operation();
    init_sigmoid();
    init_slice();
    init_tanh();
    basicLSTMCell = op({
      basicLSTMCell_
    });
  }
});

// node_modules/@tensorflow/tfjs-core/dist/ops/batch_to_space_nd.js
function batchToSpaceND_(x, blockShape, crops) {
  const $x = convertToTensor(x, "x", "batchToSpaceND");
  const prod3 = blockShape.reduce((a, b) => a * b);
  assert($x.rank >= 1 + blockShape.length, () => `input rank is ${$x.rank} but should be > than blockShape.length ${blockShape.length}`);
  assert(crops.length === blockShape.length, () => `crops.length is ${crops.length} but should be equal to blockShape.length  ${blockShape.length}`);
  assert($x.shape[0] % prod3 === 0, () => `input tensor batch is ${$x.shape[0]} but is not divisible by the product of the elements of blockShape ${blockShape.join(" * ")} === ${prod3}`);
  const inputs = {
    x: $x
  };
  const attrs = {
    blockShape,
    crops
  };
  return ENGINE.runKernel(BatchToSpaceND, inputs, attrs);
}
var batchToSpaceND;
var init_batch_to_space_nd = __esm({
  "node_modules/@tensorflow/tfjs-core/dist/ops/batch_to_space_nd.js"() {
    init_engine();
    init_kernel_names();
    init_tensor_util_env();
    init_util();
    init_operation();
    batchToSpaceND = op({
      batchToSpaceND_
    });
  }
});

// node_modules/@tensorflow/tfjs-core/dist/ops/batchnorm_util.js
function xAs4D(x) {
  let x4D;
  if (x.rank === 0 || x.rank === 1) {
    x4D = reshape(x, [1, 1, 1, x.size]);
  } else if (x.rank === 2) {
    x4D = reshape(x, [1, 1, x.shape[0], x.shape[1]]);
  } else if (x.rank === 3) {
    x4D = reshape(x, [1, x.shape[0], x.shape[1], x.shape[2]]);
  } else {
    x4D = x;
  }
  return x4D;
}
var init_batchnorm_util = __esm({
  "node_modules/@tensorflow/tfjs-core/dist/ops/batchnorm_util.js"() {
    init_reshape();
  }
});

// node_modules/@tensorflow/tfjs-core/dist/ops/batchnorm.js
function batchNorm_(x, mean2, variance, offset, scale, varianceEpsilon) {
  if (varianceEpsilon == null) {
    varianceEpsilon = 1e-3;
  }
  const $x = convertToTensor(x, "x", "batchNorm");
  const $mean = convertToTensor(mean2, "mean", "batchNorm");
  const $variance = convertToTensor(variance, "variance", "batchNorm");
  let $scale;
  if (scale != null) {
    $scale = convertToTensor(scale, "scale", "batchNorm");
  }
  let $offset;
  if (offset != null) {
    $offset = convertToTensor(offset, "offset", "batchNorm");
  }
  assert($mean.rank === $variance.rank, () => "Batch normalization gradient requires mean and variance to have equal ranks.");
  assert($offset == null || $mean.rank === $offset.rank, () => "Batch normalization gradient requires mean and offset to have equal ranks.");
  assert($scale == null || $mean.rank === $scale.rank, () => "Batch normalization gradient requires mean and scale to have equal ranks.");
  const x4D = xAs4D($x);
  const inputs = {
    x: x4D,
    scale: $scale,
    offset: $offset,
    mean: $mean,
    variance: $variance
  };
  const attrs = {
    varianceEpsilon
  };
  const res = ENGINE.runKernel(FusedBatchNorm, inputs, attrs);
  return reshape(res, $x.shape);
}
var batchNorm;
var init_batchnorm = __esm({
  "node_modules/@tensorflow/tfjs-core/dist/ops/batchnorm.js"() {
    init_engine();
    init_kernel_names();
    init_tensor_util_env();
    init_util();
    init_batchnorm_util();
    init_operation();
    init_reshape();
    batchNorm = op({
      batchNorm_
    });
  }
});

// node_modules/@tensorflow/tfjs-core/dist/ops/batchnorm2d.js
function batchNorm2d_(x, mean2, variance, offset, scale, varianceEpsilon) {
  const $x = convertToTensor(x, "x", "batchNorm");
  const $mean = convertToTensor(mean2, "mean", "batchNorm");
  const $variance = convertToTensor(variance, "variance", "batchNorm");
  let $scale;
  if (scale != null) {
    $scale = convertToTensor(scale, "scale", "batchNorm");
  }
  let $offset;
  if (offset != null) {
    $offset = convertToTensor(offset, "offset", "batchNorm");
  }
  assert($x.rank === 2, () => `Error in batchNorm2D: x must be rank 2 but got rank ${$x.rank}.`);
  assert($mean.rank === 2 || $mean.rank === 1, () => `Error in batchNorm2D: mean must be rank 2 or rank 1 but got rank ${$mean.rank}.`);
  assert($variance.rank === 2 || $variance.rank === 1, () => `Error in batchNorm2D: variance must be rank 2 or rank 1 but got rank ${$variance.rank}.`);
  if ($scale != null) {
    assert($scale.rank === 2 || $scale.rank === 1, () => `Error in batchNorm2D: scale must be rank 2 or rank 1 but got rank ${$scale.rank}.`);
  }
  if ($offset != null) {
    assert($offset.rank === 2 || $offset.rank === 1, () => `Error in batchNorm2D: offset must be rank 2 or rank 1 but got rank ${$offset.rank}.`);
  }
  return batchNorm($x, $mean, $variance, $offset, $scale, varianceEpsilon);
}
var batchNorm2d;
var init_batchnorm2d = __esm({
  "node_modules/@tensorflow/tfjs-core/dist/ops/batchnorm2d.js"() {
    init_tensor_util_env();
    init_util();
    init_batchnorm();
    init_operation();
    batchNorm2d = op({
      batchNorm2d_
    });
  }
});

// node_modules/@tensorflow/tfjs-core/dist/ops/batchnorm3d.js
function batchNorm3d_(x, mean2, variance, offset, scale, varianceEpsilon) {
  const $x = convertToTensor(x, "x", "batchNorm");
  const $mean = convertToTensor(mean2, "mean", "batchNorm");
  const $variance = convertToTensor(variance, "variance", "batchNorm");
  let $scale;
  if (scale != null) {
    $scale = convertToTensor(scale, "scale", "batchNorm");
  }
  let $offset;
  if (offset != null) {
    $offset = convertToTensor(offset, "offset", "batchNorm");
  }
  assert($x.rank === 3, () => `Error in batchNorm3D: x must be rank 3 but got rank ${$x.rank}.`);
  assert($mean.rank === 3 || $mean.rank === 1, () => `Error in batchNorm3D: mean must be rank 3 or rank 1 but got rank ${$mean.rank}.`);
  assert($variance.rank === 3 || $variance.rank === 1, () => `Error in batchNorm3D: variance must be rank 3 or rank 1 but got rank ${$variance.rank}.`);
  if ($scale != null) {
    assert($scale.rank === 3 || $scale.rank === 1, () => `Error in batchNorm3D: scale must be rank 3 or rank 1 but got rank ${$scale.rank}.`);
  }
  if ($offset != null) {
    assert($offset.rank === 3 || $offset.rank === 1, () => `Error in batchNorm3D: offset must be rank 3 or rank 1 but got rank ${$offset.rank}.`);
  }
  return batchNorm($x, $mean, $variance, $offset, $scale, varianceEpsilon);
}
var batchNorm3d;
var init_batchnorm3d = __esm({
  "node_modules/@tensorflow/tfjs-core/dist/ops/batchnorm3d.js"() {
    init_tensor_util_env();
    init_util();
    init_batchnorm();
    init_operation();
    batchNorm3d = op({
      batchNorm3d_
    });
  }
});

// node_modules/@tensorflow/tfjs-core/dist/ops/batchnorm4d.js
function batchNorm4d_(x, mean2, variance, offset, scale, varianceEpsilon) {
  const $x = convertToTensor(x, "x", "batchNorm");
  const $mean = convertToTensor(mean2, "mean", "batchNorm");
  const $variance = convertToTensor(variance, "variance", "batchNorm");
  let $scale;
  if (scale != null) {
    $scale = convertToTensor(scale, "scale", "batchNorm");
  }
  let $offset;
  if (offset != null) {
    $offset = convertToTensor(offset, "offset", "batchNorm");
  }
  assert($x.rank === 4, () => `Error in batchNorm4D: x must be rank 4 but got rank ${$x.rank}.`);
  assert($mean.rank === 4 || $mean.rank === 1, () => `Error in batchNorm4D: mean must be rank 4 or rank 1 but got rank ${$mean.rank}.`);
  assert($variance.rank === 4 || $variance.rank === 1, () => `Error in batchNorm4D: variance must be rank 4 or rank 1 but got rank ${$variance.rank}.`);
  if ($scale != null) {
    assert($scale.rank === 4 || $scale.rank === 1, () => `Error in batchNorm4D: scale must be rank 4 or rank 1 but got rank ${$scale.rank}.`);
  }
  if ($offset != null) {
    assert($offset.rank === 4 || $offset.rank === 1, () => `Error in batchNorm4D: offset must be rank 4 or rank 1 but got rank ${$offset.rank}.`);
  }
  return batchNorm($x, $mean, $variance, $offset, $scale, varianceEpsilon);
}
var batchNorm4d;
var init_batchnorm4d = __esm({
  "node_modules/@tensorflow/tfjs-core/dist/ops/batchnorm4d.js"() {
    init_tensor_util_env();
    init_util();
    init_batchnorm();
    init_operation();
    batchNorm4d = op({
      batchNorm4d_
    });
  }
});

// node_modules/@tensorflow/tfjs-core/dist/ops/bincount.js
function bincount_(x, weights, size) {
  const $x = convertToTensor(x, "x", "bincount");
  const $weights = convertToTensor(weights, "weights", "bincount");
  assert($x.dtype === "int32", () => `Error in bincount: input dtype must be int32, but got ${$x.dtype}`);
  assert(size >= 0, () => `size must be non-negative, but got ${size}.`);
  assert($weights.size === $x.size || $weights.size === 0, () => `Error in bincount: weights must have the same size as input or0-length, but got input shape: ${$x.shape}, weights shape: ${$weights.shape}.`);
  const inputs = {
    x: $x,
    weights: $weights
  };
  const attrs = {
    size
  };
  return ENGINE.runKernel(Bincount, inputs, attrs);
}
var bincount;
var init_bincount = __esm({
  "node_modules/@tensorflow/tfjs-core/dist/ops/bincount.js"() {
    init_engine();
    init_kernel_names();
    init_tensor_util_env();
    init_util();
    init_operation();
    bincount = op({
      bincount_
    });
  }
});

// node_modules/@tensorflow/tfjs-core/dist/ops/bitwise_and.js
function bitwiseAnd_(x, y) {
  const $x = convertToTensor(x, "x", "bitwiseAnd");
  const $y = convertToTensor(y, "y", "bitwiseAnd");
  if (!arraysEqual($x.shape, $y.shape)) {
    throw new Error(`BitwiseAnd: Tensors must have the same shape. x: ${$x.shape}, y: ${$y.shape}`);
  }
  if ($x.dtype !== "int32" || $y.dtype !== "int32") {
    throw new Error(`BitwiseAnd: Only supports 'int32' values in tensor, found type of x: ${$x.dtype} and type of y: ${$y.dtype}`);
  }
  const inputs = {
    a: $x,
    b: $y
  };
  return ENGINE.runKernel(BitwiseAnd, inputs);
}
var bitwiseAnd;
var init_bitwise_and = __esm({
  "node_modules/@tensorflow/tfjs-core/dist/ops/bitwise_and.js"() {
    init_engine();
    init_kernel_names();
    init_tensor_util_env();
    init_util_base();
    init_operation();
    bitwiseAnd = op({
      bitwiseAnd_
    });
  }
});

// node_modules/@tensorflow/tfjs-core/dist/ops/broadcast_args.js
function broadcastArgs_(s0, s1) {
  const shape1Input = convertToTensor(s0, "s0", "broadcastArgs", "int32");
  const shape2Input = convertToTensor(s1, "s1", "broadcastArgs", "int32");
  if (shape1Input.rank !== 1) {
    throw new Error(`broadcastArgs(): first input must be a vector (rank=1). Has rank ${shape1Input.rank}`);
  }
  if (shape2Input.rank !== 1) {
    throw new Error(`broadcastArgs(): second input must be a vector (rank=1). Has rank ${shape2Input.rank}`);
  }
  const inputs = {
    s0: shape1Input,
    s1: shape2Input
  };
  return ENGINE.runKernel(BroadcastArgs, inputs);
}
var broadcastArgs;
var init_broadcast_args = __esm({
  "node_modules/@tensorflow/tfjs-core/dist/ops/broadcast_args.js"() {
    init_engine();
    init_kernel_names();
    init_tensor_util_env();
    init_operation();
    broadcastArgs = op({
      broadcastArgs_
    });
  }
});

// node_modules/@tensorflow/tfjs-core/dist/ops/broadcast_to.js
function broadcastTo_(x, shape) {
  let input = convertToTensor(x, "broadcastTo", "x");
  const xShape = input.shape;
  assertNonNegativeIntegerDimensions(shape);
  if (shape.length < input.rank) {
    throw new Error(`broadcastTo(): shape.length=${shape.length} < input.rank=${input.rank}.`);
  }
  if (shape.length > input.rank) {
    const newShape = input.shape.slice();
    while (newShape.length < shape.length) {
      newShape.unshift(1);
    }
    input = reshape(input, newShape);
  }
  const inputShape = input.shape;
  const reps = Array.from(shape);
  for (let i = shape.length - 1; i >= 0; i--) {
    if (inputShape[i] === shape[i]) {
      reps[i] = 1;
    } else if (input.shape[i] !== 1) {
      throw new Error(`broadcastTo(): [${xShape}] cannot be broadcast to [${shape}].`);
    }
  }
  const axes = reps.map((n, i) => n > 1 ? i : -1).filter((i) => i >= 0);
  if (axes.length === 0) {
    return clone(input);
  }
  const inputs = {
    x: input
  };
  const attrs = {
    reps
  };
  return ENGINE.runKernel(Tile, inputs, attrs);
}
var broadcastTo;
var init_broadcast_to = __esm({
  "node_modules/@tensorflow/tfjs-core/dist/ops/broadcast_to.js"() {
    init_engine();
    init_kernel_names();
    init_tensor_util_env();
    init_util_base();
    init_clone();
    init_operation();
    init_reshape();
    broadcastTo = op({
      broadcastTo_
    });
  }
});

// node_modules/@tensorflow/tfjs-core/dist/ops/ceil.js
function ceil_(x) {
  const $x = convertToTensor(x, "x", "ceil", "float32");
  const inputs = {
    x: $x
  };
  return ENGINE.runKernel(Ceil, inputs);
}
var ceil;
var init_ceil = __esm({
  "node_modules/@tensorflow/tfjs-core/dist/ops/ceil.js"() {
    init_engine();
    init_kernel_names();
    init_tensor_util_env();
    init_operation();
    ceil = op({
      ceil_
    });
  }
});

// node_modules/@tensorflow/tfjs-core/dist/ops/fill.js
function fill(shape, value, dtype) {
  assertNonNegativeIntegerDimensions(shape);
  dtype = dtype || inferDtype(value);
  const attrs = {
    shape,
    value,
    dtype
  };
  return ENGINE.runKernel(Fill, {}, attrs);
}
var init_fill = __esm({
  "node_modules/@tensorflow/tfjs-core/dist/ops/fill.js"() {
    init_engine();
    init_kernel_names();
    init_util();
    init_util_base();
  }
});

// node_modules/@tensorflow/tfjs-core/dist/ops/clip_by_value.js
function clipByValue_(x, clipValueMin, clipValueMax) {
  const $x = convertToTensor(x, "x", "clipByValue");
  assert(clipValueMin <= clipValueMax, () => `Error in clip: min (${clipValueMin}) must be less than or equal to max (${clipValueMax}).`);
  if (clipValueMin === clipValueMax) {
    return fill($x.shape, clipValueMin, $x.dtype);
  }
  const inputs = {
    x: $x
  };
  const attrs = {
    clipValueMin,
    clipValueMax
  };
  return ENGINE.runKernel(ClipByValue, inputs, attrs);
}
var clipByValue;
var init_clip_by_value = __esm({
  "node_modules/@tensorflow/tfjs-core/dist/ops/clip_by_value.js"() {
    init_engine();
    init_kernel_names();
    init_tensor_util_env();
    init_util();
    init_fill();
    init_operation();
    clipByValue = op({
      clipByValue_
    });
  }
});

// node_modules/@tensorflow/tfjs-core/dist/ops/concat_1d.js
function concat1d_(tensors) {
  return concat(
    tensors,
    0
    /* axis */
  );
}
var concat1d;
var init_concat_1d = __esm({
  "node_modules/@tensorflow/tfjs-core/dist/ops/concat_1d.js"() {
    init_concat();
    init_operation();
    concat1d = op({
      concat1d_
    });
  }
});

// node_modules/@tensorflow/tfjs-core/dist/ops/concat_2d.js
function concat2d_(tensors, axis) {
  return concat(tensors, axis);
}
var concat2d;
var init_concat_2d = __esm({
  "node_modules/@tensorflow/tfjs-core/dist/ops/concat_2d.js"() {
    init_concat();
    init_operation();
    concat2d = op({
      concat2d_
    });
  }
});

// node_modules/@tensorflow/tfjs-core/dist/ops/concat_3d.js
function concat3d_(tensors, axis) {
  return concat(tensors, axis);
}
var concat3d;
var init_concat_3d = __esm({
  "node_modules/@tensorflow/tfjs-core/dist/ops/concat_3d.js"() {
    init_concat();
    init_operation();
    concat3d = op({
      concat3d_
    });
  }
});

// node_modules/@tensorflow/tfjs-core/dist/ops/concat_4d.js
function concat4d_(tensors, axis) {
  return concat(tensors, axis);
}
var concat4d;
var init_concat_4d = __esm({
  "node_modules/@tensorflow/tfjs-core/dist/ops/concat_4d.js"() {
    init_concat();
    init_operation();
    concat4d = op({
      concat4d_
    });
  }
});

// node_modules/@tensorflow/tfjs-core/dist/ops/conv2d.js
function conv2d_(x, filter, strides, pad2, dataFormat = "NHWC", dilations = [1, 1], dimRoundingMode) {
  const $x = convertToTensor(x, "x", "conv2d", "float32");
  const $filter = convertToTensor(filter, "filter", "conv2d", "float32");
  let x4D = $x;
  let reshapedTo4D = false;
  if ($x.rank === 3) {
    reshapedTo4D = true;
    x4D = reshape($x, [1, $x.shape[0], $x.shape[1], $x.shape[2]]);
  }
  assert(x4D.rank === 4, () => `Error in conv2d: input must be rank 4, but got rank ${x4D.rank}.`);
  assert($filter.rank === 4, () => `Error in conv2d: filter must be rank 4, but got rank ${$filter.rank}.`);
  checkPadOnDimRoundingMode("conv2d", pad2, dimRoundingMode);
  const inDepth = dataFormat === "NHWC" ? x4D.shape[3] : x4D.shape[1];
  assert(inDepth === $filter.shape[2], () => `Error in conv2d: depth of input (${inDepth}) must match input depth for filter ${$filter.shape[2]}.`);
  assert(eitherStridesOrDilationsAreOne(strides, dilations), () => `Error in conv2D: Either strides or dilations must be 1. Got strides ${strides} and dilations '${dilations}'`);
  assert(stridesOrDilationsArePositive(dilations), () => "Error in conv2D: Dilated rates should be larger than 0.");
  assert(stridesOrDilationsArePositive(strides), () => "Error in conv2D: Strides should be larger than 0.");
  const inputs = {
    x: x4D,
    filter: $filter
  };
  const attrs = {
    strides,
    pad: pad2,
    dataFormat,
    dilations,
    dimRoundingMode
  };
  const res = ENGINE.runKernel(Conv2D, inputs, attrs);
  if (reshapedTo4D) {
    return reshape(res, [res.shape[1], res.shape[2], res.shape[3]]);
  }
  return res;
}
var conv2d;
var init_conv2d = __esm({
  "node_modules/@tensorflow/tfjs-core/dist/ops/conv2d.js"() {
    init_engine();
    init_kernel_names();
    init_tensor_util_env();
    init_util();
    init_conv_util();
    init_operation();
    init_reshape();
    conv2d = op({
      conv2d_
    });
  }
});

// node_modules/@tensorflow/tfjs-core/dist/ops/conv1d.js
function conv1d_(x, filter, stride, pad2, dataFormat = "NWC", dilation = 1, dimRoundingMode) {
  const $x = convertToTensor(x, "x", "conv1d");
  const $filter = convertToTensor(filter, "filter", "conv1d");
  let x3D = $x;
  let reshapedTo3D = false;
  if ($x.rank === 2) {
    reshapedTo3D = true;
    x3D = reshape($x, [1, $x.shape[0], $x.shape[1]]);
  }
  assert(x3D.rank === 3, () => `Error in conv1d: input must be rank 3, but got rank ${x3D.rank}.`);
  assert($filter.rank === 3, () => `Error in conv1d: filter must be rank 3, but got rank ${$filter.rank}.`);
  checkPadOnDimRoundingMode("conv1d", pad2, dimRoundingMode);
  assert(x3D.shape[2] === $filter.shape[1], () => `Error in conv1d: depth of input (${x3D.shape[2]}) must match input depth for filter ${$filter.shape[1]}.`);
  assert(eitherStridesOrDilationsAreOne(stride, dilation), () => `Error in conv1D: Either stride or dilation must be 1. Got stride ${stride} and dilation '${dilation}'`);
  assert(stridesOrDilationsArePositive(dilation), () => "Error in conv1D: Dilated rates should be larger than 0.");
  assert(stridesOrDilationsArePositive(stride), () => "Error in conv1D: Stride should be larger than 0.");
  assert(dataFormat === "NWC", () => `Error in conv1d: got dataFormat of ${dataFormat} but only NWC is currently supported.`);
  const filter4D = reshape($filter, [1, $filter.shape[0], $filter.shape[1], $filter.shape[2]]);
  const input4D = reshape(x3D, [x3D.shape[0], 1, x3D.shape[1], x3D.shape[2]]);
  const strides = [1, stride];
  const dilations = [1, dilation];
  const conv2dDataFormat = "NHWC";
  const res = conv2d(input4D, filter4D, strides, pad2, conv2dDataFormat, dilations, dimRoundingMode);
  if (reshapedTo3D) {
    return reshape(res, [res.shape[2], res.shape[3]]);
  }
  return reshape(res, [res.shape[0], res.shape[2], res.shape[3]]);
}
var conv1d;
var init_conv1d = __esm({
  "node_modules/@tensorflow/tfjs-core/dist/ops/conv1d.js"() {
    init_tensor_util_env();
    init_util();
    init_conv2d();
    init_conv_util();
    init_operation();
    init_reshape();
    conv1d = op({
      conv1d_
    });
  }
});

// node_modules/@tensorflow/tfjs-core/dist/ops/conv2d_backprop_input.js
function conv2DBackpropInput_(xShape, dy, filter, strides, pad2, dataFormat = "NHWC", dimRoundingMode) {
  assert(xShape.length === dy.rank, () => `Length of inShape (${xShape.length}) and rank of dy (${dy.rank}) must match`);
  let xShape4D = xShape;
  let dy4D = dy;
  let reshapedTo4D = false;
  if (dy.rank === 3) {
    reshapedTo4D = true;
    dy4D = reshape(dy, [1, dy.shape[0], dy.shape[1], dy.shape[2]]);
    xShape4D = [1, xShape[0], xShape[1], xShape[2]];
  }
  assert(xShape4D.length === 4, () => `Error in conv2dDerInput: inShape must be length 4, but got length ${xShape4D.length}.`);
  assert(dy4D.rank === 4, () => `Error in conv2dDerInput: dy must be rank 4, but got rank ${dy4D.rank}`);
  assert(filter.rank === 4, () => `Error in conv2dDerInput: filter must be rank 4, but got rank ${filter.rank}`);
  const inDepth = dataFormat === "NHWC" ? xShape4D[3] : xShape4D[1];
  const outDepth = dataFormat === "NHWC" ? dy4D.shape[3] : dy4D.shape[1];
  assert(inDepth === filter.shape[2], () => `Error in conv2dDerInput: depth of input (${inDepth}) must match input depth for filter ${filter.shape[2]}.`);
  assert(outDepth === filter.shape[3], () => `Error in conv2dDerInput: depth of output (${outDepth}) must match output depth for filter ${filter.shape[3]}.`);
  checkPadOnDimRoundingMode("conv2dDerInput", pad2, dimRoundingMode);
  const inputs = {
    dy: dy4D,
    filter
  };
  const attrs = {
    strides,
    pad: pad2,
    dataFormat,
    dimRoundingMode,
    inputShape: xShape4D
  };
  const res = ENGINE.runKernel(Conv2DBackpropInput, inputs, attrs);
  if (reshapedTo4D) {
    return reshape(res, [res.shape[1], res.shape[2], res.shape[3]]);
  }
  return res;
}
var conv2DBackpropInput;
var init_conv2d_backprop_input = __esm({
  "node_modules/@tensorflow/tfjs-core/dist/ops/conv2d_backprop_input.js"() {
    init_engine();
    init_kernel_names();
    init_util();
    init_conv_util();
    init_operation();
    init_reshape();
    conv2DBackpropInput = op({
      conv2DBackpropInput_
    });
  }
});

// node_modules/@tensorflow/tfjs-core/dist/ops/conv2d_transpose.js
function conv2dTranspose_(x, filter, outputShape, strides, pad2, dimRoundingMode) {
  const $x = convertToTensor(x, "x", "conv2dTranspose");
  const $filter = convertToTensor(filter, "filter", "conv2dTranspose");
  return conv2DBackpropInput(outputShape, $x, $filter, strides, pad2, "NHWC", dimRoundingMode);
}
var conv2dTranspose;
var init_conv2d_transpose = __esm({
  "node_modules/@tensorflow/tfjs-core/dist/ops/conv2d_transpose.js"() {
    init_tensor_util_env();
    init_conv2d_backprop_input();
    init_operation();
    conv2dTranspose = op({
      conv2dTranspose_
    });
  }
});

// node_modules/@tensorflow/tfjs-core/dist/ops/conv3d.js
function conv3d_(x, filter, strides, pad2, dataFormat = "NDHWC", dilations = [1, 1, 1]) {
  const $x = convertToTensor(x, "x", "conv3d");
  const $filter = convertToTensor(filter, "filter", "conv3d");
  let x5D = $x;
  let reshapedTo5D = false;
  if ($x.rank === 4) {
    reshapedTo5D = true;
    x5D = reshape($x, [1, $x.shape[0], $x.shape[1], $x.shape[2], $x.shape[3]]);
  }
  assert(x5D.rank === 5, () => `Error in conv3d: input must be rank 5, but got rank ${x5D.rank}.`);
  assert($filter.rank === 5, () => `Error in conv3d: filter must be rank 5, but got rank ${$filter.rank}.`);
  assert(x5D.shape[4] === $filter.shape[3], () => `Error in conv3d: depth of input (${x5D.shape[4]}) must match input depth for filter ${$filter.shape[3]}.`);
  assert(eitherStridesOrDilationsAreOne(strides, dilations), () => `Error in conv3D: Either strides or dilations must be 1. Got strides ${strides} and dilations '${dilations}'`);
  assert(dataFormat === "NDHWC", () => `Error in conv3d: got dataFormat of ${dataFormat} but only NDHWC is currently supported.`);
  assert(stridesOrDilationsArePositive(dilations), () => "Error in conv3D: Dilated rates should be larger than 0.");
  assert(stridesOrDilationsArePositive(strides), () => "Error in conv3D: Strides should be larger than 0.");
  const inputs = {
    x: x5D,
    filter: $filter
  };
  const attrs = {
    strides,
    pad: pad2,
    dataFormat,
    dilations
  };
  const res = ENGINE.runKernel(Conv3D, inputs, attrs);
  if (reshapedTo5D) {
    return reshape(res, [res.shape[1], res.shape[2], res.shape[3], res.shape[4]]);
  }
  return res;
}
var conv3d;
var init_conv3d = __esm({
  "node_modules/@tensorflow/tfjs-core/dist/ops/conv3d.js"() {
    init_engine();
    init_kernel_names();
    init_tensor_util_env();
    init_util();
    init_conv_util();
    init_operation();
    init_reshape();
    conv3d = op({
      conv3d_
    });
  }
});

// node_modules/@tensorflow/tfjs-core/dist/ops/conv3d_backprop_input.js
function conv3DBackpropInput_(xShape, dy, filter, strides, pad2) {
  assert(xShape.length === dy.rank, () => `Length of inShape (${xShape.length}) and rank of dy (${dy.rank}) must match`);
  let xShape5D = xShape;
  let dy5D = dy;
  let reshapedTo5D = false;
  if (dy.rank === 4) {
    reshapedTo5D = true;
    dy5D = reshape(dy, [1, dy.shape[0], dy.shape[1], dy.shape[2], dy.shape[3]]);
    xShape5D = [1, xShape[0], xShape[1], xShape[2], xShape[3]];
  }
  const inDepth = xShape5D[4];
  const outDepth = dy5D.shape[4];
  assert(xShape5D.length === 5, () => `Error in conv3dDerInput: inShape must be length 5, but got length ${xShape5D.length}.`);
  assert(dy5D.rank === 5, () => `Error in conv3dDerInput: dy must be rank 5, but got rank ${dy5D.rank}`);
  assert(filter.rank === 5, () => `Error in conv3dDerInput: filter must be rank 5, but got rank ${filter.rank}`);
  assert(inDepth === filter.shape[3], () => `Error in conv3dDerInput: depth of input (${inDepth}) must match input depth for filter ${filter.shape[3]}.`);
  assert(outDepth === filter.shape[4], () => `Error in conv3dDerInput: depth of output (${outDepth}) must match output depth for filter ${filter.shape[4]}.`);
  const inputs = {
    dy: dy5D,
    filter
  };
  const attrs = {
    pad: pad2,
    strides,
    inputShape: xShape5D
  };
  const res = ENGINE.runKernel(Conv3DBackpropInputV2, inputs, attrs);
  if (reshapedTo5D) {
    return reshape(res, [res.shape[1], res.shape[2], res.shape[3], res.shape[4]]);
  }
  return res;
}
var conv3DBackpropInput;
var init_conv3d_backprop_input = __esm({
  "node_modules/@tensorflow/tfjs-core/dist/ops/conv3d_backprop_input.js"() {
    init_engine();
    init_kernel_names();
    init_util();
    init_operation();
    init_reshape();
    conv3DBackpropInput = op({
      conv3DBackpropInput_
    });
  }
});

// node_modules/@tensorflow/tfjs-core/dist/ops/conv3d_transpose.js
function conv3dTranspose_(x, filter, outputShape, strides, pad2) {
  const $x = convertToTensor(x, "x", "conv3dTranspose");
  const $filter = convertToTensor(filter, "filter", "conv3dTranspose");
  return conv3DBackpropInput(outputShape, $x, $filter, strides, pad2);
}
var conv3dTranspose;
var init_conv3d_transpose = __esm({
  "node_modules/@tensorflow/tfjs-core/dist/ops/conv3d_transpose.js"() {
    init_tensor_util_env();
    init_conv3d_backprop_input();
    init_operation();
    conv3dTranspose = op({
      conv3dTranspose_
    });
  }
});

// node_modules/@tensorflow/tfjs-core/dist/ops/cos.js
function cos_(x) {
  const $x = convertToTensor(x, "x", "cos", "float32");
  const inputs = {
    x: $x
  };
  return ENGINE.runKernel(Cos, inputs);
}
var cos;
var init_cos = __esm({
  "node_modules/@tensorflow/tfjs-core/dist/ops/cos.js"() {
    init_engine();
    init_kernel_names();
    init_tensor_util_env();
    init_operation();
    cos = op({
      cos_
    });
  }
});

// node_modules/@tensorflow/tfjs-core/dist/ops/cosh.js
function cosh_(x) {
  const $x = convertToTensor(x, "x", "cosh", "float32");
  const inputs = {
    x: $x
  };
  return ENGINE.runKernel(Cosh, inputs);
}
var cosh;
var init_cosh = __esm({
  "node_modules/@tensorflow/tfjs-core/dist/ops/cosh.js"() {
    init_engine();
    init_kernel_names();
    init_tensor_util_env();
    init_operation();
    cosh = op({
      cosh_
    });
  }
});

// node_modules/@tensorflow/tfjs-core/dist/ops/cumprod.js
function cumprod_(x, axis = 0, exclusive = false, reverse2 = false) {
  const $x = convertToTensor(x, "x", "cumprod");
  const inputs = {
    x: $x
  };
  const attrs = {
    axis,
    exclusive,
    reverse: reverse2
  };
  return ENGINE.runKernel(Cumprod, inputs, attrs);
}
var cumprod;
var init_cumprod = __esm({
  "node_modules/@tensorflow/tfjs-core/dist/ops/cumprod.js"() {
    init_engine();
    init_kernel_names();
    init_tensor_util_env();
    init_operation();
    cumprod = op({
      cumprod_
    });
  }
});

// node_modules/@tensorflow/tfjs-core/dist/ops/cumsum.js
function cumsum_(x, axis = 0, exclusive = false, reverse2 = false) {
  const $x = convertToTensor(x, "x", "cumsum");
  const inputs = {
    x: $x
  };
  const attrs = {
    axis,
    exclusive,
    reverse: reverse2
  };
  return ENGINE.runKernel(Cumsum, inputs, attrs);
}
var cumsum;
var init_cumsum = __esm({
  "node_modules/@tensorflow/tfjs-core/dist/ops/cumsum.js"() {
    init_engine();
    init_kernel_names();
    init_tensor_util_env();
    init_operation();
    cumsum = op({
      cumsum_
    });
  }
});

// node_modules/@tensorflow/tfjs-core/dist/ops/dense_bincount.js
function denseBincount_(x, weights, size, binaryOutput = false) {
  const $x = convertToTensor(x, "x", "denseBincount");
  const $weights = convertToTensor(weights, "weights", "denseBincount");
  assert($x.dtype === "int32", () => `Error in denseBincount: input dtype must be int32, but got ${$x.dtype}`);
  assert($x.rank <= 2, () => `Error in denseBincount: input must be at most rank 2, but got rank ${$x.rank}.`);
  assert(size >= 0, () => `size must be non-negative, but got ${size}.`);
  assert($weights.size === $x.size || $weights.size === 0, () => `Error in denseBincount: weights must have the same shape as x or 0-length, but got x shape: ${$x.shape}, weights shape: ${$weights.shape}.`);
  const inputs = {
    x: $x,
    weights: $weights
  };
  const attrs = {
    size,
    binaryOutput
  };
  return ENGINE.runKernel(DenseBincount, inputs, attrs);
}
var denseBincount;
var init_dense_bincount = __esm({
  "node_modules/@tensorflow/tfjs-core/dist/ops/dense_bincount.js"() {
    init_engine();
    init_kernel_names();
    init_tensor_util_env();
    init_util();
    init_operation();
    denseBincount = op({
      denseBincount_
    });
  }
});

// node_modules/@tensorflow/tfjs-core/dist/ops/depth_to_space.js
function depthToSpace_(x, blockSize, dataFormat = "NHWC") {
  const $x = convertToTensor(x, "x", "depthToSpace", "float32");
  const inputHeight = dataFormat === "NHWC" ? $x.shape[1] : $x.shape[2];
  const inputWidth = dataFormat === "NHWC" ? $x.shape[2] : $x.shape[3];
  const inputDepth = dataFormat === "NHWC" ? $x.shape[3] : $x.shape[1];
  assert(blockSize > 1, () => `blockSize should be > 1 for depthToSpace, but was: ${blockSize}`);
  assert(inputHeight * blockSize >= 0, () => `Negative dimension size caused by overflow when multiplying
    ${inputHeight} and ${blockSize}  for depthToSpace with input shape
    ${$x.shape}`);
  assert(inputWidth * blockSize >= 0, () => `Negative dimension size caused by overflow when multiplying
    ${inputWidth} and ${blockSize} for depthToSpace with input shape
        ${$x.shape}`);
  assert(inputDepth % (blockSize * blockSize) === 0, () => `Dimension size must be evenly divisible by ${blockSize * blockSize} but is ${inputDepth} for depthToSpace with input shape ${$x.shape}`);
  const inputs = {
    x: $x
  };
  const attrs = {
    blockSize,
    dataFormat
  };
  return ENGINE.runKernel(DepthToSpace, inputs, attrs);
}
var depthToSpace;
var init_depth_to_space = __esm({
  "node_modules/@tensorflow/tfjs-core/dist/ops/depth_to_space.js"() {
    init_engine();
    init_kernel_names();
    init_tensor_util_env();
    init_util();
    init_operation();
    depthToSpace = op({
      depthToSpace_
    });
  }
});

// node_modules/@tensorflow/tfjs-core/dist/ops/depthwise_conv2d.js
function depthwiseConv2d_(x, filter, strides, pad2, dataFormat = "NHWC", dilations = [1, 1], dimRoundingMode) {
  const $x = convertToTensor(x, "x", "depthwiseConv2d", "float32");
  const $filter = convertToTensor(filter, "filter", "depthwiseConv2d", "float32");
  let x4D = $x;
  let reshapedTo4D = false;
  if ($x.rank === 3) {
    reshapedTo4D = true;
    x4D = reshape($x, [1, $x.shape[0], $x.shape[1], $x.shape[2]]);
  }
  assert(x4D.rank === 4, () => `Error in depthwiseConv2d: input must be rank 4, but got rank ${x4D.rank}.`);
  assert($filter.rank === 4, () => `Error in depthwiseConv2d: filter must be rank 4, but got rank ${$filter.rank}.`);
  const inChannels = dataFormat === "NHWC" ? x4D.shape[3] : x4D.shape[1];
  assert(inChannels === $filter.shape[2], () => `Error in depthwiseConv2d: number of input channels (${inChannels}) must match the inChannels dimension in filter ${$filter.shape[2]}.`);
  checkPadOnDimRoundingMode("depthwiseConv2d", pad2, dimRoundingMode);
  const inputs = {
    x: x4D,
    filter: $filter
  };
  const attrs = {
    strides,
    pad: pad2,
    dataFormat,
    dilations,
    dimRoundingMode
  };
  const res = ENGINE.runKernel(DepthwiseConv2dNative, inputs, attrs);
  if (reshapedTo4D) {
    return reshape(res, [res.shape[1], res.shape[2], res.shape[3]]);
  }
  return res;
}
var depthwiseConv2d;
var init_depthwise_conv2d = __esm({
  "node_modules/@tensorflow/tfjs-core/dist/ops/depthwise_conv2d.js"() {
    init_engine();
    init_kernel_names();
    init_tensor_util_env();
    init_util();
    init_conv_util();
    init_operation();
    init_reshape();
    depthwiseConv2d = op({
      depthwiseConv2d_
    });
  }
});

// node_modules/@tensorflow/tfjs-core/dist/ops/diag.js
function diag_(x) {
  const $x = convertToTensor(x, "x", "diag");
  const inputs = {
    x: $x
  };
  return ENGINE.runKernel(Diag, inputs);
}
var diag;
var init_diag = __esm({
  "node_modules/@tensorflow/tfjs-core/dist/ops/diag.js"() {
    init_engine();
    init_kernel_names();
    init_tensor_util_env();
    init_operation();
    diag = op({
      diag_
    });
  }
});

// node_modules/@tensorflow/tfjs-core/dist/ops/dilation2d.js
function dilation2d_(x, filter, strides, pad2, dilations = [1, 1], dataFormat = "NHWC") {
  const $x = convertToTensor(x, "x", "dilation2d");
  const $filter = convertToTensor(filter, "filter", "dilation2d");
  assert($x.rank === 3 || $x.rank === 4, () => `Error in dilation2d: input must be rank 3 or 4, but got rank ${$x.rank}.`);
  assert($filter.rank === 3, () => `Error in dilation2d: filter must be rank 3, but got rank ${$filter.rank}.`);
  assert(dataFormat === "NHWC", () => `Error in dilation2d: Only NHWC is currently supported, but got dataFormat of ${dataFormat}`);
  let x4D = $x;
  let reshapedTo4D = false;
  if ($x.rank === 3) {
    x4D = reshape($x, [1, $x.shape[0], $x.shape[1], $x.shape[2]]);
    reshapedTo4D = true;
  }
  assert(x4D.shape[3] === $filter.shape[2], () => `Error in dilation2d:  input and filter must have the same depth: ${x4D.shape[3]} vs ${$filter.shape[2]}`);
  const inputs = {
    x: x4D,
    filter: $filter
  };
  const attrs = {
    strides,
    pad: pad2,
    dilations
  };
  const res = ENGINE.runKernel(Dilation2D, inputs, attrs);
  if (reshapedTo4D) {
    return reshape(res, [res.shape[1], res.shape[2], res.shape[3]]);
  }
  return res;
}
var dilation2d;
var init_dilation2d = __esm({
  "node_modules/@tensorflow/tfjs-core/dist/ops/dilation2d.js"() {
    init_engine();
    init_kernel_names();
    init_tensor_util_env();
    init_util();
    init_operation();
    init_reshape();
    dilation2d = op({
      dilation2d_
    });
  }
});

// node_modules/@tensorflow/tfjs-core/dist/ops/broadcast_util.js
var broadcast_util_exports = {};
__export(broadcast_util_exports, {
  assertAndGetBroadcastShape: () => assertAndGetBroadcastShape,
  getBroadcastDims: () => getBroadcastDims,
  getReductionAxes: () => getReductionAxes
});
function getBroadcastDims(inShape, outShape) {
  const inRank = inShape.length;
  const dims = [];
  for (let i = 0; i < inRank; i++) {
    const dim = inRank - 1 - i;
    const a = inShape[dim] || 1;
    const b = outShape[outShape.length - 1 - i] || 1;
    if (b > 1 && a === 1) {
      dims.unshift(dim);
    }
  }
  return dims;
}
function getReductionAxes(inShape, outShape) {
  const result = [];
  for (let i = 0; i < outShape.length; i++) {
    const inDim = inShape[inShape.length - i - 1];
    const outAxis = outShape.length - i - 1;
    const outDim = outShape[outAxis];
    if (inDim == null || inDim === 1 && outDim > 1) {
      result.unshift(outAxis);
    }
  }
  return result;
}
function assertAndGetBroadcastShape(shapeA, shapeB) {
  const l = Math.max(shapeA.length, shapeB.length);
  const result = new Array(l);
  for (let i = 0; i < l; i++) {
    let a = shapeA[shapeA.length - i - 1];
    if (a == null) {
      a = 1;
    }
    let b = shapeB[shapeB.length - i - 1];
    if (b == null) {
      b = 1;
    }
    if (a === 1) {
      result[l - i - 1] = b;
    } else if (b === 1) {
      result[l - i - 1] = a;
    } else if (a !== b) {
      const errMsg = `Operands could not be broadcast together with shapes ${shapeA} and ${shapeB}.`;
      throw Error(errMsg);
    } else {
      result[l - i - 1] = a;
    }
  }
  return result;
}
var init_broadcast_util = __esm({
  "node_modules/@tensorflow/tfjs-core/dist/ops/broadcast_util.js"() {
  }
});

// node_modules/@tensorflow/tfjs-core/dist/ops/equal.js
function equal_(a, b) {
  let $a = convertToTensor(a, "a", "equal", "string_or_numeric");
  let $b = convertToTensor(b, "b", "equal", "string_or_numeric");
  [$a, $b] = makeTypesMatch($a, $b);
  assertAndGetBroadcastShape($a.shape, $b.shape);
  const inputs = {
    a: $a,
    b: $b
  };
  return ENGINE.runKernel(Equal, inputs);
}
var equal;
var init_equal = __esm({
  "node_modules/@tensorflow/tfjs-core/dist/ops/equal.js"() {
    init_engine();
    init_kernel_names();
    init_tensor_util();
    init_tensor_util_env();
    init_broadcast_util();
    init_operation();
    equal = op({
      equal_
    });
  }
});

// node_modules/@tensorflow/tfjs-core/dist/ops/where.js
function where_(condition, a, b) {
  const $a = convertToTensor(a, "a", "where");
  const $b = convertToTensor(b, "b", "where");
  const $condition = convertToTensor(condition, "condition", "where", "bool");
  const broadcastShape = assertAndGetBroadcastShape(assertAndGetBroadcastShape($condition.shape, $a.shape), $b.shape);
  const $broadcastedCondition = broadcastTo($condition, broadcastShape);
  const $broadcastedA = broadcastTo($a, broadcastShape);
  const $broadcastedB = broadcastTo($b, broadcastShape);
  const inputs = {
    condition: $broadcastedCondition,
    t: $broadcastedA,
    e: $broadcastedB
  };
  return ENGINE.runKernel(Select, inputs);
}
var where;
var init_where = __esm({
  "node_modules/@tensorflow/tfjs-core/dist/ops/where.js"() {
    init_engine();
    init_kernel_names();
    init_tensor_util_env();
    init_broadcast_to();
    init_broadcast_util();
    init_operation();
    where = op({
      where_
    });
  }
});

// node_modules/@tensorflow/tfjs-core/dist/ops/zeros_like.js
function zerosLike_(x) {
  const $x = convertToTensor(x, "x", "zerosLike");
  const inputs = {
    x: $x
  };
  return ENGINE.runKernel(ZerosLike, inputs);
}
var zerosLike;
var init_zeros_like = __esm({
  "node_modules/@tensorflow/tfjs-core/dist/ops/zeros_like.js"() {
    init_engine();
    init_kernel_names();
    init_tensor_util_env();
    init_operation();
    zerosLike = op({
      zerosLike_
    });
  }
});

// node_modules/@tensorflow/tfjs-core/dist/ops/div_no_nan.js
function divNoNan_(a, b) {
  let $a = convertToTensor(a, "a", "div");
  let $b = convertToTensor(b, "b", "div");
  [$a, $b] = makeTypesMatch($a, $b);
  const divResult = div($a, $b);
  const zeros3 = zerosLike(divResult);
  const bEqualsZero = equal($b, zeros3);
  return where(bEqualsZero, zeros3, divResult);
}
var divNoNan;
var init_div_no_nan = __esm({
  "node_modules/@tensorflow/tfjs-core/dist/ops/div_no_nan.js"() {
    init_tensor_util();
    init_tensor_util_env();
    init_div();
    init_equal();
    init_operation();
    init_where();
    init_zeros_like();
    divNoNan = op({
      divNoNan_
    });
  }
});

// node_modules/@tensorflow/tfjs-core/dist/ops/dot.js
function dot_(t1, t2) {
  const $t1 = convertToTensor(t1, "t1", "dot");
  const $t2 = convertToTensor(t2, "t2", "dot");
  assert(($t1.rank === 1 || $t1.rank === 2) && ($t2.rank === 1 || $t2.rank === 2), () => `Error in dot: inputs must all be rank 1 or 2, but got ranks ${$t1.rank} and ${$t2.rank}.`);
  const t1Inner = $t1.rank === 1 ? $t1.size : $t1.shape[1];
  const t2Inner = $t2.rank === 1 ? $t2.size : $t2.shape[0];
  assert(t1Inner === t2Inner, () => `Error in dot: inner dimensions of inputs must match, but got ${t1Inner} and ${t2Inner}.`);
  if ($t1.rank === 1 && $t2.rank === 1) {
    const t12D = reshape($t1, [1, -1]);
    const t22D = reshape($t2, [-1, 1]);
    const t1t2 = matMul(t12D, t22D);
    return reshape(t1t2, []);
  } else if ($t1.rank === 1 && $t2.rank === 2) {
    const t12D = reshape($t1, [1, -1]);
    const t22D = reshape($t2, [$t2.shape[0], $t2.shape[1]]);
    const t1t2 = matMul(t12D, t22D);
    return reshape(t1t2, [t1t2.size]);
  } else if ($t1.rank === 2 && $t2.rank === 1) {
    const t22D = reshape($t2, [-1, 1]);
    const t1t2 = matMul($t1, t22D);
    return reshape(t1t2, [t1t2.size]);
  } else {
    const t22D = reshape($t2, [$t2.shape[0], $t2.shape[1]]);
    const t1t2 = matMul($t1, t22D);
    return t1t2;
  }
}
var dot;
var init_dot = __esm({
  "node_modules/@tensorflow/tfjs-core/dist/ops/dot.js"() {
    init_tensor_util_env();
    init_util();
    init_mat_mul();
    init_operation();
    init_reshape();
    dot = op({
      dot_
    });
  }
});

// node_modules/@tensorflow/tfjs-core/dist/ops/einsum.js
function einsum_(equation, ...tensors) {
  const $tensors = tensors.map((t, i) => convertToTensor(t, `tensors${i}`, "einsum"));
  const attrs = {
    equation
  };
  return ENGINE.runKernel(Einsum, $tensors, attrs);
}
var einsum;
var init_einsum = __esm({
  "node_modules/@tensorflow/tfjs-core/dist/ops/einsum.js"() {
    init_engine();
    init_kernel_names();
    init_tensor_util_env();
    init_operation();
    einsum = op({
      einsum_
    });
  }
});

// node_modules/@tensorflow/tfjs-core/dist/ops/elu.js
function elu_(x) {
  const $x = convertToTensor(x, "x", "elu", "float32");
  const inputs = {
    x: $x
  };
  return ENGINE.runKernel(Elu, inputs);
}
var elu;
var init_elu = __esm({
  "node_modules/@tensorflow/tfjs-core/dist/ops/elu.js"() {
    init_engine();
    init_kernel_names();
    init_tensor_util_env();
    init_operation();
    elu = op({
      elu_
    });
  }
});

// node_modules/@tensorflow/tfjs-core/dist/ops/ensure_shape.js
function ensureShape_(x, shape) {
  const $x = convertToTensor(x, "x", "ensureShape", "string_or_numeric");
  if (!arraysEqualWithNull($x.shape, shape)) {
    throw new Error(`EnsureShape: Shape of tensor ${$x.shape} is not compatible with expected shape ${shape}`);
  }
  return x;
}
var ensureShape;
var init_ensure_shape = __esm({
  "node_modules/@tensorflow/tfjs-core/dist/ops/ensure_shape.js"() {
    init_tensor_util_env();
    init_util_base();
    init_operation();
    ensureShape = op({
      ensureShape_
    });
  }
});

// node_modules/@tensorflow/tfjs-core/dist/ops/erf.js
function erf_(x) {
  let $x = convertToTensor(x, "x", "erf");
  assert($x.dtype === "int32" || $x.dtype === "float32", () => "Input dtype must be `int32` or `float32`.");
  if ($x.dtype === "int32") {
    $x = cast($x, "float32");
  }
  const inputs = {
    x: $x
  };
  return ENGINE.runKernel(Erf, inputs);
}
var erf;
var init_erf = __esm({
  "node_modules/@tensorflow/tfjs-core/dist/ops/erf.js"() {
    init_engine();
    init_kernel_names();
    init_tensor_util_env();
    init_util();
    init_cast();
    init_operation();
    erf = op({
      erf_
    });
  }
});

// node_modules/@tensorflow/tfjs-core/dist/ops/max.js
function max_(x, axis = null, keepDims = false) {
  const $x = convertToTensor(x, "x", "max");
  const inputs = {
    x: $x
  };
  const attrs = {
    reductionIndices: axis,
    keepDims
  };
  return ENGINE.runKernel(Max, inputs, attrs);
}
var max;
var init_max = __esm({
  "node_modules/@tensorflow/tfjs-core/dist/ops/max.js"() {
    init_engine();
    init_kernel_names();
    init_tensor_util_env();
    init_operation();
    max = op({
      max_
    });
  }
});

// node_modules/@tensorflow/tfjs-core/dist/ops/min.js
function min_(x, axis = null, keepDims = false) {
  const $x = convertToTensor(x, "x", "min");
  const inputs = {
    x: $x
  };
  const attrs = {
    axis,
    keepDims
  };
  return ENGINE.runKernel(Min, inputs, attrs);
}
var min;
var init_min = __esm({
  "node_modules/@tensorflow/tfjs-core/dist/ops/min.js"() {
    init_engine();
    init_kernel_names();
    init_tensor_util_env();
    init_operation();
    min = op({
      min_
    });
  }
});

// node_modules/@tensorflow/tfjs-core/dist/ops/pow.js
function pow_(base, exp3) {
  let $base = convertToTensor(base, "base", "pow");
  let $exp = convertToTensor(exp3, "exp", "pow");
  [$base, $exp] = makeTypesMatch($base, $exp);
  const inputs = {
    a: $base,
    b: $exp
  };
  return ENGINE.runKernel(Pow, inputs);
}
var pow;
var init_pow = __esm({
  "node_modules/@tensorflow/tfjs-core/dist/ops/pow.js"() {
    init_engine();
    init_kernel_names();
    init_tensor_util();
    init_tensor_util_env();
    init_operation();
    pow = op({
      pow_
    });
  }
});

// node_modules/@tensorflow/tfjs-core/dist/ops/scalar.js
function scalar(value, dtype) {
  if ((isTypedArray(value) && dtype !== "string" || Array.isArray(value)) && dtype !== "complex64") {
    throw new Error("Error creating a new Scalar: value must be a primitive (number|boolean|string)");
  }
  if (dtype === "string" && isTypedArray(value) && !(value instanceof Uint8Array)) {
    throw new Error("When making a scalar from encoded string, the value must be `Uint8Array`.");
  }
  const shape = [];
  const inferredShape = [];
  return makeTensor(value, shape, inferredShape, dtype);
}
var init_scalar = __esm({
  "node_modules/@tensorflow/tfjs-core/dist/ops/scalar.js"() {
    init_util();
    init_tensor_ops_util();
  }
});

// node_modules/@tensorflow/tfjs-core/dist/ops/sqrt.js
function sqrt_(x) {
  const $x = convertToTensor(x, "x", "sqrt", "float32");
  const inputs = {
    x: $x
  };
  return ENGINE.runKernel(Sqrt, inputs);
}
var sqrt;
var init_sqrt = __esm({
  "node_modules/@tensorflow/tfjs-core/dist/ops/sqrt.js"() {
    init_engine();
    init_kernel_names();
    init_tensor_util_env();
    init_operation();
    sqrt = op({
      sqrt_
    });
  }
});

// node_modules/@tensorflow/tfjs-core/dist/ops/square.js
function square_(x) {
  const $x = convertToTensor(x, "x", "square");
  const attrs = {};
  return ENGINE.runKernel("Square", {
    x: $x
  }, attrs);
}
var square;
var init_square = __esm({
  "node_modules/@tensorflow/tfjs-core/dist/ops/square.js"() {
    init_engine();
    init_tensor_util_env();
    init_operation();
    square = op({
      square_
    });
  }
});

// node_modules/@tensorflow/tfjs-core/dist/ops/sum.js
function sum_(x, axis = null, keepDims = false) {
  let $x = convertToTensor(x, "x", "sum");
  if ($x.dtype === "bool") {
    $x = cast($x, "int32");
  }
  const inputs = {
    x: $x
  };
  const attrs = {
    axis,
    keepDims
  };
  return ENGINE.runKernel(Sum, inputs, attrs);
}
var sum2;
var init_sum = __esm({
  "node_modules/@tensorflow/tfjs-core/dist/ops/sum.js"() {
    init_engine();
    init_kernel_names();
    init_tensor_util_env();
    init_cast();
    init_operation();
    sum2 = op({
      sum_
    });
  }
});

// node_modules/@tensorflow/tfjs-core/dist/ops/axis_util.js
function axesAreInnerMostDims(axes, rank) {
  for (let i = 0; i < axes.length; ++i) {
    if (axes[axes.length - i - 1] !== rank - 1 - i) {
      return false;
    }
  }
  return true;
}
function combineLocations(outputLoc, reduceLoc, axes) {
  const rank = outputLoc.length + reduceLoc.length;
  const loc = [];
  let outIdx = 0;
  let reduceIdx = 0;
  for (let dim = 0; dim < rank; dim++) {
    if (axes.indexOf(dim) === -1) {
      loc.push(outputLoc[outIdx++]);
    } else {
      loc.push(reduceLoc[reduceIdx++]);
    }
  }
  return loc;
}
function computeOutAndReduceShapes(aShape, axes) {
  const outShape = [];
  const rank = aShape.length;
  for (let dim = 0; dim < rank; dim++) {
    if (axes.indexOf(dim) === -1) {
      outShape.push(aShape[dim]);
    }
  }
  const reduceShape = axes.map((dim) => aShape[dim]);
  return [outShape, reduceShape];
}
function expandShapeToKeepDim(shape, axes) {
  const reduceSubShape = axes.map((x) => 1);
  return combineLocations(shape, reduceSubShape, axes);
}
function assertAxesAreInnerMostDims(msg, axes, rank) {
  assert(axesAreInnerMostDims(axes, rank), () => `${msg} supports only inner-most axes for now. Got axes ${axes} and rank-${rank} input.`);
}
function getAxesPermutation(axes, rank) {
  if (axesAreInnerMostDims(axes, rank)) {
    return null;
  }
  const result = [];
  for (let i = 0; i < rank; ++i) {
    if (axes.indexOf(i) === -1) {
      result.push(i);
    }
  }
  axes.forEach((axis) => result.push(axis));
  return result;
}
function getUndoAxesPermutation(axes) {
  return axes.map((axis, i) => [i, axis]).sort((a, b) => a[1] - b[1]).map((x) => x[0]);
}
function getInnerMostAxes(numAxes, rank) {
  const res = [];
  for (let i = rank - numAxes; i < rank; ++i) {
    res.push(i);
  }
  return res;
}
var init_axis_util = __esm({
  "node_modules/@tensorflow/tfjs-core/dist/ops/axis_util.js"() {
    init_util();
  }
});

// node_modules/@tensorflow/tfjs-core/dist/ops/norm.js
function norm_(x, ord = "euclidean", axis = null, keepDims = false) {
  x = convertToTensor(x, "x", "norm");
  const norm2 = normImpl(x, ord, axis);
  let keepDimsShape = norm2.shape;
  if (keepDims) {
    const axes = parseAxisParam(axis, x.shape);
    keepDimsShape = expandShapeToKeepDim(norm2.shape, axes);
  }
  return reshape(norm2, keepDimsShape);
}
function normImpl(x, p, axis = null) {
  if (x.rank === 0) {
    return abs(x);
  }
  if (x.rank !== 1 && axis === null) {
    return normImpl(reshape(x, [-1]), p, axis);
  }
  if (x.rank === 1 || typeof axis === "number" || Array.isArray(axis) && axis.length === 1) {
    if (p === 1) {
      return sum2(abs(x), axis);
    }
    if (p === Infinity) {
      return max(abs(x), axis);
    }
    if (p === -Infinity) {
      return min(abs(x), axis);
    }
    if (p === "euclidean" || p === 2) {
      return sqrt(sum2(pow(abs(x), scalar(2, "int32")), axis));
    }
    throw new Error(`Error in norm: invalid ord value: ${p}`);
  }
  if (Array.isArray(axis) && axis.length === 2) {
    if (p === 1) {
      return max(sum2(abs(x), axis[0]), axis[1] - 1);
    }
    if (p === Infinity) {
      return max(sum2(abs(x), axis[1]), axis[0]);
    }
    if (p === -Infinity) {
      return min(sum2(abs(x), axis[1]), axis[0]);
    }
    if (p === "fro" || p === "euclidean") {
      return sqrt(sum2(square(x), axis));
    }
    throw new Error(`Error in norm: invalid ord value: ${p}`);
  }
  throw new Error(`Error in norm: invalid axis: ${axis}`);
}
var norm;
var init_norm = __esm({
  "node_modules/@tensorflow/tfjs-core/dist/ops/norm.js"() {
    init_tensor_util_env();
    init_util();
    init_abs();
    init_axis_util();
    init_max();
    init_min();
    init_operation();
    init_pow();
    init_reshape();
    init_scalar();
    init_sqrt();
    init_square();
    init_sum();
    norm = op({
      norm_
    });
  }
});

// node_modules/@tensorflow/tfjs-core/dist/ops/euclidean_norm.js
function euclideanNorm_(x, axis = null, keepDims = false) {
  return norm(x, "euclidean", axis, keepDims);
}
var euclideanNorm;
var init_euclidean_norm = __esm({
  "node_modules/@tensorflow/tfjs-core/dist/ops/euclidean_norm.js"() {
    init_norm();
    init_operation();
    euclideanNorm = op({
      euclideanNorm_
    });
  }
});

// node_modules/@tensorflow/tfjs-core/dist/ops/exp.js
function exp_(x) {
  const $x = convertToTensor(x, "x", "exp");
  const inputs = {
    x: $x
  };
  return ENGINE.runKernel(Exp, inputs);
}
var exp;
var init_exp = __esm({
  "node_modules/@tensorflow/tfjs-core/dist/ops/exp.js"() {
    init_engine();
    init_kernel_names();
    init_tensor_util_env();
    init_operation();
    exp = op({
      exp_
    });
  }
});

// node_modules/@tensorflow/tfjs-core/dist/ops/expand_dims.js
function expandDims_(x, axis = 0) {
  const $x = convertToTensor(x, "x", "expandDims", "string_or_numeric");
  assert(axis <= $x.rank, () => "Axis must be <= rank of the tensor");
  const inputs = {
    input: $x
  };
  const attrs = {
    dim: axis
  };
  return ENGINE.runKernel(ExpandDims, inputs, attrs);
}
var expandDims;
var init_expand_dims = __esm({
  "node_modules/@tensorflow/tfjs-core/dist/ops/expand_dims.js"() {
    init_engine();
    init_kernel_names();
    init_tensor_util_env();
    init_util();
    init_operation();
    expandDims = op({
      expandDims_
    });
  }
});

// node_modules/@tensorflow/tfjs-core/dist/ops/expm1.js
function expm1_(x) {
  const $x = convertToTensor(x, "x", "expm1");
  const inputs = {
    x: $x
  };
  return ENGINE.runKernel(Expm1, inputs);
}
var expm1;
var init_expm1 = __esm({
  "node_modules/@tensorflow/tfjs-core/dist/ops/expm1.js"() {
    init_engine();
    init_kernel_names();
    init_tensor_util_env();
    init_operation();
    expm1 = op({
      expm1_
    });
  }
});

// node_modules/@tensorflow/tfjs-core/dist/ops/tile.js
function tile_(x, reps) {
  const $x = convertToTensor(x, "x", "tile", "string_or_numeric");
  assert($x.rank === reps.length, () => `Error in transpose: rank of input ${$x.rank} must match length of reps ${reps}.`);
  const inputs = {
    x: $x
  };
  const attrs = {
    reps
  };
  return ENGINE.runKernel(Tile, inputs, attrs);
}
var tile;
var init_tile = __esm({
  "node_modules/@tensorflow/tfjs-core/dist/ops/tile.js"() {
    init_engine();
    init_kernel_names();
    init_tensor_util_env();
    init_util();
    init_operation();
    tile = op({
      tile_
    });
  }
});

// node_modules/@tensorflow/tfjs-core/dist/ops/eye.js
function eye_(numRows, numColumns, batchShape, dtype = "float32") {
  if (numColumns == null) {
    numColumns = numRows;
  }
  const buff = buffer([numRows, numColumns], dtype);
  const n = numRows <= numColumns ? numRows : numColumns;
  for (let i = 0; i < n; ++i) {
    buff.set(1, i, i);
  }
  const out = reshape(buff.toTensor(), [numRows, numColumns]);
  if (batchShape == null) {
    return out;
  } else {
    if (batchShape.length === 1) {
      return tile(expandDims(out, 0), [batchShape[0], 1, 1]);
    } else if (batchShape.length === 2) {
      return tile(expandDims(expandDims(out, 0), 0), [batchShape[0], batchShape[1], 1, 1]);
    } else if (batchShape.length === 3) {
      return tile(expandDims(expandDims(expandDims(out, 0), 0), 0), [batchShape[0], batchShape[1], batchShape[2], 1, 1]);
    } else {
      throw new Error(`eye() currently supports only 1D and 2D batchShapes, but received ${batchShape.length}D.`);
    }
  }
}
var eye;
var init_eye = __esm({
  "node_modules/@tensorflow/tfjs-core/dist/ops/eye.js"() {
    init_buffer();
    init_expand_dims();
    init_operation();
    init_reshape();
    init_tile();
    eye = op({
      eye_
    });
  }
});

// node_modules/@tensorflow/tfjs-core/dist/ops/floor.js
function floor_(x) {
  const $x = convertToTensor(x, "x", "floor", "float32");
  const inputs = {
    x: $x
  };
  return ENGINE.runKernel(Floor, inputs);
}
var floor;
var init_floor = __esm({
  "node_modules/@tensorflow/tfjs-core/dist/ops/floor.js"() {
    init_engine();
    init_kernel_names();
    init_tensor_util_env();
    init_operation();
    floor = op({
      floor_
    });
  }
});

// node_modules/@tensorflow/tfjs-core/dist/ops/gather.js
function gather_(x, indices, axis = 0, batchDims = 0) {
  const $x = convertToTensor(x, "x", "gather");
  const $indices = convertToTensor(indices, "indices", "gather", "int32");
  const inputs = {
    x: $x,
    indices: $indices
  };
  const attrs = {
    axis,
    batchDims
  };
  return ENGINE.runKernel(GatherV2, inputs, attrs);
}
var gather;
var init_gather = __esm({
  "node_modules/@tensorflow/tfjs-core/dist/ops/gather.js"() {
    init_engine();
    init_kernel_names();
    init_tensor_util_env();
    init_operation();
    gather = op({
      gather_
    });
  }
});

// node_modules/@tensorflow/tfjs-core/dist/ops/greater.js
function greater_(a, b) {
  let $a = convertToTensor(a, "a", "greater", "string_or_numeric");
  let $b = convertToTensor(b, "b", "greater", "string_or_numeric");
  [$a, $b] = makeTypesMatch($a, $b);
  assertAndGetBroadcastShape($a.shape, $b.shape);
  const inputs = {
    a: $a,
    b: $b
  };
  return ENGINE.runKernel(Greater, inputs);
}
var greater;
var init_greater = __esm({
  "node_modules/@tensorflow/tfjs-core/dist/ops/greater.js"() {
    init_engine();
    init_kernel_names();
    init_tensor_util();
    init_tensor_util_env();
    init_broadcast_util();
    init_operation();
    greater = op({
      greater_
    });
  }
});

// node_modules/@tensorflow/tfjs-core/dist/ops/greater_equal.js
function greaterEqual_(a, b) {
  let $a = convertToTensor(a, "a", "greaterEqual", "string_or_numeric");
  let $b = convertToTensor(b, "b", "greaterEqual", "string_or_numeric");
  [$a, $b] = makeTypesMatch($a, $b);
  assertAndGetBroadcastShape($a.shape, $b.shape);
  const inputs = {
    a: $a,
    b: $b
  };
  return ENGINE.runKernel(GreaterEqual, inputs);
}
var greaterEqual;
var init_greater_equal = __esm({
  "node_modules/@tensorflow/tfjs-core/dist/ops/greater_equal.js"() {
    init_engine();
    init_kernel_names();
    init_tensor_util();
    init_tensor_util_env();
    init_broadcast_util();
    init_operation();
    greaterEqual = op({
      greaterEqual_
    });
  }
});

// node_modules/@tensorflow/tfjs-core/dist/ops/imag.js
function imag_(input) {
  const $input = convertToTensor(input, "input", "imag");
  const inputs = {
    input: $input
  };
  return ENGINE.runKernel(Imag, inputs);
}
var imag;
var init_imag = __esm({
  "node_modules/@tensorflow/tfjs-core/dist/ops/imag.js"() {
    init_engine();
    init_kernel_names();
    init_tensor_util_env();
    init_operation();
    imag = op({
      imag_
    });
  }
});

// node_modules/@tensorflow/tfjs-core/dist/ops/is_finite.js
function isFinite_(x) {
  const $x = convertToTensor(x, "x", "isFinite");
  const inputs = {
    x: $x
  };
  return ENGINE.runKernel(IsFinite, inputs);
}
var isFinite2;
var init_is_finite = __esm({
  "node_modules/@tensorflow/tfjs-core/dist/ops/is_finite.js"() {
    init_engine();
    init_kernel_names();
    init_tensor_util_env();
    init_operation();
    isFinite2 = op({
      isFinite_
    });
  }
});

// node_modules/@tensorflow/tfjs-core/dist/ops/is_inf.js
function isInf_(x) {
  const $x = convertToTensor(x, "x", "isInf");
  const inputs = {
    x: $x
  };
  return ENGINE.runKernel(IsInf, inputs);
}
var isInf;
var init_is_inf = __esm({
  "node_modules/@tensorflow/tfjs-core/dist/ops/is_inf.js"() {
    init_engine();
    init_kernel_names();
    init_tensor_util_env();
    init_operation();
    isInf = op({
      isInf_
    });
  }
});

// node_modules/@tensorflow/tfjs-core/dist/ops/is_nan.js
function isNaN_(x) {
  const $x = convertToTensor(x, "x", "isNaN");
  const inputs = {
    x: $x
  };
  return ENGINE.runKernel(IsNan, inputs);
}
var isNaN2;
var init_is_nan = __esm({
  "node_modules/@tensorflow/tfjs-core/dist/ops/is_nan.js"() {
    init_engine();
    init_kernel_names();
    init_tensor_util_env();
    init_operation();
    isNaN2 = op({
      isNaN_
    });
  }
});

// node_modules/@tensorflow/tfjs-core/dist/ops/leaky_relu.js
function leakyRelu_(x, alpha = 0.2) {
  const $x = convertToTensor(x, "x", "leakyRelu");
  const inputs = {
    x: $x
  };
  const attrs = {
    alpha
  };
  return ENGINE.runKernel(LeakyRelu, inputs, attrs);
}
var leakyRelu;
var init_leaky_relu = __esm({
  "node_modules/@tensorflow/tfjs-core/dist/ops/leaky_relu.js"() {
    init_engine();
    init_kernel_names();
    init_tensor_util_env();
    init_operation();
    leakyRelu = op({
      leakyRelu_
    });
  }
});

// node_modules/@tensorflow/tfjs-core/dist/ops/less.js
function less_(a, b) {
  let $a = convertToTensor(a, "a", "less", "string_or_numeric");
  let $b = convertToTensor(b, "b", "less", "string_or_numeric");
  [$a, $b] = makeTypesMatch($a, $b);
  assertAndGetBroadcastShape($a.shape, $b.shape);
  const inputs = {
    a: $a,
    b: $b
  };
  return ENGINE.runKernel(Less, inputs);
}
var less;
var init_less = __esm({
  "node_modules/@tensorflow/tfjs-core/dist/ops/less.js"() {
    init_engine();
    init_kernel_names();
    init_tensor_util();
    init_tensor_util_env();
    init_broadcast_util();
    init_operation();
    less = op({
      less_
    });
  }
});

// node_modules/@tensorflow/tfjs-core/dist/ops/less_equal.js
function lessEqual_(a, b) {
  let $a = convertToTensor(a, "a", "lessEqual", "string_or_numeric");
  let $b = convertToTensor(b, "b", "lessEqual", "string_or_numeric");
  [$a, $b] = makeTypesMatch($a, $b);
  assertAndGetBroadcastShape($a.shape, $b.shape);
  const inputs = {
    a: $a,
    b: $b
  };
  return ENGINE.runKernel(LessEqual, inputs);
}
var lessEqual;
var init_less_equal = __esm({
  "node_modules/@tensorflow/tfjs-core/dist/ops/less_equal.js"() {
    init_engine();
    init_kernel_names();
    init_tensor_util();
    init_tensor_util_env();
    init_broadcast_util();
    init_operation();
    lessEqual = op({
      lessEqual_
    });
  }
});

// node_modules/@tensorflow/tfjs-core/dist/ops/linspace.js
function linspace(start, stop, num) {
  if (num <= 0) {
    throw new Error("The number of values should be positive.");
  }
  const attrs = {
    start,
    stop,
    num
  };
  return ENGINE.runKernel(LinSpace, {}, attrs);
}
var init_linspace = __esm({
  "node_modules/@tensorflow/tfjs-core/dist/ops/linspace.js"() {
    init_engine();
    init_kernel_names();
  }
});

// node_modules/@tensorflow/tfjs-core/dist/ops/local_response_normalization.js
function localResponseNormalization_(x, depthRadius = 5, bias = 1, alpha = 1, beta = 0.5) {
  const $x = convertToTensor(x, "x", "localResponseNormalization");
  assert($x.rank === 4 || $x.rank === 3, () => `Error in localResponseNormalization: x must be rank 3 or 4 but got
               rank ${$x.rank}.`);
  assert(isInt(depthRadius), () => `Error in localResponseNormalization: depthRadius must be an integer but got depthRadius ${depthRadius}.`);
  let x4D = $x;
  let reshapedTo4D = false;
  if ($x.rank === 3) {
    reshapedTo4D = true;
    x4D = reshape($x, [1, $x.shape[0], $x.shape[1], $x.shape[2]]);
  }
  const inputs = {
    x: x4D
  };
  const attrs = {
    depthRadius,
    bias,
    alpha,
    beta
  };
  const res = ENGINE.runKernel(LRN, inputs, attrs);
  if (reshapedTo4D) {
    return reshape(res, [res.shape[1], res.shape[2], res.shape[3]]);
  } else {
    return res;
  }
}
var localResponseNormalization;
var init_local_response_normalization = __esm({
  "node_modules/@tensorflow/tfjs-core/dist/ops/local_response_normalization.js"() {
    init_engine();
    init_kernel_names();
    init_tensor_util_env();
    init_util();
    init_operation();
    init_reshape();
    localResponseNormalization = op({
      localResponseNormalization_
    });
  }
});

// node_modules/@tensorflow/tfjs-core/dist/ops/log.js
function log_(x) {
  const $x = convertToTensor(x, "x", "log", "float32");
  const inputs = {
    x: $x
  };
  return ENGINE.runKernel(Log, inputs);
}
var log2;
var init_log2 = __esm({
  "node_modules/@tensorflow/tfjs-core/dist/ops/log.js"() {
    init_engine();
    init_kernel_names();
    init_tensor_util_env();
    init_operation();
    log2 = op({
      log_
    });
  }
});

// node_modules/@tensorflow/tfjs-core/dist/ops/log1p.js
function log1p_(x) {
  const $x = convertToTensor(x, "x", "log1p");
  const inputs = {
    x: $x
  };
  return ENGINE.runKernel(Log1p, inputs);
}
var log1p;
var init_log1p = __esm({
  "node_modules/@tensorflow/tfjs-core/dist/ops/log1p.js"() {
    init_engine();
    init_kernel_names();
    init_tensor_util_env();
    init_operation();
    log1p = op({
      log1p_
    });
  }
});

// node_modules/@tensorflow/tfjs-core/dist/gradients.js
function grad(f) {
  assert(isFunction(f), () => "The f passed in grad(f) must be a function");
  return (x, dy) => {
    const $x = convertToTensor(x, "x", "tf.grad", "string_or_numeric");
    const $dy = dy != null ? convertToTensor(dy, "dy", "tf.grad") : null;
    return ENGINE.tidy(() => {
      const {
        value,
        grads: grads2
      } = ENGINE.gradients(() => f($x), [$x], $dy);
      if ($dy != null) {
        assertShapesMatch(value.shape, $dy.shape, "The shape of dy passed in grad(f)(x, dy) must match the shape returned by f(x)");
      }
      checkGrads(grads2);
      return grads2[0];
    });
  };
}
function grads(f) {
  assert(isFunction(f), () => "The f passed in grads(f) must be a function");
  return (args, dy) => {
    assert(Array.isArray(args), () => "The args passed in grads(f)(args) must be an array of `Tensor`s or `TensorLike`s");
    const $args = convertToTensorArray(args, "args", "tf.grads", "string_or_numeric");
    const $dy = dy != null ? convertToTensor(dy, "dy", "tf.grads") : null;
    return ENGINE.tidy(() => {
      const {
        value,
        grads: grads2
      } = ENGINE.gradients(() => f(...$args), $args, $dy);
      if ($dy != null) {
        assertShapesMatch(value.shape, $dy.shape, "The shape of dy passed in grads(f)([x1,...], dy) must match the shape returned by f([x1,...])");
      }
      checkGrads(grads2);
      return grads2;
    });
  };
}
function valueAndGrad(f) {
  assert(isFunction(f), () => "The f passed in valueAndGrad(f) must be a function");
  return (x, dy) => {
    assert(x instanceof Tensor, () => "The x passed in valueAndGrad(f)(x) must be a tensor");
    assert(dy == null || dy instanceof Tensor, () => "The dy passed in valueAndGrad(f)(x, dy) must be a tensor");
    const {
      grads: grads2,
      value
    } = ENGINE.gradients(() => f(x), [x], dy);
    checkGrads(grads2);
    return {
      grad: grads2[0],
      value
    };
  };
}
function valueAndGrads(f) {
  assert(isFunction(f), () => "The f passed in valueAndGrads(f) must be a function");
  return (args, dy) => {
    assert(Array.isArray(args) && args.every((arg) => arg instanceof Tensor), () => "The args passed in valueAndGrads(f)(args) must be array of tensors");
    assert(dy == null || dy instanceof Tensor, () => "The dy passed in valueAndGrads(f)(args, dy) must be a tensor");
    const res = ENGINE.gradients(() => f(...args), args, dy);
    if (dy != null) {
      assertShapesMatch(res.value.shape, dy.shape, "The shape of dy passed in valueAndGrads(f)([x1,...], dy) must match the shape returned by f([x1,...])");
    }
    checkGrads(res.grads);
    return res;
  };
}
function variableGrads(f, varList) {
  assert(isFunction(f), () => "The f passed in variableGrads(f) must be a function");
  assert(varList == null || Array.isArray(varList) && varList.every((v) => v instanceof Variable), () => "The varList passed in variableGrads(f, varList) must be an array of variables");
  const specifiedVarList = varList != null;
  if (!specifiedVarList) {
    varList = [];
    for (const varName in ENGINE.registeredVariables) {
      varList.push(ENGINE.registeredVariables[varName]);
    }
  }
  const specifiedNonTrainable = specifiedVarList ? varList.filter((variable2) => !variable2.trainable) : null;
  const originalVarCount = varList.length;
  varList = varList.filter((variable2) => variable2.trainable);
  assert(varList.length > 0, () => `variableGrads() expects at least one of the input variables to be trainable, but none of the ${originalVarCount} variables is trainable.`);
  const allowNoGradients = true;
  const {
    value,
    grads: grads2
  } = ENGINE.gradients(f, varList, null, allowNoGradients);
  assert(grads2.some((g) => g != null), () => "Cannot find a connection between any variable and the result of the loss function y=f(x). Please make sure the operations that use variables are inside the function f passed to minimize().");
  assert(value.rank === 0, () => `The f passed in variableGrads(f) must return a scalar, but it returned a rank-${value.rank} tensor`);
  const namedGrads = {};
  varList.forEach((v, i) => {
    if (grads2[i] != null) {
      namedGrads[v.name] = grads2[i];
    }
  });
  if (specifiedNonTrainable != null) {
    specifiedNonTrainable.forEach((v) => namedGrads[v.name] = null);
  }
  return {
    value,
    grads: namedGrads
  };
}
function customGrad(f) {
  return ENGINE.customGrad(f);
}
function checkGrads(grads2) {
  const numNullGradients = grads2.filter((g) => g == null).length;
  if (numNullGradients > 0) {
    throw new Error(`Cannot compute gradient of y=f(x) with respect to x. Make sure that
    the f you passed encloses all operations that lead from x to y.`);
  }
}
var init_gradients = __esm({
  "node_modules/@tensorflow/tfjs-core/dist/gradients.js"() {
    init_engine();
    init_tensor();
    init_tensor_util_env();
    init_util();
  }
});

// node_modules/@tensorflow/tfjs-core/dist/ops/neg.js
function neg_(x) {
  const $x = convertToTensor(x, "x", "neg");
  const inputs = {
    x: $x
  };
  return ENGINE.runKernel(Neg, inputs);
}
var neg;
var init_neg = __esm({
  "node_modules/@tensorflow/tfjs-core/dist/ops/neg.js"() {
    init_engine();
    init_kernel_names();
    init_tensor_util_env();
    init_operation();
    neg = op({
      neg_
    });
  }
});

// node_modules/@tensorflow/tfjs-core/dist/ops/softplus.js
function softplus_(x) {
  const $x = convertToTensor(x, "x", "softplus");
  const inputs = {
    x: $x
  };
  return ENGINE.runKernel(Softplus, inputs);
}
var softplus;
var init_softplus = __esm({
  "node_modules/@tensorflow/tfjs-core/dist/ops/softplus.js"() {
    init_engine();
    init_kernel_names();
    init_tensor_util_env();
    init_operation();
    softplus = op({
      softplus_
    });
  }
});

// node_modules/@tensorflow/tfjs-core/dist/ops/log_sigmoid.js
function logSigmoid_(x) {
  const $x = convertToTensor(x, "x", "logSigmoid");
  const customOp = customGrad((x2) => {
    const value = neg(softplus(neg(x2)));
    const gradFunc = (dy) => {
      const derX = mul(dy, sigmoid(neg(x2)));
      return derX;
    };
    return {
      value,
      gradFunc
    };
  });
  return customOp($x);
}
var logSigmoid;
var init_log_sigmoid = __esm({
  "node_modules/@tensorflow/tfjs-core/dist/ops/log_sigmoid.js"() {
    init_gradients();
    init_tensor_util_env();
    init_mul();
    init_neg();
    init_operation();
    init_sigmoid();
    init_softplus();
    logSigmoid = op({
      logSigmoid_
    });
  }
});

// node_modules/@tensorflow/tfjs-core/dist/ops/sub.js
function sub_(a, b) {
  let $a = convertToTensor(a, "a", "sub");
  let $b = convertToTensor(b, "b", "sub");
  [$a, $b] = makeTypesMatch($a, $b);
  const inputs = {
    a: $a,
    b: $b
  };
  return ENGINE.runKernel(Sub, inputs);
}
var sub;
var init_sub = __esm({
  "node_modules/@tensorflow/tfjs-core/dist/ops/sub.js"() {
    init_engine();
    init_kernel_names();
    init_tensor_util();
    init_tensor_util_env();
    init_operation();
    sub = op({
      sub_
    });
  }
});

// node_modules/@tensorflow/tfjs-core/dist/ops/log_softmax.js
function logSoftmax_(logits, axis = -1) {
  const $logits = convertToTensor(logits, "logits", "logSoftmax");
  if (axis === -1) {
    axis = $logits.rank - 1;
  }
  if (axis !== $logits.rank - 1) {
    throw Error(`Log Softmax along a non-last dimension is not yet supported. Logits was rank ${$logits.rank} and axis was ${axis}`);
  }
  const customOp = customGrad((logits2, save) => {
    const keepDims = true;
    const xMax = max(logits2, axis, true);
    const shifted = sub(logits2, xMax);
    const value = sub(cast(shifted, "float32"), log2(sum2(exp(shifted), axis, keepDims)));
    save([value]);
    const gradFunc = (dy, saved) => {
      const [value2] = saved;
      const keepDims2 = true;
      const softmax2 = exp(value2);
      return sub(dy, mul(sum2(dy, axis, keepDims2), softmax2));
    };
    return {
      value,
      gradFunc
    };
  });
  return customOp($logits);
}
var logSoftmax;
var init_log_softmax = __esm({
  "node_modules/@tensorflow/tfjs-core/dist/ops/log_softmax.js"() {
    init_gradients();
    init_tensor_util_env();
    init_cast();
    init_exp();
    init_log2();
    init_max();
    init_mul();
    init_operation();
    init_sub();
    init_sum();
    logSoftmax = op({
      logSoftmax_
    });
  }
});

// node_modules/@tensorflow/tfjs-core/dist/ops/log_sum_exp.js
function logSumExp_(x, axis = null, keepDims = false) {
  const $x = convertToTensor(x, "x", "logSumExp");
  const axes = parseAxisParam(axis, $x.shape);
  const xMax = max(
    $x,
    axes,
    true
    /* keepDims */
  );
  const a = sub($x, xMax);
  const b = exp(a);
  const c = sum2(b, axes);
  const d = log2(c);
  const res = add2(reshape(xMax, d.shape), d);
  if (keepDims) {
    const newShape = expandShapeToKeepDim(res.shape, axes);
    return reshape(res, newShape);
  }
  return res;
}
var logSumExp;
var init_log_sum_exp = __esm({
  "node_modules/@tensorflow/tfjs-core/dist/ops/log_sum_exp.js"() {
    init_tensor_util_env();
    init_util();
    init_add();
    init_axis_util();
    init_exp();
    init_log2();
    init_max();
    init_operation();
    init_reshape();
    init_sub();
    init_sum();
    logSumExp = op({
      logSumExp_
    });
  }
});

// node_modules/@tensorflow/tfjs-core/dist/ops/logical_and.js
function logicalAnd_(a, b) {
  const $a = convertToTensor(a, "a", "logicalAnd", "bool");
  const $b = convertToTensor(b, "b", "logicalAnd", "bool");
  assertAndGetBroadcastShape($a.shape, $b.shape);
  const inputs = {
    a: $a,
    b: $b
  };
  return ENGINE.runKernel(LogicalAnd, inputs);
}
var logicalAnd;
var init_logical_and = __esm({
  "node_modules/@tensorflow/tfjs-core/dist/ops/logical_and.js"() {
    init_engine();
    init_kernel_names();
    init_tensor_util_env();
    init_broadcast_util();
    init_operation();
    logicalAnd = op({
      logicalAnd_
    });
  }
});

// node_modules/@tensorflow/tfjs-core/dist/ops/logical_not.js
function logicalNot_(x) {
  const $x = convertToTensor(x, "x", "logicalNot", "bool");
  const inputs = {
    x: $x
  };
  return ENGINE.runKernel(LogicalNot, inputs);
}
var logicalNot;
var init_logical_not = __esm({
  "node_modules/@tensorflow/tfjs-core/dist/ops/logical_not.js"() {
    init_engine();
    init_kernel_names();
    init_tensor_util_env();
    init_operation();
    logicalNot = op({
      logicalNot_
    });
  }
});

// node_modules/@tensorflow/tfjs-core/dist/ops/logical_or.js
function logicalOr_(a, b) {
  const $a = convertToTensor(a, "a", "logicalOr", "bool");
  const $b = convertToTensor(b, "b", "logicalOr", "bool");
  assertAndGetBroadcastShape($a.shape, $b.shape);
  const inputs = {
    a: $a,
    b: $b
  };
  return ENGINE.runKernel(LogicalOr, inputs);
}
var logicalOr;
var init_logical_or = __esm({
  "node_modules/@tensorflow/tfjs-core/dist/ops/logical_or.js"() {
    init_engine();
    init_kernel_names();
    init_tensor_util_env();
    init_broadcast_util();
    init_operation();
    logicalOr = op({
      logicalOr_
    });
  }
});

// node_modules/@tensorflow/tfjs-core/dist/ops/logical_xor.js
function logicalXor_(a, b) {
  const $a = convertToTensor(a, "a", "logicalXor", "bool");
  const $b = convertToTensor(b, "b", "logicalXor", "bool");
  assertAndGetBroadcastShape($a.shape, $b.shape);
  return logicalAnd(logicalOr(a, b), logicalNot(logicalAnd(a, b)));
}
var logicalXor;
var init_logical_xor = __esm({
  "node_modules/@tensorflow/tfjs-core/dist/ops/logical_xor.js"() {
    init_tensor_util_env();
    init_broadcast_util();
    init_logical_and();
    init_logical_not();
    init_logical_or();
    init_operation();
    logicalXor = op({
      logicalXor_
    });
  }
});

// node_modules/@tensorflow/tfjs-core/dist/ops/search_sorted.js
function searchSorted_(sortedSequence, values, side = "left") {
  const $sortedSequence = convertToTensor(sortedSequence, "sortedSequence", "searchSorted");
  const $values = convertToTensor(values, "values", "searchSorted");
  const sequenceSize = $sortedSequence.shape[$sortedSequence.shape.length - 1];
  const valuesSize = $values.shape[$values.shape.length - 1];
  const $sortedSequence2D = reshape($sortedSequence, [-1, sequenceSize]);
  const $values2D = reshape($values, [-1, valuesSize]);
  if ($sortedSequence2D.rank < 2) {
    throw new Error(`Sorted input argument must be at least 2-dimensional`);
  }
  if ($sortedSequence2D.shape[0] !== $values2D.shape[0]) {
    throw new Error(`Leading dimension of 'sortedSequence' and 'values' must match.`);
  }
  if (sizeFromShape($values2D.shape) >= INT32_MAX) {
    throw new Error(`values tensor size must less than ${INT32_MAX}`);
  }
  if ($sortedSequence2D.shape[1] >= INT32_MAX) {
    throw new Error(`trailing dim_size must less than ${INT32_MAX} for int32 output type, was ${$sortedSequence2D.shape[1]}`);
  }
  const inputs = {
    sortedSequence: $sortedSequence2D,
    values: $values2D
  };
  const attrs = {
    side
  };
  return ENGINE.runKernel(SearchSorted, inputs, attrs);
}
var INT32_MAX, searchSorted;
var init_search_sorted = __esm({
  "node_modules/@tensorflow/tfjs-core/dist/ops/search_sorted.js"() {
    init_engine();
    init_kernel_names();
    init_tensor_util_env();
    init_util_base();
    init_operation();
    init_reshape();
    INT32_MAX = 2147483648;
    searchSorted = op({
      searchSorted_
    });
  }
});

// node_modules/@tensorflow/tfjs-core/dist/ops/lower_bound.js
function lowerBound(sortedSequence, values) {
  return searchSorted(sortedSequence, values, "left");
}
var init_lower_bound = __esm({
  "node_modules/@tensorflow/tfjs-core/dist/ops/lower_bound.js"() {
    init_search_sorted();
  }
});

// node_modules/@tensorflow/tfjs-core/dist/ops/max_pool.js
function maxPool_(x, filterSize, strides, pad2, dimRoundingMode) {
  const $x = convertToTensor(x, "x", "maxPool");
  const dilations = 1;
  let x4D = $x;
  let reshapedTo4D = false;
  if ($x.rank === 3) {
    reshapedTo4D = true;
    x4D = reshape($x, [1, $x.shape[0], $x.shape[1], $x.shape[2]]);
  }
  assert(x4D.rank === 4, () => `Error in maxPool: input must be rank 4 but got rank ${x4D.rank}.`);
  assert(eitherStridesOrDilationsAreOne(strides, dilations), () => `Error in maxPool: Either strides or dilations must be 1. Got strides ${strides} and dilations '${dilations}'`);
  checkPadOnDimRoundingMode("maxPool", pad2, dimRoundingMode);
  const inputs = {
    x: x4D
  };
  const attrs = {
    filterSize,
    strides,
    pad: pad2,
    dimRoundingMode
  };
  const res = ENGINE.runKernel(MaxPool, inputs, attrs);
  if (reshapedTo4D) {
    return reshape(res, [res.shape[1], res.shape[2], res.shape[3]]);
  }
  return res;
}
var maxPool;
var init_max_pool = __esm({
  "node_modules/@tensorflow/tfjs-core/dist/ops/max_pool.js"() {
    init_engine();
    init_kernel_names();
    init_tensor_util_env();
    init_util();
    init_conv_util();
    init_operation();
    init_reshape();
    maxPool = op({
      maxPool_
    });
  }
});

// node_modules/@tensorflow/tfjs-core/dist/ops/max_pool_3d.js
function maxPool3d_(x, filterSize = [1, 1, 1], strides, pad2, dimRoundingMode, dataFormat = "NDHWC") {
  const $x = convertToTensor(x, "x", "maxPool3d");
  let x5D = $x;
  let reshapedTo5D = false;
  if ($x.rank === 4) {
    reshapedTo5D = true;
    x5D = reshape($x, [1, $x.shape[0], $x.shape[1], $x.shape[2], $x.shape[3]]);
  }
  assert(x5D.rank === 5, () => `Error in maxPool3d: x must be rank 5 but got rank ${x5D.rank}.`);
  assert(dataFormat === "NDHWC", () => `Error in maxPool3d: Only NDHWC is currently supported, but got dataFormat of ${dataFormat}`);
  checkPadOnDimRoundingMode("maxPool3d", pad2, dimRoundingMode);
  const inputs = {
    x: x5D
  };
  const attrs = {
    filterSize,
    strides,
    pad: pad2,
    dimRoundingMode,
    dataFormat
  };
  const res = ENGINE.runKernel(MaxPool3D, inputs, attrs);
  if (reshapedTo5D) {
    return reshape(res, [res.shape[1], res.shape[2], res.shape[3], res.shape[4]]);
  }
  return res;
}
var maxPool3d;
var init_max_pool_3d = __esm({
  "node_modules/@tensorflow/tfjs-core/dist/ops/max_pool_3d.js"() {
    init_engine();
    init_kernel_names();
    init_tensor_util_env();
    init_util();
    init_conv_util();
    init_operation();
    init_reshape();
    maxPool3d = op({
      maxPool3d_
    });
  }
});

// node_modules/@tensorflow/tfjs-core/dist/ops/max_pool_with_argmax.js
function maxPoolWithArgmax_(x, filterSize, strides, pad2, includeBatchInIndex = false) {
  const $x = convertToTensor(x, "x", "maxPoolWithArgmax");
  const inputs = {
    x: $x
  };
  const attrs = {
    filterSize,
    strides,
    pad: pad2,
    includeBatchInIndex
  };
  const result = ENGINE.runKernel(MaxPoolWithArgmax, inputs, attrs);
  return {
    result: result[0],
    indexes: result[1]
  };
}
var maxPoolWithArgmax;
var init_max_pool_with_argmax = __esm({
  "node_modules/@tensorflow/tfjs-core/dist/ops/max_pool_with_argmax.js"() {
    init_engine();
    init_kernel_names();
    init_tensor_util_env();
    init_operation();
    maxPoolWithArgmax = op({
      maxPoolWithArgmax_
    });
  }
});

// node_modules/@tensorflow/tfjs-core/dist/ops/maximum.js
function maximum_(a, b) {
  let $a = convertToTensor(a, "a", "maximum");
  let $b = convertToTensor(b, "b", "maximum");
  [$a, $b] = makeTypesMatch($a, $b);
  if ($a.dtype === "bool") {
    $a = cast($a, "int32");
    $b = cast($b, "int32");
  }
  assertAndGetBroadcastShape($a.shape, $b.shape);
  const inputs = {
    a: $a,
    b: $b
  };
  return ENGINE.runKernel(Maximum, inputs);
}
var maximum;
var init_maximum = __esm({
  "node_modules/@tensorflow/tfjs-core/dist/ops/maximum.js"() {
    init_engine();
    init_kernel_names();
    init_tensor_util();
    init_tensor_util_env();
    init_broadcast_util();
    init_cast();
    init_operation();
    maximum = op({
      maximum_
    });
  }
});

// node_modules/@tensorflow/tfjs-core/dist/ops/mean.js
function mean_(x, axis = null, keepDims = false) {
  const $x = convertToTensor(x, "x", "mean");
  const inputs = {
    x: $x
  };
  const attrs = {
    axis,
    keepDims
  };
  return ENGINE.runKernel(Mean, inputs, attrs);
}
var mean;
var init_mean = __esm({
  "node_modules/@tensorflow/tfjs-core/dist/ops/mean.js"() {
    init_engine();
    init_kernel_names();
    init_tensor_util_env();
    init_operation();
    mean = op({
      mean_
    });
  }
});

// node_modules/@tensorflow/tfjs-core/dist/ops/zeros.js
function zeros(shape, dtype = "float32") {
  assertNonNegativeIntegerDimensions(shape);
  if (dtype === "complex64") {
    const real3 = zeros(shape, "float32");
    const imag2 = zeros(shape, "float32");
    return complex(real3, imag2);
  }
  const values = makeZerosTypedArray(sizeFromShape(shape), dtype);
  return ENGINE.makeTensor(values, shape, dtype);
}
var init_zeros = __esm({
  "node_modules/@tensorflow/tfjs-core/dist/ops/zeros.js"() {
    init_engine();
    init_util();
    init_complex();
  }
});

// node_modules/@tensorflow/tfjs-core/dist/ops/ones.js
function ones2(shape, dtype = "float32") {
  assertNonNegativeIntegerDimensions(shape);
  if (dtype === "complex64") {
    const real3 = ones2(shape, "float32");
    const imag2 = zeros(shape, "float32");
    return complex(real3, imag2);
  }
  const values = makeOnesTypedArray(sizeFromShape(shape), dtype);
  return ENGINE.makeTensor(values, shape, dtype);
}
var init_ones = __esm({
  "node_modules/@tensorflow/tfjs-core/dist/ops/ones.js"() {
    init_engine();
    init_util();
    init_util_base();
    init_complex();
    init_zeros();
  }
});

// node_modules/@tensorflow/tfjs-core/dist/ops/meshgrid.js
function meshgrid(x, y, {
  indexing = "xy"
} = {}) {
  if (indexing !== "xy" && indexing !== "ij") {
    throw new TypeError(`${indexing} is not a valid third argument to meshgrid`);
  }
  if (x === void 0) {
    return [];
  }
  let $x = convertToTensor(x, "x", "meshgrid", x instanceof Tensor ? x.dtype : "float32");
  if (y === void 0) {
    return [$x];
  }
  let $y = convertToTensor(y, "y", "meshgrid", y instanceof Tensor ? y.dtype : "float32");
  const w = sizeFromShape($x.shape);
  const h = sizeFromShape($y.shape);
  if (indexing === "xy") {
    $x = reshape($x, [1, -1]);
    $y = reshape($y, [-1, 1]);
    return [matMul(ones2([h, 1], $x.dtype), $x), matMul($y, ones2([1, w], $y.dtype))];
  }
  $x = reshape($x, [-1, 1]);
  $y = reshape($y, [1, -1]);
  return [matMul($x, ones2([1, h], $x.dtype)), matMul(ones2([w, 1], $y.dtype), $y)];
}
var init_meshgrid = __esm({
  "node_modules/@tensorflow/tfjs-core/dist/ops/meshgrid.js"() {
    init_mat_mul();
    init_ones();
    init_reshape();
    init_tensor();
    init_tensor_util_env();
    init_util_base();
  }
});

// node_modules/@tensorflow/tfjs-core/dist/ops/minimum.js
function minimum_(a, b) {
  let $a = convertToTensor(a, "a", "minimum");
  let $b = convertToTensor(b, "b", "minimum");
  [$a, $b] = makeTypesMatch($a, $b);
  if ($a.dtype === "bool") {
    $a = cast($a, "int32");
    $b = cast($b, "int32");
  }
  assertAndGetBroadcastShape($a.shape, $b.shape);
  const inputs = {
    a: $a,
    b: $b
  };
  return ENGINE.runKernel(Minimum, inputs);
}
var minimum;
var init_minimum = __esm({
  "node_modules/@tensorflow/tfjs-core/dist/ops/minimum.js"() {
    init_engine();
    init_kernel_names();
    init_tensor_util();
    init_tensor_util_env();
    init_broadcast_util();
    init_cast();
    init_operation();
    minimum = op({
      minimum_
    });
  }
});

// node_modules/@tensorflow/tfjs-core/dist/ops/mirror_pad.js
function mirrorPad_(x, paddings, mode) {
  assert(mode === "reflect" || mode === "symmetric", () => `Invalid mode. Mode must be either reflect or symmetric. Got ${mode}.`);
  const $x = convertToTensor(x, "x", "mirrorPad");
  if ($x.rank === 0) {
    throw new Error("mirrorPad(scalar) is not defined. Pass non-scalar to mirrorPad");
  }
  assert(paddings.length === $x.rank, () => `Padding doesn't match input. Must be ${$x.rank}. Got ${paddings.length}.`);
  const shapeOffset = mode === "reflect" ? 1 : 0;
  for (let i = 0; i < $x.rank; i++) {
    assert(paddings[i].length === 2, () => `Invalid number of paddings. Must be length of 2 each.`);
    assert(paddings[i][0] >= 0 && paddings[i][0] <= $x.shape[i] - shapeOffset && paddings[i][1] >= 0 && paddings[i][1] <= $x.shape[i] - shapeOffset, () => `Padding in dimension ${i} cannot be greater than or equal to ${$x.shape[i] - shapeOffset} or less than 0 for input of shape ${$x.shape}`);
  }
  const attrs = {
    paddings,
    mode
  };
  const inputs = {
    x: $x
  };
  return ENGINE.runKernel(MirrorPad, inputs, attrs);
}
var mirrorPad;
var init_mirror_pad = __esm({
  "node_modules/@tensorflow/tfjs-core/dist/ops/mirror_pad.js"() {
    init_engine();
    init_kernel_names();
    init_tensor_util_env();
    init_util();
    init_operation();
    mirrorPad = op({
      mirrorPad_
    });
  }
});

// node_modules/@tensorflow/tfjs-core/dist/ops/mod.js
function mod_(a, b) {
  let $a = convertToTensor(a, "a", "mod");
  let $b = convertToTensor(b, "b", "mod");
  [$a, $b] = makeTypesMatch($a, $b);
  const inputs = {
    a: $a,
    b: $b
  };
  return ENGINE.runKernel(Mod, inputs);
}
var mod;
var init_mod = __esm({
  "node_modules/@tensorflow/tfjs-core/dist/ops/mod.js"() {
    init_engine();
    init_kernel_names();
    init_tensor_util();
    init_tensor_util_env();
    init_operation();
    mod = op({
      mod_
    });
  }
});

// node_modules/@tensorflow/tfjs-core/dist/ops/moments.js
function moments_(x, axis = null, keepDims = false) {
  x = convertToTensor(x, "x", "moments");
  const axes = parseAxisParam(axis, x.shape);
  const xMean = mean(x, axes, keepDims);
  let keepDimsShape = xMean.shape;
  if (!keepDims) {
    keepDimsShape = expandShapeToKeepDim(xMean.shape, axes);
  }
  const devSquared = square(sub(cast(x, "float32"), reshape(xMean, keepDimsShape)));
  const variance = mean(devSquared, axes, keepDims);
  return {
    mean: xMean,
    variance
  };
}
var moments;
var init_moments = __esm({
  "node_modules/@tensorflow/tfjs-core/dist/ops/moments.js"() {
    init_tensor_util_env();
    init_util();
    init_axis_util();
    init_cast();
    init_mean();
    init_operation();
    init_reshape();
    init_square();
    init_sub();
    moments = op({
      moments_
    });
  }
});

// node_modules/@tensorflow/tfjs-core/dist/ops/multi_rnn_cell.js
function multiRNNCell_(lstmCells, data, c, h) {
  const $data = convertToTensor(data, "data", "multiRNNCell");
  const $c = convertToTensorArray(c, "c", "multiRNNCell");
  const $h = convertToTensorArray(h, "h", "multiRNNCell");
  let input = $data;
  const newStates = [];
  for (let i = 0; i < lstmCells.length; i++) {
    const output = lstmCells[i](input, $c[i], $h[i]);
    newStates.push(output[0]);
    newStates.push(output[1]);
    input = output[1];
  }
  const newC = [];
  const newH = [];
  for (let i = 0; i < newStates.length; i += 2) {
    newC.push(newStates[i]);
    newH.push(newStates[i + 1]);
  }
  return [newC, newH];
}
var multiRNNCell;
var init_multi_rnn_cell = __esm({
  "node_modules/@tensorflow/tfjs-core/dist/ops/multi_rnn_cell.js"() {
    init_tensor_util_env();
    init_operation();
    multiRNNCell = op({
      multiRNNCell_
    });
  }
});

// node_modules/@tensorflow/tfjs-core/dist/ops/multinomial.js
function multinomial_(logits, numSamples, seed, normalized = false) {
  const $logits = convertToTensor(logits, "logits", "multinomial");
  const numOutcomes = $logits.size;
  const origRank = $logits.rank;
  if (numOutcomes < 2) {
    throw new Error(`Error in multinomial: you need at least 2 outcomes, but got ${numOutcomes}.`);
  }
  if (origRank > 2) {
    throw new Error(`Rank of probabilities must be 1 or 2, but is ${origRank}`);
  }
  seed = seed || Math.random();
  const logits2D = origRank === 1 ? reshape($logits, [1, -1]) : $logits;
  const inputs = {
    logits: logits2D
  };
  const attrs = {
    numSamples,
    seed,
    normalized
  };
  const res = ENGINE.runKernel(Multinomial, inputs, attrs);
  return origRank === 1 ? reshape(res, [res.size]) : res;
}
var multinomial;
var init_multinomial = __esm({
  "node_modules/@tensorflow/tfjs-core/dist/ops/multinomial.js"() {
    init_engine();
    init_kernel_names();
    init_tensor_util_env();
    init_operation();
    init_reshape();
    multinomial = op({
      multinomial_
    });
  }
});

// node_modules/@tensorflow/tfjs-core/dist/ops/not_equal.js
function notEqual_(a, b) {
  let $a = convertToTensor(a, "a", "notEqual", "string_or_numeric");
  let $b = convertToTensor(b, "b", "notEqual", "string_or_numeric");
  [$a, $b] = makeTypesMatch($a, $b);
  assertAndGetBroadcastShape($a.shape, $b.shape);
  const inputs = {
    a: $a,
    b: $b
  };
  return ENGINE.runKernel(NotEqual, inputs);
}
var notEqual;
var init_not_equal = __esm({
  "node_modules/@tensorflow/tfjs-core/dist/ops/not_equal.js"() {
    init_engine();
    init_kernel_names();
    init_tensor_util();
    init_tensor_util_env();
    init_broadcast_util();
    init_operation();
    notEqual = op({
      notEqual_
    });
  }
});

// node_modules/@tensorflow/tfjs-core/dist/ops/one_hot.js
function oneHot_(indices, depth, onValue = 1, offValue = 0, dtype = "int32") {
  if (depth < 2) {
    throw new Error(`Error in oneHot: depth must be >=2, but it is ${depth}`);
  }
  const $indices = convertToTensor(indices, "indices", "oneHot", "int32");
  const inputs = {
    indices: $indices
  };
  const attrs = {
    dtype,
    depth,
    onValue,
    offValue
  };
  return ENGINE.runKernel(OneHot, inputs, attrs);
}
var oneHot;
var init_one_hot = __esm({
  "node_modules/@tensorflow/tfjs-core/dist/ops/one_hot.js"() {
    init_engine();
    init_kernel_names();
    init_tensor_util_env();
    init_operation();
    oneHot = op({
      oneHot_
    });
  }
});

// node_modules/@tensorflow/tfjs-core/dist/ops/ones_like.js
function onesLike_(x) {
  const $x = convertToTensor(x, "x", "onesLike");
  const inputs = {
    x: $x
  };
  return ENGINE.runKernel(OnesLike, inputs);
}
var onesLike;
var init_ones_like = __esm({
  "node_modules/@tensorflow/tfjs-core/dist/ops/ones_like.js"() {
    init_engine();
    init_kernel_names();
    init_tensor_util_env();
    init_operation();
    onesLike = op({
      onesLike_
    });
  }
});

// node_modules/@tensorflow/tfjs-core/dist/ops/outer_product.js
function outerProduct_(v1, v2) {
  const $v1 = convertToTensor(v1, "v1", "outerProduct");
  const $v2 = convertToTensor(v2, "v2", "outerProduct");
  assert($v1.rank === 1 && $v2.rank === 1, () => `Error in outerProduct: inputs must be rank 1, but got ranks ${$v1.rank} and ${$v2.rank}.`);
  const v12D = reshape($v1, [-1, 1]);
  const v22D = reshape($v2, [1, -1]);
  return matMul(v12D, v22D);
}
var outerProduct;
var init_outer_product = __esm({
  "node_modules/@tensorflow/tfjs-core/dist/ops/outer_product.js"() {
    init_tensor_util_env();
    init_util();
    init_mat_mul();
    init_operation();
    init_reshape();
    outerProduct = op({
      outerProduct_
    });
  }
});

// node_modules/@tensorflow/tfjs-core/dist/ops/pad.js
function pad_(x, paddings, constantValue = 0) {
  const $x = convertToTensor(x, "x", "pad");
  if ($x.rank === 0) {
    throw new Error("pad(scalar) is not defined. Pass non-scalar to pad");
  }
  const attrs = {
    paddings,
    constantValue
  };
  const inputs = {
    x: $x
  };
  return ENGINE.runKernel(PadV2, inputs, attrs);
}
var pad;
var init_pad = __esm({
  "node_modules/@tensorflow/tfjs-core/dist/ops/pad.js"() {
    init_engine();
    init_kernel_names();
    init_tensor_util_env();
    init_operation();
    pad = op({
      pad_
    });
  }
});

// node_modules/@tensorflow/tfjs-core/dist/ops/pad1d.js
function pad1d_(x, paddings, constantValue = 0) {
  assert(paddings.length === 2, () => "Invalid number of paddings. Must be length of 2.");
  return pad(x, [paddings], constantValue);
}
var pad1d;
var init_pad1d = __esm({
  "node_modules/@tensorflow/tfjs-core/dist/ops/pad1d.js"() {
    init_util();
    init_operation();
    init_pad();
    pad1d = op({
      pad1d_
    });
  }
});

// node_modules/@tensorflow/tfjs-core/dist/ops/pad2d.js
function pad2d_(x, paddings, constantValue = 0) {
  assert(paddings.length === 2 && paddings[0].length === 2 && paddings[1].length === 2, () => "Invalid number of paddings. Must be length of 2 each.");
  return pad(x, paddings, constantValue);
}
var pad2d;
var init_pad2d = __esm({
  "node_modules/@tensorflow/tfjs-core/dist/ops/pad2d.js"() {
    init_util();
    init_operation();
    init_pad();
    pad2d = op({
      pad2d_
    });
  }
});

// node_modules/@tensorflow/tfjs-core/dist/ops/pad3d.js
function pad3d_(x, paddings, constantValue = 0) {
  assert(paddings.length === 3 && paddings[0].length === 2 && paddings[1].length === 2 && paddings[2].length === 2, () => "Invalid number of paddings. Must be length of 2 each.");
  return pad(x, paddings, constantValue);
}
var pad3d;
var init_pad3d = __esm({
  "node_modules/@tensorflow/tfjs-core/dist/ops/pad3d.js"() {
    init_util();
    init_operation();
    init_pad();
    pad3d = op({
      pad3d_
    });
  }
});

// node_modules/@tensorflow/tfjs-core/dist/ops/pad4d.js
function pad4d_(x, paddings, constantValue = 0) {
  assert(paddings.length === 4 && paddings[0].length === 2 && paddings[1].length === 2 && paddings[2].length === 2 && paddings[3].length === 2, () => "Invalid number of paddings. Must be length of 2 each.");
  return pad(x, paddings, constantValue);
}
var pad4d;
var init_pad4d = __esm({
  "node_modules/@tensorflow/tfjs-core/dist/ops/pad4d.js"() {
    init_util();
    init_operation();
    init_pad();
    pad4d = op({
      pad4d_
    });
  }
});

// node_modules/@tensorflow/tfjs-core/dist/ops/space_to_batch_nd.js
function spaceToBatchND_(x, blockShape, paddings) {
  const $x = convertToTensor(x, "x", "spaceToBatchND");
  assert($x.rank >= 1 + blockShape.length, () => `input rank ${$x.rank} should be > than [blockShape] ${blockShape.length}`);
  assert(paddings.length === blockShape.length, () => `paddings.shape[0] ${paddings.length} must be equal to [blockShape] ${blockShape.length}`);
  assert($x.shape.reduce((a, b, i) => {
    if (i > 0 && i <= blockShape.length) {
      return a && (b + paddings[i - 1][0] + paddings[i - 1][1]) % blockShape[i - 1] === 0;
    }
    return a;
  }, true), () => `input spatial dimensions ${$x.shape.slice(1)} with paddings ${paddings.toString()} must be divisible by blockShapes ${blockShape.toString()}`);
  const inputs = {
    x: $x
  };
  const attrs = {
    blockShape,
    paddings
  };
  return ENGINE.runKernel(SpaceToBatchND, inputs, attrs);
}
var spaceToBatchND;
var init_space_to_batch_nd = __esm({
  "node_modules/@tensorflow/tfjs-core/dist/ops/space_to_batch_nd.js"() {
    init_engine();
    init_kernel_names();
    init_tensor_util_env();
    init_util();
    init_operation();
    spaceToBatchND = op({
      spaceToBatchND_
    });
  }
});

// node_modules/@tensorflow/tfjs-core/dist/ops/pool.js
function pool_(input, windowShape, poolingType, pad2, dilations, strides, dimRoundingMode) {
  if (dilations == null) {
    dilations = [1, 1];
  }
  if (strides == null) {
    strides = 1;
  }
  if (pad2 === 0) {
    pad2 = "valid";
  }
  const $x = convertToTensor(input, "x", "maxPool");
  let x4D = $x;
  let reshapedTo4D = false;
  if ($x.rank === 3) {
    reshapedTo4D = true;
    x4D = reshape($x, [1, $x.shape[0], $x.shape[1], $x.shape[2]]);
  }
  assert(eitherStridesOrDilationsAreOne(strides, dilations), () => `Error in pool: Either strides or dilations must be 1. Got strides ${strides} and dilations '${dilations}'`);
  const convInfo = computePool2DInfo(x4D.shape, windowShape, strides, dilations, pad2);
  const dilation = [convInfo.dilationHeight, convInfo.dilationWidth];
  let basePadding;
  if (pad2 === "same") {
    basePadding = withSpaceToBatchBasePaddings([convInfo.filterHeight, convInfo.filterWidth], dilation);
  } else {
    basePadding = [[0, 0], [0, 0]];
  }
  const isDilationOne = dilation[0] === 1 && dilation[1] === 1;
  const [adjustedPadding, adjustedCrops] = requiredSpaceToBatchPaddings([convInfo.inHeight, convInfo.inWidth], dilation, basePadding);
  const convertedPad = isDilationOne ? pad2 : "valid";
  const convertedX = isDilationOne ? x4D : spaceToBatchND(x4D, dilation, adjustedPadding);
  const forwardOp = poolingType === "avg" ? () => avgPool(convertedX, windowShape, strides, convertedPad, dimRoundingMode) : () => maxPool(convertedX, windowShape, strides, convertedPad, dimRoundingMode);
  const y = forwardOp();
  const res = isDilationOne ? y : batchToSpaceND(y, dilation, adjustedCrops);
  if (reshapedTo4D) {
    return reshape(res, [res.shape[1], res.shape[2], res.shape[3]]);
  }
  return res;
}
function requiredSpaceToBatchPaddings(inputShape, blockShape, basePadding) {
  const padStart = basePadding.map((b) => b[0]);
  const origPadEnd = basePadding.map((b) => b[1]);
  const fullInputShape = inputShape.concat(padStart, origPadEnd);
  const padEndExtra = blockShape.map((b, i) => (b - fullInputShape[i] % b) % b);
  const padEnd = origPadEnd.map((s, i) => s + padEndExtra[i]);
  const paddings = blockShape.map((_, i) => [padStart[i], padEnd[i]]);
  const crops = blockShape.map((_, i) => [0, padEndExtra[i]]);
  return [paddings, crops];
}
function withSpaceToBatchBasePaddings(filterShape, dilation) {
  const dilatedFilterShape = filterShape.map((s, i) => {
    return s + (s - 1) * (dilation[i] - 1);
  });
  const padExtraShape = dilatedFilterShape.map((s) => s - 1);
  const padExtraStart = padExtraShape.map((s) => Math.floor(s / 2));
  const padExtraEnd = padExtraShape.map((s, i) => s - padExtraStart[i]);
  return padExtraShape.map((_, i) => {
    return [padExtraStart[i], padExtraEnd[i]];
  });
}
var pool;
var init_pool = __esm({
  "node_modules/@tensorflow/tfjs-core/dist/ops/pool.js"() {
    init_tensor_util_env();
    init_util();
    init_avg_pool();
    init_batch_to_space_nd();
    init_conv_util();
    init_max_pool();
    init_operation();
    init_reshape();
    init_space_to_batch_nd();
    pool = op({
      pool_
    });
  }
});

// node_modules/@tensorflow/tfjs-core/dist/ops/prelu.js
function prelu_(x, alpha) {
  const $x = convertToTensor(x, "x", "prelu");
  const $alpha = convertToTensor(alpha, "alpha", "prelu");
  const inputs = {
    x: $x,
    alpha: $alpha
  };
  return ENGINE.runKernel(Prelu, inputs);
}
var prelu;
var init_prelu = __esm({
  "node_modules/@tensorflow/tfjs-core/dist/ops/prelu.js"() {
    init_engine();
    init_kernel_names();
    init_tensor_util_env();
    init_operation();
    prelu = op({
      prelu_
    });
  }
});

// node_modules/@tensorflow/tfjs-core/dist/ops/prod.js
function prod_(x, axis = null, keepDims = false) {
  let $x = convertToTensor(x, "x", "prod");
  if ($x.dtype === "bool") {
    $x = cast($x, "int32");
  }
  const inputs = {
    x: $x
  };
  const attrs = {
    axis,
    keepDims
  };
  return ENGINE.runKernel(Prod, inputs, attrs);
}
var prod;
var init_prod = __esm({
  "node_modules/@tensorflow/tfjs-core/dist/ops/prod.js"() {
    init_engine();
    init_kernel_names();
    init_tensor_util_env();
    init_cast();
    init_operation();
    prod = op({
      prod_
    });
  }
});

// node_modules/@tensorflow/tfjs-core/dist/ops/ragged_gather.js
function raggedGather_(paramsNestedSplits, paramsDenseValues, indices, outputRaggedRank) {
  const $paramsNestedSplits = paramsNestedSplits.map((t, i) => convertToTensor(t, `tensors${i}`, "raggedGather", "int32"));
  const $paramsDenseValues = convertToTensor(paramsDenseValues, "paramsDenseValues", "raggedGather");
  const $indices = convertToTensor(indices, "indices", "raggedGather", "int32");
  const inputs = {
    paramsNestedSplits: $paramsNestedSplits,
    paramsDenseValues: $paramsDenseValues,
    indices: $indices
  };
  const attrs = {
    outputRaggedRank
  };
  const result = ENGINE.runKernel(RaggedGather, inputs, attrs);
  return {
    outputNestedSplits: result.slice(0, result.length - 1),
    outputDenseValues: result[result.length - 1]
  };
}
var raggedGather;
var init_ragged_gather = __esm({
  "node_modules/@tensorflow/tfjs-core/dist/ops/ragged_gather.js"() {
    init_engine();
    init_kernel_names();
    init_tensor_util_env();
    init_operation();
    raggedGather = op({
      raggedGather_
    });
  }
});

// node_modules/@tensorflow/tfjs-core/dist/ops/ragged_range.js
function raggedRange_(starts, limits, deltas) {
  const $starts = convertToTensor(starts, "starts", "raggedRange");
  const $limits = convertToTensor(limits, "limits", "raggedRange", $starts.dtype);
  const $deltas = convertToTensor(deltas, "deltas", "raggedRange", $starts.dtype);
  const inputs = {
    starts: $starts,
    limits: $limits,
    deltas: $deltas
  };
  const result = ENGINE.runKernel(RaggedRange, inputs);
  return {
    rtNestedSplits: result[0],
    rtDenseValues: result[1]
  };
}
var raggedRange;
var init_ragged_range = __esm({
  "node_modules/@tensorflow/tfjs-core/dist/ops/ragged_range.js"() {
    init_engine();
    init_kernel_names();
    init_tensor_util_env();
    init_operation();
    raggedRange = op({
      raggedRange_
    });
  }
});

// node_modules/@tensorflow/tfjs-core/dist/ops/ragged_tensor_to_tensor.js
function raggedTensorToTensor_(shape, values, defaultValue, rowPartitionTensors, rowPartitionTypes) {
  const $shape = convertToTensor(shape, "shape", "raggedTensorToTensor", "int32");
  const $values = convertToTensor(values, "values", "raggedTensorToTensor");
  const $defaultValue = convertToTensor(defaultValue, "defaultValue", "raggedTensorToTensor", $values.dtype);
  const $rowPartitionTensors = rowPartitionTensors.map((t, i) => convertToTensor(t, `tensors${i}`, "raggedTensorToTensor", "int32"));
  const inputs = {
    shape: $shape,
    values: $values,
    defaultValue: $defaultValue,
    rowPartitionTensors: $rowPartitionTensors
  };
  const attrs = {
    rowPartitionTypes
  };
  return ENGINE.runKernel(RaggedTensorToTensor, inputs, attrs);
}
var raggedTensorToTensor;
var init_ragged_tensor_to_tensor = __esm({
  "node_modules/@tensorflow/tfjs-core/dist/ops/ragged_tensor_to_tensor.js"() {
    init_engine();
    init_kernel_names();
    init_tensor_util_env();
    init_operation();
    raggedTensorToTensor = op({
      raggedTensorToTensor_
    });
  }
});

// node_modules/@tensorflow/tfjs-core/dist/ops/rand.js
function rand_(shape, randFunction, dtype) {
  assertNonNegativeIntegerDimensions(shape);
  const size = sizeFromShape(shape);
  let values = null;
  if (dtype == null || dtype === "float32") {
    values = new Float32Array(size);
  } else if (dtype === "int32") {
    values = new Int32Array(size);
  } else if (dtype === "bool") {
    values = new Uint8Array(size);
  } else {
    throw new Error(`Unknown data type ${dtype}`);
  }
  for (let i = 0; i < size; i++) {
    values[i] = randFunction();
  }
  return ENGINE.makeTensor(values, shape, dtype);
}
var rand;
var init_rand = __esm({
  "node_modules/@tensorflow/tfjs-core/dist/ops/rand.js"() {
    init_engine();
    init_util();
    init_util_base();
    init_operation();
    rand = op({
      rand_
    });
  }
});

// node_modules/@tensorflow/tfjs-core/dist/test_util.js
var test_util_exports = {};
__export(test_util_exports, {
  TEST_EPSILON_FLOAT16: () => TEST_EPSILON_FLOAT16,
  createVideoElement: () => createVideoElement,
  encodeStrings: () => encodeStrings,
  expectArrayBuffersEqual: () => expectArrayBuffersEqual,
  expectArraysClose: () => expectArraysClose,
  expectArraysEqual: () => expectArraysEqual,
  expectNumbersClose: () => expectNumbersClose,
  expectPromiseToFail: () => expectPromiseToFail,
  expectValuesInRange: () => expectValuesInRange,
  play: () => play,
  testEpsilon: () => testEpsilon
});
function expectArraysClose(actual, expected, epsilon) {
  if (epsilon == null) {
    epsilon = testEpsilon();
  }
  return expectArraysPredicate(actual, expected, (a, b) => areClose(a, b, epsilon));
}
function testEpsilon() {
  return ENGINE.backend.floatPrecision() === 32 ? TEST_EPSILON_FLOAT32 : TEST_EPSILON_FLOAT16;
}
function expectArraysPredicate(actual, expected, predicate) {
  let checkClassType = true;
  if (isTypedArray(actual) || isTypedArray(expected)) {
    checkClassType = false;
  }
  if (isTypedArray(actual) && isTypedArray(expected)) {
    checkClassType = true;
  }
  if (checkClassType) {
    const aType = actual.constructor.name;
    const bType = expected.constructor.name;
    if (aType !== bType) {
      throw new Error(`Arrays are of different type. Actual: ${aType}. Expected: ${bType}`);
    }
  }
  if (Array.isArray(actual) && Array.isArray(expected)) {
    const actualShape = inferShape(actual);
    const expectedShape = inferShape(expected);
    if (!arraysEqual(actualShape, expectedShape)) {
      throw new Error(`Arrays have different shapes. Actual: [${actualShape}]. Expected: [${expectedShape}]`);
    }
  }
  const actualFlat = isTypedArray(actual) ? actual : flatten(actual);
  const expectedFlat = isTypedArray(expected) ? expected : flatten(expected);
  if (actualFlat.length !== expectedFlat.length) {
    throw new Error(`Arrays have different lengths actual: ${actualFlat.length} vs expected: ${expectedFlat.length}.
Actual:   ${actualFlat}.
Expected: ${expectedFlat}.`);
  }
  for (let i = 0; i < expectedFlat.length; ++i) {
    const a = actualFlat[i];
    const e = expectedFlat[i];
    if (!predicate(a, e)) {
      throw new Error(`Arrays differ: actual[${i}] = ${a}, expected[${i}] = ${e}.
Actual:   ${actualFlat}.
Expected: ${expectedFlat}.`);
    }
  }
  if (typeof expect !== "undefined") {
    expect().nothing();
  }
}
function expectPromiseToFail(fn, done) {
  fn().then(() => done.fail(), () => done());
  if (typeof expect !== "undefined") {
    expect().nothing();
  }
}
function expectArraysEqual(actual, expected) {
  const exp3 = typeof expected === "string" || typeof expected === "number" || typeof expected === "boolean" ? [expected] : expected;
  if (isString(actual) || isString(actual[0]) || isString(expected) || isString(expected[0])) {
    return expectArraysPredicate(actual, exp3, (a, b) => a == b);
  }
  return expectArraysPredicate(actual, expected, (a, b) => areClose(a, b, 0));
}
function expectNumbersClose(a, e, epsilon) {
  if (epsilon == null) {
    epsilon = testEpsilon();
  }
  if (!areClose(a, e, epsilon)) {
    throw new Error(`Numbers differ: actual === ${a}, expected === ${e}`);
  }
  if (typeof expect !== "undefined") {
    expect().nothing();
  }
}
function areClose(a, e, epsilon) {
  if (!isFinite(a) && !isFinite(e)) {
    return true;
  }
  if (isNaN(a) || isNaN(e) || Math.abs(a - e) > epsilon) {
    return false;
  }
  return true;
}
function expectValuesInRange(actual, low, high) {
  for (let i = 0; i < actual.length; i++) {
    if (actual[i] < low || actual[i] > high) {
      throw new Error(`Value out of range:${actual[i]} low: ${low}, high: ${high}`);
    }
  }
}
function expectArrayBuffersEqual(actual, expected) {
  const actualArray = new Float32Array(actual);
  const expectedArray = new Float32Array(expected);
  if (actualArray.length !== expectedArray.length) {
    throw new Error(`Expected ArrayBuffer to be of length ${expectedArray.length}, but it was ${actualArray.length}`);
  }
  for (let i = 0; i < expectedArray.length; i++) {
    if (actualArray[i] !== expectedArray[i]) {
      throw new Error(`Expected ArrayBuffer value at ${i} to be ${expectedArray[i]} but got ${actualArray[i]} instead`);
    }
  }
}
function encodeStrings(a) {
  for (let i = 0; i < a.length; i++) {
    const val = a[i];
    if (Array.isArray(val)) {
      encodeStrings(val);
    } else {
      a[i] = encodeString(val);
    }
  }
  return a;
}
function createVideoElement(source) {
  const video = document.createElement("video");
  if ("playsInline" in video) {
    video.playsInline = true;
  }
  video.muted = true;
  video.loop = true;
  video.style.position = "fixed";
  video.style.left = "0px";
  video.style.top = "0px";
  video.preload = "auto";
  video.appendChild(source);
  return new Promise((resolve) => {
    video.addEventListener("loadeddata", (_) => resolve(video));
    video.load();
  });
}
function play(video) {
  return __async(this, null, function* () {
    yield video.play();
    if ("requestVideoFrameCallback" in video) {
      yield new Promise((resolve) => {
        video.requestVideoFrameCallback(resolve);
      });
    }
  });
}
var TEST_EPSILON_FLOAT32, TEST_EPSILON_FLOAT16;
var init_test_util = __esm({
  "node_modules/@tensorflow/tfjs-core/dist/test_util.js"() {
    init_engine();
    init_tensor_util_env();
    init_util();
    TEST_EPSILON_FLOAT32 = 1e-3;
    TEST_EPSILON_FLOAT16 = 0.1;
  }
});

// node_modules/seedrandom/lib/alea.js
var require_alea = __commonJS({
  "node_modules/seedrandom/lib/alea.js"(exports, module) {
    (function(global2, module2, define2) {
      function Alea(seed) {
        var me = this, mash = Mash();
        me.next = function() {
          var t = 2091639 * me.s0 + me.c * 23283064365386963e-26;
          me.s0 = me.s1;
          me.s1 = me.s2;
          return me.s2 = t - (me.c = t | 0);
        };
        me.c = 1;
        me.s0 = mash(" ");
        me.s1 = mash(" ");
        me.s2 = mash(" ");
        me.s0 -= mash(seed);
        if (me.s0 < 0) {
          me.s0 += 1;
        }
        me.s1 -= mash(seed);
        if (me.s1 < 0) {
          me.s1 += 1;
        }
        me.s2 -= mash(seed);
        if (me.s2 < 0) {
          me.s2 += 1;
        }
        mash = null;
      }
      function copy(f, t) {
        t.c = f.c;
        t.s0 = f.s0;
        t.s1 = f.s1;
        t.s2 = f.s2;
        return t;
      }
      function impl(seed, opts) {
        var xg = new Alea(seed), state = opts && opts.state, prng = xg.next;
        prng.int32 = function() {
          return xg.next() * 4294967296 | 0;
        };
        prng.double = function() {
          return prng() + (prng() * 2097152 | 0) * 11102230246251565e-32;
        };
        prng.quick = prng;
        if (state) {
          if (typeof state == "object") copy(state, xg);
          prng.state = function() {
            return copy(xg, {});
          };
        }
        return prng;
      }
      function Mash() {
        var n = 4022871197;
        var mash = function(data) {
          data = String(data);
          for (var i = 0; i < data.length; i++) {
            n += data.charCodeAt(i);
            var h = 0.02519603282416938 * n;
            n = h >>> 0;
            h -= n;
            h *= n;
            n = h >>> 0;
            h -= n;
            n += h * 4294967296;
          }
          return (n >>> 0) * 23283064365386963e-26;
        };
        return mash;
      }
      if (module2 && module2.exports) {
        module2.exports = impl;
      } else if (define2 && define2.amd) {
        define2(function() {
          return impl;
        });
      } else {
        this.alea = impl;
      }
    })(
      exports,
      typeof module == "object" && module,
      // present in node.js
      typeof define == "function" && define
      // present with an AMD loader
    );
  }
});

// node_modules/seedrandom/lib/xor128.js
var require_xor128 = __commonJS({
  "node_modules/seedrandom/lib/xor128.js"(exports, module) {
    (function(global2, module2, define2) {
      function XorGen(seed) {
        var me = this, strseed = "";
        me.x = 0;
        me.y = 0;
        me.z = 0;
        me.w = 0;
        me.next = function() {
          var t = me.x ^ me.x << 11;
          me.x = me.y;
          me.y = me.z;
          me.z = me.w;
          return me.w ^= me.w >>> 19 ^ t ^ t >>> 8;
        };
        if (seed === (seed | 0)) {
          me.x = seed;
        } else {
          strseed += seed;
        }
        for (var k = 0; k < strseed.length + 64; k++) {
          me.x ^= strseed.charCodeAt(k) | 0;
          me.next();
        }
      }
      function copy(f, t) {
        t.x = f.x;
        t.y = f.y;
        t.z = f.z;
        t.w = f.w;
        return t;
      }
      function impl(seed, opts) {
        var xg = new XorGen(seed), state = opts && opts.state, prng = function() {
          return (xg.next() >>> 0) / 4294967296;
        };
        prng.double = function() {
          do {
            var top = xg.next() >>> 11, bot = (xg.next() >>> 0) / 4294967296, result = (top + bot) / (1 << 21);
          } while (result === 0);
          return result;
        };
        prng.int32 = xg.next;
        prng.quick = prng;
        if (state) {
          if (typeof state == "object") copy(state, xg);
          prng.state = function() {
            return copy(xg, {});
          };
        }
        return prng;
      }
      if (module2 && module2.exports) {
        module2.exports = impl;
      } else if (define2 && define2.amd) {
        define2(function() {
          return impl;
        });
      } else {
        this.xor128 = impl;
      }
    })(
      exports,
      typeof module == "object" && module,
      // present in node.js
      typeof define == "function" && define
      // present with an AMD loader
    );
  }
});

// node_modules/seedrandom/lib/xorwow.js
var require_xorwow = __commonJS({
  "node_modules/seedrandom/lib/xorwow.js"(exports, module) {
    (function(global2, module2, define2) {
      function XorGen(seed) {
        var me = this, strseed = "";
        me.next = function() {
          var t = me.x ^ me.x >>> 2;
          me.x = me.y;
          me.y = me.z;
          me.z = me.w;
          me.w = me.v;
          return (me.d = me.d + 362437 | 0) + (me.v = me.v ^ me.v << 4 ^ (t ^ t << 1)) | 0;
        };
        me.x = 0;
        me.y = 0;
        me.z = 0;
        me.w = 0;
        me.v = 0;
        if (seed === (seed | 0)) {
          me.x = seed;
        } else {
          strseed += seed;
        }
        for (var k = 0; k < strseed.length + 64; k++) {
          me.x ^= strseed.charCodeAt(k) | 0;
          if (k == strseed.length) {
            me.d = me.x << 10 ^ me.x >>> 4;
          }
          me.next();
        }
      }
      function copy(f, t) {
        t.x = f.x;
        t.y = f.y;
        t.z = f.z;
        t.w = f.w;
        t.v = f.v;
        t.d = f.d;
        return t;
      }
      function impl(seed, opts) {
        var xg = new XorGen(seed), state = opts && opts.state, prng = function() {
          return (xg.next() >>> 0) / 4294967296;
        };
        prng.double = function() {
          do {
            var top = xg.next() >>> 11, bot = (xg.next() >>> 0) / 4294967296, result = (top + bot) / (1 << 21);
          } while (result === 0);
          return result;
        };
        prng.int32 = xg.next;
        prng.quick = prng;
        if (state) {
          if (typeof state == "object") copy(state, xg);
          prng.state = function() {
            return copy(xg, {});
          };
        }
        return prng;
      }
      if (module2 && module2.exports) {
        module2.exports = impl;
      } else if (define2 && define2.amd) {
        define2(function() {
          return impl;
        });
      } else {
        this.xorwow = impl;
      }
    })(
      exports,
      typeof module == "object" && module,
      // present in node.js
      typeof define == "function" && define
      // present with an AMD loader
    );
  }
});

// node_modules/seedrandom/lib/xorshift7.js
var require_xorshift7 = __commonJS({
  "node_modules/seedrandom/lib/xorshift7.js"(exports, module) {
    (function(global2, module2, define2) {
      function XorGen(seed) {
        var me = this;
        me.next = function() {
          var X = me.x, i = me.i, t, v, w;
          t = X[i];
          t ^= t >>> 7;
          v = t ^ t << 24;
          t = X[i + 1 & 7];
          v ^= t ^ t >>> 10;
          t = X[i + 3 & 7];
          v ^= t ^ t >>> 3;
          t = X[i + 4 & 7];
          v ^= t ^ t << 7;
          t = X[i + 7 & 7];
          t = t ^ t << 13;
          v ^= t ^ t << 9;
          X[i] = v;
          me.i = i + 1 & 7;
          return v;
        };
        function init(me2, seed2) {
          var j, w, X = [];
          if (seed2 === (seed2 | 0)) {
            w = X[0] = seed2;
          } else {
            seed2 = "" + seed2;
            for (j = 0; j < seed2.length; ++j) {
              X[j & 7] = X[j & 7] << 15 ^ seed2.charCodeAt(j) + X[j + 1 & 7] << 13;
            }
          }
          while (X.length < 8) X.push(0);
          for (j = 0; j < 8 && X[j] === 0; ++j) ;
          if (j == 8) w = X[7] = -1;
          else w = X[j];
          me2.x = X;
          me2.i = 0;
          for (j = 256; j > 0; --j) {
            me2.next();
          }
        }
        init(me, seed);
      }
      function copy(f, t) {
        t.x = f.x.slice();
        t.i = f.i;
        return t;
      }
      function impl(seed, opts) {
        if (seed == null) seed = +/* @__PURE__ */ new Date();
        var xg = new XorGen(seed), state = opts && opts.state, prng = function() {
          return (xg.next() >>> 0) / 4294967296;
        };
        prng.double = function() {
          do {
            var top = xg.next() >>> 11, bot = (xg.next() >>> 0) / 4294967296, result = (top + bot) / (1 << 21);
          } while (result === 0);
          return result;
        };
        prng.int32 = xg.next;
        prng.quick = prng;
        if (state) {
          if (state.x) copy(state, xg);
          prng.state = function() {
            return copy(xg, {});
          };
        }
        return prng;
      }
      if (module2 && module2.exports) {
        module2.exports = impl;
      } else if (define2 && define2.amd) {
        define2(function() {
          return impl;
        });
      } else {
        this.xorshift7 = impl;
      }
    })(
      exports,
      typeof module == "object" && module,
      // present in node.js
      typeof define == "function" && define
      // present with an AMD loader
    );
  }
});

// node_modules/seedrandom/lib/xor4096.js
var require_xor4096 = __commonJS({
  "node_modules/seedrandom/lib/xor4096.js"(exports, module) {
    (function(global2, module2, define2) {
      function XorGen(seed) {
        var me = this;
        me.next = function() {
          var w = me.w, X = me.X, i = me.i, t, v;
          me.w = w = w + 1640531527 | 0;
          v = X[i + 34 & 127];
          t = X[i = i + 1 & 127];
          v ^= v << 13;
          t ^= t << 17;
          v ^= v >>> 15;
          t ^= t >>> 12;
          v = X[i] = v ^ t;
          me.i = i;
          return v + (w ^ w >>> 16) | 0;
        };
        function init(me2, seed2) {
          var t, v, i, j, w, X = [], limit = 128;
          if (seed2 === (seed2 | 0)) {
            v = seed2;
            seed2 = null;
          } else {
            seed2 = seed2 + "\0";
            v = 0;
            limit = Math.max(limit, seed2.length);
          }
          for (i = 0, j = -32; j < limit; ++j) {
            if (seed2) v ^= seed2.charCodeAt((j + 32) % seed2.length);
            if (j === 0) w = v;
            v ^= v << 10;
            v ^= v >>> 15;
            v ^= v << 4;
            v ^= v >>> 13;
            if (j >= 0) {
              w = w + 1640531527 | 0;
              t = X[j & 127] ^= v + w;
              i = 0 == t ? i + 1 : 0;
            }
          }
          if (i >= 128) {
            X[(seed2 && seed2.length || 0) & 127] = -1;
          }
          i = 127;
          for (j = 4 * 128; j > 0; --j) {
            v = X[i + 34 & 127];
            t = X[i = i + 1 & 127];
            v ^= v << 13;
            t ^= t << 17;
            v ^= v >>> 15;
            t ^= t >>> 12;
            X[i] = v ^ t;
          }
          me2.w = w;
          me2.X = X;
          me2.i = i;
        }
        init(me, seed);
      }
      function copy(f, t) {
        t.i = f.i;
        t.w = f.w;
        t.X = f.X.slice();
        return t;
      }
      ;
      function impl(seed, opts) {
        if (seed == null) seed = +/* @__PURE__ */ new Date();
        var xg = new XorGen(seed), state = opts && opts.state, prng = function() {
          return (xg.next() >>> 0) / 4294967296;
        };
        prng.double = function() {
          do {
            var top = xg.next() >>> 11, bot = (xg.next() >>> 0) / 4294967296, result = (top + bot) / (1 << 21);
          } while (result === 0);
          return result;
        };
        prng.int32 = xg.next;
        prng.quick = prng;
        if (state) {
          if (state.X) copy(state, xg);
          prng.state = function() {
            return copy(xg, {});
          };
        }
        return prng;
      }
      if (module2 && module2.exports) {
        module2.exports = impl;
      } else if (define2 && define2.amd) {
        define2(function() {
          return impl;
        });
      } else {
        this.xor4096 = impl;
      }
    })(
      exports,
      // window object or global
      typeof module == "object" && module,
      // present in node.js
      typeof define == "function" && define
      // present with an AMD loader
    );
  }
});

// node_modules/seedrandom/lib/tychei.js
var require_tychei = __commonJS({
  "node_modules/seedrandom/lib/tychei.js"(exports, module) {
    (function(global2, module2, define2) {
      function XorGen(seed) {
        var me = this, strseed = "";
        me.next = function() {
          var b = me.b, c = me.c, d = me.d, a = me.a;
          b = b << 25 ^ b >>> 7 ^ c;
          c = c - d | 0;
          d = d << 24 ^ d >>> 8 ^ a;
          a = a - b | 0;
          me.b = b = b << 20 ^ b >>> 12 ^ c;
          me.c = c = c - d | 0;
          me.d = d << 16 ^ c >>> 16 ^ a;
          return me.a = a - b | 0;
        };
        me.a = 0;
        me.b = 0;
        me.c = 2654435769 | 0;
        me.d = 1367130551;
        if (seed === Math.floor(seed)) {
          me.a = seed / 4294967296 | 0;
          me.b = seed | 0;
        } else {
          strseed += seed;
        }
        for (var k = 0; k < strseed.length + 20; k++) {
          me.b ^= strseed.charCodeAt(k) | 0;
          me.next();
        }
      }
      function copy(f, t) {
        t.a = f.a;
        t.b = f.b;
        t.c = f.c;
        t.d = f.d;
        return t;
      }
      ;
      function impl(seed, opts) {
        var xg = new XorGen(seed), state = opts && opts.state, prng = function() {
          return (xg.next() >>> 0) / 4294967296;
        };
        prng.double = function() {
          do {
            var top = xg.next() >>> 11, bot = (xg.next() >>> 0) / 4294967296, result = (top + bot) / (1 << 21);
          } while (result === 0);
          return result;
        };
        prng.int32 = xg.next;
        prng.quick = prng;
        if (state) {
          if (typeof state == "object") copy(state, xg);
          prng.state = function() {
            return copy(xg, {});
          };
        }
        return prng;
      }
      if (module2 && module2.exports) {
        module2.exports = impl;
      } else if (define2 && define2.amd) {
        define2(function() {
          return impl;
        });
      } else {
        this.tychei = impl;
      }
    })(
      exports,
      typeof module == "object" && module,
      // present in node.js
      typeof define == "function" && define
      // present with an AMD loader
    );
  }
});

// browser-external:crypto
var require_crypto = __commonJS({
  "browser-external:crypto"(exports, module) {
    module.exports = Object.create(new Proxy({}, {
      get(_, key) {
        if (key !== "__esModule" && key !== "__proto__" && key !== "constructor" && key !== "splice") {
          console.warn(`Module "crypto" has been externalized for browser compatibility. Cannot access "crypto.${key}" in client code. See https://vite.dev/guide/troubleshooting.html#module-externalized-for-browser-compatibility for more details.`);
        }
      }
    }));
  }
});

// node_modules/seedrandom/seedrandom.js
var require_seedrandom = __commonJS({
  "node_modules/seedrandom/seedrandom.js"(exports, module) {
    (function(global2, pool2, math) {
      var width = 256, chunks = 6, digits = 52, rngname = "random", startdenom = math.pow(width, chunks), significance = math.pow(2, digits), overflow = significance * 2, mask = width - 1, nodecrypto;
      function seedrandom2(seed, options, callback) {
        var key = [];
        options = options == true ? {
          entropy: true
        } : options || {};
        var shortseed = mixkey(flatten2(options.entropy ? [seed, tostring(pool2)] : seed == null ? autoseed() : seed, 3), key);
        var arc4 = new ARC4(key);
        var prng = function() {
          var n = arc4.g(chunks), d = startdenom, x = 0;
          while (n < significance) {
            n = (n + x) * width;
            d *= width;
            x = arc4.g(1);
          }
          while (n >= overflow) {
            n /= 2;
            d /= 2;
            x >>>= 1;
          }
          return (n + x) / d;
        };
        prng.int32 = function() {
          return arc4.g(4) | 0;
        };
        prng.quick = function() {
          return arc4.g(4) / 4294967296;
        };
        prng.double = prng;
        mixkey(tostring(arc4.S), pool2);
        return (options.pass || callback || function(prng2, seed2, is_math_call, state) {
          if (state) {
            if (state.S) {
              copy(state, arc4);
            }
            prng2.state = function() {
              return copy(arc4, {});
            };
          }
          if (is_math_call) {
            math[rngname] = prng2;
            return seed2;
          } else return prng2;
        })(prng, shortseed, "global" in options ? options.global : this == math, options.state);
      }
      function ARC4(key) {
        var t, keylen = key.length, me = this, i = 0, j = me.i = me.j = 0, s = me.S = [];
        if (!keylen) {
          key = [keylen++];
        }
        while (i < width) {
          s[i] = i++;
        }
        for (i = 0; i < width; i++) {
          s[i] = s[j = mask & j + key[i % keylen] + (t = s[i])];
          s[j] = t;
        }
        (me.g = function(count) {
          var t2, r = 0, i2 = me.i, j2 = me.j, s2 = me.S;
          while (count--) {
            t2 = s2[i2 = mask & i2 + 1];
            r = r * width + s2[mask & (s2[i2] = s2[j2 = mask & j2 + t2]) + (s2[j2] = t2)];
          }
          me.i = i2;
          me.j = j2;
          return r;
        })(width);
      }
      function copy(f, t) {
        t.i = f.i;
        t.j = f.j;
        t.S = f.S.slice();
        return t;
      }
      ;
      function flatten2(obj, depth) {
        var result = [], typ = typeof obj, prop;
        if (depth && typ == "object") {
          for (prop in obj) {
            try {
              result.push(flatten2(obj[prop], depth - 1));
            } catch (e) {
            }
          }
        }
        return result.length ? result : typ == "string" ? obj : obj + "\0";
      }
      function mixkey(seed, key) {
        var stringseed = seed + "", smear, j = 0;
        while (j < stringseed.length) {
          key[mask & j] = mask & (smear ^= key[mask & j] * 19) + stringseed.charCodeAt(j++);
        }
        return tostring(key);
      }
      function autoseed() {
        try {
          var out;
          if (nodecrypto && (out = nodecrypto.randomBytes)) {
            out = out(width);
          } else {
            out = new Uint8Array(width);
            (global2.crypto || global2.msCrypto).getRandomValues(out);
          }
          return tostring(out);
        } catch (e) {
          var browser = global2.navigator, plugins = browser && browser.plugins;
          return [+/* @__PURE__ */ new Date(), global2, plugins, global2.screen, tostring(pool2)];
        }
      }
      function tostring(a) {
        return String.fromCharCode.apply(0, a);
      }
      mixkey(math.random(), pool2);
      if (typeof module == "object" && module.exports) {
        module.exports = seedrandom2;
        try {
          nodecrypto = require_crypto();
        } catch (ex) {
        }
      } else if (typeof define == "function" && define.amd) {
        define(function() {
          return seedrandom2;
        });
      } else {
        math["seed" + rngname] = seedrandom2;
      }
    })(
      // global: `self` in browsers (including strict mode and web workers),
      // otherwise `this` in Node and other environments
      typeof self !== "undefined" ? self : exports,
      [],
      // pool: entropy pool starts empty
      Math
      // math: package containing random, pow, and seedrandom
    );
  }
});

// node_modules/seedrandom/index.js
var require_seedrandom2 = __commonJS({
  "node_modules/seedrandom/index.js"(exports, module) {
    var alea2 = require_alea();
    var xor128 = require_xor128();
    var xorwow = require_xorwow();
    var xorshift7 = require_xorshift7();
    var xor4096 = require_xor4096();
    var tychei = require_tychei();
    var sr = require_seedrandom();
    sr.alea = alea2;
    sr.xor128 = xor128;
    sr.xorwow = xorwow;
    sr.xorshift7 = xorshift7;
    sr.xor4096 = xor4096;
    sr.tychei = tychei;
    module.exports = sr;
  }
});

// node_modules/@tensorflow/tfjs-core/dist/ops/rand_util.js
var seedrandom, MPRandGauss, RandGamma, UniformRandom;
var init_rand_util = __esm({
  "node_modules/@tensorflow/tfjs-core/dist/ops/rand_util.js"() {
    seedrandom = __toESM(require_seedrandom2());
    init_test_util();
    MPRandGauss = class {
      constructor(mean2, stdDeviation, dtype, truncated, seed) {
        this.mean = mean2;
        this.stdDev = stdDeviation;
        this.dtype = dtype;
        this.nextVal = NaN;
        this.truncated = truncated;
        if (this.truncated) {
          this.upper = this.mean + this.stdDev * 2;
          this.lower = this.mean - this.stdDev * 2;
        }
        const seedValue = seed ? seed : Math.random();
        this.random = seedrandom.alea(seedValue.toString());
      }
      /** Returns next sample from a Gaussian distribution. */
      nextValue() {
        if (!isNaN(this.nextVal)) {
          const value = this.nextVal;
          this.nextVal = NaN;
          return value;
        }
        let resultX, resultY;
        let isValid = false;
        while (!isValid) {
          let v1, v2, s;
          do {
            v1 = 2 * this.random() - 1;
            v2 = 2 * this.random() - 1;
            s = v1 * v1 + v2 * v2;
          } while (s >= 1 || s === 0);
          const mul2 = Math.sqrt(-2 * Math.log(s) / s);
          resultX = this.mean + this.stdDev * v1 * mul2;
          resultY = this.mean + this.stdDev * v2 * mul2;
          if (!this.truncated || this.isValidTruncated(resultX)) {
            isValid = true;
          }
        }
        if (!this.truncated || this.isValidTruncated(resultY)) {
          this.nextVal = this.convertValue(resultY);
        }
        return this.convertValue(resultX);
      }
      /** Handles proper rounding for non-floating-point numbers. */
      convertValue(value) {
        if (this.dtype == null || this.dtype === "float32") {
          return value;
        }
        return Math.round(value);
      }
      /** Returns true if less than 2-standard-deviations from the mean. */
      isValidTruncated(value) {
        return value <= this.upper && value >= this.lower;
      }
    };
    RandGamma = class {
      constructor(alpha, beta, dtype, seed) {
        this.alpha = alpha;
        this.beta = 1 / beta;
        this.dtype = dtype;
        const seedValue = seed ? seed : Math.random();
        this.randu = seedrandom.alea(seedValue.toString());
        this.randn = new MPRandGauss(0, 1, dtype, false, this.randu());
        if (alpha < 1) {
          this.d = alpha + 2 / 3;
        } else {
          this.d = alpha - 1 / 3;
        }
        this.c = 1 / Math.sqrt(9 * this.d);
      }
      /** Returns next sample from a gamma distribution. */
      nextValue() {
        let x2, v0, v1, x, u, v;
        while (true) {
          do {
            x = this.randn.nextValue();
            v = 1 + this.c * x;
          } while (v <= 0);
          v *= v * v;
          x2 = x * x;
          v0 = 1 - 0.331 * x2 * x2;
          v1 = 0.5 * x2 + this.d * (1 - v + Math.log(v));
          u = this.randu();
          if (u < v0 || Math.log(u) < v1) {
            break;
          }
        }
        v = 1 / this.beta * this.d * v;
        if (this.alpha < 1) {
          v *= Math.pow(this.randu(), 1 / this.alpha);
        }
        return this.convertValue(v);
      }
      /** Handles proper rounding for non-floating-point numbers. */
      convertValue(value) {
        if (this.dtype === "float32") {
          return value;
        }
        return Math.round(value);
      }
    };
    UniformRandom = class {
      constructor(min2 = 0, max2 = 1, dtype, seed) {
        this.canReturnFloat = () => this.dtype == null || this.dtype === "float32";
        this.min = min2;
        this.range = max2 - min2;
        this.dtype = dtype;
        if (seed == null) {
          seed = Math.random();
        }
        if (typeof seed === "number") {
          seed = seed.toString();
        }
        if (!this.canReturnFloat() && this.range <= 1) {
          throw new Error(`The difference between ${min2} - ${max2} <= 1 and dtype is not float`);
        }
        this.random = seedrandom.alea(seed);
      }
      convertValue(value) {
        if (this.canReturnFloat()) {
          return value;
        }
        return Math.round(value);
      }
      nextValue() {
        return this.convertValue(this.min + this.range * this.random());
      }
    };
  }
});

// node_modules/@tensorflow/tfjs-core/dist/ops/random_gamma.js
function randomGamma_(shape, alpha, beta = 1, dtype = "float32", seed) {
  assertNonNegativeIntegerDimensions(shape);
  if (beta == null) {
    beta = 1;
  }
  if (dtype == null) {
    dtype = "float32";
  }
  if (dtype !== "float32" && dtype !== "int32") {
    throw new Error(`Unsupported data type ${dtype}`);
  }
  const rgamma = new RandGamma(alpha, beta, dtype, seed);
  const res = buffer(shape, dtype);
  for (let i = 0; i < res.values.length; i++) {
    res.values[i] = rgamma.nextValue();
  }
  return res.toTensor();
}
var randomGamma;
var init_random_gamma = __esm({
  "node_modules/@tensorflow/tfjs-core/dist/ops/random_gamma.js"() {
    init_util_base();
    init_buffer();
    init_operation();
    init_rand_util();
    randomGamma = op({
      randomGamma_
    });
  }
});

// node_modules/@tensorflow/tfjs-core/dist/ops/random_normal.js
function randomNormal_(shape, mean2 = 0, stdDev = 1, dtype, seed) {
  assertNonNegativeIntegerDimensions(shape);
  if (dtype != null && dtype === "bool") {
    throw new Error(`Unsupported data type ${dtype}`);
  }
  const randGauss = new MPRandGauss(mean2, stdDev, dtype, false, seed);
  const res = buffer(shape, dtype);
  for (let i = 0; i < res.values.length; i++) {
    res.values[i] = randGauss.nextValue();
  }
  return res.toTensor();
}
var randomNormal;
var init_random_normal = __esm({
  "node_modules/@tensorflow/tfjs-core/dist/ops/random_normal.js"() {
    init_util_base();
    init_buffer();
    init_operation();
    init_rand_util();
    randomNormal = op({
      randomNormal_
    });
  }
});

// node_modules/@tensorflow/tfjs-core/dist/ops/random_standard_normal.js
function randomStandardNormal_(shape, dtype, seed) {
  if (dtype != null && dtype === "bool") {
    throw new Error(`Unsupported data type ${dtype}`);
  }
  return randomNormal(shape, 0, 1, dtype, seed);
}
var randomStandardNormal;
var init_random_standard_normal = __esm({
  "node_modules/@tensorflow/tfjs-core/dist/ops/random_standard_normal.js"() {
    init_operation();
    init_random_normal();
    randomStandardNormal = op({
      randomStandardNormal_
    });
  }
});

// node_modules/@tensorflow/tfjs-core/dist/ops/random_uniform.js
function randomUniform_(shape, minval = 0, maxval = 1, dtype = "float32", seed) {
  assertNonNegativeIntegerDimensions(shape);
  const res = buffer(shape, dtype);
  const random = new UniformRandom(minval, maxval, null, seed);
  for (let i = 0; i < res.values.length; i++) {
    res.values[i] = random.nextValue();
  }
  return res.toTensor();
}
var randomUniform;
var init_random_uniform = __esm({
  "node_modules/@tensorflow/tfjs-core/dist/ops/random_uniform.js"() {
    init_util_base();
    init_buffer();
    init_operation();
    init_rand_util();
    randomUniform = op({
      randomUniform_
    });
  }
});

// node_modules/@tensorflow/tfjs-core/dist/ops/random_uniform_int.js
function randomUniformInt_(shape, minval, maxval, seed) {
  return randomUniform(shape, minval, maxval, "int32", seed);
}
var randomUniformInt;
var init_random_uniform_int = __esm({
  "node_modules/@tensorflow/tfjs-core/dist/ops/random_uniform_int.js"() {
    init_operation();
    init_random_uniform();
    randomUniformInt = op({
      randomUniformInt_
    });
  }
});

// node_modules/@tensorflow/tfjs-core/dist/ops/range.js
function range(start, stop, step2 = 1, dtype = "float32") {
  if (step2 === 0) {
    throw new Error("Cannot have a step of zero");
  }
  const attrs = {
    start,
    stop,
    step: step2,
    dtype
  };
  return ENGINE.runKernel(Range, {}, attrs);
}
var init_range = __esm({
  "node_modules/@tensorflow/tfjs-core/dist/ops/range.js"() {
    init_engine();
    init_kernel_names();
  }
});

// node_modules/@tensorflow/tfjs-core/dist/ops/real.js
function real_(input) {
  const $input = convertToTensor(input, "input", "real");
  const inputs = {
    input: $input
  };
  return ENGINE.runKernel(Real, inputs);
}
var real;
var init_real = __esm({
  "node_modules/@tensorflow/tfjs-core/dist/ops/real.js"() {
    init_engine();
    init_kernel_names();
    init_tensor_util_env();
    init_operation();
    real = op({
      real_
    });
  }
});

// node_modules/@tensorflow/tfjs-core/dist/ops/reciprocal.js
function reciprocal_(x) {
  const $x = convertToTensor(x, "x", "reciprocal");
  const inputs = {
    x: $x
  };
  return ENGINE.runKernel(Reciprocal, inputs);
}
var reciprocal;
var init_reciprocal = __esm({
  "node_modules/@tensorflow/tfjs-core/dist/ops/reciprocal.js"() {
    init_engine();
    init_kernel_names();
    init_tensor_util_env();
    init_operation();
    reciprocal = op({
      reciprocal_
    });
  }
});

// node_modules/@tensorflow/tfjs-core/dist/ops/relu.js
function relu_(x) {
  const $x = convertToTensor(x, "x", "relu");
  const inputs = {
    x: $x
  };
  return ENGINE.runKernel(Relu, inputs);
}
var relu;
var init_relu = __esm({
  "node_modules/@tensorflow/tfjs-core/dist/ops/relu.js"() {
    init_engine();
    init_kernel_names();
    init_tensor_util_env();
    init_operation();
    relu = op({
      relu_
    });
  }
});

// node_modules/@tensorflow/tfjs-core/dist/ops/relu6.js
function relu6_(x) {
  const $x = convertToTensor(x, "x", "relu6");
  const inputs = {
    x: $x
  };
  return ENGINE.runKernel(Relu6, inputs);
}
var relu6;
var init_relu6 = __esm({
  "node_modules/@tensorflow/tfjs-core/dist/ops/relu6.js"() {
    init_engine();
    init_kernel_names();
    init_tensor_util_env();
    init_operation();
    relu6 = op({
      relu6_
    });
  }
});

// node_modules/@tensorflow/tfjs-core/dist/ops/reverse.js
function reverse_(x, axis) {
  const $x = convertToTensor(x, "x", "reverse");
  const inputs = {
    x: $x
  };
  const attrs = {
    dims: axis
  };
  return ENGINE.runKernel(Reverse, inputs, attrs);
}
var reverse;
var init_reverse = __esm({
  "node_modules/@tensorflow/tfjs-core/dist/ops/reverse.js"() {
    init_engine();
    init_kernel_names();
    init_tensor_util_env();
    init_operation();
    reverse = op({
      reverse_
    });
  }
});

// node_modules/@tensorflow/tfjs-core/dist/ops/reverse_1d.js
function reverse1d_(x) {
  const $x = convertToTensor(x, "x", "reverse");
  assert($x.rank === 1, () => `Error in reverse1D: x must be rank 1 but got rank ${$x.rank}.`);
  return reverse($x, 0);
}
var reverse1d;
var init_reverse_1d = __esm({
  "node_modules/@tensorflow/tfjs-core/dist/ops/reverse_1d.js"() {
    init_tensor_util_env();
    init_util();
    init_operation();
    init_reverse();
    reverse1d = op({
      reverse1d_
    });
  }
});

// node_modules/@tensorflow/tfjs-core/dist/ops/reverse_2d.js
function reverse2d_(x, axis) {
  const $x = convertToTensor(x, "x", "reverse");
  assert($x.rank === 2, () => `Error in reverse2D: x must be rank 2 but got rank ${$x.rank}.`);
  return reverse($x, axis);
}
var reverse2d;
var init_reverse_2d = __esm({
  "node_modules/@tensorflow/tfjs-core/dist/ops/reverse_2d.js"() {
    init_tensor_util_env();
    init_util();
    init_operation();
    init_reverse();
    reverse2d = op({
      reverse2d_
    });
  }
});

// node_modules/@tensorflow/tfjs-core/dist/ops/reverse_3d.js
function reverse3d_(x, axis) {
  const $x = convertToTensor(x, "x", "reverse");
  assert($x.rank === 3, () => `Error in reverse3D: x must be rank 3 but got rank ${$x.rank}.`);
  return reverse($x, axis);
}
var reverse3d;
var init_reverse_3d = __esm({
  "node_modules/@tensorflow/tfjs-core/dist/ops/reverse_3d.js"() {
    init_tensor_util_env();
    init_util();
    init_operation();
    init_reverse();
    reverse3d = op({
      reverse3d_
    });
  }
});

// node_modules/@tensorflow/tfjs-core/dist/ops/reverse_4d.js
function reverse4d_(x, axis) {
  const $x = convertToTensor(x, "x", "reverse");
  assert($x.rank === 4, () => `Error in reverse4D: x must be rank 4 but got rank ${$x.rank}.`);
  return reverse($x, axis);
}
var reverse4d;
var init_reverse_4d = __esm({
  "node_modules/@tensorflow/tfjs-core/dist/ops/reverse_4d.js"() {
    init_tensor_util_env();
    init_util();
    init_operation();
    init_reverse();
    reverse4d = op({
      reverse4d_
    });
  }
});

// node_modules/@tensorflow/tfjs-core/dist/ops/round.js
function round_(x) {
  const $x = convertToTensor(x, "x", "round");
  const inputs = {
    x: $x
  };
  return ENGINE.runKernel(Round, inputs);
}
var round2;
var init_round = __esm({
  "node_modules/@tensorflow/tfjs-core/dist/ops/round.js"() {
    init_engine();
    init_kernel_names();
    init_tensor_util_env();
    init_operation();
    round2 = op({
      round_
    });
  }
});

// node_modules/@tensorflow/tfjs-core/dist/ops/rsqrt.js
function rsqrt_(x) {
  const $x = convertToTensor(x, "x", "rsqrt", "float32");
  const inputs = {
    x: $x
  };
  return ENGINE.runKernel(Rsqrt, inputs);
}
var rsqrt;
var init_rsqrt = __esm({
  "node_modules/@tensorflow/tfjs-core/dist/ops/rsqrt.js"() {
    init_engine();
    init_kernel_names();
    init_tensor_util_env();
    init_operation();
    rsqrt = op({
      rsqrt_
    });
  }
});

// node_modules/@tensorflow/tfjs-core/dist/ops/selu.js
function selu_(x) {
  const $x = convertToTensor(x, "x", "selu");
  const inputs = {
    x: $x
  };
  return ENGINE.runKernel(Selu, inputs);
}
var selu;
var init_selu = __esm({
  "node_modules/@tensorflow/tfjs-core/dist/ops/selu.js"() {
    init_engine();
    init_kernel_names();
    init_tensor_util_env();
    init_operation();
    selu = op({
      selu_
    });
  }
});

// node_modules/@tensorflow/tfjs-core/dist/ops/separable_conv2d.js
function separableConv2d_(x, depthwiseFilter, pointwiseFilter, strides, pad2, dilation = [1, 1], dataFormat = "NHWC") {
  const $x = convertToTensor(x, "x", "separableConv2d");
  const $depthwiseFilter = convertToTensor(depthwiseFilter, "depthwiseFilter", "separableConv2d");
  const $pointwiseFilter = convertToTensor(pointwiseFilter, "pointwiseFilter", "separableConv2d");
  let x4D = $x;
  let reshapedTo4D = false;
  if ($x.rank === 3) {
    reshapedTo4D = true;
    x4D = reshape($x, [1, $x.shape[0], $x.shape[1], $x.shape[2]]);
  }
  if (dataFormat === "NCHW") {
    throw new Error("separableConv2d currently does not support dataFormat NCHW; only NHWC is supported");
  }
  assert(x4D.rank === 4, () => `Error in separableConv2d: input must be rank 4, but got rank ${x4D.rank}.`);
  assert($depthwiseFilter.rank === 4, () => `Error in separableConv2d: depthwise filter must be rank 4, but got rank ${$depthwiseFilter.rank}.`);
  assert($pointwiseFilter.rank === 4, () => `Error in separableConv2d: pointwise filter must be rank 4, but got rank ${$depthwiseFilter.rank}.`);
  assert($pointwiseFilter.shape[0] === 1, () => `Error in separableConv2d: the first dimension of pointwise filter  must be 1, but got ${$pointwiseFilter.shape[0]}.`);
  assert($pointwiseFilter.shape[1] === 1, () => `Error in separableConv2d: the second dimension of pointwise filter must be 1, but got ${$pointwiseFilter.shape[1]}.`);
  const inChannels = $depthwiseFilter.shape[2];
  const channelMultiplier = $depthwiseFilter.shape[3];
  assert($pointwiseFilter.shape[2] === inChannels * channelMultiplier, () => `Error in separableConv2d: the third dimension of pointwise filter must be ${inChannels * channelMultiplier}, but got ${$pointwiseFilter.shape[2]}.`);
  const depthwise = depthwiseConv2d(x4D, $depthwiseFilter, strides, pad2, dataFormat, dilation);
  const pointwiseStride = 1;
  const res = conv2d(depthwise, $pointwiseFilter, pointwiseStride, "valid", dataFormat);
  if (reshapedTo4D) {
    return reshape(res, [res.shape[1], res.shape[2], res.shape[3]]);
  }
  return res;
}
var separableConv2d;
var init_separable_conv2d = __esm({
  "node_modules/@tensorflow/tfjs-core/dist/ops/separable_conv2d.js"() {
    init_tensor_util_env();
    init_util();
    init_conv2d();
    init_depthwise_conv2d();
    init_operation();
    init_reshape();
    separableConv2d = op({
      separableConv2d_
    });
  }
});

// node_modules/@tensorflow/tfjs-core/dist/ops/setdiff1d_async.js
function setdiff1dAsync_(x, y) {
  return __async(this, null, function* () {
    const $x = convertToTensor(x, "x", "setdiff1d");
    const $y = convertToTensor(y, "y", "setdiff1d");
    assert($x.dtype === $y.dtype, () => `x and y should have the same dtype, but got x (${$x.dtype}) and y (${$y.dtype}).`);
    assert($x.rank === 1, () => `x should be 1D tensor, but got x (${$x.shape}).`);
    assert($y.rank === 1, () => `y should be 1D tensor, but got y (${$y.shape}).`);
    const xVals = yield $x.data();
    const yVals = yield $y.data();
    const ySet = new Set(yVals);
    let outputSize = 0;
    for (let i = 0; i < xVals.length; i++) {
      if (!ySet.has(xVals[i])) {
        outputSize++;
      }
    }
    const buffer2 = new TensorBuffer([outputSize], $x.dtype);
    const indices = new TensorBuffer([outputSize], "int32");
    for (let i = 0, p = 0; i < xVals.length; i++) {
      if (!ySet.has(xVals[i])) {
        buffer2.values[p] = xVals[i];
        indices.values[p] = i;
        p++;
      }
    }
    return [buffer2.toTensor(), indices.toTensor()];
  });
}
var setdiff1dAsync;
var init_setdiff1d_async = __esm({
  "node_modules/@tensorflow/tfjs-core/dist/ops/setdiff1d_async.js"() {
    init_tensor();
    init_tensor_util_env();
    init_util();
    setdiff1dAsync = setdiff1dAsync_;
  }
});

// node_modules/@tensorflow/tfjs-core/dist/ops/sign.js
function sign_(x) {
  const $x = convertToTensor(x, "x", "sign");
  const inputs = {
    x: $x
  };
  return ENGINE.runKernel(Sign, inputs);
}
var sign;
var init_sign = __esm({
  "node_modules/@tensorflow/tfjs-core/dist/ops/sign.js"() {
    init_engine();
    init_kernel_names();
    init_tensor_util_env();
    init_operation();
    sign = op({
      sign_
    });
  }
});

// node_modules/@tensorflow/tfjs-core/dist/ops/sin.js
function sin_(x) {
  const $x = convertToTensor(x, "x", "sin", "float32");
  const inputs = {
    x: $x
  };
  return ENGINE.runKernel(Sin, inputs);
}
var sin;
var init_sin = __esm({
  "node_modules/@tensorflow/tfjs-core/dist/ops/sin.js"() {
    init_engine();
    init_kernel_names();
    init_tensor_util_env();
    init_operation();
    sin = op({
      sin_
    });
  }
});

// node_modules/@tensorflow/tfjs-core/dist/ops/sinh.js
function sinh_(x) {
  const $x = convertToTensor(x, "x", "sinh");
  const inputs = {
    x: $x
  };
  return ENGINE.runKernel(Sinh, inputs);
}
var sinh;
var init_sinh = __esm({
  "node_modules/@tensorflow/tfjs-core/dist/ops/sinh.js"() {
    init_engine();
    init_kernel_names();
    init_tensor_util_env();
    init_operation();
    sinh = op({
      sinh_
    });
  }
});

// node_modules/@tensorflow/tfjs-core/dist/ops/slice1d.js
function slice1d_(x, begin, size) {
  const $x = convertToTensor(x, "x", "slice1d");
  assert($x.rank === 1, () => `slice1d expects a rank-1 tensor, but got a rank-${$x.rank} tensor`);
  return slice($x, [begin], [size]);
}
var slice1d;
var init_slice1d = __esm({
  "node_modules/@tensorflow/tfjs-core/dist/ops/slice1d.js"() {
    init_tensor_util_env();
    init_util();
    init_operation();
    init_slice();
    slice1d = op({
      slice1d_
    });
  }
});

// node_modules/@tensorflow/tfjs-core/dist/ops/slice2d.js
function slice2d_(x, begin, size) {
  const $x = convertToTensor(x, "x", "slice2d");
  assert($x.rank === 2, () => `slice2d expects a rank-2 tensor, but got a rank-${$x.rank} tensor`);
  return slice($x, begin, size);
}
var slice2d;
var init_slice2d = __esm({
  "node_modules/@tensorflow/tfjs-core/dist/ops/slice2d.js"() {
    init_tensor_util_env();
    init_util();
    init_operation();
    init_slice();
    slice2d = op({
      slice2d_
    });
  }
});

// node_modules/@tensorflow/tfjs-core/dist/ops/slice3d.js
function slice3d_(x, begin, size) {
  const $x = convertToTensor(x, "x", "slice3d");
  assert($x.rank === 3, () => `slice3d expects a rank-3 tensor, but got a rank-${$x.rank} tensor`);
  return slice($x, begin, size);
}
var slice3d;
var init_slice3d = __esm({
  "node_modules/@tensorflow/tfjs-core/dist/ops/slice3d.js"() {
    init_tensor_util_env();
    init_util();
    init_operation();
    init_slice();
    slice3d = op({
      slice3d_
    });
  }
});

// node_modules/@tensorflow/tfjs-core/dist/ops/slice4d.js
function slice4d_(x, begin, size) {
  const $x = convertToTensor(x, "x", "slice4d");
  assert($x.rank === 4, () => `slice4d expects a rank-4 tensor, but got a rank-${$x.rank} tensor`);
  return slice($x, begin, size);
}
var slice4d;
var init_slice4d = __esm({
  "node_modules/@tensorflow/tfjs-core/dist/ops/slice4d.js"() {
    init_tensor_util_env();
    init_util();
    init_operation();
    init_slice();
    slice4d = op({
      slice4d_
    });
  }
});

// node_modules/@tensorflow/tfjs-core/dist/ops/softmax.js
function softmax_(logits, dim = -1) {
  const $logits = convertToTensor(logits, "logits", "softmax", "float32");
  if (dim === -1) {
    dim = $logits.rank - 1;
  }
  if (dim !== $logits.rank - 1) {
    throw Error(`Softmax along a non-last dimension is not yet supported. Logits was rank ${$logits.rank} and dim was ${dim}`);
  }
  const inputs = {
    logits: $logits
  };
  const attrs = {
    dim
  };
  return ENGINE.runKernel(Softmax, inputs, attrs);
}
var softmax;
var init_softmax = __esm({
  "node_modules/@tensorflow/tfjs-core/dist/ops/softmax.js"() {
    init_engine();
    init_kernel_names();
    init_tensor_util_env();
    init_operation();
    softmax = op({
      softmax_
    });
  }
});

// node_modules/@tensorflow/tfjs-core/dist/ops/spectral/fft.js
function fft_(input) {
  assert(input.dtype === "complex64", () => `The dtype for tf.spectral.fft() must be complex64 but got ${input.dtype}.`);
  const inputs = {
    input
  };
  return ENGINE.runKernel(FFT, inputs);
}
var fft;
var init_fft = __esm({
  "node_modules/@tensorflow/tfjs-core/dist/ops/spectral/fft.js"() {
    init_engine();
    init_kernel_names();
    init_util();
    init_operation();
    fft = op({
      fft_
    });
  }
});

// node_modules/@tensorflow/tfjs-core/dist/ops/spectral/ifft.js
function ifft_(input) {
  assert(input.dtype === "complex64", () => `The dtype for tf.spectral.ifft() must be complex64 but got ${input.dtype}.`);
  const inputs = {
    input
  };
  return ENGINE.runKernel(IFFT, inputs);
}
var ifft;
var init_ifft = __esm({
  "node_modules/@tensorflow/tfjs-core/dist/ops/spectral/ifft.js"() {
    init_engine();
    init_kernel_names();
    init_util();
    init_operation();
    ifft = op({
      ifft_
    });
  }
});

// node_modules/@tensorflow/tfjs-core/dist/ops/spectral/irfft.js
function irfft_(input) {
  const innerDimensionSize = input.shape[input.shape.length - 1];
  const batch = input.size / innerDimensionSize;
  let ret;
  if (innerDimensionSize <= 2) {
    const complexInput = reshape(input, [batch, innerDimensionSize]);
    ret = ifft(complexInput);
  } else {
    const outputShape = [batch, 2 * (innerDimensionSize - 1)];
    const realInput = reshape(real(input), [batch, innerDimensionSize]);
    const imagInput = reshape(imag(input), [batch, innerDimensionSize]);
    const realConjugate = reverse(slice(realInput, [0, 1], [batch, innerDimensionSize - 2]), 1);
    const imagConjugate = mul(reverse(slice(imagInput, [0, 1], [batch, innerDimensionSize - 2]), 1), scalar(-1));
    const r = concat([realInput, realConjugate], 1);
    const i = concat([imagInput, imagConjugate], 1);
    const complexInput = reshape(complex(r, i), [outputShape[0], outputShape[1]]);
    ret = ifft(complexInput);
  }
  ret = real(ret);
  if (input.rank === 3 && input.shape[0] !== 0) {
    const temp = ret;
    const batch2 = input.shape[0];
    ret = reshape(ret, [batch2, ret.shape[0] / batch2, ret.shape[1]]);
    temp.dispose();
  }
  return ret;
}
var irfft;
var init_irfft = __esm({
  "node_modules/@tensorflow/tfjs-core/dist/ops/spectral/irfft.js"() {
    init_complex();
    init_concat();
    init_imag();
    init_mul();
    init_operation();
    init_real();
    init_reshape();
    init_reverse();
    init_scalar();
    init_slice();
    init_ifft();
    irfft = op({
      irfft_
    });
  }
});

// node_modules/@tensorflow/tfjs-core/dist/ops/split.js
function split_(x, numOrSizeSplits, axis = 0) {
  const $x = convertToTensor(x, "x", "split");
  const inputs = {
    x: $x
  };
  const attr = {
    numOrSizeSplits,
    axis
  };
  return ENGINE.runKernel(SplitV, inputs, attr);
}
var split;
var init_split = __esm({
  "node_modules/@tensorflow/tfjs-core/dist/ops/split.js"() {
    init_engine();
    init_kernel_names();
    init_tensor_util_env();
    init_operation();
    split = op({
      split_
    });
  }
});

// node_modules/@tensorflow/tfjs-core/dist/ops/spectral/rfft.js
function rfft_(input, fftLength) {
  assert(input.dtype === "float32", () => `The dtype for rfft() must be real value but got ${input.dtype}`);
  let innerDimensionSize = input.shape[input.shape.length - 1];
  const batch = input.size / innerDimensionSize;
  let adjustedInput;
  if (fftLength != null && fftLength < innerDimensionSize) {
    const begin = input.shape.map((v) => 0);
    const size = input.shape.map((v) => v);
    size[input.shape.length - 1] = fftLength;
    adjustedInput = slice(input, begin, size);
    innerDimensionSize = fftLength;
  } else if (fftLength != null && fftLength > innerDimensionSize) {
    const zerosShape = input.shape.map((v) => v);
    zerosShape[input.shape.length - 1] = fftLength - innerDimensionSize;
    adjustedInput = concat([input, zeros(zerosShape)], input.shape.length - 1);
    innerDimensionSize = fftLength;
  } else {
    adjustedInput = input;
  }
  const zerosInput = zerosLike(adjustedInput);
  const complexInput = reshape(complex(adjustedInput, zerosInput), [batch, innerDimensionSize]);
  const ret = fft(complexInput);
  const half = Math.floor(innerDimensionSize / 2) + 1;
  const realValues = real(ret);
  const imagValues = imag(ret);
  const realComplexConjugate = split(realValues, [half, innerDimensionSize - half], realValues.shape.length - 1);
  const imagComplexConjugate = split(imagValues, [half, innerDimensionSize - half], imagValues.shape.length - 1);
  const outputShape = adjustedInput.shape.slice();
  outputShape[adjustedInput.shape.length - 1] = half;
  return reshape(complex(realComplexConjugate[0], imagComplexConjugate[0]), outputShape);
}
var rfft;
var init_rfft = __esm({
  "node_modules/@tensorflow/tfjs-core/dist/ops/spectral/rfft.js"() {
    init_util();
    init_complex();
    init_concat();
    init_imag();
    init_operation();
    init_real();
    init_reshape();
    init_slice();
    init_split();
    init_zeros();
    init_zeros_like();
    init_fft();
    rfft = op({
      rfft_
    });
  }
});

// node_modules/@tensorflow/tfjs-core/dist/ops/squared_difference.js
function squaredDifference_(a, b) {
  let $a = convertToTensor(a, "a", "squaredDifference");
  let $b = convertToTensor(b, "b", "squaredDifference");
  [$a, $b] = makeTypesMatch($a, $b);
  assertAndGetBroadcastShape($a.shape, $b.shape);
  const inputs = {
    a: $a,
    b: $b
  };
  const attrs = {};
  return ENGINE.runKernel(SquaredDifference, inputs, attrs);
}
var squaredDifference;
var init_squared_difference = __esm({
  "node_modules/@tensorflow/tfjs-core/dist/ops/squared_difference.js"() {
    init_engine();
    init_kernel_names();
    init_tensor_util();
    init_tensor_util_env();
    init_broadcast_util();
    init_operation();
    squaredDifference = op({
      squaredDifference_
    });
  }
});

// node_modules/@tensorflow/tfjs-core/dist/ops/squeeze.js
function squeeze_(x, axis) {
  const $x = convertToTensor(x, "x", "squeeze", "string_or_numeric");
  return reshape($x, squeezeShape($x.shape, axis).newShape);
}
var squeeze;
var init_squeeze = __esm({
  "node_modules/@tensorflow/tfjs-core/dist/ops/squeeze.js"() {
    init_tensor_util_env();
    init_util();
    init_operation();
    init_reshape();
    squeeze = op({
      squeeze_
    });
  }
});

// node_modules/@tensorflow/tfjs-core/dist/ops/stack.js
function stack_(tensors, axis = 0) {
  const $tensors = convertToTensorArray(tensors, "tensors", "stack", "string_or_numeric");
  assert($tensors.length >= 1, () => "Pass at least one tensor to tf.stack");
  if ($tensors.length > 0) {
    assert(axis <= $tensors[0].rank, () => "Axis must be <= rank of the tensor");
  }
  const inputs = $tensors;
  const attrs = {
    axis
  };
  return ENGINE.runKernel(Pack, inputs, attrs);
}
var stack;
var init_stack = __esm({
  "node_modules/@tensorflow/tfjs-core/dist/ops/stack.js"() {
    init_engine();
    init_kernel_names();
    init_tensor_util_env();
    init_util();
    init_operation();
    stack = op({
      stack_
    });
  }
});

// node_modules/@tensorflow/tfjs-core/dist/ops/step.js
function step_(x, alpha = 0) {
  const $x = convertToTensor(x, "x", "step");
  const inputs = {
    x: $x
  };
  const attrs = {
    alpha
  };
  return ENGINE.runKernel(Step, inputs, attrs);
}
var step;
var init_step = __esm({
  "node_modules/@tensorflow/tfjs-core/dist/ops/step.js"() {
    init_engine();
    init_kernel_names();
    init_tensor_util_env();
    init_operation();
    step = op({
      step_
    });
  }
});

// node_modules/@tensorflow/tfjs-core/dist/ops/strided_slice.js
function stridedSlice_(x, begin, end, strides, beginMask = 0, endMask = 0, ellipsisMask = 0, newAxisMask = 0, shrinkAxisMask = 0) {
  const $x = convertToTensor(x, "x", "stridedSlice", "string_or_numeric");
  const inputs = {
    x: $x
  };
  const attrs = {
    begin,
    end,
    strides,
    beginMask,
    endMask,
    ellipsisMask,
    newAxisMask,
    shrinkAxisMask
  };
  return ENGINE.runKernel(StridedSlice, inputs, attrs);
}
var stridedSlice;
var init_strided_slice = __esm({
  "node_modules/@tensorflow/tfjs-core/dist/ops/strided_slice.js"() {
    init_engine();
    init_kernel_names();
    init_tensor_util_env();
    init_operation();
    stridedSlice = op({
      stridedSlice_
    });
  }
});

// node_modules/@tensorflow/tfjs-core/dist/ops/tan.js
function tan_(x) {
  const $x = convertToTensor(x, "x", "tan", "float32");
  const inputs = {
    x: $x
  };
  return ENGINE.runKernel(Tan, inputs);
}
var tan;
var init_tan = __esm({
  "node_modules/@tensorflow/tfjs-core/dist/ops/tan.js"() {
    init_engine();
    init_kernel_names();
    init_tensor_util_env();
    init_operation();
    tan = op({
      tan_
    });
  }
});

// node_modules/@tensorflow/tfjs-core/dist/ops/tensor1d.js
function tensor1d(values, dtype) {
  assertNonNull(values);
  const inferredShape = inferShape(values, dtype);
  if (inferredShape.length !== 1) {
    throw new Error("tensor1d() requires values to be a flat/TypedArray");
  }
  const shape = null;
  return makeTensor(values, shape, inferredShape, dtype);
}
var init_tensor1d = __esm({
  "node_modules/@tensorflow/tfjs-core/dist/ops/tensor1d.js"() {
    init_tensor_util_env();
    init_util();
    init_tensor_ops_util();
  }
});

// node_modules/@tensorflow/tfjs-core/dist/ops/tensor2d.js
function tensor2d(values, shape, dtype) {
  assertNonNull(values);
  if (shape != null && shape.length !== 2) {
    throw new Error("tensor2d() requires shape to have two numbers");
  }
  const inferredShape = inferShape(values, dtype);
  if (inferredShape.length !== 2 && inferredShape.length !== 1) {
    throw new Error("tensor2d() requires values to be number[][] or flat/TypedArray");
  }
  if (inferredShape.length === 1 && shape == null) {
    throw new Error("tensor2d() requires shape to be provided when `values` are a flat/TypedArray");
  }
  return makeTensor(values, shape, inferredShape, dtype);
}
var init_tensor2d = __esm({
  "node_modules/@tensorflow/tfjs-core/dist/ops/tensor2d.js"() {
    init_tensor_util_env();
    init_util();
    init_tensor_ops_util();
  }
});

// node_modules/@tensorflow/tfjs-core/dist/ops/tensor3d.js
function tensor3d(values, shape, dtype) {
  assertNonNull(values);
  if (shape != null && shape.length !== 3) {
    throw new Error("tensor3d() requires shape to have three numbers");
  }
  const inferredShape = inferShape(values, dtype);
  if (inferredShape.length !== 3 && inferredShape.length !== 1) {
    throw new Error("tensor3d() requires values to be number[][][] or flat/TypedArray");
  }
  if (inferredShape.length === 1 && shape == null) {
    throw new Error("tensor3d() requires shape to be provided when `values` are a flat array");
  }
  return makeTensor(values, shape, inferredShape, dtype);
}
var init_tensor3d = __esm({
  "node_modules/@tensorflow/tfjs-core/dist/ops/tensor3d.js"() {
    init_tensor_util_env();
    init_util();
    init_tensor_ops_util();
  }
});

// node_modules/@tensorflow/tfjs-core/dist/ops/tensor4d.js
function tensor4d(values, shape, dtype) {
  assertNonNull(values);
  if (shape != null && shape.length !== 4) {
    throw new Error("tensor4d() requires shape to have four numbers");
  }
  const inferredShape = inferShape(values, dtype);
  if (inferredShape.length !== 4 && inferredShape.length !== 1) {
    throw new Error("tensor4d() requires values to be number[][][][] or flat/TypedArray");
  }
  if (inferredShape.length === 1 && shape == null) {
    throw new Error("tensor4d() requires shape to be provided when `values` are a flat array");
  }
  return makeTensor(values, shape, inferredShape, dtype);
}
var init_tensor4d = __esm({
  "node_modules/@tensorflow/tfjs-core/dist/ops/tensor4d.js"() {
    init_tensor_util_env();
    init_util();
    init_tensor_ops_util();
  }
});

// node_modules/@tensorflow/tfjs-core/dist/ops/tensor5d.js
function tensor5d(values, shape, dtype) {
  assertNonNull(values);
  if (shape != null && shape.length !== 5) {
    throw new Error("tensor5d() requires shape to have five numbers");
  }
  const inferredShape = inferShape(values, dtype);
  if (inferredShape.length !== 5 && inferredShape.length !== 1) {
    throw new Error("tensor5d() requires values to be number[][][][][] or flat/TypedArray");
  }
  if (inferredShape.length === 1 && shape == null) {
    throw new Error("tensor5d() requires shape to be provided when `values` are a flat array");
  }
  return makeTensor(values, shape, inferredShape, dtype);
}
var init_tensor5d = __esm({
  "node_modules/@tensorflow/tfjs-core/dist/ops/tensor5d.js"() {
    init_tensor_util_env();
    init_util();
    init_tensor_ops_util();
  }
});

// node_modules/@tensorflow/tfjs-core/dist/ops/tensor6d.js
function tensor6d(values, shape, dtype) {
  assertNonNull(values);
  if (shape != null && shape.length !== 6) {
    throw new Error("tensor6d() requires shape to have six numbers");
  }
  const inferredShape = inferShape(values, dtype);
  if (inferredShape.length !== 6 && inferredShape.length !== 1) {
    throw new Error("tensor6d() requires values to be number[][][][][][] or flat/TypedArray");
  }
  if (inferredShape.length === 1 && shape == null) {
    throw new Error("tensor6d() requires shape to be provided when `values` are a flat array");
  }
  shape = shape || inferredShape;
  return makeTensor(values, shape, inferredShape, dtype);
}
var init_tensor6d = __esm({
  "node_modules/@tensorflow/tfjs-core/dist/ops/tensor6d.js"() {
    init_tensor_util_env();
    init_util();
    init_tensor_ops_util();
  }
});

// node_modules/@tensorflow/tfjs-core/dist/ops/scatter_nd_util.js
var scatter_nd_util_exports = {};
__export(scatter_nd_util_exports, {
  calculateShapes: () => calculateShapes,
  validateInput: () => validateInput,
  validateUpdateShape: () => validateUpdateShape
});
function validateUpdateShape(shape, indices, updates) {
  const sliceDim = indices.rank > 1 ? indices.shape[indices.rank - 1] : 1;
  const batchDim = indices.rank > 1 ? indices.rank - 1 : 1;
  const shapeError = `Must have updates.shape = indices.shape[:batchDim] + shape[sliceDim:], got updates.shape: ${updates.shape}, indices.shape: ${indices.shape}, shape: ${shape}, sliceDim: ${sliceDim}, and batchDim: ${batchDim}.`;
  if (updates.rank < batchDim) {
    throw new Error(shapeError + ` update.rank < ${batchDim}. `);
  }
  if (shape.length < sliceDim + (updates.rank - batchDim)) {
    throw new Error(shapeError + ` Output shape length < ${sliceDim + (updates.rank - batchDim)}`);
  }
  if (updates.rank !== batchDim + shape.length - sliceDim) {
    throw new Error(shapeError + ` update.rank != ${batchDim + shape.length - sliceDim}`);
  }
  for (let d = 0; d < batchDim; ++d) {
    if (updates.shape[d] !== indices.shape[d]) {
      throw new Error(shapeError + ` updates.shape[${d}] (${updates.shape[d]}) != indices.shape[${d}] (${indices.shape[d]}).`);
    }
  }
  for (let d = 0; d < updates.rank - batchDim; ++d) {
    if (updates.shape[d + batchDim] !== shape[d + sliceDim]) {
      throw new Error(shapeError + ` updates.shape[${d + batchDim}] (${updates.shape[d + batchDim]}) != shape[${d + batchDim}] (${shape[d + batchDim]})`);
    }
  }
}
function validateInput(updates, indices, shape) {
  if (indices.rank < 1) {
    throw new Error(`tf.scatterND() expects the indices to be rank 1 or higher, but the rank was ${indices.rank}.`);
  }
  if (updates.rank < 1) {
    throw new Error(`tf.scatterND() expects the updates to be rank 1 or higher, but the rank was ${updates.rank}.`);
  }
  if (indices.dtype !== "int32") {
    throw new Error(`The dtype of 'indices' should be int32, but got dtype: ${indices.dtype}`);
  }
  if (shape.length < 1) {
    throw new Error(`Output rank must be greater or equal to 1, but got shape: ${shape}`);
  }
  if (shape.length === 0) {
    if (indices.size === 0) {
      throw new Error(`Indices specified for empty output. indices shape: ${indices.shape}`);
    }
    if (updates.size === 0) {
      throw new Error(`Updates specified for empty output. updates shape: ${updates.shape}`);
    }
  }
  validateUpdateShape(shape, indices, updates);
}
function calculateShapes(updates, indices, shape) {
  const indicesRank = indices.shape.length;
  const sliceRank = indicesRank > 1 ? indices.shape[indicesRank - 1] : 1;
  const totalNd = shape.length;
  let sliceSize = 1;
  for (let i = sliceRank; i < totalNd; ++i) {
    sliceSize *= shape[i];
  }
  const safeSliceDim = sliceRank < 1 ? 1 : sliceRank;
  const numUpdates = sizeFromShape(indices.shape) / safeSliceDim;
  const strides = [...computeStrides(shape.slice(0, sliceRank)), 1];
  const outputSize = sizeFromShape(shape);
  return {
    sliceRank,
    numUpdates,
    sliceSize,
    strides,
    outputSize
  };
}
var init_scatter_nd_util = __esm({
  "node_modules/@tensorflow/tfjs-core/dist/ops/scatter_nd_util.js"() {
    init_util();
  }
});

// node_modules/@tensorflow/tfjs-core/dist/ops/tensor_scatter_update.js
function tensorScatterUpdate_(tensor2, indices, updates) {
  const $tensor = convertToTensor(tensor2, "tensor", "tensorScatterupdate");
  const $indices = convertToTensor(indices, "indices", "tensorScatterupdate", "int32");
  const $updates = convertToTensor(updates, "updates", "tensorScatterupdate");
  validateInput($updates, $indices, $tensor.shape);
  if ($tensor.dtype !== $updates.dtype) {
    throw new Error(`tensor and updates must have the same dtype, instead they are ${$tensor.dtype} and ${$updates.dtype}.`);
  }
  const inputs = {
    tensor: $tensor,
    indices: $indices,
    updates: $updates
  };
  const attrs = {};
  return ENGINE.runKernel(TensorScatterUpdate, inputs, attrs);
}
var tensorScatterUpdate;
var init_tensor_scatter_update = __esm({
  "node_modules/@tensorflow/tfjs-core/dist/ops/tensor_scatter_update.js"() {
    init_engine();
    init_kernel_names();
    init_tensor_util_env();
    init_operation();
    init_scatter_nd_util();
    tensorScatterUpdate = op({
      tensorScatterUpdate_
    });
  }
});

// node_modules/@tensorflow/tfjs-core/dist/ops/topk.js
function topk_(x, k = 1, sorted = true) {
  const $x = convertToTensor(x, "x", "topk");
  if ($x.rank === 0) {
    throw new Error("topk() expects the input to be of rank 1 or higher");
  }
  const lastDim = $x.shape[$x.shape.length - 1];
  if (k < 0) {
    throw new Error(`'k' passed to topk() must be >= 0 but got ${k}`);
  }
  if (k > lastDim) {
    throw new Error(`'k' passed to topk() must be <= the last dimension (${lastDim}) but got ${k}`);
  }
  const inputs = {
    x: $x
  };
  const attrs = {
    k,
    sorted
  };
  const [values, indices] = ENGINE.runKernel(TopK, inputs, attrs);
  return {
    values,
    indices
  };
}
var topk;
var init_topk = __esm({
  "node_modules/@tensorflow/tfjs-core/dist/ops/topk.js"() {
    init_engine();
    init_kernel_names();
    init_tensor_util_env();
    init_operation();
    topk = op({
      topk_
    });
  }
});

// node_modules/@tensorflow/tfjs-core/dist/ops/truncated_normal.js
function truncatedNormal_(shape, mean2 = 0, stdDev = 1, dtype, seed) {
  assertNonNegativeIntegerDimensions(shape);
  if (dtype != null && dtype === "bool") {
    throw new Error(`Unsupported data type $ { dtype }`);
  }
  const randGauss = new MPRandGauss(mean2, stdDev, dtype, true, seed);
  const res = buffer(shape, dtype);
  for (let i = 0; i < res.values.length; i++) {
    res.values[i] = randGauss.nextValue();
  }
  return res.toTensor();
}
var truncatedNormal;
var init_truncated_normal = __esm({
  "node_modules/@tensorflow/tfjs-core/dist/ops/truncated_normal.js"() {
    init_util_base();
    init_buffer();
    init_operation();
    init_rand_util();
    truncatedNormal = op({
      truncatedNormal_
    });
  }
});

// node_modules/@tensorflow/tfjs-core/dist/ops/unique.js
function unique_(x, axis = 0) {
  const $x = convertToTensor(x, "x", "unique", "string_or_numeric");
  assert($x.rank > 0, () => "The input tensor must be at least 1D");
  const inputs = {
    x: $x
  };
  const attrs = {
    axis
  };
  const [values, indices] = ENGINE.runKernel(Unique, inputs, attrs);
  return {
    values,
    indices
  };
}
var unique;
var init_unique = __esm({
  "node_modules/@tensorflow/tfjs-core/dist/ops/unique.js"() {
    init_engine();
    init_kernel_names();
    init_tensor_util_env();
    init_util();
    init_operation();
    unique = op({
      unique_
    });
  }
});

// node_modules/@tensorflow/tfjs-core/dist/ops/unsorted_segment_sum.js
function unsortedSegmentSum_(x, segmentIds, numSegments) {
  const $x = convertToTensor(x, "x", "unsortedSegmentSum");
  const $segmentIds = convertToTensor(segmentIds, "segmentIds", "unsortedSegmentSum", "int32");
  assert(isInt(numSegments), () => "numSegments must be of dtype int");
  const inputs = {
    x: $x,
    segmentIds: $segmentIds
  };
  const attrs = {
    numSegments
  };
  return ENGINE.runKernel(UnsortedSegmentSum, inputs, attrs);
}
var unsortedSegmentSum;
var init_unsorted_segment_sum = __esm({
  "node_modules/@tensorflow/tfjs-core/dist/ops/unsorted_segment_sum.js"() {
    init_engine();
    init_kernel_names();
    init_tensor_util_env();
    init_util();
    init_operation();
    unsortedSegmentSum = op({
      unsortedSegmentSum_
    });
  }
});

// node_modules/@tensorflow/tfjs-core/dist/ops/unstack.js
function unstack_(x, axis = 0) {
  const $x = convertToTensor(x, "x", "unstack", "string_or_numeric");
  assert(axis >= -$x.shape.length && axis < $x.shape.length, () => `Axis = ${axis} is not in [-${$x.shape.length}, ${$x.shape.length})`);
  const inputs = {
    value: $x
  };
  const attrs = {
    axis
  };
  return ENGINE.runKernel(Unpack, inputs, attrs);
}
var unstack;
var init_unstack = __esm({
  "node_modules/@tensorflow/tfjs-core/dist/ops/unstack.js"() {
    init_engine();
    init_kernel_names();
    init_tensor_util_env();
    init_util();
    init_operation();
    unstack = op({
      unstack_
    });
  }
});

// node_modules/@tensorflow/tfjs-core/dist/ops/upper_bound.js
function upperBound(sortedSequence, values) {
  return searchSorted(sortedSequence, values, "right");
}
var init_upper_bound = __esm({
  "node_modules/@tensorflow/tfjs-core/dist/ops/upper_bound.js"() {
    init_search_sorted();
  }
});

// node_modules/@tensorflow/tfjs-core/dist/ops/variable.js
function variable(initialValue, trainable = true, name, dtype) {
  return ENGINE.makeVariable(initialValue, trainable, name, dtype);
}
var init_variable = __esm({
  "node_modules/@tensorflow/tfjs-core/dist/ops/variable.js"() {
    init_engine();
  }
});

// node_modules/@tensorflow/tfjs-core/dist/backends/where_impl.js
function whereImpl(condShape, condVals) {
  const indices = [];
  for (let i = 0; i < condVals.length; i++) {
    if (condVals[i]) {
      indices.push(i);
    }
  }
  const inBuffer = buffer(condShape, "int32");
  const out = buffer([indices.length, condShape.length], "int32");
  for (let i = 0; i < indices.length; i++) {
    const loc = inBuffer.indexToLoc(indices[i]);
    const offset = i * condShape.length;
    out.values.set(loc, offset);
  }
  return out.toTensor();
}
var init_where_impl = __esm({
  "node_modules/@tensorflow/tfjs-core/dist/backends/where_impl.js"() {
    init_buffer();
  }
});

// node_modules/@tensorflow/tfjs-core/dist/ops/where_async.js
function whereAsync_(condition) {
  return __async(this, null, function* () {
    const $condition = convertToTensor(condition, "condition", "whereAsync", "bool");
    const vals = yield $condition.data();
    const res = whereImpl($condition.shape, vals);
    if (condition !== $condition) {
      $condition.dispose();
    }
    return res;
  });
}
var whereAsync;
var init_where_async = __esm({
  "node_modules/@tensorflow/tfjs-core/dist/ops/where_async.js"() {
    init_where_impl();
    init_tensor_util_env();
    whereAsync = whereAsync_;
  }
});

// node_modules/@tensorflow/tfjs-core/dist/ops/boolean_mask.js
function booleanMaskAsync_(tensor2, mask, axis) {
  return __async(this, null, function* () {
    const $tensor = convertToTensor(tensor2, "tensor", "boolMask");
    const $mask = convertToTensor(mask, "mask", "boolMask", "bool");
    const axisFrom = axis == null ? 0 : axis;
    const maskDim = $mask.rank;
    const tensorShape = $tensor.shape;
    assert(maskDim > 0, () => "mask cannot be scalar");
    assertShapesMatch(tensorShape.slice(axisFrom, axisFrom + maskDim), $mask.shape, `mask's shape must match the first K dimensions of tensor's shape,`);
    let leadingSize = 1;
    for (let i = axisFrom; i < axisFrom + maskDim; i++) {
      leadingSize *= tensorShape[i];
    }
    const targetTensorShape = tensorShape.slice(0, axisFrom).concat([leadingSize], tensorShape.slice(axisFrom + maskDim));
    const reshapedTensor = reshape($tensor, targetTensorShape);
    const reshapedMask = reshape($mask, [-1]);
    const positivePositions = yield whereAsync(reshapedMask);
    const indices = squeeze(positivePositions, [1]);
    const res = gather(reshapedTensor, indices, axisFrom);
    if (tensor2 !== $tensor) {
      $tensor.dispose();
    }
    if (mask !== $mask) {
      $mask.dispose();
    }
    indices.dispose();
    reshapedTensor.dispose();
    reshapedMask.dispose();
    positivePositions.dispose();
    return res;
  });
}
var booleanMaskAsync;
var init_boolean_mask = __esm({
  "node_modules/@tensorflow/tfjs-core/dist/ops/boolean_mask.js"() {
    init_tensor_util_env();
    init_util();
    init_gather();
    init_reshape();
    init_squeeze();
    init_where_async();
    booleanMaskAsync = booleanMaskAsync_;
  }
});

// node_modules/@tensorflow/tfjs-core/dist/ops/transpose.js
function transpose_(x, perm, conjugate) {
  const $x = convertToTensor(x, "x", "transpose");
  if (perm == null) {
    perm = $x.shape.map((s, i) => i).reverse();
  }
  assert($x.rank === perm.length, () => `Error in transpose: rank of input ${$x.rank} must match length of perm ${perm}.`);
  perm.forEach((axis) => {
    assert(axis >= 0 && axis < $x.rank, () => `All entries in 'perm' must be between 0 and ${$x.rank - 1} but got ${perm}`);
  });
  if ($x.rank <= 1) {
    return $x.clone();
  }
  const inputs = {
    x: $x
  };
  const attrs = {
    perm
  };
  if ($x.dtype === "complex64") {
    return tidy(() => {
      let $real = real($x);
      let $imag = imag($x);
      $real = ENGINE.runKernel(Transpose, {
        x: $real
      }, attrs);
      $imag = ENGINE.runKernel(Transpose, {
        x: $imag
      }, attrs);
      if (conjugate) {
        $imag = neg($imag);
      }
      return complex($real, $imag);
    });
  }
  return ENGINE.runKernel(Transpose, inputs, attrs);
}
var transpose;
var init_transpose = __esm({
  "node_modules/@tensorflow/tfjs-core/dist/ops/transpose.js"() {
    init_engine();
    init_globals();
    init_kernel_names();
    init_tensor_util_env();
    init_util();
    init_complex();
    init_imag();
    init_neg();
    init_operation();
    init_real();
    transpose = op({
      transpose_
    });
  }
});

// node_modules/@tensorflow/tfjs-core/dist/ops/moving_average.js
function movingAverage_(v, x, decay, step2, zeroDebias = true) {
  const $v = convertToTensor(v, "v", "movingAverage");
  const $x = convertToTensor(x, "x", "movingAverage");
  const $decay = convertToTensor(decay, "decay", "movingAverage");
  assertTypesMatch($v, $x);
  assert(arraysEqual($v.shape, $x.shape), () => "Shape mismatch in v and x");
  const one = scalar(1);
  const oneMinusDecay = sub(one, $decay);
  let update = mul(sub($x, $v), oneMinusDecay);
  if (zeroDebias) {
    assert(step2 != null, () => "When using zeroDebias: true, step is required.");
    const $step = convertToTensor(step2, "step", "movingAverage");
    update = div(update, sub(one, pow($decay, $step)));
  }
  return add2($v, update);
}
var movingAverage;
var init_moving_average = __esm({
  "node_modules/@tensorflow/tfjs-core/dist/ops/moving_average.js"() {
    init_tensor_util();
    init_tensor_util_env();
    init_util();
    init_add();
    init_div();
    init_mul();
    init_operation();
    init_pow();
    init_scalar();
    init_sub();
    movingAverage = op({
      movingAverage_
    });
  }
});

// node_modules/@tensorflow/tfjs-core/dist/ops/scatter_nd.js
function scatterND_(indices, updates, shape) {
  assertNonNegativeIntegerDimensions(shape);
  const $indices = convertToTensor(indices, "indices", "scatterND", "int32");
  const $updates = convertToTensor(updates, "updates", "scatterND");
  validateInput($updates, $indices, shape);
  const inputs = {
    indices: $indices,
    updates: $updates
  };
  const attrs = {
    shape
  };
  return ENGINE.runKernel(ScatterNd, inputs, attrs);
}
var scatterND;
var init_scatter_nd = __esm({
  "node_modules/@tensorflow/tfjs-core/dist/ops/scatter_nd.js"() {
    init_engine();
    init_kernel_names();
    init_tensor_util_env();
    init_util_base();
    init_operation();
    init_scatter_nd_util();
    scatterND = op({
      scatterND_
    });
  }
});

// node_modules/@tensorflow/tfjs-core/dist/ops/sparse_to_dense_util.js
function validateInput2(sparseIndices, sparseValues, outputShape, defaultValues) {
  if (sparseIndices.dtype !== "int32") {
    throw new Error(`tf.sparseToDense() expects the indices to be int32 type, but the dtype was ${sparseIndices.dtype}.`);
  }
  if (sparseIndices.rank > 2) {
    throw new Error(`sparseIndices should be a scalar, vector, or matrix, but got shape ${sparseIndices.shape}.`);
  }
  const numElems = sparseIndices.rank > 0 ? sparseIndices.shape[0] : 1;
  const numDims = sparseIndices.rank > 1 ? sparseIndices.shape[1] : 1;
  if (outputShape.length !== numDims) {
    throw new Error(`outputShape has incorrect number of elements:, ${outputShape.length}, should be: ${numDims}.`);
  }
  const numValues = sparseValues.size;
  if (!(sparseValues.rank === 0 || sparseValues.rank === 1 && numValues === numElems)) {
    throw new Error(`sparseValues has incorrect shape ${sparseValues.shape}, should be [] or [${numElems}]`);
  }
  if (sparseValues.dtype !== defaultValues.dtype) {
    throw new Error("sparseValues.dtype must match defaultValues.dtype");
  }
}
var init_sparse_to_dense_util = __esm({
  "node_modules/@tensorflow/tfjs-core/dist/ops/sparse_to_dense_util.js"() {
  }
});

// node_modules/@tensorflow/tfjs-core/dist/ops/sparse_to_dense.js
function sparseToDense_(sparseIndices, sparseValues, outputShape, defaultValue = 0) {
  assertNonNegativeIntegerDimensions(outputShape);
  const $sparseIndices = convertToTensor(sparseIndices, "sparseIndices", "sparseToDense", "int32");
  const $sparseValues = convertToTensor(sparseValues, "sparseValues", "sparseToDense", "string_or_numeric");
  const $defaultValue = convertToTensor(defaultValue, "defaultValue", "sparseToDense", $sparseValues.dtype);
  validateInput2($sparseIndices, $sparseValues, outputShape, $defaultValue);
  const inputs = {
    sparseIndices: $sparseIndices,
    sparseValues: $sparseValues,
    defaultValue: $defaultValue
  };
  const attrs = {
    outputShape
  };
  return ENGINE.runKernel(SparseToDense, inputs, attrs);
}
var sparseToDense;
var init_sparse_to_dense = __esm({
  "node_modules/@tensorflow/tfjs-core/dist/ops/sparse_to_dense.js"() {
    init_engine();
    init_kernel_names();
    init_sparse_to_dense_util();
    init_tensor_util_env();
    init_util_base();
    init_operation();
    sparseToDense = op({
      sparseToDense_
    });
  }
});

// node_modules/@tensorflow/tfjs-core/dist/ops/gather_nd.js
function gatherND_(x, indices) {
  const $indices = convertToTensor(indices, "indices", "gatherND", "int32");
  const $x = convertToTensor(x, "x", "gatherND", "string_or_numeric");
  const inputs = {
    params: $x,
    indices: $indices
  };
  return ENGINE.runKernel(GatherNd, inputs);
}
var gatherND;
var init_gather_nd = __esm({
  "node_modules/@tensorflow/tfjs-core/dist/ops/gather_nd.js"() {
    init_engine();
    init_kernel_names();
    init_tensor_util_env();
    init_operation();
    gatherND = op({
      gatherND_
    });
  }
});

// node_modules/@tensorflow/tfjs-core/dist/ops/dropout_util.js
function getNoiseShape(x, noiseShape) {
  if (noiseShape == null) {
    return x.shape.slice();
  }
  if (arraysEqual(x.shape, noiseShape)) {
    return noiseShape;
  }
  if (x.shape.length === noiseShape.length) {
    const newDimension = [];
    for (let i = 0; i < x.shape.length; i++) {
      if (noiseShape[i] == null && x.shape[i] != null) {
        newDimension.push(x.shape[i]);
      } else {
        newDimension.push(noiseShape[i]);
      }
    }
    return newDimension;
  }
  return noiseShape;
}
var init_dropout_util = __esm({
  "node_modules/@tensorflow/tfjs-core/dist/ops/dropout_util.js"() {
    init_util();
  }
});

// node_modules/@tensorflow/tfjs-core/dist/ops/dropout.js
function dropout_(x, rate, noiseShape, seed) {
  const $x = convertToTensor(x, "x", "dropout");
  assert($x.dtype === "float32", () => `x has to be a floating point tensor since it's going to be scaled, but got a ${$x.dtype} tensor instead.`);
  assert(rate >= 0 && rate < 1, () => `rate must be a float in the range [0, 1), but got ${rate}.`);
  if (rate === 0) {
    return x instanceof Tensor ? $x.clone() : $x;
  }
  const $noiseShape = getNoiseShape($x, noiseShape);
  const keepProb = 1 - rate;
  const multiplier = div(floor(add2(randomUniform($noiseShape, 0, 1, "float32", seed), keepProb)), keepProb);
  return mul($x, multiplier);
}
var dropout;
var init_dropout = __esm({
  "node_modules/@tensorflow/tfjs-core/dist/ops/dropout.js"() {
    init_tensor();
    init_tensor_util_env();
    init_util();
    init_add();
    init_div();
    init_dropout_util();
    init_floor();
    init_mul();
    init_operation();
    init_random_uniform();
    dropout = op({
      dropout_
    });
  }
});

// node_modules/@tensorflow/tfjs-core/dist/ops/signal_ops_util.js
function enclosingPowerOfTwo(value) {
  return Math.floor(Math.pow(2, Math.ceil(Math.log(value) / Math.log(2))));
}
function cosineWindow(windowLength, a, b) {
  const even = 1 - windowLength % 2;
  const newValues = new Float32Array(windowLength);
  for (let i = 0; i < windowLength; ++i) {
    const cosArg = 2 * Math.PI * i / (windowLength + even - 1);
    newValues[i] = a - b * Math.cos(cosArg);
  }
  return tensor1d(newValues, "float32");
}
var init_signal_ops_util = __esm({
  "node_modules/@tensorflow/tfjs-core/dist/ops/signal_ops_util.js"() {
    init_tensor1d();
  }
});

// node_modules/@tensorflow/tfjs-core/dist/ops/in_top_k.js
function inTopKAsync_(predictions, targets, k = 1) {
  return __async(this, null, function* () {
    const $predictions = convertToTensor(predictions, "predictions", "inTopK");
    const $targets = convertToTensor(targets, "targets", "inTopK");
    assert($predictions.rank > 1, () => `inTopK() expects the predictions to be of rank 2 or higher, but got ${$predictions.rank}`);
    assert($predictions.rank - 1 === $targets.rank, () => `predictions rank should be 1 larger than targets rank, but got predictions rank ${$predictions.rank} and targets rank ${$targets.rank}`);
    assertShapesMatch($predictions.shape.slice(0, $predictions.shape.length - 1), $targets.shape, `predictions's shape should be align with the targets' shape, except the last dimension.`);
    const lastDim = $predictions.shape[$predictions.shape.length - 1];
    assert(k > 0 && k <= lastDim, () => `'k' passed to inTopK() must be > 0 && <= the predictions last dimension (${lastDim}), but got ${k}`);
    const predictionsVals = yield $predictions.data();
    const targetsVals = yield $targets.data();
    const [batch, size] = [predictionsVals.length / lastDim, lastDim];
    const precision = getTypedArrayFromDType("bool", batch);
    for (let b = 0; b < batch; b++) {
      const offset = b * size;
      const vals = predictionsVals.subarray(offset, offset + size);
      const valAndInd = [];
      for (let i = 0; i < vals.length; i++) {
        valAndInd.push({
          value: vals[i],
          index: i
        });
      }
      valAndInd.sort((a, b2) => b2.value - a.value);
      precision[b] = 0;
      for (let i = 0; i < k; i++) {
        if (valAndInd[i].index === targetsVals[b]) {
          precision[b] = 1;
          break;
        }
      }
    }
    if (predictions !== $predictions) {
      $predictions.dispose();
    }
    if (targets !== $targets) {
      $targets.dispose();
    }
    return tensor(precision, $targets.shape, "bool");
  });
}
var inTopKAsync;
var init_in_top_k = __esm({
  "node_modules/@tensorflow/tfjs-core/dist/ops/in_top_k.js"() {
    init_tensor_util_env();
    init_util();
    init_tensor2();
    inTopKAsync = inTopKAsync_;
  }
});

// node_modules/@tensorflow/tfjs-core/dist/ops/conv2d_backprop_filter.js
function conv2DBackpropFilter_(x, dy, filterShape, strides, pad2, dataFormat = "NHWC", dimRoundingMode) {
  let x4D = x;
  if (x.rank === 3) {
    x4D = reshape(x, [1, x.shape[0], x.shape[1], x.shape[2]]);
  }
  let dy4D = dy;
  if (dy4D.rank === 3) {
    dy4D = reshape(dy, [1, dy.shape[0], dy.shape[1], dy.shape[2]]);
  }
  assert(x4D.rank === 4, () => `Error in conv2dDerFilter: input must be rank 4, but got shape ${x4D.shape}.`);
  assert(dy4D.rank === 4, () => `Error in conv2dDerFilter: dy must be rank 4, but got shape ${dy4D.shape}.`);
  assert(filterShape.length === 4, () => `Error in conv2dDerFilter: filterShape must be length 4, but got ${filterShape}.`);
  const inDepth = dataFormat === "NHWC" ? x4D.shape[3] : x4D.shape[1];
  const outDepth = dataFormat === "NHWC" ? dy4D.shape[3] : dy4D.shape[1];
  assert(inDepth === filterShape[2], () => `Error in conv2dDerFilter: depth of input ${inDepth}) must match input depth in filter (${filterShape[2]}.`);
  assert(outDepth === filterShape[3], () => `Error in conv2dDerFilter: depth of dy (${outDepth}) must match output depth for filter (${filterShape[3]}).`);
  checkPadOnDimRoundingMode("conv2dDerFilter", pad2, dimRoundingMode);
  const inputs = {
    x: x4D,
    dy: dy4D
  };
  const attrs = {
    strides,
    pad: pad2,
    dataFormat,
    dimRoundingMode,
    filterShape
  };
  return ENGINE.runKernel(Conv2DBackpropFilter, inputs, attrs);
}
var conv2DBackpropFilter;
var init_conv2d_backprop_filter = __esm({
  "node_modules/@tensorflow/tfjs-core/dist/ops/conv2d_backprop_filter.js"() {
    init_engine();
    init_kernel_names();
    init_util();
    init_conv_util();
    init_operation();
    init_reshape();
    conv2DBackpropFilter = op({
      conv2DBackpropFilter_
    });
  }
});

// node_modules/@tensorflow/tfjs-core/dist/ops/fused_util.js
function getFusedDyActivation(dy, y, activation) {
  if (activation == null || activation === "linear") {
    return dy;
  }
  if (activation === "relu") {
    return mul(dy, step(y));
  }
  throw new Error(`Cannot compute gradient for fused activation ${activation}.`);
}
function getFusedBiasGradient(bias, dyActivation) {
  let res = dyActivation;
  const reduceAxes = getReductionAxes(bias.shape, dyActivation.shape);
  if (reduceAxes.length > 0) {
    res = sum2(res, reduceAxes);
  }
  return reshape(res, bias.shape);
}
function applyActivation(x, activation, preluActivationWeights, leakyreluAlpha) {
  if (activation === "linear") {
    return x;
  } else if (activation === "relu") {
    return relu(x);
  } else if (activation === "elu") {
    return elu(x);
  } else if (activation === "relu6") {
    return relu6(x);
  } else if (activation === "prelu") {
    return prelu(x, preluActivationWeights);
  } else if (activation === "leakyrelu") {
    return leakyRelu(x, leakyreluAlpha);
  } else if (activation === "sigmoid") {
    return sigmoid(x);
  }
  throw new Error(`Unknown fused activation ${activation}.`);
}
var shouldFuse;
var init_fused_util = __esm({
  "node_modules/@tensorflow/tfjs-core/dist/ops/fused_util.js"() {
    init_broadcast_util();
    init_elu();
    init_leaky_relu();
    init_mul();
    init_prelu();
    init_relu();
    init_relu6();
    init_reshape();
    init_sigmoid();
    init_step();
    init_sum();
    shouldFuse = (gradientDepth, activation) => {
      const gradientMode = gradientDepth > 0;
      return !gradientMode || activation === "linear";
    };
  }
});

// node_modules/@tensorflow/tfjs-core/dist/ops/fused/conv2d.js
function fusedConv2d_({
  x,
  filter,
  strides,
  pad: pad2,
  dataFormat = "NHWC",
  dilations = [1, 1],
  dimRoundingMode,
  bias,
  activation = "linear",
  preluActivationWeights,
  leakyreluAlpha
}) {
  activation = activation || "linear";
  if (shouldFuse(ENGINE.state.gradientDepth, activation) === false) {
    assert(dataFormat === "NHWC", () => `Error in fused conv2d: got dataFormat of ${dataFormat} but only NHWC is currently supported for the case of gradient depth is 0 and the activation is not linear.`);
    let result = conv2d(x, filter, strides, pad2, dataFormat, dilations, dimRoundingMode);
    if (bias != null) {
      result = add2(result, bias);
    }
    return applyActivation(result, activation, preluActivationWeights, leakyreluAlpha);
  }
  const $x = convertToTensor(x, "x", "conv2d", "float32");
  const $filter = convertToTensor(filter, "filter", "conv2d", "float32");
  let x4D = $x;
  let reshapedTo4D = false;
  if ($x.rank === 3) {
    reshapedTo4D = true;
    x4D = reshape($x, [1, $x.shape[0], $x.shape[1], $x.shape[2]]);
  }
  assert(x4D.rank === 4, () => `Error in fused conv2d: input must be rank 4, but got rank ${x4D.rank}.`);
  assert($filter.rank === 4, () => `Error in fused conv2d: filter must be rank 4, but got rank ${$filter.rank}.`);
  checkPadOnDimRoundingMode("fused conv2d", pad2, dimRoundingMode);
  const inputChannels = dataFormat === "NHWC" ? x4D.shape[3] : x4D.shape[1];
  assert($filter.shape[2] === inputChannels, () => `Error in conv2d: depth of input (${inputChannels}) must match input depth for filter ${$filter.shape[2]}.`);
  assert(eitherStridesOrDilationsAreOne(strides, dilations), () => `Error in conv2D: Either strides or dilations must be 1. Got strides ${strides} and dilations '${dilations}'`);
  const convInfo = computeConv2DInfo(x4D.shape, $filter.shape, strides, dilations, pad2, dimRoundingMode);
  let $bias;
  if (bias != null) {
    $bias = convertToTensor(bias, "bias", "fused conv2d");
    [$bias] = makeTypesMatch($bias, $x);
    if (dataFormat === "NHWC") {
      assertAndGetBroadcastShape(convInfo.outShape, $bias.shape);
    } else {
      assert($bias.shape.length <= 1, () => `Error in fused conv2d: only supports scalar or 1-D Tensor bias for NCHW format but got the bias of rank-${$bias.shape.length}.`);
      assert($bias.shape.length === 0 || $bias.shape[0] === convInfo.outChannels || $bias.shape[0] === 1, () => `Error in fused conv2d: bias shape (${$bias.shape}) is not compatible with the number of output channels (${convInfo.outChannels})`);
    }
  }
  let $preluActivationWeights;
  if (preluActivationWeights != null) {
    const alphaShape = preluActivationWeights.shape;
    assert(alphaShape.length <= 1 || alphaShape.length === 3, () => `Error in fused conv2d: only supports scalar, 1-D Tensor or 3-D Tensor PReLU activation weights but got a tensor of rank-${alphaShape.length}.`);
    if (alphaShape.length === 1) {
      assert(alphaShape[0] === 1 || alphaShape[0] === convInfo.outChannels, () => `Error in fused conv2d: PReLU activation weights (${alphaShape}) is not compatible with the number of output channels (${convInfo.outChannels}).`);
    } else if (alphaShape.length === 3) {
      try {
        assertAndGetBroadcastShape(alphaShape, convInfo.outShape);
      } catch (e) {
        const errMsg = `Error in fused conv2d: PReLU activation weights (${alphaShape}) is not compatible with the output shape of the conv2d (${convInfo.outShape}).`;
        throw Error(errMsg);
      }
    }
    $preluActivationWeights = convertToTensor(preluActivationWeights, "prelu weights", "fused conv2d");
  }
  const grad2 = (dy, saved) => {
    assert(dataFormat === "NHWC", () => `Error in gradient of fused conv2D: got dataFormat of ${dataFormat} but only NHWC is currently supported.`);
    const [$filter2, x4D2, y, $bias2] = saved;
    const dyActivation = getFusedDyActivation(dy, y, activation);
    assert(tupleValuesAreOne(dilations), () => `Error in gradient of fused conv2D: dilation rates greater than 1 are not yet supported in gradients. Got dilations '${dilations}'`);
    const xDer = conv2DBackpropInput(x4D2.shape, dyActivation, $filter2, strides, pad2);
    const filterDer = conv2DBackpropFilter(x4D2, dyActivation, $filter2.shape, strides, pad2);
    const der = [xDer, filterDer];
    if ($bias2 != null) {
      const biasDer = getFusedBiasGradient($bias2, dyActivation);
      der.push(biasDer);
    }
    return der;
  };
  const inputs = {
    x: x4D,
    filter: $filter,
    bias: $bias,
    preluActivationWeights: $preluActivationWeights
  };
  const attrs = {
    strides,
    pad: pad2,
    dataFormat,
    dilations,
    dimRoundingMode,
    activation,
    leakyreluAlpha
  };
  if (bias == null) {
    const customOp = customGrad((x4D2, filter2, save) => {
      let res = (
        // tslint:disable-next-line: no-unnecessary-type-assertion
        ENGINE.runKernel(FusedConv2D, inputs, attrs)
      );
      save([filter2, x4D2, res]);
      if (reshapedTo4D) {
        res = reshape(res, [res.shape[1], res.shape[2], res.shape[3]]);
      }
      return {
        value: res,
        gradFunc: grad2
      };
    });
    return customOp(x4D, $filter);
  } else {
    const customOpWithBias = customGrad((x4D2, filter2, bias2, save) => {
      let res = ENGINE.runKernel(FusedConv2D, inputs, attrs);
      save([filter2, x4D2, res, bias2]);
      if (reshapedTo4D) {
        res = reshape(res, [res.shape[1], res.shape[2], res.shape[3]]);
      }
      return {
        value: res,
        gradFunc: grad2
      };
    });
    return customOpWithBias(x4D, $filter, $bias);
  }
}
var conv2d2;
var init_conv2d2 = __esm({
  "node_modules/@tensorflow/tfjs-core/dist/ops/fused/conv2d.js"() {
    init_engine();
    init_gradients();
    init_kernel_names();
    init_tensor_util();
    init_tensor_util_env();
    init_util();
    init_add();
    init_broadcast_util();
    init_conv2d();
    init_conv2d_backprop_filter();
    init_conv2d_backprop_input();
    init_conv_util();
    init_fused_util();
    init_operation();
    init_reshape();
    conv2d2 = op({
      fusedConv2d_
    });
  }
});

// node_modules/@tensorflow/tfjs-core/dist/ops/depthwise_conv2d_native_backprop_filter.js
function depthwiseConv2dNativeBackpropFilter_(x, dy, filterShape, strides, pad2, dilations = [1, 1], dimRoundingMode) {
  let x4D = x;
  if (x.rank === 3) {
    x4D = reshape(x, [1, x.shape[0], x.shape[1], x.shape[2]]);
  }
  let dy4D = dy;
  if (dy4D.rank === 3) {
    dy4D = reshape(dy, [1, dy.shape[0], dy.shape[1], dy.shape[2]]);
  }
  const inputs = {
    x: x4D,
    dy: dy4D
  };
  const attrs = {
    strides,
    pad: pad2,
    dimRoundingMode,
    dilations,
    filterShape
  };
  return ENGINE.runKernel(DepthwiseConv2dNativeBackpropFilter, inputs, attrs);
}
var depthwiseConv2dNativeBackpropFilter;
var init_depthwise_conv2d_native_backprop_filter = __esm({
  "node_modules/@tensorflow/tfjs-core/dist/ops/depthwise_conv2d_native_backprop_filter.js"() {
    init_engine();
    init_kernel_names();
    init_operation();
    init_reshape();
    depthwiseConv2dNativeBackpropFilter = op({
      depthwiseConv2dNativeBackpropFilter_
    });
  }
});

// node_modules/@tensorflow/tfjs-core/dist/ops/depthwise_conv2d_native_backprop_input.js
function depthwiseConv2dNativeBackpropInput_(xShape, dy, filter, strides, pad2, dilations = [1, 1], dimRoundingMode) {
  let dy4D = dy;
  let reshapedTo4D = false;
  if (dy.rank === 3) {
    reshapedTo4D = true;
    dy4D = reshape(dy, [1, dy.shape[0], dy.shape[1], dy.shape[2]]);
  }
  const inputs = {
    dy: dy4D,
    filter
  };
  const attrs = {
    strides,
    pad: pad2,
    dimRoundingMode,
    dilations,
    inputShape: xShape
  };
  const res = (
    // tslint:disable-next-line: no-unnecessary-type-assertion
    ENGINE.runKernel(DepthwiseConv2dNativeBackpropInput, inputs, attrs)
  );
  if (reshapedTo4D) {
    return reshape(res, [res.shape[1], res.shape[2], res.shape[3]]);
  }
  return res;
}
var depthwiseConv2dNativeBackpropInput;
var init_depthwise_conv2d_native_backprop_input = __esm({
  "node_modules/@tensorflow/tfjs-core/dist/ops/depthwise_conv2d_native_backprop_input.js"() {
    init_engine();
    init_kernel_names();
    init_operation();
    init_reshape();
    depthwiseConv2dNativeBackpropInput = op({
      depthwiseConv2dNativeBackpropInput_
    });
  }
});

// node_modules/@tensorflow/tfjs-core/dist/ops/fused/depthwise_conv2d.js
function fusedDepthwiseConv2d_({
  x,
  filter,
  strides,
  pad: pad2,
  dataFormat = "NHWC",
  dilations = [1, 1],
  dimRoundingMode,
  bias,
  activation = "linear",
  preluActivationWeights,
  leakyreluAlpha
}) {
  if (shouldFuse(ENGINE.state.gradientDepth, activation) === false) {
    let result = depthwiseConv2d(x, filter, strides, pad2, dataFormat, dilations, dimRoundingMode);
    if (bias != null) {
      result = add2(result, bias);
    }
    return applyActivation(result, activation, preluActivationWeights, leakyreluAlpha);
  }
  const $x = convertToTensor(x, "x", "depthwiseConv2d", "float32");
  const $filter = convertToTensor(filter, "filter", "depthwiseConv2d", "float32");
  let x4D = $x;
  let reshapedTo4D = false;
  if ($x.rank === 3) {
    reshapedTo4D = true;
    x4D = reshape($x, [1, $x.shape[0], $x.shape[1], $x.shape[2]]);
  }
  assert(x4D.rank === 4, () => `Error in fused depthwiseConv2d: input must be rank 4, but got rank ${x4D.rank}.`);
  assert($filter.rank === 4, () => `Error in fused depthwiseConv2d: filter must be rank 4, but got rank ${$filter.rank}.`);
  assert(x4D.shape[3] === $filter.shape[2], () => `Error in fused depthwiseConv2d: number of input channels (${x4D.shape[3]}) must match the inChannels dimension in filter ${$filter.shape[2]}.`);
  if (dilations == null) {
    dilations = [1, 1];
  }
  assert(eitherStridesOrDilationsAreOne(strides, dilations), () => `Error in fused depthwiseConv2d: Either strides or dilations must be 1. Got strides ${strides} and dilations '${dilations}'`);
  checkPadOnDimRoundingMode("fused depthwiseConv2d", pad2, dimRoundingMode);
  const convInfo = computeConv2DInfo(
    x4D.shape,
    $filter.shape,
    strides,
    dilations,
    pad2,
    dimRoundingMode,
    true
    /* depthwise */
  );
  let $bias;
  if (bias != null) {
    $bias = convertToTensor(bias, "bias", "fused conv2d");
    [$bias] = makeTypesMatch($bias, $x);
    assertAndGetBroadcastShape(convInfo.outShape, $bias.shape);
  }
  let $preluActivationWeights;
  if (preluActivationWeights != null) {
    $preluActivationWeights = convertToTensor(preluActivationWeights, "prelu weights", "fused depthwiseConv2d");
  }
  const grad2 = (dy, saved) => {
    assert(tupleValuesAreOne(dilations), () => `Error in gradient of fused depthwiseConv2d: dilation rates greater than 1 are not yet supported. Got dilations '${dilations}'`);
    const [$filter2, x4D2, y, bias2] = saved;
    const dyActivation = getFusedDyActivation(dy, y, activation);
    const xDer = depthwiseConv2dNativeBackpropInput(x4D2.shape, dyActivation, $filter2, strides, pad2, dilations, dimRoundingMode);
    const filterDer = depthwiseConv2dNativeBackpropFilter(x4D2, dyActivation, $filter2.shape, strides, pad2, dilations, dimRoundingMode);
    if (bias2 != null) {
      const biasDer = getFusedBiasGradient($bias, dyActivation);
      return [xDer, filterDer, biasDer];
    }
    return [xDer, filterDer];
  };
  const inputs = {
    x: x4D,
    filter: $filter,
    bias: $bias,
    preluActivationWeights: $preluActivationWeights
  };
  const attrs = {
    strides,
    pad: pad2,
    dataFormat,
    dilations,
    dimRoundingMode,
    activation,
    leakyreluAlpha
  };
  if (bias == null) {
    const customOp = customGrad((x4D2, filter2, save) => {
      let res = ENGINE.runKernel(FusedDepthwiseConv2D, inputs, attrs);
      save([filter2, x4D2, res]);
      if (reshapedTo4D) {
        res = reshape(res, [res.shape[1], res.shape[2], res.shape[3]]);
      }
      return {
        value: res,
        gradFunc: grad2
      };
    });
    return customOp(x4D, $filter);
  } else {
    const customOpWithBias = customGrad((x4D2, filter2, bias2, save) => {
      let res = ENGINE.runKernel(FusedDepthwiseConv2D, inputs, attrs);
      save([filter2, x4D2, res, bias2]);
      if (reshapedTo4D) {
        res = reshape(res, [res.shape[1], res.shape[2], res.shape[3]]);
      }
      return {
        value: res,
        gradFunc: grad2
      };
    });
    return customOpWithBias(x4D, $filter, $bias);
  }
}
var depthwiseConv2d2;
var init_depthwise_conv2d2 = __esm({
  "node_modules/@tensorflow/tfjs-core/dist/ops/fused/depthwise_conv2d.js"() {
    init_engine();
    init_gradients();
    init_kernel_names();
    init_tensor_util();
    init_tensor_util_env();
    init_util();
    init_add();
    init_broadcast_util();
    init_conv_util();
    init_depthwise_conv2d();
    init_depthwise_conv2d_native_backprop_filter();
    init_depthwise_conv2d_native_backprop_input();
    init_fused_util();
    init_operation();
    init_reshape();
    depthwiseConv2d2 = op({
      fusedDepthwiseConv2d_
    });
  }
});

// node_modules/@tensorflow/tfjs-core/dist/ops/fused/mat_mul.js
function fusedMatMul_({
  a,
  b,
  transposeA = false,
  transposeB = false,
  bias,
  activation = "linear",
  preluActivationWeights,
  leakyreluAlpha = 0.2
}) {
  if (shouldFuse(ENGINE.state.gradientDepth, activation) === false) {
    let result = matMul(a, b, transposeA, transposeB);
    if (bias != null) {
      result = add2(result, bias);
    }
    return applyActivation(result, activation, preluActivationWeights, leakyreluAlpha);
  }
  let $a = convertToTensor(a, "a", "fused matMul");
  let $b = convertToTensor(b, "b", "fused matMul");
  [$a, $b] = makeTypesMatch($a, $b);
  const innerShapeA = transposeA ? $a.shape[$a.rank - 2] : $a.shape[$a.rank - 1];
  const innerShapeB = transposeB ? $b.shape[$b.rank - 1] : $b.shape[$b.rank - 2];
  const outerShapeA = transposeA ? $a.shape[$a.rank - 1] : $a.shape[$a.rank - 2];
  const outerShapeB = transposeB ? $b.shape[$b.rank - 2] : $b.shape[$b.rank - 1];
  const outerDimsA = $a.shape.slice(0, -2);
  const outerDimsB = $b.shape.slice(0, -2);
  const batchDimA = sizeFromShape(outerDimsA);
  const batchDimB = sizeFromShape(outerDimsB);
  assert(innerShapeA === innerShapeB, () => `Error in fused matMul: inner shapes (${innerShapeA}) and (${innerShapeB}) of Tensors with shapes ${$a.shape} and ${$b.shape} and transposeA=${transposeA} and transposeB=${transposeB} must match.`);
  const outShapeOuterDims = assertAndGetBroadcastShape($a.shape.slice(0, -2), $b.shape.slice(0, -2));
  const outShape = outShapeOuterDims.concat([outerShapeA, outerShapeB]);
  const a3D = transposeA ? reshape($a, [batchDimA, innerShapeA, outerShapeA]) : reshape($a, [batchDimA, outerShapeA, innerShapeA]);
  const b3D = transposeB ? reshape($b, [batchDimB, outerShapeB, innerShapeB]) : reshape($b, [batchDimB, innerShapeB, outerShapeB]);
  let $bias;
  if (bias != null) {
    $bias = convertToTensor(bias, "bias", "fused matMul");
    [$bias] = makeTypesMatch($bias, $a);
    assertAndGetBroadcastShape(outShape, $bias.shape);
  }
  let $preluActivationWeights;
  if (preluActivationWeights != null) {
    $preluActivationWeights = convertToTensor(preluActivationWeights, "prelu weights", "fused matMul");
  }
  const grad2 = (dy, saved) => {
    const [a3D2, b3D2, y, $bias2] = saved;
    const dyActivation = getFusedDyActivation(reshape(dy, y.shape), y, activation);
    let aDer;
    let bDer;
    if (!transposeA && !transposeB) {
      aDer = matMul(dyActivation, b3D2, false, true);
      bDer = matMul(a3D2, dyActivation, true, false);
    } else if (!transposeA && transposeB) {
      aDer = matMul(dyActivation, b3D2, false, false);
      bDer = matMul(dyActivation, a3D2, true, false);
    } else if (transposeA && !transposeB) {
      aDer = matMul(b3D2, dyActivation, false, true);
      bDer = matMul(a3D2, dyActivation, false, false);
    } else {
      aDer = matMul(b3D2, dyActivation, true, true);
      bDer = matMul(dyActivation, a3D2, true, true);
    }
    if (bias != null) {
      const biasDer = getFusedBiasGradient($bias2, dyActivation);
      return [aDer, bDer, biasDer];
    } else {
      return [aDer, bDer];
    }
  };
  const inputs = {
    a: a3D,
    b: b3D,
    bias: $bias,
    preluActivationWeights: $preluActivationWeights
  };
  const attrs = {
    transposeA,
    transposeB,
    activation,
    leakyreluAlpha
  };
  if (bias == null) {
    const customOp = customGrad((a3D2, b3D2, save) => {
      const res = (
        // tslint:disable-next-line: no-unnecessary-type-assertion
        ENGINE.runKernel(_FusedMatMul, inputs, attrs)
      );
      save([a3D2, b3D2, res]);
      return {
        value: reshape(res, outShape),
        gradFunc: grad2
      };
    });
    return customOp(a3D, b3D);
  } else {
    const customOpWithBias = customGrad((a3D2, b3D2, $bias2, save) => {
      const res = (
        // tslint:disable-next-line: no-unnecessary-type-assertion
        ENGINE.runKernel(_FusedMatMul, inputs, attrs)
      );
      save([a3D2, b3D2, res, $bias2]);
      return {
        value: reshape(res, outShape),
        gradFunc: grad2
      };
    });
    return customOpWithBias(a3D, b3D, $bias);
  }
}
var matMul2;
var init_mat_mul2 = __esm({
  "node_modules/@tensorflow/tfjs-core/dist/ops/fused/mat_mul.js"() {
    init_engine();
    init_gradients();
    init_kernel_names();
    init_tensor_util();
    init_tensor_util_env();
    init_util();
    init_add();
    init_broadcast_util();
    init_fused_util();
    init_mat_mul();
    init_operation();
    init_reshape();
    matMul2 = op({
      fusedMatMul_
    });
  }
});

// node_modules/@tensorflow/tfjs-core/dist/ops/fused_ops.js
var fused_ops_exports = {};
__export(fused_ops_exports, {
  conv2d: () => conv2d2,
  depthwiseConv2d: () => depthwiseConv2d2,
  matMul: () => matMul2
});
var init_fused_ops = __esm({
  "node_modules/@tensorflow/tfjs-core/dist/ops/fused_ops.js"() {
    init_conv2d2();
    init_depthwise_conv2d2();
    init_mat_mul2();
  }
});

// node_modules/@tensorflow/tfjs-core/dist/ops/loss_ops_utils.js
var Reduction;
var init_loss_ops_utils = __esm({
  "node_modules/@tensorflow/tfjs-core/dist/ops/loss_ops_utils.js"() {
    (function(Reduction2) {
      Reduction2[Reduction2["NONE"] = 0] = "NONE";
      Reduction2[Reduction2["MEAN"] = 1] = "MEAN";
      Reduction2[Reduction2["SUM"] = 2] = "SUM";
      Reduction2[Reduction2["SUM_BY_NONZERO_WEIGHTS"] = 3] = "SUM_BY_NONZERO_WEIGHTS";
    })(Reduction || (Reduction = {}));
  }
});

// node_modules/@tensorflow/tfjs-core/dist/ops/signal/hamming_window.js
function hammingWindow_(windowLength) {
  return cosineWindow(windowLength, 0.54, 0.46);
}
var hammingWindow;
var init_hamming_window = __esm({
  "node_modules/@tensorflow/tfjs-core/dist/ops/signal/hamming_window.js"() {
    init_operation();
    init_signal_ops_util();
    hammingWindow = op({
      hammingWindow_
    });
  }
});

// node_modules/@tensorflow/tfjs-core/dist/ops/signal/hann_window.js
function hannWindow_(windowLength) {
  return cosineWindow(windowLength, 0.5, 0.5);
}
var hannWindow;
var init_hann_window = __esm({
  "node_modules/@tensorflow/tfjs-core/dist/ops/signal/hann_window.js"() {
    init_operation();
    init_signal_ops_util();
    hannWindow = op({
      hannWindow_
    });
  }
});

// node_modules/@tensorflow/tfjs-core/dist/ops/signal/frame.js
function frame_(signal2, frameLength, frameStep, padEnd = false, padValue = 0) {
  let start = 0;
  const output = [];
  while (start + frameLength <= signal2.size) {
    output.push(slice(signal2, start, frameLength));
    start += frameStep;
  }
  if (padEnd) {
    while (start < signal2.size) {
      const padLen = start + frameLength - signal2.size;
      const pad2 = concat([slice(signal2, start, frameLength - padLen), fill([padLen], padValue)]);
      output.push(pad2);
      start += frameStep;
    }
  }
  if (output.length === 0) {
    return tensor2d([], [0, frameLength]);
  }
  return reshape(concat(output), [output.length, frameLength]);
}
var frame;
var init_frame = __esm({
  "node_modules/@tensorflow/tfjs-core/dist/ops/signal/frame.js"() {
    init_concat();
    init_fill();
    init_operation();
    init_reshape();
    init_slice();
    init_tensor2d();
    frame = op({
      frame_
    });
  }
});

// node_modules/@tensorflow/tfjs-core/dist/ops/signal/stft.js
function stft_(signal2, frameLength, frameStep, fftLength, windowFn = hannWindow) {
  if (fftLength == null) {
    fftLength = enclosingPowerOfTwo(frameLength);
  }
  const framedSignal = frame(signal2, frameLength, frameStep);
  const windowedSignal = mul(framedSignal, windowFn(frameLength));
  return rfft(windowedSignal, fftLength);
}
var stft;
var init_stft = __esm({
  "node_modules/@tensorflow/tfjs-core/dist/ops/signal/stft.js"() {
    init_mul();
    init_operation();
    init_signal_ops_util();
    init_rfft();
    init_frame();
    init_hann_window();
    stft = op({
      stft_
    });
  }
});

// node_modules/@tensorflow/tfjs-core/dist/ops/image/crop_and_resize.js
function cropAndResize_(image2, boxes, boxInd, cropSize, method = "bilinear", extrapolationValue = 0) {
  const $image = convertToTensor(image2, "image", "cropAndResize");
  const $boxes = convertToTensor(boxes, "boxes", "cropAndResize", "float32");
  const $boxInd = convertToTensor(boxInd, "boxInd", "cropAndResize", "int32");
  const numBoxes = $boxes.shape[0];
  assert($image.rank === 4, () => `Error in cropAndResize: image must be rank 4,but got rank ${$image.rank}.`);
  assert($boxes.rank === 2 && $boxes.shape[1] === 4, () => `Error in cropAndResize: boxes must be have size [${numBoxes},4] but had shape ${$boxes.shape}.`);
  assert($boxInd.rank === 1 && $boxInd.shape[0] === numBoxes, () => `Error in cropAndResize: boxInd must be have size [${numBoxes}] but had shape ${$boxes.shape}.`);
  assert(cropSize.length === 2, () => `Error in cropAndResize: cropSize must be of length 2, but got length ${cropSize.length}.`);
  assert(cropSize[0] >= 1 && cropSize[1] >= 1, () => `cropSize must be atleast [1,1], but was ${cropSize}`);
  assert(method === "bilinear" || method === "nearest", () => `method must be bilinear or nearest, but was ${method}`);
  const inputs = {
    image: $image,
    boxes: $boxes,
    boxInd: $boxInd
  };
  const attrs = {
    method,
    extrapolationValue,
    cropSize
  };
  const res = ENGINE.runKernel(CropAndResize, inputs, attrs);
  return res;
}
var cropAndResize;
var init_crop_and_resize = __esm({
  "node_modules/@tensorflow/tfjs-core/dist/ops/image/crop_and_resize.js"() {
    init_engine();
    init_kernel_names();
    init_tensor_util_env();
    init_util();
    init_operation();
    cropAndResize = op({
      cropAndResize_
    });
  }
});

// node_modules/@tensorflow/tfjs-core/dist/ops/image/flip_left_right.js
function flipLeftRight_(image2) {
  const $image = convertToTensor(image2, "image", "flipLeftRight", "float32");
  assert($image.rank === 4, () => `Error in flipLeftRight: image must be rank 4,but got rank ${$image.rank}.`);
  const inputs = {
    image: $image
  };
  const res = ENGINE.runKernel(FlipLeftRight, inputs, {});
  return res;
}
var flipLeftRight;
var init_flip_left_right = __esm({
  "node_modules/@tensorflow/tfjs-core/dist/ops/image/flip_left_right.js"() {
    init_engine();
    init_kernel_names();
    init_tensor_util_env();
    init_util();
    init_operation();
    flipLeftRight = op({
      flipLeftRight_
    });
  }
});

// node_modules/@tensorflow/tfjs-core/dist/ops/image/grayscale_to_rgb.js
function grayscaleToRGB_(image2) {
  const $image = convertToTensor(image2, "image", "grayscaleToRGB");
  const lastDimsIdx = $image.rank - 1;
  const lastDims = $image.shape[lastDimsIdx];
  assert($image.rank >= 2, () => `Error in grayscaleToRGB: images must be at least rank 2, but got rank ${$image.rank}.`);
  assert(lastDims === 1, () => `Error in grayscaleToRGB: last dimension of a grayscale image should be size 1, but got size ${lastDims}.`);
  const reps = new Array($image.rank);
  reps.fill(1, 0, lastDimsIdx);
  reps[lastDimsIdx] = 3;
  return tile($image, reps);
}
var grayscaleToRGB;
var init_grayscale_to_rgb = __esm({
  "node_modules/@tensorflow/tfjs-core/dist/ops/image/grayscale_to_rgb.js"() {
    init_tensor_util_env();
    init_util();
    init_operation();
    init_tile();
    grayscaleToRGB = op({
      grayscaleToRGB_
    });
  }
});

// node_modules/@tensorflow/tfjs-core/dist/ops/image/rgb_to_grayscale.js
function rgbToGrayscale_(image2) {
  const $image = convertToTensor(image2, "image", "RGBToGrayscale");
  const lastDimsIdx = $image.rank - 1;
  const lastDims = $image.shape[lastDimsIdx];
  assert($image.rank >= 2, () => `Error in RGBToGrayscale: images must be at least rank 2, but got rank ${$image.rank}.`);
  assert(lastDims === 3, () => `Error in RGBToGrayscale: last dimension of an RGB image should be size 3, but got size ${lastDims}.`);
  const origDtype = $image.dtype;
  const fltImage = cast($image, "float32");
  const rgbWeights = tensor1d([0.2989, 0.587, 0.114]);
  let grayFloat;
  switch ($image.rank) {
    case 2:
      grayFloat = einsum("ij,j->i", fltImage, rgbWeights);
      break;
    case 3:
      grayFloat = einsum("ijk,k->ij", fltImage, rgbWeights);
      break;
    case 4:
      grayFloat = einsum("ijkl,l->ijk", fltImage, rgbWeights);
      break;
    case 5:
      grayFloat = einsum("ijklm,m->ijkl", fltImage, rgbWeights);
      break;
    case 6:
      grayFloat = einsum("ijklmn,n->ijklm", fltImage, rgbWeights);
      break;
    default:
      throw new Error("Not a valid tensor rank.");
  }
  grayFloat = expandDims(grayFloat, -1);
  return cast(grayFloat, origDtype);
}
var rgbToGrayscale;
var init_rgb_to_grayscale = __esm({
  "node_modules/@tensorflow/tfjs-core/dist/ops/image/rgb_to_grayscale.js"() {
    init_tensor_util_env();
    init_util();
    init_cast();
    init_einsum();
    init_expand_dims();
    init_operation();
    init_tensor1d();
    rgbToGrayscale = op({
      rgbToGrayscale_
    });
  }
});

// node_modules/@tensorflow/tfjs-core/dist/ops/image/rotate_with_offset.js
function rotateWithOffset_(image2, radians, fillValue = 0, center = 0.5) {
  const $image = convertToTensor(image2, "image", "rotateWithOffset", "float32");
  assert($image.rank === 4, () => `Error in rotateWithOffset: image must be rank 4,but got rank ${$image.rank}.`);
  const inputs = {
    image: $image
  };
  const attrs = {
    radians,
    fillValue,
    center
  };
  const res = ENGINE.runKernel(RotateWithOffset, inputs, attrs);
  return res;
}
var rotateWithOffset;
var init_rotate_with_offset = __esm({
  "node_modules/@tensorflow/tfjs-core/dist/ops/image/rotate_with_offset.js"() {
    init_engine();
    init_kernel_names();
    init_tensor_util_env();
    init_util();
    init_operation();
    rotateWithOffset = op({
      rotateWithOffset_
    });
  }
});

// node_modules/@tensorflow/tfjs-core/dist/ops/nonmax_util.js
function nonMaxSuppSanityCheck(boxes, scores, maxOutputSize, iouThreshold, scoreThreshold, softNmsSigma) {
  if (iouThreshold == null) {
    iouThreshold = 0.5;
  }
  if (scoreThreshold == null) {
    scoreThreshold = Number.NEGATIVE_INFINITY;
  }
  if (softNmsSigma == null) {
    softNmsSigma = 0;
  }
  const numBoxes = boxes.shape[0];
  maxOutputSize = Math.min(maxOutputSize, numBoxes);
  assert(0 <= iouThreshold && iouThreshold <= 1, () => `iouThreshold must be in [0, 1], but was '${iouThreshold}'`);
  assert(boxes.rank === 2, () => `boxes must be a 2D tensor, but was of rank '${boxes.rank}'`);
  assert(boxes.shape[1] === 4, () => `boxes must have 4 columns, but 2nd dimension was ${boxes.shape[1]}`);
  assert(scores.rank === 1, () => "scores must be a 1D tensor");
  assert(scores.shape[0] === numBoxes, () => `scores has incompatible shape with boxes. Expected ${numBoxes}, but was ${scores.shape[0]}`);
  assert(0 <= softNmsSigma && softNmsSigma <= 1, () => `softNmsSigma must be in [0, 1], but was '${softNmsSigma}'`);
  return {
    maxOutputSize,
    iouThreshold,
    scoreThreshold,
    softNmsSigma
  };
}
var init_nonmax_util = __esm({
  "node_modules/@tensorflow/tfjs-core/dist/ops/nonmax_util.js"() {
    init_util();
  }
});

// node_modules/@tensorflow/tfjs-core/dist/ops/image/non_max_suppression.js
function nonMaxSuppression_(boxes, scores, maxOutputSize, iouThreshold = 0.5, scoreThreshold = Number.NEGATIVE_INFINITY) {
  const $boxes = convertToTensor(boxes, "boxes", "nonMaxSuppression", "float32");
  const $scores = convertToTensor(scores, "scores", "nonMaxSuppression", "float32");
  const inputs = nonMaxSuppSanityCheck($boxes, $scores, maxOutputSize, iouThreshold, scoreThreshold);
  maxOutputSize = inputs.maxOutputSize;
  iouThreshold = inputs.iouThreshold;
  scoreThreshold = inputs.scoreThreshold;
  const attrs = {
    maxOutputSize,
    iouThreshold,
    scoreThreshold
  };
  return ENGINE.runKernel(NonMaxSuppressionV3, {
    boxes: $boxes,
    scores: $scores
  }, attrs);
}
var nonMaxSuppression;
var init_non_max_suppression = __esm({
  "node_modules/@tensorflow/tfjs-core/dist/ops/image/non_max_suppression.js"() {
    init_engine();
    init_kernel_names();
    init_tensor_util_env();
    init_nonmax_util();
    init_operation();
    nonMaxSuppression = op({
      nonMaxSuppression_
    });
  }
});

// node_modules/@tensorflow/tfjs-core/dist/backends/non_max_suppression_util.js
function binaryInsert(arr, element, comparator) {
  const index = binarySearch(arr, element, comparator);
  const insertionPoint = index < 0 ? -(index + 1) : index;
  arr.splice(insertionPoint, 0, element);
}
function binarySearch(arr, target, comparator) {
  return binarySearch_(arr, target, comparator || defaultComparator);
}
function defaultComparator(a, b) {
  return a > b ? 1 : a < b ? -1 : 0;
}
function binarySearch_(arr, target, comparator) {
  let left = 0;
  let right = arr.length;
  let middle = 0;
  let found = false;
  while (left < right) {
    middle = left + (right - left >>> 1);
    const compareResult = comparator(target, arr[middle]);
    if (compareResult > 0) {
      left = middle + 1;
    } else {
      right = middle;
      found = !compareResult;
    }
  }
  return found ? left : -left - 1;
}
var init_non_max_suppression_util = __esm({
  "node_modules/@tensorflow/tfjs-core/dist/backends/non_max_suppression_util.js"() {
  }
});

// node_modules/@tensorflow/tfjs-core/dist/backends/non_max_suppression_impl.js
function nonMaxSuppressionV3Impl(boxes, scores, maxOutputSize, iouThreshold, scoreThreshold) {
  return nonMaxSuppressionImpl_(
    boxes,
    scores,
    maxOutputSize,
    iouThreshold,
    scoreThreshold,
    0
    /* softNmsSigma */
  );
}
function nonMaxSuppressionV4Impl(boxes, scores, maxOutputSize, iouThreshold, scoreThreshold, padToMaxOutputSize) {
  return nonMaxSuppressionImpl_(
    boxes,
    scores,
    maxOutputSize,
    iouThreshold,
    scoreThreshold,
    0,
    false,
    padToMaxOutputSize,
    true
    /* returnValidOutputs */
  );
}
function nonMaxSuppressionV5Impl(boxes, scores, maxOutputSize, iouThreshold, scoreThreshold, softNmsSigma) {
  return nonMaxSuppressionImpl_(
    boxes,
    scores,
    maxOutputSize,
    iouThreshold,
    scoreThreshold,
    softNmsSigma,
    true
    /* returnScoresTensor */
  );
}
function nonMaxSuppressionImpl_(boxes, scores, maxOutputSize, iouThreshold, scoreThreshold, softNmsSigma, returnScoresTensor = false, padToMaxOutputSize = false, returnValidOutputs = false) {
  const candidates = [];
  for (let i = 0; i < scores.length; i++) {
    if (scores[i] > scoreThreshold) {
      candidates.push({
        score: scores[i],
        boxIndex: i,
        suppressBeginIndex: 0
      });
    }
  }
  candidates.sort(ascendingComparator);
  const scale = softNmsSigma > 0 ? -0.5 / softNmsSigma : 0;
  const selectedIndices = [];
  const selectedScores = [];
  while (selectedIndices.length < maxOutputSize && candidates.length > 0) {
    const candidate = candidates.pop();
    const {
      score: originalScore,
      boxIndex,
      suppressBeginIndex
    } = candidate;
    if (originalScore < scoreThreshold) {
      break;
    }
    let ignoreCandidate = false;
    for (let j = selectedIndices.length - 1; j >= suppressBeginIndex; --j) {
      const iou = intersectionOverUnion(boxes, boxIndex, selectedIndices[j]);
      if (iou >= iouThreshold) {
        ignoreCandidate = true;
        break;
      }
      candidate.score = candidate.score * suppressWeight(iouThreshold, scale, iou);
      if (candidate.score <= scoreThreshold) {
        break;
      }
    }
    candidate.suppressBeginIndex = selectedIndices.length;
    if (!ignoreCandidate) {
      if (candidate.score === originalScore) {
        selectedIndices.push(boxIndex);
        selectedScores.push(candidate.score);
      } else if (candidate.score > scoreThreshold) {
        binaryInsert(candidates, candidate, ascendingComparator);
      }
    }
  }
  const validOutputs = selectedIndices.length;
  const elemsToPad = maxOutputSize - validOutputs;
  if (padToMaxOutputSize && elemsToPad > 0) {
    selectedIndices.push(...new Array(elemsToPad).fill(0));
    selectedScores.push(...new Array(elemsToPad).fill(0));
  }
  const result = {
    selectedIndices
  };
  if (returnScoresTensor) {
    result["selectedScores"] = selectedScores;
  }
  if (returnValidOutputs) {
    result["validOutputs"] = validOutputs;
  }
  return result;
}
function intersectionOverUnion(boxes, i, j) {
  const iCoord = boxes.subarray(i * 4, i * 4 + 4);
  const jCoord = boxes.subarray(j * 4, j * 4 + 4);
  const yminI = Math.min(iCoord[0], iCoord[2]);
  const xminI = Math.min(iCoord[1], iCoord[3]);
  const ymaxI = Math.max(iCoord[0], iCoord[2]);
  const xmaxI = Math.max(iCoord[1], iCoord[3]);
  const yminJ = Math.min(jCoord[0], jCoord[2]);
  const xminJ = Math.min(jCoord[1], jCoord[3]);
  const ymaxJ = Math.max(jCoord[0], jCoord[2]);
  const xmaxJ = Math.max(jCoord[1], jCoord[3]);
  const areaI = (ymaxI - yminI) * (xmaxI - xminI);
  const areaJ = (ymaxJ - yminJ) * (xmaxJ - xminJ);
  if (areaI <= 0 || areaJ <= 0) {
    return 0;
  }
  const intersectionYmin = Math.max(yminI, yminJ);
  const intersectionXmin = Math.max(xminI, xminJ);
  const intersectionYmax = Math.min(ymaxI, ymaxJ);
  const intersectionXmax = Math.min(xmaxI, xmaxJ);
  const intersectionArea = Math.max(intersectionYmax - intersectionYmin, 0) * Math.max(intersectionXmax - intersectionXmin, 0);
  return intersectionArea / (areaI + areaJ - intersectionArea);
}
function suppressWeight(iouThreshold, scale, iou) {
  const weight = Math.exp(scale * iou * iou);
  return iou <= iouThreshold ? weight : 0;
}
function ascendingComparator(c1, c2) {
  return c1.score - c2.score || c1.score === c2.score && c2.boxIndex - c1.boxIndex;
}
var init_non_max_suppression_impl = __esm({
  "node_modules/@tensorflow/tfjs-core/dist/backends/non_max_suppression_impl.js"() {
    init_non_max_suppression_util();
  }
});

// node_modules/@tensorflow/tfjs-core/dist/ops/image/non_max_suppression_async.js
function nonMaxSuppressionAsync_(_0, _1, _2) {
  return __async(this, arguments, function* (boxes, scores, maxOutputSize, iouThreshold = 0.5, scoreThreshold = Number.NEGATIVE_INFINITY) {
    const $boxes = convertToTensor(boxes, "boxes", "nonMaxSuppressionAsync");
    const $scores = convertToTensor(scores, "scores", "nonMaxSuppressionAsync");
    const inputs = nonMaxSuppSanityCheck($boxes, $scores, maxOutputSize, iouThreshold, scoreThreshold);
    maxOutputSize = inputs.maxOutputSize;
    iouThreshold = inputs.iouThreshold;
    scoreThreshold = inputs.scoreThreshold;
    const boxesAndScores = yield Promise.all([$boxes.data(), $scores.data()]);
    const boxesVals = boxesAndScores[0];
    const scoresVals = boxesAndScores[1];
    const {
      selectedIndices
    } = nonMaxSuppressionV3Impl(boxesVals, scoresVals, maxOutputSize, iouThreshold, scoreThreshold);
    if ($boxes !== boxes) {
      $boxes.dispose();
    }
    if ($scores !== scores) {
      $scores.dispose();
    }
    return tensor1d(selectedIndices, "int32");
  });
}
var nonMaxSuppressionAsync;
var init_non_max_suppression_async = __esm({
  "node_modules/@tensorflow/tfjs-core/dist/ops/image/non_max_suppression_async.js"() {
    init_non_max_suppression_impl();
    init_tensor_util_env();
    init_nonmax_util();
    init_tensor1d();
    nonMaxSuppressionAsync = nonMaxSuppressionAsync_;
  }
});

// node_modules/@tensorflow/tfjs-core/dist/ops/image/non_max_suppression_with_score.js
function nonMaxSuppressionWithScore_(boxes, scores, maxOutputSize, iouThreshold = 0.5, scoreThreshold = Number.NEGATIVE_INFINITY, softNmsSigma = 0) {
  const $boxes = convertToTensor(boxes, "boxes", "nonMaxSuppression");
  const $scores = convertToTensor(scores, "scores", "nonMaxSuppression");
  const params = nonMaxSuppSanityCheck($boxes, $scores, maxOutputSize, iouThreshold, scoreThreshold, softNmsSigma);
  maxOutputSize = params.maxOutputSize;
  iouThreshold = params.iouThreshold;
  scoreThreshold = params.scoreThreshold;
  softNmsSigma = params.softNmsSigma;
  const inputs = {
    boxes: $boxes,
    scores: $scores
  };
  const attrs = {
    maxOutputSize,
    iouThreshold,
    scoreThreshold,
    softNmsSigma
  };
  const result = ENGINE.runKernel(NonMaxSuppressionV5, inputs, attrs);
  return {
    selectedIndices: result[0],
    selectedScores: result[1]
  };
}
var nonMaxSuppressionWithScore;
var init_non_max_suppression_with_score = __esm({
  "node_modules/@tensorflow/tfjs-core/dist/ops/image/non_max_suppression_with_score.js"() {
    init_engine();
    init_kernel_names();
    init_tensor_util_env();
    init_nonmax_util();
    init_operation();
    nonMaxSuppressionWithScore = op({
      nonMaxSuppressionWithScore_
    });
  }
});

// node_modules/@tensorflow/tfjs-core/dist/ops/image/non_max_suppression_with_score_async.js
function nonMaxSuppressionWithScoreAsync_(_0, _1, _2) {
  return __async(this, arguments, function* (boxes, scores, maxOutputSize, iouThreshold = 0.5, scoreThreshold = Number.NEGATIVE_INFINITY, softNmsSigma = 0) {
    const $boxes = convertToTensor(boxes, "boxes", "nonMaxSuppressionAsync");
    const $scores = convertToTensor(scores, "scores", "nonMaxSuppressionAsync");
    const params = nonMaxSuppSanityCheck($boxes, $scores, maxOutputSize, iouThreshold, scoreThreshold, softNmsSigma);
    maxOutputSize = params.maxOutputSize;
    iouThreshold = params.iouThreshold;
    scoreThreshold = params.scoreThreshold;
    softNmsSigma = params.softNmsSigma;
    const boxesAndScores = yield Promise.all([$boxes.data(), $scores.data()]);
    const boxesVals = boxesAndScores[0];
    const scoresVals = boxesAndScores[1];
    const {
      selectedIndices,
      selectedScores
    } = nonMaxSuppressionV5Impl(boxesVals, scoresVals, maxOutputSize, iouThreshold, scoreThreshold, softNmsSigma);
    if ($boxes !== boxes) {
      $boxes.dispose();
    }
    if ($scores !== scores) {
      $scores.dispose();
    }
    return {
      selectedIndices: tensor1d(selectedIndices, "int32"),
      selectedScores: tensor1d(selectedScores)
    };
  });
}
var nonMaxSuppressionWithScoreAsync;
var init_non_max_suppression_with_score_async = __esm({
  "node_modules/@tensorflow/tfjs-core/dist/ops/image/non_max_suppression_with_score_async.js"() {
    init_non_max_suppression_impl();
    init_tensor_util_env();
    init_nonmax_util();
    init_tensor1d();
    nonMaxSuppressionWithScoreAsync = nonMaxSuppressionWithScoreAsync_;
  }
});

// node_modules/@tensorflow/tfjs-core/dist/ops/image/non_max_suppression_padded.js
function nonMaxSuppressionPadded_(boxes, scores, maxOutputSize, iouThreshold = 0.5, scoreThreshold = Number.NEGATIVE_INFINITY, padToMaxOutputSize = false) {
  const $boxes = convertToTensor(boxes, "boxes", "nonMaxSuppression");
  const $scores = convertToTensor(scores, "scores", "nonMaxSuppression");
  const params = nonMaxSuppSanityCheck(
    $boxes,
    $scores,
    maxOutputSize,
    iouThreshold,
    scoreThreshold,
    null
    /* softNmsSigma */
  );
  const $maxOutputSize = params.maxOutputSize;
  const $iouThreshold = params.iouThreshold;
  const $scoreThreshold = params.scoreThreshold;
  const inputs = {
    boxes: $boxes,
    scores: $scores
  };
  const attrs = {
    maxOutputSize: $maxOutputSize,
    iouThreshold: $iouThreshold,
    scoreThreshold: $scoreThreshold,
    padToMaxOutputSize
  };
  const result = ENGINE.runKernel(NonMaxSuppressionV4, inputs, attrs);
  return {
    selectedIndices: result[0],
    validOutputs: result[1]
  };
}
var nonMaxSuppressionPadded;
var init_non_max_suppression_padded = __esm({
  "node_modules/@tensorflow/tfjs-core/dist/ops/image/non_max_suppression_padded.js"() {
    init_engine();
    init_kernel_names();
    init_tensor_util_env();
    init_nonmax_util();
    init_operation();
    nonMaxSuppressionPadded = op({
      nonMaxSuppressionPadded_
    });
  }
});

// node_modules/@tensorflow/tfjs-core/dist/ops/image/non_max_suppression_padded_async.js
function nonMaxSuppressionPaddedAsync_(_0, _1, _2) {
  return __async(this, arguments, function* (boxes, scores, maxOutputSize, iouThreshold = 0.5, scoreThreshold = Number.NEGATIVE_INFINITY, padToMaxOutputSize = false) {
    const $boxes = convertToTensor(boxes, "boxes", "nonMaxSuppressionAsync");
    const $scores = convertToTensor(scores, "scores", "nonMaxSuppressionAsync");
    const params = nonMaxSuppSanityCheck(
      $boxes,
      $scores,
      maxOutputSize,
      iouThreshold,
      scoreThreshold,
      null
      /* softNmsSigma */
    );
    const $maxOutputSize = params.maxOutputSize;
    const $iouThreshold = params.iouThreshold;
    const $scoreThreshold = params.scoreThreshold;
    const [boxesVals, scoresVals] = yield Promise.all([$boxes.data(), $scores.data()]);
    const {
      selectedIndices,
      validOutputs
    } = nonMaxSuppressionV4Impl(boxesVals, scoresVals, $maxOutputSize, $iouThreshold, $scoreThreshold, padToMaxOutputSize);
    if ($boxes !== boxes) {
      $boxes.dispose();
    }
    if ($scores !== scores) {
      $scores.dispose();
    }
    return {
      selectedIndices: tensor1d(selectedIndices, "int32"),
      validOutputs: scalar(validOutputs, "int32")
    };
  });
}
var nonMaxSuppressionPaddedAsync;
var init_non_max_suppression_padded_async = __esm({
  "node_modules/@tensorflow/tfjs-core/dist/ops/image/non_max_suppression_padded_async.js"() {
    init_non_max_suppression_impl();
    init_tensor_util_env();
    init_nonmax_util();
    init_scalar();
    init_tensor1d();
    nonMaxSuppressionPaddedAsync = nonMaxSuppressionPaddedAsync_;
  }
});

// node_modules/@tensorflow/tfjs-core/dist/ops/image/resize_bilinear.js
function resizeBilinear_(images, size, alignCorners = false, halfPixelCenters = false) {
  const $images = convertToTensor(images, "images", "resizeBilinear");
  assert($images.rank === 3 || $images.rank === 4, () => `Error in resizeBilinear: x must be rank 3 or 4, but got rank ${$images.rank}.`);
  assert(size.length === 2, () => `Error in resizeBilinear: new shape must 2D, but got shape ${size}.`);
  assert(halfPixelCenters === false || alignCorners === false, () => `Error in resizeBilinear: If halfPixelCenters is true, alignCorners must be false.`);
  let batchImages = $images;
  let reshapedTo4D = false;
  if ($images.rank === 3) {
    reshapedTo4D = true;
    batchImages = reshape($images, [1, $images.shape[0], $images.shape[1], $images.shape[2]]);
  }
  const [] = size;
  const inputs = {
    images: batchImages
  };
  const attrs = {
    alignCorners,
    halfPixelCenters,
    size
  };
  const res = ENGINE.runKernel(ResizeBilinear, inputs, attrs);
  if (reshapedTo4D) {
    return reshape(res, [res.shape[1], res.shape[2], res.shape[3]]);
  }
  return res;
}
var resizeBilinear;
var init_resize_bilinear = __esm({
  "node_modules/@tensorflow/tfjs-core/dist/ops/image/resize_bilinear.js"() {
    init_engine();
    init_kernel_names();
    init_tensor_util_env();
    init_util();
    init_operation();
    init_reshape();
    resizeBilinear = op({
      resizeBilinear_
    });
  }
});

// node_modules/@tensorflow/tfjs-core/dist/ops/image/resize_nearest_neighbor.js
function resizeNearestNeighbor_(images, size, alignCorners = false, halfPixelCenters = false) {
  const $images = convertToTensor(images, "images", "resizeNearestNeighbor");
  assert($images.rank === 3 || $images.rank === 4, () => `Error in resizeNearestNeighbor: x must be rank 3 or 4, but got rank ${$images.rank}.`);
  assert(size.length === 2, () => `Error in resizeNearestNeighbor: new shape must 2D, but got shape ${size}.`);
  assert($images.dtype === "float32" || $images.dtype === "int32", () => "`images` must have `int32` or `float32` as dtype");
  assert(halfPixelCenters === false || alignCorners === false, () => `Error in resizeNearestNeighbor: If halfPixelCenters is true, alignCorners must be false.`);
  let batchImages = $images;
  let reshapedTo4D = false;
  if ($images.rank === 3) {
    reshapedTo4D = true;
    batchImages = reshape($images, [1, $images.shape[0], $images.shape[1], $images.shape[2]]);
  }
  const [] = size;
  const inputs = {
    images: batchImages
  };
  const attrs = {
    alignCorners,
    halfPixelCenters,
    size
  };
  const res = ENGINE.runKernel(ResizeNearestNeighbor, inputs, attrs);
  if (reshapedTo4D) {
    return reshape(res, [res.shape[1], res.shape[2], res.shape[3]]);
  }
  return res;
}
var resizeNearestNeighbor;
var init_resize_nearest_neighbor = __esm({
  "node_modules/@tensorflow/tfjs-core/dist/ops/image/resize_nearest_neighbor.js"() {
    init_engine();
    init_kernel_names();
    init_tensor_util_env();
    init_util();
    init_operation();
    init_reshape();
    resizeNearestNeighbor = op({
      resizeNearestNeighbor_
    });
  }
});

// node_modules/@tensorflow/tfjs-core/dist/ops/image/threshold.js
function threshold_(image2, method = "binary", inverted = false, threshValue = 0.5) {
  const $image = convertToTensor(image2, "image", "threshold");
  const RED_INTENCITY_COEF = 0.2989;
  const GREEN_INTENCITY_COEF = 0.587;
  const BLUE_INTENCITY_COEF = 0.114;
  const totalPixelsInImage = $image.shape[0] * $image.shape[1];
  let $threshold = mul(tensor1d([threshValue]), 255);
  let r, g, b, grayscale;
  assert($image.rank === 3, () => `Error in threshold: image must be rank 3,but got rank ${$image.rank}.`);
  assert($image.shape[2] === 3 || $image.shape[2] === 1, () => `Error in threshold: image color channel must be equal to 3 or 1but got ${$image.shape[2]}.`);
  assert($image.dtype === "int32" || $image.dtype === "float32", () => `Error in dtype: image dtype must be int32 or float32,but got dtype ${$image.dtype}.`);
  assert(method === "otsu" || method === "binary", () => `Method must be binary or otsu, but was ${method}`);
  if ($image.shape[2] === 3) {
    [r, g, b] = split($image, [1, 1, 1], -1);
    const $r = mul(r, RED_INTENCITY_COEF);
    const $g = mul(g, GREEN_INTENCITY_COEF);
    const $b = mul(b, BLUE_INTENCITY_COEF);
    grayscale = add2(add2($r, $g), $b);
  } else {
    grayscale = image2;
  }
  if (method === "otsu") {
    const $histogram = bincount(cast(round2(grayscale), "int32"), tensor([]), 256);
    $threshold = otsu($histogram, totalPixelsInImage);
  }
  const invCondition = inverted ? lessEqual(grayscale, $threshold) : greater(grayscale, $threshold);
  const result = cast(mul(invCondition, 255), "int32");
  return result;
}
function otsu(histogram, total) {
  let bestThresh = tensor1d([-1]);
  let bestInBetVar = tensor1d([0]);
  let cInBetVar = tensor1d([0]);
  let classFirst, classSecond, meanFirst, meanSec, weightForeground, weightBack;
  for (let index = 0; index < histogram.size - 1; index++) {
    classFirst = slice(histogram, 0, index + 1);
    classSecond = slice(histogram, index + 1);
    weightForeground = div(sum2(classFirst), total);
    weightBack = div(sum2(classSecond), total);
    const meanFirstDivA = sum2(mul(classFirst, range(0, classFirst.size)));
    meanFirst = div(meanFirstDivA, sum2(classFirst));
    const meanSecFill = fill(classSecond.shape, classFirst.size);
    const meanSecAdd = add2(range(0, classSecond.size), meanSecFill);
    const meanSecMul = mul(classSecond, meanSecAdd);
    meanSec = div(sum2(meanSecMul), sum2(classSecond));
    const cInBetVarSubA = sub(meanFirst, meanSec);
    const cInBetVarSubB = sub(meanFirst, meanSec);
    const cInBetVarMul = mul(weightForeground, weightBack);
    cInBetVar = mul(mul(cInBetVarMul, cInBetVarSubA), cInBetVarSubB);
    const condition = greater(cInBetVar, bestInBetVar);
    bestInBetVar = where(condition, cInBetVar, bestInBetVar);
    bestThresh = where(condition, tensor1d([index]), bestThresh);
  }
  return bestThresh;
}
var threshold;
var init_threshold = __esm({
  "node_modules/@tensorflow/tfjs-core/dist/ops/image/threshold.js"() {
    init_tensor1d();
    init_operation();
    init_cast();
    init_split();
    init_bincount();
    init_less_equal();
    init_greater();
    init_sum();
    init_add();
    init_mul();
    init_div();
    init_sub();
    init_round();
    init_where();
    init_fill();
    init_slice();
    init_range();
    init_tensor2();
    init_util();
    init_tensor_util_env();
    threshold = op({
      threshold_
    });
  }
});

// node_modules/@tensorflow/tfjs-core/dist/ops/image/transform.js
function transform_(image2, transforms, interpolation = "nearest", fillMode = "constant", fillValue = 0, outputShape) {
  const $image = convertToTensor(image2, "image", "transform", "float32");
  const $transforms = convertToTensor(transforms, "transforms", "transform", "float32");
  assert($image.rank === 4, () => `Error in transform: image must be rank 4,but got rank ${$image.rank}.`);
  assert($transforms.rank === 2 && ($transforms.shape[0] === $image.shape[0] || $transforms.shape[0] === 1) && $transforms.shape[1] === 8, () => `Error in transform: Input transform should be batch x 8 or 1 x 8`);
  assert(outputShape == null || outputShape.length === 2, () => `Error in transform: outputShape must be [height, width] or null, but got ${outputShape}.`);
  const inputs = {
    image: $image,
    transforms: $transforms
  };
  const attrs = {
    interpolation,
    fillMode,
    fillValue,
    outputShape
  };
  return ENGINE.runKernel(Transform, inputs, attrs);
}
var transform;
var init_transform = __esm({
  "node_modules/@tensorflow/tfjs-core/dist/ops/image/transform.js"() {
    init_engine();
    init_kernel_names();
    init_tensor_util_env();
    init_util();
    init_operation();
    transform = op({
      transform_
    });
  }
});

// node_modules/@tensorflow/tfjs-core/dist/ops/linalg/band_part.js
function bandPart_(a, numLower, numUpper) {
  const $a = convertToTensor(a, "a", "bandPart");
  assert($a.rank >= 2, () => `bandPart(): Rank must be at least 2, got ${$a.rank}.`);
  const shape = $a.shape;
  const [M, N] = $a.shape.slice(-2);
  let $numLower;
  let $numUpper;
  if (typeof numLower === "number") {
    assert(numLower % 1 === 0, () => `bandPart(): numLower must be an integer, got ${numLower}.`);
    assert(numLower <= M, () => `bandPart(): numLower (${numLower}) must not be greater than the number of rows (${M}).`);
    $numLower = convertToTensor(numLower < 0 ? M : numLower, "numLower", "bandPart");
  } else {
    assert(numLower.dtype === "int32", () => `bandPart(): numLower's dtype must be an int32.`);
    $numLower = where(less(numLower, 0), M, minimum(numLower, M));
  }
  if (typeof numUpper === "number") {
    assert(numUpper % 1 === 0, () => `bandPart(): numUpper must be an integer, got ${numUpper}.`);
    assert(numUpper <= N, () => `bandPart(): numUpper (${numUpper}) must not be greater than the number of columns (${N}).`);
    $numUpper = convertToTensor(numUpper < 0 ? N : numUpper, "numUpper", "bandPart");
  } else {
    assert(numUpper.dtype === "int32", () => `bandPart(): numUpper's dtype must be an int32.`);
    $numUpper = where(less(numUpper, 0), N, minimum(numUpper, N));
  }
  const i = reshape(range(0, M, 1, "int32"), [-1, 1]);
  const j = range(0, N, 1, "int32");
  const ij = sub(i, j);
  const inBand = logicalAnd(lessEqual(ij, $numLower), greaterEqual(ij, neg($numUpper)));
  const zero = zeros([M, N], $a.dtype);
  return reshape(stack(unstack(reshape($a, [-1, M, N])).map((mat) => where(inBand, mat, zero))), shape);
}
var bandPart;
var init_band_part = __esm({
  "node_modules/@tensorflow/tfjs-core/dist/ops/linalg/band_part.js"() {
    init_tensor_util_env();
    init_util();
    init_greater_equal();
    init_less();
    init_less_equal();
    init_logical_and();
    init_minimum();
    init_neg();
    init_operation();
    init_range();
    init_reshape();
    init_stack();
    init_sub();
    init_unstack();
    init_where();
    init_zeros();
    bandPart = op({
      bandPart_
    });
  }
});

// node_modules/@tensorflow/tfjs-core/dist/ops/linalg/gram_schmidt.js
function gramSchmidt_(xs) {
  let inputIsTensor2D;
  if (Array.isArray(xs)) {
    inputIsTensor2D = false;
    assert(xs != null && xs.length > 0, () => "Gram-Schmidt process: input must not be null, undefined, or empty");
    const dim = xs[0].shape[0];
    for (let i = 1; i < xs.length; ++i) {
      assert(xs[i].shape[0] === dim, () => `Gram-Schmidt: Non-unique lengths found in the input vectors: (${xs[i].shape[0]} vs. ${dim})`);
    }
  } else {
    inputIsTensor2D = true;
    xs = split(xs, xs.shape[0], 0).map((x) => squeeze(x, [0]));
  }
  assert(xs.length <= xs[0].shape[0], () => `Gram-Schmidt: Number of vectors (${xs.length}) exceeds number of dimensions (${xs[0].shape[0]}).`);
  const ys = [];
  const xs1d = xs;
  for (let i = 0; i < xs.length; ++i) {
    ys.push(ENGINE.tidy(() => {
      let x = xs1d[i];
      if (i > 0) {
        for (let j = 0; j < i; ++j) {
          const proj = mul(sum2(mul(ys[j], x)), ys[j]);
          x = sub(x, proj);
        }
      }
      return div(x, norm(x, "euclidean"));
    }));
  }
  if (inputIsTensor2D) {
    return stack(ys, 0);
  } else {
    return ys;
  }
}
var gramSchmidt;
var init_gram_schmidt = __esm({
  "node_modules/@tensorflow/tfjs-core/dist/ops/linalg/gram_schmidt.js"() {
    init_engine();
    init_util();
    init_div();
    init_mul();
    init_norm();
    init_operation();
    init_split();
    init_squeeze();
    init_stack();
    init_sub();
    init_sum();
    gramSchmidt = op({
      gramSchmidt_
    });
  }
});

// node_modules/@tensorflow/tfjs-core/dist/ops/linalg/qr.js
function qr_(x, fullMatrices = false) {
  assert(x.rank >= 2, () => `qr() requires input tensor to have a rank >= 2, but got rank ${x.rank}`);
  if (x.rank === 2) {
    return qr2d(x, fullMatrices);
  } else {
    const outerDimsProd = x.shape.slice(0, x.shape.length - 2).reduce((value, prev) => value * prev);
    const x2ds = unstack(reshape(x, [outerDimsProd, x.shape[x.shape.length - 2], x.shape[x.shape.length - 1]]), 0);
    const q2ds = [];
    const r2ds = [];
    x2ds.forEach((x2d) => {
      const [q2d, r2d] = qr2d(x2d, fullMatrices);
      q2ds.push(q2d);
      r2ds.push(r2d);
    });
    const q = reshape(stack(q2ds, 0), x.shape);
    const r = reshape(stack(r2ds, 0), x.shape);
    return [q, r];
  }
}
function qr2d(x, fullMatrices = false) {
  return ENGINE.tidy(() => {
    assert(x.shape.length === 2, () => `qr2d() requires a 2D Tensor, but got a ${x.shape.length}D Tensor.`);
    const m = x.shape[0];
    const n = x.shape[1];
    let q = eye(m);
    let r = clone(x);
    const one2D = tensor2d([[1]], [1, 1]);
    let w = clone(one2D);
    const iters = m >= n ? n : m;
    for (let j = 0; j < iters; ++j) {
      const rTemp = r;
      const wTemp = w;
      const qTemp = q;
      [w, r, q] = ENGINE.tidy(() => {
        const rjEnd1 = slice(r, [j, j], [m - j, 1]);
        const normX = norm(rjEnd1);
        const rjj = slice(r, [j, j], [1, 1]);
        const s = where(greater(rjj, 0), tensor2d([[-1]]), tensor2d([[1]]));
        const u1 = sub(rjj, mul(s, normX));
        const wPre = div(rjEnd1, u1);
        if (wPre.shape[0] === 1) {
          w = clone(one2D);
        } else {
          w = concat([one2D, slice(wPre, [1, 0], [wPre.shape[0] - 1, wPre.shape[1]])], 0);
        }
        const tau = neg(div(matMul(s, u1), normX));
        const rjEndAll = slice(r, [j, 0], [m - j, n]);
        const tauTimesW = mul(tau, w);
        const wT = transpose(w);
        if (j === 0) {
          r = sub(rjEndAll, matMul(tauTimesW, matMul(wT, rjEndAll)));
        } else {
          const rTimesTau = sub(rjEndAll, matMul(tauTimesW, matMul(wT, rjEndAll)));
          r = concat([slice(r, [0, 0], [j, n]), rTimesTau], 0);
        }
        const tawTimesWT = transpose(tauTimesW);
        const qAllJEnd = slice(q, [0, j], [m, q.shape[1] - j]);
        if (j === 0) {
          q = sub(qAllJEnd, matMul(matMul(qAllJEnd, w), tawTimesWT));
        } else {
          const qTimesTau = sub(qAllJEnd, matMul(matMul(qAllJEnd, w), tawTimesWT));
          q = concat([slice(q, [0, 0], [m, j]), qTimesTau], 1);
        }
        return [w, r, q];
      });
      dispose([rTemp, wTemp, qTemp]);
    }
    if (!fullMatrices && m > n) {
      q = slice(q, [0, 0], [m, n]);
      r = slice(r, [0, 0], [n, n]);
    }
    return [q, r];
  });
}
var qr;
var init_qr = __esm({
  "node_modules/@tensorflow/tfjs-core/dist/ops/linalg/qr.js"() {
    init_engine();
    init_globals();
    init_util();
    init_clone();
    init_concat();
    init_div();
    init_eye();
    init_greater();
    init_mat_mul();
    init_mul();
    init_neg();
    init_norm();
    init_operation();
    init_reshape();
    init_slice();
    init_stack();
    init_sub();
    init_tensor2d();
    init_transpose();
    init_unstack();
    init_where();
    qr = op({
      qr_
    });
  }
});

// node_modules/@tensorflow/tfjs-core/dist/ops/losses/compute_weighted_loss.js
function computeWeightedLoss_(losses2, weights, reduction = Reduction.SUM_BY_NONZERO_WEIGHTS) {
  const $losses = convertToTensor(losses2, "losses", "computeWeightedLoss");
  let $weights = null;
  if (weights != null) {
    $weights = convertToTensor(weights, "weights", "computeWeightedLoss");
  }
  const weightedLoss = $weights == null ? $losses : mul($losses, $weights);
  if (reduction === Reduction.NONE) {
    return weightedLoss;
  }
  if (reduction === Reduction.SUM) {
    return sum2(weightedLoss);
  }
  if (reduction === Reduction.MEAN) {
    if ($weights == null) {
      return mean(weightedLoss);
    } else {
      const broadcastFactor = $losses.size / $weights.size;
      const result = div(sum2(weightedLoss), sum2($weights));
      return broadcastFactor > 1 ? div(result, scalar(broadcastFactor)) : result;
    }
  }
  if (reduction === Reduction.SUM_BY_NONZERO_WEIGHTS) {
    if ($weights == null) {
      return div(sum2(weightedLoss), scalar($losses.size));
    } else {
      const broadcastedWeights = mul($weights, ones2($losses.shape));
      const numNonZeros = cast(sum2(notEqual(broadcastedWeights, scalar(0))), "float32");
      return div(sum2(weightedLoss), numNonZeros);
    }
  }
  throw Error(`Unknown reduction: ${reduction}`);
}
var computeWeightedLoss;
var init_compute_weighted_loss = __esm({
  "node_modules/@tensorflow/tfjs-core/dist/ops/losses/compute_weighted_loss.js"() {
    init_tensor_util_env();
    init_cast();
    init_div();
    init_loss_ops_utils();
    init_mean();
    init_mul();
    init_not_equal();
    init_ones();
    init_operation();
    init_scalar();
    init_sum();
    computeWeightedLoss = op({
      computeWeightedLoss_
    });
  }
});

// node_modules/@tensorflow/tfjs-core/dist/ops/losses/absolute_difference.js
function absoluteDifference_(labels, predictions, weights, reduction = Reduction.SUM_BY_NONZERO_WEIGHTS) {
  const $labels = convertToTensor(labels, "labels", "absoluteDifference");
  const $predictions = convertToTensor(predictions, "predictions", "absoluteDifference");
  let $weights = null;
  if (weights != null) {
    $weights = convertToTensor(weights, "weights", "absoluteDifference");
  }
  assertShapesMatch($labels.shape, $predictions.shape, "Error in absoluteDifference: ");
  const losses2 = abs(sub($labels, $predictions));
  return computeWeightedLoss(losses2, $weights, reduction);
}
var absoluteDifference;
var init_absolute_difference = __esm({
  "node_modules/@tensorflow/tfjs-core/dist/ops/losses/absolute_difference.js"() {
    init_tensor_util_env();
    init_util();
    init_abs();
    init_loss_ops_utils();
    init_operation();
    init_sub();
    init_compute_weighted_loss();
    absoluteDifference = op({
      absoluteDifference_
    });
  }
});

// node_modules/@tensorflow/tfjs-core/dist/ops/losses/cosine_distance.js
function cosineDistance_(labels, predictions, axis, weights, reduction = Reduction.SUM_BY_NONZERO_WEIGHTS) {
  const $labels = convertToTensor(labels, "labels", "cosineDistance");
  const $predictions = convertToTensor(predictions, "predictions", "cosineDistance");
  let $weights = null;
  if (weights != null) {
    $weights = convertToTensor(weights, "weights", "cosineDistance");
  }
  assertShapesMatch($labels.shape, $predictions.shape, "Error in cosineDistance: ");
  const one = scalar(1);
  const losses2 = sub(one, sum2(mul($labels, $predictions), axis, true));
  return computeWeightedLoss(losses2, $weights, reduction);
}
var cosineDistance;
var init_cosine_distance = __esm({
  "node_modules/@tensorflow/tfjs-core/dist/ops/losses/cosine_distance.js"() {
    init_tensor_util_env();
    init_util();
    init_loss_ops_utils();
    init_mul();
    init_operation();
    init_scalar();
    init_sub();
    init_sum();
    init_compute_weighted_loss();
    cosineDistance = op({
      cosineDistance_
    });
  }
});

// node_modules/@tensorflow/tfjs-core/dist/ops/losses/hinge_loss.js
function hingeLoss_(labels, predictions, weights, reduction = Reduction.SUM_BY_NONZERO_WEIGHTS) {
  let $labels = convertToTensor(labels, "labels", "hingeLoss");
  const $predictions = convertToTensor(predictions, "predictions", "hingeLoss");
  let $weights = null;
  if (weights != null) {
    $weights = convertToTensor(weights, "weights", "hingeLoss");
  }
  assertShapesMatch($labels.shape, $predictions.shape, "Error in hingeLoss: ");
  const one = scalar(1);
  $labels = sub(mul(scalar(2), $labels), one);
  const losses2 = relu(sub(one, mul($labels, $predictions)));
  return computeWeightedLoss(losses2, $weights, reduction);
}
var hingeLoss;
var init_hinge_loss = __esm({
  "node_modules/@tensorflow/tfjs-core/dist/ops/losses/hinge_loss.js"() {
    init_tensor_util_env();
    init_util();
    init_loss_ops_utils();
    init_mul();
    init_operation();
    init_relu();
    init_scalar();
    init_sub();
    init_compute_weighted_loss();
    hingeLoss = op({
      hingeLoss_
    });
  }
});

// node_modules/@tensorflow/tfjs-core/dist/ops/losses/huber_loss.js
function huberLoss_(labels, predictions, weights, delta = 1, reduction = Reduction.SUM_BY_NONZERO_WEIGHTS) {
  const $labels = convertToTensor(labels, "labels", "huberLoss");
  const $predictions = convertToTensor(predictions, "predictions", "huberLoss");
  let $weights = null;
  if (weights != null) {
    $weights = convertToTensor(weights, "weights", "huberLoss");
  }
  assertShapesMatch($labels.shape, $predictions.shape, "Error in huberLoss: ");
  const deltaScalar = scalar(delta);
  const error = abs(sub($predictions, $labels));
  const quadratic = minimum(error, deltaScalar);
  const linear = sub(error, quadratic);
  const losses2 = add2(mul(scalar(0.5), square(quadratic)), mul(deltaScalar, linear));
  return computeWeightedLoss(losses2, $weights, reduction);
}
var huberLoss;
var init_huber_loss = __esm({
  "node_modules/@tensorflow/tfjs-core/dist/ops/losses/huber_loss.js"() {
    init_tensor_util_env();
    init_util();
    init_abs();
    init_add();
    init_loss_ops_utils();
    init_minimum();
    init_mul();
    init_operation();
    init_scalar();
    init_square();
    init_sub();
    init_compute_weighted_loss();
    huberLoss = op({
      huberLoss_
    });
  }
});

// node_modules/@tensorflow/tfjs-core/dist/ops/losses/log_loss.js
function logLoss_(labels, predictions, weights, epsilon = 1e-7, reduction = Reduction.SUM_BY_NONZERO_WEIGHTS) {
  const $labels = convertToTensor(labels, "labels", "logLoss");
  const $predictions = convertToTensor(predictions, "predictions", "logLoss");
  let $weights = null;
  if (weights != null) {
    $weights = convertToTensor(weights, "weights", "logLoss");
  }
  assertShapesMatch($labels.shape, $predictions.shape, "Error in logLoss: ");
  const one = scalar(1);
  const epsilonScalar = scalar(epsilon);
  const l1 = neg(mul($labels, log2(add2($predictions, epsilonScalar))));
  const l2 = mul(sub(one, $labels), log2(add2(sub(one, $predictions), epsilonScalar)));
  const losses2 = sub(l1, l2);
  return computeWeightedLoss(losses2, $weights, reduction);
}
var logLoss;
var init_log_loss = __esm({
  "node_modules/@tensorflow/tfjs-core/dist/ops/losses/log_loss.js"() {
    init_tensor_util_env();
    init_util();
    init_add();
    init_log2();
    init_loss_ops_utils();
    init_mul();
    init_neg();
    init_operation();
    init_scalar();
    init_sub();
    init_compute_weighted_loss();
    logLoss = op({
      logLoss_
    });
  }
});

// node_modules/@tensorflow/tfjs-core/dist/ops/losses/mean_squared_error.js
function meanSquaredError_(labels, predictions, weights, reduction = Reduction.SUM_BY_NONZERO_WEIGHTS) {
  const $labels = convertToTensor(labels, "labels", "meanSquaredError");
  const $predictions = convertToTensor(predictions, "predictions", "meanSquaredError");
  let $weights = null;
  if (weights != null) {
    $weights = convertToTensor(weights, "weights", "meanSquaredError");
  }
  assertShapesMatch($labels.shape, $predictions.shape, "Error in meanSquaredError: ");
  const losses2 = squaredDifference($labels, $predictions);
  return computeWeightedLoss(losses2, $weights, reduction);
}
var meanSquaredError;
var init_mean_squared_error = __esm({
  "node_modules/@tensorflow/tfjs-core/dist/ops/losses/mean_squared_error.js"() {
    init_tensor_util_env();
    init_util();
    init_loss_ops_utils();
    init_operation();
    init_squared_difference();
    init_compute_weighted_loss();
    meanSquaredError = op({
      meanSquaredError_
    });
  }
});

// node_modules/@tensorflow/tfjs-core/dist/ops/losses/sigmoid_cross_entropy.js
function sigmoidCrossEntropyWithLogits_(labels, logits) {
  const $labels = convertToTensor(labels, "labels", "sigmoidCrossEntropyWithLogits");
  const $logits = convertToTensor(logits, "logits", "sigmoidCrossEntropyWithLogits");
  assertShapesMatch($labels.shape, $logits.shape, "Error in sigmoidCrossEntropyWithLogits: ");
  const maxOutput = relu($logits);
  const outputXTarget = mul($logits, $labels);
  const sigmoidOutput = log1p(exp(neg(abs($logits))));
  return add2(sub(maxOutput, outputXTarget), sigmoidOutput);
}
function sigmoidCrossEntropy_(multiClassLabels, logits, weights, labelSmoothing = 0, reduction = Reduction.SUM_BY_NONZERO_WEIGHTS) {
  let $multiClassLabels = convertToTensor(multiClassLabels, "multiClassLabels", "sigmoidCrossEntropy");
  const $logits = convertToTensor(logits, "logits", "sigmoidCrossEntropy");
  let $weights = null;
  if (weights != null) {
    $weights = convertToTensor(weights, "weights", "sigmoidCrossEntropy");
  }
  assertShapesMatch($multiClassLabels.shape, $logits.shape, "Error in sigmoidCrossEntropy: ");
  if (labelSmoothing > 0) {
    const labelSmoothingScalar = scalar(labelSmoothing);
    const one = scalar(1);
    const half = scalar(0.5);
    $multiClassLabels = add2(mul($multiClassLabels, sub(one, labelSmoothingScalar)), mul(half, labelSmoothingScalar));
  }
  const losses2 = sigmoidCrossEntropyWithLogits_($multiClassLabels, $logits);
  return computeWeightedLoss(losses2, $weights, reduction);
}
var sigmoidCrossEntropy;
var init_sigmoid_cross_entropy = __esm({
  "node_modules/@tensorflow/tfjs-core/dist/ops/losses/sigmoid_cross_entropy.js"() {
    init_tensor_util_env();
    init_util();
    init_abs();
    init_add();
    init_exp();
    init_log1p();
    init_loss_ops_utils();
    init_mul();
    init_neg();
    init_operation();
    init_relu();
    init_scalar();
    init_sub();
    init_compute_weighted_loss();
    sigmoidCrossEntropy = op({
      sigmoidCrossEntropy_
    });
  }
});

// node_modules/@tensorflow/tfjs-core/dist/ops/losses/softmax_cross_entropy.js
function softmaxCrossEntropyWithLogits_(labels, logits, dim = -1) {
  if (dim === -1) {
    dim = logits.rank - 1;
  }
  if (dim !== logits.rank - 1) {
    throw Error(`Softmax cross entropy along a non-last dimension is not yet supported. Labels / logits was rank ${logits.rank} and dim was ${dim}`);
  }
  const customOp = customGrad((labels2, logits2, save) => {
    const keepDims = true;
    const lse = logSumExp(logits2, [dim], keepDims);
    const logResult = sub(cast(logits2, "float32"), lse);
    save([labels2, logResult]);
    const costVector = neg(mul(logResult, labels2));
    const value = sum2(costVector, [dim]);
    const gradFunc = (dy, saved) => {
      const [labels3, logResult2] = saved;
      const dyShape = expandShapeToKeepDim(dy.shape, [dim]);
      return [mul(reshape(dy, dyShape), sub(cast(labels3, "float32"), exp(logResult2))), mul(reshape(dy, dyShape), sub(exp(logResult2), cast(labels3, "float32")))];
    };
    return {
      value,
      gradFunc
    };
  });
  return customOp(labels, logits);
}
function softmaxCrossEntropy_(onehotLabels, logits, weights, labelSmoothing = 0, reduction = Reduction.SUM_BY_NONZERO_WEIGHTS) {
  let $onehotLabels = convertToTensor(onehotLabels, "onehotLabels", "softmaxCrossEntropy");
  const $logits = convertToTensor(logits, "logits", "softmaxCrossEntropy");
  let $weights = null;
  if (weights != null) {
    $weights = convertToTensor(weights, "weights", "softmaxCrossEntropy");
  }
  assertShapesMatch($onehotLabels.shape, $logits.shape, "Error in softmaxCrossEntropy: ");
  if (labelSmoothing > 0) {
    const labelSmoothingScalar = scalar(labelSmoothing);
    const one = scalar(1);
    const numClasses = scalar($onehotLabels.shape[1]);
    $onehotLabels = add2(mul($onehotLabels, sub(one, labelSmoothingScalar)), div(labelSmoothingScalar, numClasses));
  }
  const losses2 = softmaxCrossEntropyWithLogits_($onehotLabels, $logits);
  return computeWeightedLoss(losses2, $weights, reduction);
}
var softmaxCrossEntropy;
var init_softmax_cross_entropy = __esm({
  "node_modules/@tensorflow/tfjs-core/dist/ops/losses/softmax_cross_entropy.js"() {
    init_gradients();
    init_tensor_util_env();
    init_util();
    init_add();
    init_axis_util();
    init_cast();
    init_div();
    init_exp();
    init_log_sum_exp();
    init_loss_ops_utils();
    init_mul();
    init_neg();
    init_operation();
    init_reshape();
    init_scalar();
    init_sub();
    init_sum();
    init_compute_weighted_loss();
    softmaxCrossEntropy = op({
      softmaxCrossEntropy_
    });
  }
});

// node_modules/@tensorflow/tfjs-core/dist/ops/sparse/sparse_fill_empty_rows.js
function sparseFillEmptyRows_(indices, values, denseShape, defaultValue) {
  const $indices = convertToTensor(indices, "indices", "sparseFillEmptyRows", "int32");
  const $values = convertToTensor(values, "values", "sparseFillEmptyRows");
  const $denseShape = convertToTensor(denseShape, "denseShape", "sparseFillEmptyRows", "int32");
  const $defaultValue = convertToTensor(defaultValue, "defaultValue", "sparseFillEmptyRows", $values.dtype);
  if ($indices.rank !== 2) {
    throw new Error(`Indices should be Tensor2D but received shape
        ${$indices.shape}`);
  }
  if ($values.rank !== 1) {
    throw new Error(`Values should be Tensor1D but received shape ${$values.shape}`);
  }
  if ($denseShape.rank !== 1) {
    throw new Error(`Dense shape should be Tensor1D but received shape ${$denseShape.shape}`);
  }
  if ($defaultValue.rank !== 0) {
    throw new Error(`Default value should be a scalar but received shape ${$defaultValue.shape}`);
  }
  const inputs = {
    indices: $indices,
    values: $values,
    denseShape: $denseShape,
    defaultValue: $defaultValue
  };
  const result = ENGINE.runKernel(SparseFillEmptyRows, inputs);
  return {
    outputIndices: result[0],
    outputValues: result[1],
    emptyRowIndicator: result[2],
    reverseIndexMap: result[3]
  };
}
var sparseFillEmptyRows;
var init_sparse_fill_empty_rows = __esm({
  "node_modules/@tensorflow/tfjs-core/dist/ops/sparse/sparse_fill_empty_rows.js"() {
    init_engine();
    init_kernel_names();
    init_tensor_util_env();
    init_operation();
    sparseFillEmptyRows = op({
      sparseFillEmptyRows_
    });
  }
});

// node_modules/@tensorflow/tfjs-core/dist/ops/sparse/sparse_reshape.js
function sparseReshape_(inputIndices, inputShape, newShape) {
  const $inputIndices = convertToTensor(inputIndices, "inputIndices", "sparseReshape", "int32");
  const $inputShape = convertToTensor(inputShape, "inputShape", "sparseReshape", "int32");
  const $newShape = convertToTensor(newShape, "newShape", "sparseReshape", "int32");
  if ($inputIndices.rank !== 2) {
    throw new Error(`Input indices should be Tensor2D but received shape
        ${$inputIndices.shape}`);
  }
  if ($inputShape.rank !== 1) {
    throw new Error(`Input shape should be Tensor1D but received shape ${$inputShape.shape}`);
  }
  if ($newShape.rank !== 1) {
    throw new Error(`New shape should be Tensor1D but received shape ${$newShape.shape}`);
  }
  const inputs = {
    inputIndices: $inputIndices,
    inputShape: $inputShape,
    newShape: $newShape
  };
  const result = ENGINE.runKernel(SparseReshape, inputs);
  return {
    outputIndices: result[0],
    outputShape: result[1]
  };
}
var sparseReshape;
var init_sparse_reshape = __esm({
  "node_modules/@tensorflow/tfjs-core/dist/ops/sparse/sparse_reshape.js"() {
    init_engine();
    init_kernel_names();
    init_tensor_util_env();
    init_operation();
    sparseReshape = op({
      sparseReshape_
    });
  }
});

// node_modules/@tensorflow/tfjs-core/dist/ops/sparse/sparse_segment_mean.js
function sparseSegmentMean_(data, indices, segmentIds) {
  const $data = convertToTensor(data, "data", "sparseSegmentMean");
  const $indices = convertToTensor(indices, "indices", "sparseSegmentMean", "int32");
  const $segmentIds = convertToTensor(segmentIds, "segmentIds", "sparseSegmentMean", "int32");
  if ($data.rank < 1) {
    throw new Error(`Data should be at least 1 dimensional but received scalar`);
  }
  if ($indices.rank !== 1) {
    throw new Error(`Indices should be Tensor1D but received shape
          ${$indices.shape}`);
  }
  if ($segmentIds.rank !== 1) {
    throw new Error(`Segment ids should be Tensor1D but received shape
          ${$segmentIds.shape}`);
  }
  const inputs = {
    data: $data,
    indices: $indices,
    segmentIds: $segmentIds
  };
  return ENGINE.runKernel(SparseSegmentMean, inputs);
}
var sparseSegmentMean;
var init_sparse_segment_mean = __esm({
  "node_modules/@tensorflow/tfjs-core/dist/ops/sparse/sparse_segment_mean.js"() {
    init_engine();
    init_kernel_names();
    init_tensor_util_env();
    init_operation();
    sparseSegmentMean = op({
      sparseSegmentMean_
    });
  }
});

// node_modules/@tensorflow/tfjs-core/dist/ops/sparse/sparse_segment_sum.js
function sparseSegmentSum_(data, indices, segmentIds) {
  const $data = convertToTensor(data, "data", "sparseSegmentSum");
  const $indices = convertToTensor(indices, "indices", "sparseSegmentSum", "int32");
  const $segmentIds = convertToTensor(segmentIds, "segmentIds", "sparseSegmentSum", "int32");
  if ($data.rank < 1) {
    throw new Error(`Data should be at least 1 dimensional but received scalar`);
  }
  if ($indices.rank !== 1) {
    throw new Error(`Indices should be Tensor1D but received shape
         ${$indices.shape}`);
  }
  if ($segmentIds.rank !== 1) {
    throw new Error(`Segment ids should be Tensor1D but received shape
         ${$segmentIds.shape}`);
  }
  const inputs = {
    data: $data,
    indices: $indices,
    segmentIds: $segmentIds
  };
  return ENGINE.runKernel(SparseSegmentSum, inputs);
}
var sparseSegmentSum;
var init_sparse_segment_sum = __esm({
  "node_modules/@tensorflow/tfjs-core/dist/ops/sparse/sparse_segment_sum.js"() {
    init_engine();
    init_kernel_names();
    init_tensor_util_env();
    init_operation();
    sparseSegmentSum = op({
      sparseSegmentSum_
    });
  }
});

// node_modules/@tensorflow/tfjs-core/dist/ops/string/string_n_grams.js
function stringNGrams_(data, dataSplits, separator, nGramWidths, leftPad, rightPad2, padWidth, preserveShortSequences) {
  const $data = convertToTensor(data, "data", "stringNGrams", "string");
  if ($data.dtype !== "string") {
    throw new Error("Data must be of datatype string");
  }
  if ($data.shape.length !== 1) {
    throw new Error(`Data must be a vector, saw: ${$data.shape}`);
  }
  const $dataSplits = convertToTensor(dataSplits, "dataSplits", "stringNGrams");
  if ($dataSplits.dtype !== "int32") {
    throw new Error("Data splits must be of datatype int32");
  }
  const attrs = {
    separator,
    nGramWidths,
    leftPad,
    rightPad: rightPad2,
    padWidth,
    preserveShortSequences
  };
  const inputs = {
    data: $data,
    dataSplits: $dataSplits
  };
  const result = ENGINE.runKernel(StringNGrams, inputs, attrs);
  return {
    nGrams: result[0],
    nGramsSplits: result[1]
  };
}
var stringNGrams;
var init_string_n_grams = __esm({
  "node_modules/@tensorflow/tfjs-core/dist/ops/string/string_n_grams.js"() {
    init_engine();
    init_kernel_names();
    init_tensor_util_env();
    init_operation();
    stringNGrams = op({
      stringNGrams_
    });
  }
});

// node_modules/@tensorflow/tfjs-core/dist/ops/string/string_split.js
function stringSplit_(input, delimiter, skipEmpty = true) {
  const $input = convertToTensor(input, "input", "stringSplit", "string");
  const $delimiter = convertToTensor(delimiter, "delimiter", "stringSplit", "string");
  if ($input.rank !== 1) {
    throw new Error(`Input should be Tensor1D but received shape ${$input.shape}`);
  }
  if ($delimiter.rank !== 0) {
    throw new Error(`Delimiter should be a scalar but received shape ${$delimiter.shape}`);
  }
  const attrs = {
    skipEmpty
  };
  const inputs = {
    input: $input,
    delimiter: $delimiter
  };
  const result = ENGINE.runKernel(StringSplit, inputs, attrs);
  return {
    indices: result[0],
    values: result[1],
    shape: result[2]
  };
}
var stringSplit;
var init_string_split = __esm({
  "node_modules/@tensorflow/tfjs-core/dist/ops/string/string_split.js"() {
    init_engine();
    init_kernel_names();
    init_tensor_util_env();
    init_operation();
    stringSplit = op({
      stringSplit_
    });
  }
});

// node_modules/@tensorflow/tfjs-core/dist/ops/string/string_to_hash_bucket_fast.js
function stringToHashBucketFast_(input, numBuckets) {
  const $input = convertToTensor(input, "input", "stringToHashBucketFast", "string");
  const attrs = {
    numBuckets
  };
  if (numBuckets <= 0) {
    throw new Error(`Number of buckets must be at least 1`);
  }
  const inputs = {
    input: $input
  };
  return ENGINE.runKernel(StringToHashBucketFast, inputs, attrs);
}
var stringToHashBucketFast;
var init_string_to_hash_bucket_fast = __esm({
  "node_modules/@tensorflow/tfjs-core/dist/ops/string/string_to_hash_bucket_fast.js"() {
    init_engine();
    init_kernel_names();
    init_tensor_util_env();
    init_operation();
    stringToHashBucketFast = op({
      stringToHashBucketFast_
    });
  }
});

// node_modules/@tensorflow/tfjs-core/dist/ops/string/static_regex_replace.js
function staticRegexReplace_(input, pattern, rewrite, replaceGlobal = true) {
  const $input = convertToTensor(input, "input", "staticRegexReplace", "string");
  const attrs = {
    pattern,
    rewrite,
    replaceGlobal
  };
  return ENGINE.runKernel(StaticRegexReplace, {
    x: $input
  }, attrs);
}
var staticRegexReplace;
var init_static_regex_replace = __esm({
  "node_modules/@tensorflow/tfjs-core/dist/ops/string/static_regex_replace.js"() {
    init_engine();
    init_kernel_names();
    init_tensor_util_env();
    init_operation();
    staticRegexReplace = op({
      staticRegexReplace_
    });
  }
});

// node_modules/@tensorflow/tfjs-core/dist/ops/ops.js
var spectral, signal, image, linalg, losses, sparse, string;
var init_ops = __esm({
  "node_modules/@tensorflow/tfjs-core/dist/ops/ops.js"() {
    init_abs();
    init_acos();
    init_acosh();
    init_add();
    init_add_n();
    init_all();
    init_any();
    init_arg_max();
    init_arg_min();
    init_asin();
    init_asinh();
    init_atan();
    init_atan2();
    init_atanh();
    init_avg_pool();
    init_avg_pool_3d();
    init_basic_lstm_cell();
    init_batch_to_space_nd();
    init_batchnorm();
    init_batchnorm2d();
    init_batchnorm3d();
    init_batchnorm4d();
    init_bincount();
    init_bitwise_and();
    init_broadcast_args();
    init_broadcast_to();
    init_buffer();
    init_cast();
    init_ceil();
    init_clip_by_value();
    init_clone();
    init_complex();
    init_concat();
    init_concat_1d();
    init_concat_2d();
    init_concat_3d();
    init_concat_4d();
    init_conv1d();
    init_conv2d();
    init_conv2d_transpose();
    init_conv3d();
    init_conv3d_transpose();
    init_cos();
    init_cosh();
    init_cumprod();
    init_cumsum();
    init_dense_bincount();
    init_depth_to_space();
    init_depthwise_conv2d();
    init_diag();
    init_dilation2d();
    init_div();
    init_div_no_nan();
    init_dot();
    init_einsum();
    init_elu();
    init_ensure_shape();
    init_equal();
    init_erf();
    init_euclidean_norm();
    init_exp();
    init_expand_dims();
    init_expm1();
    init_eye();
    init_fill();
    init_floor();
    init_floorDiv();
    init_gather();
    init_greater();
    init_greater_equal();
    init_imag();
    init_is_finite();
    init_is_inf();
    init_is_nan();
    init_leaky_relu();
    init_less();
    init_less_equal();
    init_linspace();
    init_local_response_normalization();
    init_log2();
    init_log1p();
    init_log_sigmoid();
    init_log_softmax();
    init_log_sum_exp();
    init_logical_and();
    init_logical_not();
    init_logical_or();
    init_logical_xor();
    init_lower_bound();
    init_mat_mul();
    init_max();
    init_max_pool();
    init_max_pool_3d();
    init_max_pool_with_argmax();
    init_maximum();
    init_mean();
    init_meshgrid();
    init_min();
    init_minimum();
    init_mirror_pad();
    init_mod();
    init_moments();
    init_mul();
    init_multi_rnn_cell();
    init_multinomial();
    init_neg();
    init_not_equal();
    init_one_hot();
    init_ones();
    init_ones_like();
    init_outer_product();
    init_pad();
    init_pad1d();
    init_pad2d();
    init_pad3d();
    init_pad4d();
    init_pool();
    init_pow();
    init_prelu();
    init_print();
    init_prod();
    init_ragged_gather();
    init_ragged_range();
    init_ragged_tensor_to_tensor();
    init_rand();
    init_random_gamma();
    init_random_normal();
    init_random_standard_normal();
    init_random_uniform();
    init_random_uniform_int();
    init_range();
    init_real();
    init_reciprocal();
    init_relu();
    init_relu6();
    init_reshape();
    init_reverse();
    init_reverse_1d();
    init_reverse_2d();
    init_reverse_3d();
    init_reverse_4d();
    init_round();
    init_rsqrt();
    init_scalar();
    init_selu();
    init_separable_conv2d();
    init_setdiff1d_async();
    init_sigmoid();
    init_sign();
    init_sin();
    init_sinh();
    init_slice();
    init_slice1d();
    init_slice2d();
    init_slice3d();
    init_slice4d();
    init_softmax();
    init_softplus();
    init_space_to_batch_nd();
    init_fft();
    init_ifft();
    init_irfft();
    init_rfft();
    init_split();
    init_sqrt();
    init_square();
    init_squared_difference();
    init_squeeze();
    init_stack();
    init_step();
    init_strided_slice();
    init_sub();
    init_sum();
    init_tan();
    init_tanh();
    init_tensor2();
    init_tensor1d();
    init_tensor2d();
    init_tensor3d();
    init_tensor4d();
    init_tensor5d();
    init_tensor6d();
    init_tensor_scatter_update();
    init_tile();
    init_topk();
    init_truncated_normal();
    init_unique();
    init_unsorted_segment_sum();
    init_unstack();
    init_upper_bound();
    init_variable();
    init_where();
    init_where_async();
    init_zeros();
    init_zeros_like();
    init_boolean_mask();
    init_transpose();
    init_norm();
    init_moving_average();
    init_scatter_nd();
    init_search_sorted();
    init_sparse_to_dense();
    init_gather_nd();
    init_dropout();
    init_signal_ops_util();
    init_in_top_k();
    init_operation();
    init_rfft();
    init_fft();
    init_ifft();
    init_irfft();
    init_fused_ops();
    init_hamming_window();
    init_hann_window();
    init_frame();
    init_stft();
    init_crop_and_resize();
    init_flip_left_right();
    init_grayscale_to_rgb();
    init_rgb_to_grayscale();
    init_rotate_with_offset();
    init_non_max_suppression();
    init_non_max_suppression_async();
    init_non_max_suppression_with_score();
    init_non_max_suppression_with_score_async();
    init_non_max_suppression_padded();
    init_non_max_suppression_padded_async();
    init_resize_bilinear();
    init_resize_nearest_neighbor();
    init_threshold();
    init_transform();
    init_band_part();
    init_gram_schmidt();
    init_qr();
    init_absolute_difference();
    init_compute_weighted_loss();
    init_cosine_distance();
    init_hinge_loss();
    init_huber_loss();
    init_log_loss();
    init_mean_squared_error();
    init_sigmoid_cross_entropy();
    init_softmax_cross_entropy();
    init_sparse_fill_empty_rows();
    init_sparse_reshape();
    init_sparse_segment_mean();
    init_sparse_segment_sum();
    init_string_n_grams();
    init_string_split();
    init_string_to_hash_bucket_fast();
    init_static_regex_replace();
    spectral = {
      fft,
      ifft,
      rfft,
      irfft
    };
    signal = {
      hammingWindow,
      hannWindow,
      frame,
      stft
    };
    image = {
      flipLeftRight,
      grayscaleToRGB,
      resizeNearestNeighbor,
      resizeBilinear,
      rgbToGrayscale,
      rotateWithOffset,
      cropAndResize,
      nonMaxSuppression,
      nonMaxSuppressionAsync,
      nonMaxSuppressionWithScore,
      nonMaxSuppressionWithScoreAsync,
      nonMaxSuppressionPadded,
      nonMaxSuppressionPaddedAsync,
      threshold,
      transform
    };
    linalg = {
      bandPart,
      gramSchmidt,
      qr
    };
    losses = {
      absoluteDifference,
      computeWeightedLoss,
      cosineDistance,
      hingeLoss,
      huberLoss,
      logLoss,
      meanSquaredError,
      sigmoidCrossEntropy,
      softmaxCrossEntropy
    };
    sparse = {
      sparseFillEmptyRows,
      sparseReshape,
      sparseSegmentMean,
      sparseSegmentSum
    };
    string = {
      stringNGrams,
      stringSplit,
      stringToHashBucketFast,
      staticRegexReplace
    };
  }
});

// node_modules/@tensorflow/tfjs-core/dist/serialization.js
var serialization_exports = {};
__export(serialization_exports, {
  Serializable: () => Serializable,
  SerializationMap: () => SerializationMap,
  getRegisteredName: () => getRegisteredName,
  registerClass: () => registerClass
});
function registerClass(cls, pkg, name) {
  assert(cls.className != null, () => `Class being registered does not have the static className property defined.`);
  assert(typeof cls.className === "string", () => `className is required to be a string, but got type ` + typeof cls.className);
  assert(cls.className.length > 0, () => `Class being registered has an empty-string as its className, which is disallowed.`);
  if (typeof pkg === "undefined") {
    pkg = "Custom";
  }
  if (typeof name === "undefined") {
    name = cls.className;
  }
  const className = name;
  const registerName = pkg + ">" + className;
  SerializationMap.register(cls);
  GLOBAL_CUSTOM_OBJECT.set(registerName, cls);
  GLOBAL_CUSTOM_NAMES.set(cls, registerName);
  return cls;
}
function getRegisteredName(cls) {
  if (GLOBAL_CUSTOM_NAMES.has(cls)) {
    return GLOBAL_CUSTOM_NAMES.get(cls);
  } else {
    return cls.className;
  }
}
var GLOBAL_CUSTOM_OBJECT, GLOBAL_CUSTOM_NAMES, Serializable, SerializationMap;
var init_serialization = __esm({
  "node_modules/@tensorflow/tfjs-core/dist/serialization.js"() {
    init_util();
    GLOBAL_CUSTOM_OBJECT = /* @__PURE__ */ new Map();
    GLOBAL_CUSTOM_NAMES = /* @__PURE__ */ new Map();
    Serializable = class {
      /**
       * Return the class name for this class to use in serialization contexts.
       *
       * Generally speaking this will be the same thing that constructor.name
       * would have returned.  However, the class name needs to be robust
       * against minification for serialization/deserialization to work properly.
       *
       * There's also places such as initializers.VarianceScaling, where
       * implementation details between different languages led to different
       * class hierarchies and a non-leaf node is used for serialization purposes.
       */
      getClassName() {
        return this.constructor.className;
      }
      /**
       * Creates an instance of T from a ConfigDict.
       *
       * This works for most descendants of serializable.  A few need to
       * provide special handling.
       * @param cls A Constructor for the class to instantiate.
       * @param config The Configuration for the object.
       */
      /** @nocollapse */
      static fromConfig(cls, config) {
        return new cls(config);
      }
    };
    SerializationMap = class _SerializationMap {
      constructor() {
        this.classNameMap = {};
      }
      /**
       * Returns the singleton instance of the map.
       */
      static getMap() {
        if (_SerializationMap.instance == null) {
          _SerializationMap.instance = new _SerializationMap();
        }
        return _SerializationMap.instance;
      }
      /**
       * Registers the class as serializable.
       */
      static register(cls) {
        _SerializationMap.getMap().classNameMap[cls.className] = [cls, cls.fromConfig];
      }
    };
  }
});

// node_modules/@tensorflow/tfjs-core/dist/optimizers/optimizer.js
var Optimizer;
var init_optimizer = __esm({
  "node_modules/@tensorflow/tfjs-core/dist/optimizers/optimizer.js"() {
    init_globals();
    init_gradients();
    init_ops();
    init_serialization();
    Optimizer = class extends Serializable {
      /**
       * Executes `f()` and minimizes the scalar output of `f()` by computing
       * gradients of y with respect to the list of trainable variables provided by
       * `varList`. If no list is provided, it defaults to all trainable variables.
       *
       * @param f The function to execute and whose output to minimize.
       * @param returnCost Whether to return the scalar cost value produced by
       * executing `f()`.
       * @param varList An optional list of variables to update. If specified, only
       * the trainable variables in varList will be updated by minimize. Defaults to
       * all trainable variables.
       *
       * @doc {heading: 'Training', subheading: 'Optimizers'}
       */
      minimize(f, returnCost = false, varList) {
        const {
          value,
          grads: grads2
        } = this.computeGradients(f, varList);
        if (varList != null) {
          const gradArray = varList.map((v) => ({
            name: v.name,
            tensor: grads2[v.name]
          }));
          this.applyGradients(gradArray);
        } else {
          this.applyGradients(grads2);
        }
        dispose(grads2);
        if (returnCost) {
          return value;
        } else {
          value.dispose();
          return null;
        }
      }
      /**
       * The number of iterations that this optimizer instance has been invoked for.
       */
      get iterations() {
        if (this.iterations_ == null) {
          this.iterations_ = 0;
        }
        return this.iterations_;
      }
      incrementIterations() {
        this.iterations_ = this.iterations + 1;
      }
      /**
       * Executes f() and computes the gradient of the scalar output of f() with
       * respect to the list of trainable variables provided by `varList`. If no
       * list is provided, it defaults to all trainable variables.
       *
       * @param f The function to execute and whose output to use for computing
       * gradients with respect to variables.
       * @param varList An optional list of variables to compute gradients with
       * respect to. If specified, only the trainable variables in varList will have
       * gradients computed with respect to. Defaults to all trainable variables.
       *
       * @doc {heading: 'Training', subheading: 'Optimizers'}
       */
      computeGradients(f, varList) {
        return variableGrads(f, varList);
      }
      /**
       * Dispose the variables (if any) owned by this optimizer instance.
       */
      dispose() {
        if (this.iterations_ != null) {
          dispose(this.iterations_);
        }
      }
      saveIterations() {
        return __async(this, null, function* () {
          if (this.iterations_ == null) {
            this.iterations_ = 0;
          }
          return {
            name: "iter",
            // TODO(cais): Use 'int64' type when available.
            tensor: scalar(this.iterations_, "int32")
          };
        });
      }
      getWeights() {
        return __async(this, null, function* () {
          throw new Error("getWeights() is not implemented for this optimizer yet.");
        });
      }
      setWeights(weightValues) {
        return __async(this, null, function* () {
          throw new Error(`setWeights() is not implemented for this optimizer class ${this.getClassName()}`);
        });
      }
      /**
       * Extract the first element of the weight values and set it
       * as the iterations counter variable of this instance of optimizer.
       *
       * @param weightValues
       * @returns Weight values with the first element consumed and excluded.
       */
      extractIterations(weightValues) {
        return __async(this, null, function* () {
          this.iterations_ = (yield weightValues[0].tensor.data())[0];
          return weightValues.slice(1);
        });
      }
    };
    Object.defineProperty(Optimizer, Symbol.hasInstance, {
      value: (instance) => {
        return instance.minimize != null && instance.computeGradients != null && instance.applyGradients != null;
      }
    });
  }
});

// node_modules/@tensorflow/tfjs-core/dist/optimizers/adadelta_optimizer.js
var AdadeltaOptimizer;
var init_adadelta_optimizer = __esm({
  "node_modules/@tensorflow/tfjs-core/dist/optimizers/adadelta_optimizer.js"() {
    init_engine();
    init_globals();
    init_add();
    init_div();
    init_mul();
    init_ops();
    init_square();
    init_zeros_like();
    init_optimizer();
    AdadeltaOptimizer = class extends Optimizer {
      /** @nocollapse */
      static get className() {
        return "Adadelta";
      }
      constructor(learningRate, rho, epsilon = null) {
        super();
        this.learningRate = learningRate;
        this.rho = rho;
        this.epsilon = epsilon;
        this.accumulatedGrads = [];
        this.accumulatedUpdates = [];
        if (epsilon == null) {
          this.epsilon = ENGINE.backend.epsilon();
        }
      }
      applyGradients(variableGradients) {
        const variableNames = Array.isArray(variableGradients) ? variableGradients.map((item) => item.name) : Object.keys(variableGradients);
        variableNames.forEach((name, i) => {
          const value = ENGINE.registeredVariables[name];
          const trainable = false;
          if (this.accumulatedGrads[i] == null) {
            this.accumulatedGrads[i] = {
              originalName: `${name}/accum_grad`,
              variable: tidy(() => zerosLike(value).variable(trainable))
            };
          }
          if (this.accumulatedUpdates[i] == null) {
            this.accumulatedUpdates[i] = {
              originalName: `${name}/accum_var`,
              variable: tidy(() => zerosLike(value).variable(trainable))
            };
          }
          const gradient = Array.isArray(variableGradients) ? variableGradients[i].tensor : variableGradients[name];
          if (gradient == null) {
            return;
          }
          const accumulatedGrad = this.accumulatedGrads[i].variable;
          const accumulatedUpdate = this.accumulatedUpdates[i].variable;
          tidy(() => {
            const newAccumulatedGrad = add2(mul(accumulatedGrad, this.rho), mul(square(gradient), 1 - this.rho));
            const updates = mul(div(sqrt(add2(accumulatedUpdate, this.epsilon)), sqrt(add2(accumulatedGrad, this.epsilon))), gradient);
            const newAccumulatedUpdate = add2(mul(accumulatedUpdate, this.rho), mul(square(updates), 1 - this.rho));
            accumulatedGrad.assign(newAccumulatedGrad);
            accumulatedUpdate.assign(newAccumulatedUpdate);
            const newValue = add2(mul(updates, -this.learningRate), value);
            value.assign(newValue);
          });
        });
        this.incrementIterations();
      }
      dispose() {
        if (this.accumulatedUpdates != null) {
          dispose(this.accumulatedGrads.map((v) => v.variable));
          dispose(this.accumulatedUpdates.map((v) => v.variable));
        }
      }
      getWeights() {
        return __async(this, null, function* () {
          const variables = [...this.accumulatedGrads, ...this.accumulatedUpdates];
          return [yield this.saveIterations()].concat(variables.map((v) => ({
            name: v.originalName,
            tensor: v.variable
          })));
        });
      }
      setWeights(weightValues) {
        return __async(this, null, function* () {
          weightValues = yield this.extractIterations(weightValues);
          const variableCount = weightValues.length / 2;
          const trainable = false;
          this.accumulatedGrads = weightValues.slice(0, variableCount).map((v) => ({
            originalName: v.name,
            variable: v.tensor.variable(trainable)
          }));
          this.accumulatedUpdates = weightValues.slice(variableCount, variableCount * 2).map((v) => ({
            originalName: v.name,
            variable: v.tensor.variable(trainable)
          }));
        });
      }
      getConfig() {
        return {
          "learningRate": this.learningRate,
          "rho": this.rho,
          "epsilon": this.epsilon
        };
      }
      /** @nocollapse */
      static fromConfig(cls, config) {
        return new cls(config["learningRate"], config["rho"], config["epsilon"]);
      }
    };
  }
});

// node_modules/@tensorflow/tfjs-core/dist/optimizers/adagrad_optimizer.js
var AdagradOptimizer;
var init_adagrad_optimizer = __esm({
  "node_modules/@tensorflow/tfjs-core/dist/optimizers/adagrad_optimizer.js"() {
    init_engine();
    init_globals();
    init_add();
    init_div();
    init_fill();
    init_mul();
    init_sqrt();
    init_square();
    init_optimizer();
    AdagradOptimizer = class extends Optimizer {
      /** @nocollapse */
      static get className() {
        return "Adagrad";
      }
      constructor(learningRate, initialAccumulatorValue = 0.1) {
        super();
        this.learningRate = learningRate;
        this.initialAccumulatorValue = initialAccumulatorValue;
        this.accumulatedGrads = [];
      }
      applyGradients(variableGradients) {
        const variableNames = Array.isArray(variableGradients) ? variableGradients.map((item) => item.name) : Object.keys(variableGradients);
        variableNames.forEach((name, i) => {
          const value = ENGINE.registeredVariables[name];
          if (this.accumulatedGrads[i] == null) {
            const trainable = false;
            this.accumulatedGrads[i] = {
              originalName: `${name}/accumulator`,
              variable: tidy(() => fill(value.shape, this.initialAccumulatorValue).variable(trainable))
            };
          }
          const gradient = Array.isArray(variableGradients) ? variableGradients[i].tensor : variableGradients[name];
          if (gradient == null) {
            return;
          }
          const accumulatedGrad = this.accumulatedGrads[i].variable;
          tidy(() => {
            const newAccumulatedGrad = add2(accumulatedGrad, square(gradient));
            accumulatedGrad.assign(newAccumulatedGrad);
            const newValue = add2(mul(div(gradient, sqrt(add2(newAccumulatedGrad, ENGINE.backend.epsilon()))), -this.learningRate), value);
            value.assign(newValue);
          });
        });
        this.incrementIterations();
      }
      dispose() {
        if (this.accumulatedGrads != null) {
          dispose(this.accumulatedGrads.map((v) => v.variable));
        }
      }
      getWeights() {
        return __async(this, null, function* () {
          return [yield this.saveIterations()].concat(this.accumulatedGrads.map((v) => ({
            name: v.originalName,
            tensor: v.variable
          })));
        });
      }
      setWeights(weightValues) {
        return __async(this, null, function* () {
          weightValues = yield this.extractIterations(weightValues);
          const trainable = false;
          this.accumulatedGrads = weightValues.map((v) => ({
            originalName: v.name,
            variable: v.tensor.variable(trainable)
          }));
        });
      }
      getConfig() {
        return {
          "learningRate": this.learningRate,
          "initialAccumulatorValue": this.initialAccumulatorValue
        };
      }
      /** @nocollapse */
      static fromConfig(cls, config) {
        return new cls(config["learningRate"], config["initialAccumulatorValue"]);
      }
    };
  }
});

// node_modules/@tensorflow/tfjs-core/dist/optimizers/adam_optimizer.js
var AdamOptimizer;
var init_adam_optimizer = __esm({
  "node_modules/@tensorflow/tfjs-core/dist/optimizers/adam_optimizer.js"() {
    init_engine();
    init_globals();
    init_add();
    init_div();
    init_mul();
    init_pow();
    init_scalar();
    init_sqrt();
    init_square();
    init_sub();
    init_zeros_like();
    init_optimizer();
    AdamOptimizer = class extends Optimizer {
      /** @nocollapse */
      static get className() {
        return "Adam";
      }
      constructor(learningRate, beta1, beta2, epsilon = null) {
        super();
        this.learningRate = learningRate;
        this.beta1 = beta1;
        this.beta2 = beta2;
        this.epsilon = epsilon;
        this.accumulatedFirstMoment = [];
        this.accumulatedSecondMoment = [];
        tidy(() => {
          this.accBeta1 = scalar(beta1).variable();
          this.accBeta2 = scalar(beta2).variable();
        });
        if (epsilon == null) {
          this.epsilon = ENGINE.backend.epsilon();
        }
      }
      applyGradients(variableGradients) {
        const varNames = Array.isArray(variableGradients) ? variableGradients.map((v) => v.name) : Object.keys(variableGradients);
        tidy(() => {
          const oneMinusAccBeta1 = sub(1, this.accBeta1);
          const oneMinusAccBeta2 = sub(1, this.accBeta2);
          varNames.forEach((name, i) => {
            const value = ENGINE.registeredVariables[name];
            const trainable = false;
            if (this.accumulatedFirstMoment[i] == null) {
              this.accumulatedFirstMoment[i] = {
                originalName: `${name}/m`,
                variable: tidy(() => zerosLike(value).variable(trainable))
              };
            }
            if (this.accumulatedSecondMoment[i] == null) {
              this.accumulatedSecondMoment[i] = {
                originalName: `${name}/v`,
                variable: tidy(() => zerosLike(value).variable(trainable))
              };
            }
            const gradient = Array.isArray(variableGradients) ? variableGradients[i].tensor : variableGradients[name];
            if (gradient == null) {
              return;
            }
            const firstMoment = this.accumulatedFirstMoment[i].variable;
            const secondMoment = this.accumulatedSecondMoment[i].variable;
            const newFirstMoment = add2(mul(firstMoment, this.beta1), mul(gradient, 1 - this.beta1));
            const newSecondMoment = add2(mul(secondMoment, this.beta2), mul(square(gradient), 1 - this.beta2));
            const biasCorrectedFirstMoment = div(newFirstMoment, oneMinusAccBeta1);
            const biasCorrectedSecondMoment = div(newSecondMoment, oneMinusAccBeta2);
            firstMoment.assign(newFirstMoment);
            secondMoment.assign(newSecondMoment);
            const newValue = add2(mul(div(biasCorrectedFirstMoment, add2(sqrt(biasCorrectedSecondMoment), this.epsilon)), -this.learningRate), value);
            value.assign(newValue);
          });
          this.accBeta1.assign(mul(this.accBeta1, this.beta1));
          this.accBeta2.assign(mul(this.accBeta2, this.beta2));
        });
        this.incrementIterations();
      }
      dispose() {
        this.accBeta1.dispose();
        this.accBeta2.dispose();
        if (this.accumulatedFirstMoment != null) {
          dispose(this.accumulatedFirstMoment.map((v) => v.variable));
        }
        if (this.accumulatedSecondMoment != null) {
          dispose(this.accumulatedSecondMoment.map((v) => v.variable));
        }
      }
      getWeights() {
        return __async(this, null, function* () {
          const variables = [...this.accumulatedFirstMoment, ...this.accumulatedSecondMoment];
          return [yield this.saveIterations()].concat(variables.map((v) => ({
            name: v.originalName,
            tensor: v.variable
          })));
        });
      }
      setWeights(weightValues) {
        return __async(this, null, function* () {
          weightValues = yield this.extractIterations(weightValues);
          tidy(() => {
            this.accBeta1.assign(pow(this.beta1, this.iterations_ + 1));
            this.accBeta2.assign(pow(this.beta2, this.iterations_ + 1));
          });
          const variableCount = weightValues.length / 2;
          const trainable = false;
          this.accumulatedFirstMoment = weightValues.slice(0, variableCount).map((v) => ({
            originalName: v.name,
            variable: v.tensor.variable(trainable)
          }));
          this.accumulatedSecondMoment = weightValues.slice(variableCount, variableCount * 2).map((v) => ({
            originalName: v.name,
            variable: v.tensor.variable(trainable)
          }));
        });
      }
      getConfig() {
        return {
          "learningRate": this.learningRate,
          "beta1": this.beta1,
          "beta2": this.beta2,
          "epsilon": this.epsilon
        };
      }
      /** @nocollapse */
      static fromConfig(cls, config) {
        return new cls(config["learningRate"], config["beta1"], config["beta2"], config["epsilon"]);
      }
    };
  }
});

// node_modules/@tensorflow/tfjs-core/dist/optimizers/adamax_optimizer.js
var AdamaxOptimizer;
var init_adamax_optimizer = __esm({
  "node_modules/@tensorflow/tfjs-core/dist/optimizers/adamax_optimizer.js"() {
    init_engine();
    init_globals();
    init_abs();
    init_add();
    init_div();
    init_maximum();
    init_mul();
    init_scalar();
    init_sub();
    init_zeros_like();
    init_optimizer();
    AdamaxOptimizer = class extends Optimizer {
      /** @nocollapse */
      static get className() {
        return "Adamax";
      }
      constructor(learningRate, beta1, beta2, epsilon = null, decay = 0) {
        super();
        this.learningRate = learningRate;
        this.beta1 = beta1;
        this.beta2 = beta2;
        this.epsilon = epsilon;
        this.decay = decay;
        this.accumulatedFirstMoment = [];
        this.accumulatedWeightedInfNorm = [];
        tidy(() => {
          this.iteration = scalar(0).variable();
          this.accBeta1 = scalar(beta1).variable();
        });
        if (epsilon == null) {
          this.epsilon = ENGINE.backend.epsilon();
        }
      }
      applyGradients(variableGradients) {
        const variableNames = Array.isArray(variableGradients) ? variableGradients.map((item) => item.name) : Object.keys(variableGradients);
        tidy(() => {
          const oneMinusAccBeta1 = sub(1, this.accBeta1);
          const lr = div(-this.learningRate, add2(mul(this.iteration, this.decay), 1));
          variableNames.forEach((name, i) => {
            const value = ENGINE.registeredVariables[name];
            const trainable = false;
            if (this.accumulatedFirstMoment[i] == null) {
              this.accumulatedFirstMoment[i] = {
                originalName: `${name}/m`,
                variable: zerosLike(value).variable(trainable)
              };
            }
            if (this.accumulatedWeightedInfNorm[i] == null) {
              this.accumulatedWeightedInfNorm[i] = {
                originalName: `${name}/v`,
                variable: zerosLike(value).variable(trainable)
              };
            }
            const gradient = Array.isArray(variableGradients) ? variableGradients[i].tensor : variableGradients[name];
            if (gradient == null) {
              return;
            }
            const firstMoment = this.accumulatedFirstMoment[i].variable;
            const weightedInfNorm = this.accumulatedWeightedInfNorm[i].variable;
            const newFirstMoment = add2(mul(firstMoment, this.beta1), mul(gradient, 1 - this.beta1));
            const ut0 = mul(weightedInfNorm, this.beta2);
            const ut1 = abs(gradient);
            const newWeightedInfNorm = maximum(ut0, ut1);
            firstMoment.assign(newFirstMoment);
            weightedInfNorm.assign(newWeightedInfNorm);
            const newValue = add2(mul(div(lr, oneMinusAccBeta1), div(newFirstMoment, add2(newWeightedInfNorm, this.epsilon))), value);
            value.assign(newValue);
          });
          this.iteration.assign(add2(this.iteration, 1));
          this.accBeta1.assign(mul(this.accBeta1, this.beta1));
        });
        this.incrementIterations();
      }
      dispose() {
        this.accBeta1.dispose();
        this.iteration.dispose();
        if (this.accumulatedFirstMoment != null) {
          dispose(this.accumulatedFirstMoment.map((v) => v.variable));
        }
        if (this.accumulatedWeightedInfNorm != null) {
          dispose(this.accumulatedWeightedInfNorm.map((v) => v.variable));
        }
      }
      getWeights() {
        return __async(this, null, function* () {
          throw new Error("getWeights() is not implemented for Adamax yet.");
        });
      }
      setWeights(weightValues) {
        return __async(this, null, function* () {
          throw new Error("setWeights() is not implemented for Adamax yet.");
        });
      }
      getConfig() {
        return {
          "learningRate": this.learningRate,
          "beta1": this.beta1,
          "beta2": this.beta2,
          "epsilon": this.epsilon,
          "decay": this.decay
        };
      }
      /** @nocollapse */
      static fromConfig(cls, config) {
        return new cls(config["learningRate"], config["beta1"], config["beta2"], config["epsilon"], config["decay"]);
      }
    };
  }
});

// node_modules/@tensorflow/tfjs-core/dist/optimizers/sgd_optimizer.js
var SGDOptimizer;
var init_sgd_optimizer = __esm({
  "node_modules/@tensorflow/tfjs-core/dist/optimizers/sgd_optimizer.js"() {
    init_engine();
    init_globals();
    init_add();
    init_mul();
    init_scalar();
    init_optimizer();
    SGDOptimizer = class extends Optimizer {
      /** @nocollapse */
      static get className() {
        return "SGD";
      }
      constructor(learningRate) {
        super();
        this.learningRate = learningRate;
        this.setLearningRate(learningRate);
      }
      applyGradients(variableGradients) {
        const varNames = Array.isArray(variableGradients) ? variableGradients.map((v) => v.name) : Object.keys(variableGradients);
        varNames.forEach((name, i) => {
          const gradient = Array.isArray(variableGradients) ? variableGradients[i].tensor : variableGradients[name];
          if (gradient == null) {
            return;
          }
          const value = ENGINE.registeredVariables[name];
          tidy(() => {
            const newValue = add2(mul(this.c, gradient), value);
            value.assign(newValue);
          });
        });
        this.incrementIterations();
      }
      /**
       * Sets the learning rate of the optimizer.
       */
      setLearningRate(learningRate) {
        this.learningRate = learningRate;
        if (this.c != null) {
          this.c.dispose();
        }
        this.c = keep(scalar(-learningRate));
      }
      dispose() {
        this.c.dispose();
      }
      getWeights() {
        return __async(this, null, function* () {
          return [yield this.saveIterations()];
        });
      }
      setWeights(weightValues) {
        return __async(this, null, function* () {
          weightValues = yield this.extractIterations(weightValues);
          if (weightValues.length !== 0) {
            throw new Error("SGD optimizer does not have settable weights.");
          }
        });
      }
      getConfig() {
        return {
          "learningRate": this.learningRate
        };
      }
      /** @nocollapse */
      static fromConfig(cls, config) {
        return new cls(config["learningRate"]);
      }
    };
  }
});

// node_modules/@tensorflow/tfjs-core/dist/optimizers/momentum_optimizer.js
var MomentumOptimizer;
var init_momentum_optimizer = __esm({
  "node_modules/@tensorflow/tfjs-core/dist/optimizers/momentum_optimizer.js"() {
    init_engine();
    init_globals();
    init_add();
    init_mul();
    init_scalar();
    init_zeros_like();
    init_sgd_optimizer();
    MomentumOptimizer = class extends SGDOptimizer {
      /** @nocollapse */
      // Name matters for Python compatibility.
      static get className() {
        return "Momentum";
      }
      constructor(learningRate, momentum, useNesterov = false) {
        super(learningRate);
        this.learningRate = learningRate;
        this.momentum = momentum;
        this.useNesterov = useNesterov;
        this.accumulations = [];
        this.m = scalar(this.momentum);
      }
      applyGradients(variableGradients) {
        const variableNames = Array.isArray(variableGradients) ? variableGradients.map((item) => item.name) : Object.keys(variableGradients);
        variableNames.forEach((name, i) => {
          const value = ENGINE.registeredVariables[name];
          if (this.accumulations[i] == null) {
            const trainable = false;
            this.accumulations[i] = {
              originalName: `${name}/momentum`,
              variable: tidy(() => zerosLike(value).variable(trainable))
            };
          }
          const accumulation = this.accumulations[i].variable;
          const gradient = Array.isArray(variableGradients) ? variableGradients[i].tensor : variableGradients[name];
          if (gradient == null) {
            return;
          }
          tidy(() => {
            let newValue;
            const newAccumulation = add2(mul(this.m, accumulation), gradient);
            if (this.useNesterov) {
              newValue = add2(mul(this.c, add2(gradient, mul(newAccumulation, this.m))), value);
            } else {
              newValue = add2(mul(this.c, newAccumulation), value);
            }
            accumulation.assign(newAccumulation);
            value.assign(newValue);
          });
        });
        this.incrementIterations();
      }
      dispose() {
        this.m.dispose();
        if (this.accumulations != null) {
          dispose(this.accumulations.map((v) => v.variable));
        }
      }
      /**
       * Sets the momentum of the optimizer.
       *
       * @param momentum
       */
      setMomentum(momentum) {
        this.momentum = momentum;
      }
      getWeights() {
        return __async(this, null, function* () {
          return [yield this.saveIterations()].concat(this.accumulations.map((v) => ({
            name: v.originalName,
            tensor: v.variable
          })));
        });
      }
      setWeights(weightValues) {
        return __async(this, null, function* () {
          weightValues = yield this.extractIterations(weightValues);
          const trainable = false;
          this.accumulations = weightValues.map((v) => ({
            originalName: v.name,
            variable: v.tensor.variable(trainable)
          }));
        });
      }
      getConfig() {
        return {
          "learningRate": this.learningRate,
          "momentum": this.momentum,
          "useNesterov": this.useNesterov
        };
      }
      /** @nocollapse */
      static fromConfig(cls, config) {
        return new cls(config["learningRate"], config["momentum"], config["useNesterov"]);
      }
    };
  }
});

// node_modules/@tensorflow/tfjs-core/dist/optimizers/rmsprop_optimizer.js
var RMSPropOptimizer;
var init_rmsprop_optimizer = __esm({
  "node_modules/@tensorflow/tfjs-core/dist/optimizers/rmsprop_optimizer.js"() {
    init_engine();
    init_globals();
    init_add();
    init_div();
    init_mul();
    init_sqrt();
    init_square();
    init_sub();
    init_zeros_like();
    init_optimizer();
    RMSPropOptimizer = class extends Optimizer {
      /** @nocollapse */
      static get className() {
        return "RMSProp";
      }
      constructor(learningRate, decay = 0.9, momentum = 0, epsilon = null, centered = false) {
        super();
        this.learningRate = learningRate;
        this.decay = decay;
        this.momentum = momentum;
        this.epsilon = epsilon;
        this.accumulatedMeanSquares = [];
        this.accumulatedMoments = [];
        this.accumulatedMeanGrads = [];
        this.centered = centered;
        if (epsilon == null) {
          this.epsilon = ENGINE.backend.epsilon();
        }
        if (learningRate == null) {
          throw new Error(`learningRate for RMSPropOptimizer must be defined.`);
        }
      }
      applyGradients(variableGradients) {
        const variableNames = Array.isArray(variableGradients) ? variableGradients.map((item) => item.name) : Object.keys(variableGradients);
        variableNames.forEach((name, i) => {
          const value = ENGINE.registeredVariables[name];
          const trainable = false;
          if (this.accumulatedMeanSquares[i] == null) {
            this.accumulatedMeanSquares[i] = {
              originalName: `${name}/rms`,
              variable: tidy(() => zerosLike(value).variable(trainable))
            };
          }
          if (this.accumulatedMoments[i] == null) {
            this.accumulatedMoments[i] = {
              originalName: `${name}/momentum`,
              variable: tidy(() => zerosLike(value).variable(trainable))
            };
          }
          if (this.accumulatedMeanGrads[i] == null && this.centered) {
            this.accumulatedMeanGrads[i] = {
              originalName: `${name}/mg`,
              variable: tidy(() => zerosLike(value).variable(trainable))
            };
          }
          const gradient = Array.isArray(variableGradients) ? variableGradients[i].tensor : variableGradients[name];
          if (gradient == null) {
            return;
          }
          const accumulatedMeanSquare = this.accumulatedMeanSquares[i].variable;
          const accumulatedMoments = this.accumulatedMoments[i].variable;
          tidy(() => {
            const newAccumulatedMeanSquare = add2(mul(accumulatedMeanSquare, this.decay), mul(square(gradient), 1 - this.decay));
            if (this.centered) {
              const accumulatedMeanGrad = this.accumulatedMeanGrads[i].variable;
              const newAccumulatedMeanGrad = add2(mul(accumulatedMeanGrad, this.decay), mul(gradient, 1 - this.decay));
              const gradContribution = div(mul(gradient, this.learningRate), sqrt(sub(newAccumulatedMeanSquare, add2(square(newAccumulatedMeanGrad), this.epsilon))));
              const newAccumulatedMoments = add2(mul(accumulatedMoments, this.momentum), gradContribution);
              accumulatedMeanSquare.assign(newAccumulatedMeanSquare);
              accumulatedMeanGrad.assign(newAccumulatedMeanGrad);
              accumulatedMoments.assign(newAccumulatedMoments);
              const newValue = sub(value, newAccumulatedMoments);
              value.assign(newValue);
            } else {
              const newAccumulatedMeanSquare2 = add2(mul(accumulatedMeanSquare, this.decay), mul(square(gradient), 1 - this.decay));
              const newAccumulatedMoments = add2(mul(accumulatedMoments, this.momentum), div(mul(gradient, this.learningRate), sqrt(add2(newAccumulatedMeanSquare2, this.epsilon))));
              accumulatedMeanSquare.assign(newAccumulatedMeanSquare2);
              accumulatedMoments.assign(newAccumulatedMoments);
              const newValue = sub(value, newAccumulatedMoments);
              value.assign(newValue);
            }
          });
        });
        this.incrementIterations();
      }
      dispose() {
        if (this.accumulatedMeanSquares != null) {
          dispose(this.accumulatedMeanSquares.map((v) => v.variable));
        }
        if (this.accumulatedMeanGrads != null && this.centered) {
          dispose(this.accumulatedMeanGrads.map((v) => v.variable));
        }
        if (this.accumulatedMoments != null) {
          dispose(this.accumulatedMoments.map((v) => v.variable));
        }
      }
      getWeights() {
        return __async(this, null, function* () {
          const variables = [...this.accumulatedMeanSquares, ...this.accumulatedMoments];
          if (this.centered) {
            variables.push(...this.accumulatedMeanGrads);
          }
          return [yield this.saveIterations()].concat(variables.map((v) => ({
            name: v.originalName,
            tensor: v.variable
          })));
        });
      }
      setWeights(weightValues) {
        return __async(this, null, function* () {
          weightValues = yield this.extractIterations(weightValues);
          const variableCount = this.centered ? weightValues.length / 3 : weightValues.length / 2;
          const trainable = false;
          this.accumulatedMeanSquares = weightValues.slice(0, variableCount).map((v) => ({
            originalName: v.name,
            variable: v.tensor.variable(trainable)
          }));
          this.accumulatedMoments = weightValues.slice(variableCount, variableCount * 2).map((v) => ({
            originalName: v.name,
            variable: v.tensor.variable(trainable)
          }));
          if (this.centered) {
            this.accumulatedMeanGrads = weightValues.slice(variableCount * 2, variableCount * 3).map((v) => ({
              originalName: v.name,
              variable: v.tensor.variable(trainable)
            }));
          }
        });
      }
      getConfig() {
        return {
          "learningRate": this.learningRate,
          "decay": this.decay,
          "momentum": this.momentum,
          "epsilon": this.epsilon,
          "centered": this.centered
        };
      }
      /** @nocollapse */
      static fromConfig(cls, config) {
        return new cls(config["learningRate"], config["decay"], config["momentum"], config["epsilon"], config["centered"]);
      }
    };
  }
});

// node_modules/@tensorflow/tfjs-core/dist/flags.js
var ENV2;
var init_flags = __esm({
  "node_modules/@tensorflow/tfjs-core/dist/flags.js"() {
    init_engine();
    init_device_util();
    init_environment();
    ENV2 = env();
    ENV2.registerFlag("DEBUG", () => false, (debugValue) => {
      if (debugValue) {
        console.warn("Debugging mode is ON. The output of every math call will be downloaded to CPU and checked for NaNs. This significantly impacts performance.");
      }
    });
    ENV2.registerFlag("IS_BROWSER", () => isBrowser());
    ENV2.registerFlag("IS_NODE", () => typeof process !== "undefined" && typeof process.versions !== "undefined" && typeof process.versions.node !== "undefined");
    ENV2.registerFlag("IS_CHROME", () => typeof navigator !== "undefined" && navigator != null && navigator.userAgent != null && /Chrome/.test(navigator.userAgent) && /Google Inc/.test(navigator.vendor));
    ENV2.registerFlag("IS_SAFARI", () => typeof navigator !== "undefined" && navigator != null && navigator.userAgent != null && /Safari/.test(navigator.userAgent) && /Apple/.test(navigator.vendor));
    ENV2.registerFlag("PROD", () => false);
    ENV2.registerFlag("TENSORLIKE_CHECK_SHAPE_CONSISTENCY", () => ENV2.getBool("DEBUG"));
    ENV2.registerFlag("DEPRECATION_WARNINGS_ENABLED", () => true);
    ENV2.registerFlag("IS_TEST", () => false);
    ENV2.registerFlag("CHECK_COMPUTATION_FOR_ERRORS", () => ENV2.getBool("DEBUG"));
    ENV2.registerFlag("WRAP_TO_IMAGEBITMAP", () => false);
    ENV2.registerFlag("CANVAS2D_WILL_READ_FREQUENTLY_FOR_GPU", () => false);
    ENV2.registerFlag("USE_SETTIMEOUTCUSTOM", () => false);
  }
});

// node_modules/@tensorflow/tfjs-core/dist/io/types.js
var DTYPE_VALUE_SIZE_MAP;
var init_types2 = __esm({
  "node_modules/@tensorflow/tfjs-core/dist/io/types.js"() {
    DTYPE_VALUE_SIZE_MAP = {
      "float32": 4,
      "float16": 2,
      "int32": 4,
      "uint16": 2,
      "uint8": 1,
      "bool": 1,
      "complex64": 8
    };
  }
});

// node_modules/@tensorflow/tfjs-core/dist/io/composite_array_buffer.js
function search(sortedArray, compare) {
  let min2 = 0;
  let max2 = sortedArray.length;
  while (min2 <= max2) {
    const middle = Math.floor((max2 - min2) / 2) + min2;
    const side = compare(sortedArray[middle]);
    if (side === 0) {
      return middle;
    } else if (side < 0) {
      max2 = middle;
    } else {
      min2 = middle + 1;
    }
  }
  return -1;
}
var CompositeArrayBuffer;
var init_composite_array_buffer = __esm({
  "node_modules/@tensorflow/tfjs-core/dist/io/composite_array_buffer.js"() {
    init_util();
    CompositeArrayBuffer = class _CompositeArrayBuffer {
      /**
       * Concatenate a number of ArrayBuffers into one.
       *
       * @param buffers An array of ArrayBuffers to concatenate, or a single
       *     ArrayBuffer.
       * @returns Result of concatenating `buffers` in order.
       */
      static join(buffers) {
        return new _CompositeArrayBuffer(buffers).slice();
      }
      constructor(buffers) {
        this.shards = [];
        this.previousShardIndex = 0;
        if (buffers == null) {
          return;
        }
        if (!(buffers instanceof Array)) {
          buffers = [buffers];
        }
        buffers = buffers.map((bufferOrTypedArray) => {
          if (isTypedArray(bufferOrTypedArray)) {
            return bufferOrTypedArray.buffer;
          }
          return bufferOrTypedArray;
        });
        if (buffers.length === 0) {
          return;
        }
        this.bufferUniformSize = buffers[0].byteLength;
        let start = 0;
        for (let i = 0; i < buffers.length; i++) {
          const buffer2 = buffers[i];
          if (i !== buffers.length - 1 && buffer2.byteLength !== this.bufferUniformSize) {
            this.bufferUniformSize = void 0;
          }
          const end = start + buffer2.byteLength;
          this.shards.push({
            buffer: buffer2,
            start,
            end
          });
          start = end;
        }
        if (this.shards.length === 0) {
          this.byteLength = 0;
        }
        this.byteLength = this.shards[this.shards.length - 1].end;
      }
      slice(start = 0, end = this.byteLength) {
        if (this.shards.length === 0) {
          return new ArrayBuffer(0);
        }
        start = isNaN(Number(start)) ? 0 : start;
        end = isNaN(Number(end)) ? 0 : end;
        start = Math.max(0, start);
        end = Math.min(this.byteLength, end);
        if (end <= start) {
          return new ArrayBuffer(0);
        }
        const startShardIndex = this.findShardForByte(start);
        if (startShardIndex === -1) {
          throw new Error(`Could not find start shard for byte ${start}`);
        }
        const size = end - start;
        const outputBuffer = new ArrayBuffer(size);
        const outputArray = new Uint8Array(outputBuffer);
        let sliced = 0;
        for (let i = startShardIndex; i < this.shards.length; i++) {
          const shard = this.shards[i];
          const globalStart = start + sliced;
          const localStart = globalStart - shard.start;
          const outputStart = sliced;
          const globalEnd = Math.min(end, shard.end);
          const localEnd = globalEnd - shard.start;
          const outputSlice = new Uint8Array(shard.buffer, localStart, localEnd - localStart);
          outputArray.set(outputSlice, outputStart);
          sliced += outputSlice.length;
          if (end < shard.end) {
            break;
          }
        }
        return outputBuffer;
      }
      /**
       * Get the index of the shard that contains the byte at `byteIndex`.
       */
      findShardForByte(byteIndex) {
        if (this.shards.length === 0 || byteIndex < 0 || byteIndex >= this.byteLength) {
          return -1;
        }
        if (this.bufferUniformSize != null) {
          this.previousShardIndex = Math.floor(byteIndex / this.bufferUniformSize);
          return this.previousShardIndex;
        }
        function check(shard) {
          if (byteIndex < shard.start) {
            return -1;
          }
          if (byteIndex >= shard.end) {
            return 1;
          }
          return 0;
        }
        if (check(this.shards[this.previousShardIndex]) === 0) {
          return this.previousShardIndex;
        }
        const index = search(this.shards, check);
        if (index === -1) {
          return -1;
        }
        this.previousShardIndex = index;
        return this.previousShardIndex;
      }
    };
  }
});

// node_modules/@tensorflow/tfjs-core/dist/io/io_utils.js
function encodeWeights(tensors, group) {
  return __async(this, null, function* () {
    const specs = [];
    const dataPromises = [];
    const names = Array.isArray(tensors) ? tensors.map((tensor2) => tensor2.name) : Object.keys(tensors);
    for (let i = 0; i < names.length; ++i) {
      const name = names[i];
      const t = Array.isArray(tensors) ? tensors[i].tensor : tensors[name];
      if (t.dtype !== "float32" && t.dtype !== "int32" && t.dtype !== "bool" && t.dtype !== "string" && t.dtype !== "complex64") {
        throw new Error(`Unsupported dtype in weight '${name}': ${t.dtype}`);
      }
      const spec = {
        name,
        shape: t.shape,
        dtype: t.dtype
      };
      if (t.dtype === "string") {
        const utf8bytes = new Promise((resolve) => __async(null, null, function* () {
          const vals = yield t.bytes();
          const totalNumBytes = vals.reduce((p, c) => p + c.length, 0) + NUM_BYTES_STRING_LENGTH * vals.length;
          const bytes = new Uint8Array(totalNumBytes);
          let offset = 0;
          for (let i2 = 0; i2 < vals.length; i2++) {
            const val = vals[i2];
            const bytesOfLength = new Uint8Array(new Uint32Array([val.length]).buffer);
            bytes.set(bytesOfLength, offset);
            offset += NUM_BYTES_STRING_LENGTH;
            bytes.set(val, offset);
            offset += val.length;
          }
          resolve(bytes);
        }));
        dataPromises.push(utf8bytes);
      } else {
        dataPromises.push(t.data());
      }
      if (group != null) {
        spec.group = group;
      }
      specs.push(spec);
    }
    const tensorValues = yield Promise.all(dataPromises);
    return {
      data: concatenateTypedArrays(tensorValues),
      specs
    };
  });
}
function decodeWeights(weightData, specs) {
  const compositeBuffer = new CompositeArrayBuffer(weightData);
  const out = {};
  let offset = 0;
  for (const spec of specs) {
    const byteLength = getWeightBytelength(spec, (start, end) => {
      return compositeBuffer.slice(offset + start, offset + end);
    });
    out[spec.name] = decodeWeight(spec, compositeBuffer.slice(offset, offset + byteLength));
    offset += byteLength;
  }
  return out;
}
function getWeightBytelength(spec, slice3) {
  const size = sizeFromShape(spec.shape);
  let bytesPerValue;
  if ("quantization" in spec) {
    const quantization = spec.quantization;
    bytesPerValue = DTYPE_VALUE_SIZE_MAP[quantization.dtype];
  } else if (spec.dtype === "string") {
    let byteLength = 0;
    for (let i = 0; i < size; i++) {
      byteLength += NUM_BYTES_STRING_LENGTH + new Uint32Array(slice3(byteLength, byteLength + NUM_BYTES_STRING_LENGTH))[0];
    }
    return byteLength;
  } else {
    bytesPerValue = DTYPE_VALUE_SIZE_MAP[spec.dtype];
  }
  return size * bytesPerValue;
}
function getWeightBytelengthAsync(spec, slice3) {
  return __async(this, null, function* () {
    const size = sizeFromShape(spec.shape);
    let bytesPerValue;
    if ("quantization" in spec) {
      const quantization = spec.quantization;
      bytesPerValue = DTYPE_VALUE_SIZE_MAP[quantization.dtype];
    } else if (spec.dtype === "string") {
      let byteLength = 0;
      for (let i = 0; i < size; i++) {
        byteLength += NUM_BYTES_STRING_LENGTH + new Uint32Array(yield slice3(byteLength, byteLength + NUM_BYTES_STRING_LENGTH))[0];
      }
      return byteLength;
    } else {
      bytesPerValue = DTYPE_VALUE_SIZE_MAP[spec.dtype];
    }
    return size * bytesPerValue;
  });
}
function decodeWeight(spec, byteBuffer) {
  const name = spec.name;
  const dtype = spec.dtype;
  const shape = spec.shape;
  const size = sizeFromShape(shape);
  let values;
  let offset = 0;
  if ("quantization" in spec) {
    const quantization = spec.quantization;
    if (quantization.dtype === "uint8" || quantization.dtype === "uint16") {
      if (!("min" in quantization && "scale" in quantization)) {
        throw new Error(`Weight ${spec.name} with quantization ${quantization.dtype} doesn't have corresponding metadata min and scale.`);
      }
    } else if (quantization.dtype === "float16") {
      if (dtype !== "float32") {
        throw new Error(`Weight ${spec.name} is quantized with ${quantization.dtype} which only supports weights of type float32 not ${dtype}.`);
      }
    } else {
      throw new Error(`Weight ${spec.name} has unknown quantization dtype ${quantization.dtype}. Supported quantization dtypes are: 'uint8', 'uint16', and 'float16'.`);
    }
    const quantizationSizeFactor = DTYPE_VALUE_SIZE_MAP[quantization.dtype];
    const quantizedArray = quantization.dtype === "uint8" ? new Uint8Array(byteBuffer) : new Uint16Array(byteBuffer);
    if (dtype === "float32") {
      if (quantization.dtype === "uint8" || quantization.dtype === "uint16") {
        values = new Float32Array(quantizedArray.length);
        for (let i = 0; i < quantizedArray.length; i++) {
          const v = quantizedArray[i];
          values[i] = v * quantization.scale + quantization.min;
        }
      } else if (quantization.dtype === "float16") {
        const float16Decode = getFloat16Decoder();
        values = float16Decode(quantizedArray);
      } else {
        throw new Error(`Unsupported quantization type ${quantization.dtype} for weight type float32.`);
      }
    } else if (dtype === "int32") {
      if (quantization.dtype !== "uint8" && quantization.dtype !== "uint16") {
        throw new Error(`Unsupported quantization type ${quantization.dtype} for weight type int32.`);
      }
      values = new Int32Array(quantizedArray.length);
      for (let i = 0; i < quantizedArray.length; i++) {
        const v = quantizedArray[i];
        values[i] = Math.round(v * quantization.scale + quantization.min);
      }
    } else {
      throw new Error(`Unsupported dtype in weight '${name}': ${dtype}`);
    }
    offset += size * quantizationSizeFactor;
  } else if (dtype === "string") {
    const size2 = sizeFromShape(spec.shape);
    values = [];
    for (let i = 0; i < size2; i++) {
      const byteLength = new Uint32Array(byteBuffer.slice(offset, offset + NUM_BYTES_STRING_LENGTH))[0];
      offset += NUM_BYTES_STRING_LENGTH;
      const bytes = new Uint8Array(byteBuffer.slice(offset, offset + byteLength));
      values.push(bytes);
      offset += byteLength;
    }
  } else {
    const dtypeFactor = DTYPE_VALUE_SIZE_MAP[dtype];
    if (dtype === "float32") {
      values = new Float32Array(byteBuffer);
    } else if (dtype === "int32") {
      values = new Int32Array(byteBuffer);
    } else if (dtype === "bool") {
      values = new Uint8Array(byteBuffer);
    } else if (dtype === "complex64") {
      values = new Float32Array(byteBuffer);
      const real3 = new Float32Array(values.length / 2);
      const image2 = new Float32Array(values.length / 2);
      for (let i = 0; i < real3.length; i++) {
        real3[i] = values[i * 2];
        image2[i] = values[i * 2 + 1];
      }
      const realTensor = tensor(real3, shape, "float32");
      const imageTensor = tensor(image2, shape, "float32");
      const complexTensor = complex(realTensor, imageTensor);
      realTensor.dispose();
      imageTensor.dispose();
      return complexTensor;
    } else {
      throw new Error(`Unsupported dtype in weight '${name}': ${dtype}`);
    }
    offset += size * dtypeFactor;
  }
  return tensor(values, shape, dtype);
}
function readToLength(reader, initialData, length) {
  return __async(this, null, function* () {
    let data = new Uint8Array(initialData);
    while (data.byteLength < length) {
      const {
        done,
        value
      } = yield reader.read();
      if (done && value == null) {
        const missing = length - data.byteLength;
        throw new Error(`Reader is done but ${missing} bytes are still expected`);
      }
      const newData = new Uint8Array(data.length + value.byteLength);
      newData.set(data, 0);
      newData.set(new Uint8Array(value), data.length);
      data = newData;
    }
    return data.buffer;
  });
}
function decodeWeightsStream(weightStream, specs) {
  return __async(this, null, function* () {
    const tensors = {};
    const reader = weightStream.getReader();
    let data = new ArrayBuffer(0);
    for (const spec of specs) {
      const byteLength = yield getWeightBytelengthAsync(spec, (start, end) => __async(null, null, function* () {
        data = yield readToLength(reader, data, end);
        return data.slice(start, end);
      }));
      data = yield readToLength(reader, data, byteLength);
      const tensorData = data.slice(0, byteLength);
      data = data.slice(byteLength);
      const weightTensor = decodeWeight(spec, tensorData);
      tensors[spec.name] = weightTensor;
      if (getBackend() === "webgpu") {
        const b = backend();
        if ("uploadToGPU" in b && sizeFromShape(weightTensor.shape) >= env().get("WEBGPU_CPU_HANDOFF_SIZE_THRESHOLD")) {
          b.uploadToGPU(weightTensor.dataId);
        }
      }
    }
    return tensors;
  });
}
function concatenateTypedArrays(xs) {
  if (xs === null) {
    throw new Error(`Invalid input value: ${JSON.stringify(xs)}`);
  }
  let totalByteLength = 0;
  const normalizedXs = [];
  xs.forEach((x) => {
    totalByteLength += x.byteLength;
    normalizedXs.push(x.byteLength === x.buffer.byteLength ? x : new x.constructor(x));
    if (!(x instanceof Float32Array || x instanceof Int32Array || x instanceof Uint8Array)) {
      throw new Error(`Unsupported TypedArray subtype: ${x.constructor.name}`);
    }
  });
  const y = new Uint8Array(totalByteLength);
  let offset = 0;
  normalizedXs.forEach((x) => {
    y.set(new Uint8Array(x.buffer), offset);
    offset += x.byteLength;
  });
  return y.buffer;
}
function stringByteLength(str) {
  if (useNodeBuffer) {
    return Buffer.byteLength(str, "utf8");
  }
  return new Blob([str]).size;
}
function arrayBufferToBase64String(buffer2) {
  if (useNodeBuffer) {
    return Buffer.from(buffer2).toString("base64");
  }
  const buf = new Uint8Array(buffer2);
  let s = "";
  for (let i = 0, l = buf.length; i < l; i++) {
    s += String.fromCharCode(buf[i]);
  }
  return btoa(s);
}
function base64StringToArrayBuffer(str) {
  if (useNodeBuffer) {
    const buf = Buffer.from(str, "base64");
    return buf.buffer.slice(buf.byteOffset, buf.byteOffset + buf.byteLength);
  }
  const s = atob(str);
  const buffer2 = new Uint8Array(s.length);
  for (let i = 0; i < s.length; ++i) {
    buffer2.set([s.charCodeAt(i)], i);
  }
  return buffer2.buffer;
}
function concatenateArrayBuffers(buffers) {
  return CompositeArrayBuffer.join(buffers);
}
function basename(path) {
  const SEPARATOR = "/";
  path = path.trim();
  while (path.endsWith(SEPARATOR)) {
    path = path.slice(0, path.length - 1);
  }
  const items = path.split(SEPARATOR);
  return items[items.length - 1];
}
function getModelJSONForModelArtifacts(artifacts, manifest) {
  const result = {
    modelTopology: artifacts.modelTopology,
    format: artifacts.format,
    generatedBy: artifacts.generatedBy,
    convertedBy: artifacts.convertedBy,
    weightsManifest: manifest
  };
  if (artifacts.signature != null) {
    result.signature = artifacts.signature;
  }
  if (artifacts.userDefinedMetadata != null) {
    result.userDefinedMetadata = artifacts.userDefinedMetadata;
  }
  if (artifacts.modelInitializer != null) {
    result.modelInitializer = artifacts.modelInitializer;
  }
  if (artifacts.initializerSignature != null) {
    result.initializerSignature = artifacts.initializerSignature;
  }
  if (artifacts.trainingConfig != null) {
    result.trainingConfig = artifacts.trainingConfig;
  }
  return result;
}
function getModelArtifactsForJSONSync(modelJSON, weightSpecs, weightData) {
  const modelArtifacts = {
    modelTopology: modelJSON.modelTopology,
    format: modelJSON.format,
    generatedBy: modelJSON.generatedBy,
    convertedBy: modelJSON.convertedBy
  };
  if (modelJSON.trainingConfig != null) {
    modelArtifacts.trainingConfig = modelJSON.trainingConfig;
  }
  if (modelJSON.weightsManifest != null) {
    if (!weightSpecs) {
      throw new Error("modelJSON has weightsManifest but weightSpecs is null");
    }
    if (!weightData) {
      throw new Error("modelJSON has weightsManifest but weightData is null");
    }
    modelArtifacts.weightSpecs = weightSpecs;
    modelArtifacts.weightData = weightData;
  }
  if (modelJSON.signature != null) {
    modelArtifacts.signature = modelJSON.signature;
  }
  if (modelJSON.userDefinedMetadata != null) {
    modelArtifacts.userDefinedMetadata = modelJSON.userDefinedMetadata;
  }
  if (modelJSON.modelInitializer != null) {
    modelArtifacts.modelInitializer = modelJSON.modelInitializer;
  }
  if (modelJSON.initializerSignature != null) {
    modelArtifacts.initializerSignature = modelJSON.initializerSignature;
  }
  return modelArtifacts;
}
function getModelArtifactsForJSON(modelJSON, loadWeights2) {
  return __async(this, null, function* () {
    let weightSpecs;
    let weightData;
    if (modelJSON.weightsManifest != null) {
      [weightSpecs, weightData] = yield loadWeights2(modelJSON.weightsManifest);
    }
    return getModelArtifactsForJSONSync(modelJSON, weightSpecs, weightData);
  });
}
function getModelArtifactsInfoForJSON(modelArtifacts) {
  if (modelArtifacts.modelTopology instanceof ArrayBuffer) {
    throw new Error("Expected JSON model topology, received ArrayBuffer.");
  }
  return {
    dateSaved: /* @__PURE__ */ new Date(),
    modelTopologyType: "JSON",
    modelTopologyBytes: modelArtifacts.modelTopology == null ? 0 : stringByteLength(JSON.stringify(modelArtifacts.modelTopology)),
    weightSpecsBytes: modelArtifacts.weightSpecs == null ? 0 : stringByteLength(JSON.stringify(modelArtifacts.weightSpecs)),
    weightDataBytes: modelArtifacts.weightData == null ? 0 : new CompositeArrayBuffer(modelArtifacts.weightData).byteLength
  };
}
function getWeightSpecs(weightsManifest) {
  const weightSpecs = [];
  for (const entry of weightsManifest) {
    weightSpecs.push(...entry.weights);
  }
  return weightSpecs;
}
function computeFloat16MantisaTable() {
  const convertMantissa = (i) => {
    let m = i << 13;
    let e = 0;
    while ((m & 8388608) === 0) {
      e -= 8388608;
      m <<= 1;
    }
    m &= ~8388608;
    e += 947912704;
    return m | e;
  };
  const mantisaTable = new Uint32Array(2048);
  mantisaTable[0] = 0;
  for (let i = 1; i < 1024; i++) {
    mantisaTable[i] = convertMantissa(i);
  }
  for (let i = 1024; i < 2048; i++) {
    mantisaTable[i] = 939524096 + (i - 1024 << 13);
  }
  return mantisaTable;
}
function computeFloat16ExponentTable() {
  const exponentTable = new Uint32Array(64);
  exponentTable[0] = 0;
  exponentTable[31] = 1199570944;
  exponentTable[32] = 2147483648;
  exponentTable[63] = 3347054592;
  for (let i = 1; i < 31; i++) {
    exponentTable[i] = i << 23;
  }
  for (let i = 33; i < 63; i++) {
    exponentTable[i] = 2147483648 + (i - 32 << 23);
  }
  return exponentTable;
}
function computeFloat16OffsetTable() {
  const offsetTable = new Uint32Array(64);
  for (let i = 0; i < 64; i++) {
    offsetTable[i] = 1024;
  }
  offsetTable[0] = offsetTable[32] = 0;
  return offsetTable;
}
function getFloat16Decoder() {
  const mantisaTable = computeFloat16MantisaTable();
  const exponentTable = computeFloat16ExponentTable();
  const offsetTable = computeFloat16OffsetTable();
  return (quantizedArray) => {
    const buffer2 = new ArrayBuffer(4 * quantizedArray.length);
    const bufferUint32View = new Uint32Array(buffer2);
    for (let index = 0; index < quantizedArray.length; index++) {
      const float16Bits = quantizedArray[index];
      const float32Bits = mantisaTable[offsetTable[float16Bits >> 10] + (float16Bits & 1023)] + exponentTable[float16Bits >> 10];
      bufferUint32View[index] = float32Bits;
    }
    return new Float32Array(buffer2);
  };
}
var NUM_BYTES_STRING_LENGTH, useNodeBuffer;
var init_io_utils = __esm({
  "node_modules/@tensorflow/tfjs-core/dist/io/io_utils.js"() {
    init_complex();
    init_tensor2();
    init_util();
    init_types2();
    init_composite_array_buffer();
    init_globals();
    init_environment();
    init_globals();
    NUM_BYTES_STRING_LENGTH = 4;
    useNodeBuffer = typeof Buffer !== "undefined" && (typeof Blob === "undefined" || typeof atob === "undefined" || typeof btoa === "undefined");
  }
});

// node_modules/@tensorflow/tfjs-core/dist/io/router_registry.js
var IORouterRegistry, registerSaveRouter, registerLoadRouter, getSaveHandlers, getLoadHandlers;
var init_router_registry = __esm({
  "node_modules/@tensorflow/tfjs-core/dist/io/router_registry.js"() {
    IORouterRegistry = class _IORouterRegistry {
      constructor() {
        this.saveRouters = [];
        this.loadRouters = [];
      }
      static getInstance() {
        if (_IORouterRegistry.instance == null) {
          _IORouterRegistry.instance = new _IORouterRegistry();
        }
        return _IORouterRegistry.instance;
      }
      /**
       * Register a save-handler router.
       *
       * @param saveRouter A function that maps a URL-like string onto an instance
       * of `IOHandler` with the `save` method defined or `null`.
       */
      static registerSaveRouter(saveRouter) {
        _IORouterRegistry.getInstance().saveRouters.push(saveRouter);
      }
      /**
       * Register a load-handler router.
       *
       * @param loadRouter A function that maps a URL-like string onto an instance
       * of `IOHandler` with the `load` method defined or `null`.
       */
      static registerLoadRouter(loadRouter) {
        _IORouterRegistry.getInstance().loadRouters.push(loadRouter);
      }
      /**
       * Look up IOHandler for saving, given a URL-like string.
       *
       * @param url
       * @returns If only one match is found, an instance of IOHandler with the
       * `save` method defined. If no match is found, `null`.
       * @throws Error, if more than one match is found.
       */
      static getSaveHandlers(url) {
        return _IORouterRegistry.getHandlers(url, "save");
      }
      /**
       * Look up IOHandler for loading, given a URL-like string.
       *
       * @param url
       * @param loadOptions Optional, custom load options.
       * @returns All valid handlers for `url`, given the currently registered
       *   handler routers.
       */
      static getLoadHandlers(url, loadOptions) {
        return _IORouterRegistry.getHandlers(url, "load", loadOptions);
      }
      static getHandlers(url, handlerType, loadOptions) {
        const validHandlers = [];
        const routers = handlerType === "load" ? _IORouterRegistry.getInstance().loadRouters : _IORouterRegistry.getInstance().saveRouters;
        routers.forEach((router) => {
          const handler = router(url, loadOptions);
          if (handler !== null) {
            validHandlers.push(handler);
          }
        });
        return validHandlers;
      }
    };
    registerSaveRouter = (loudRouter) => IORouterRegistry.registerSaveRouter(loudRouter);
    registerLoadRouter = (loudRouter) => IORouterRegistry.registerLoadRouter(loudRouter);
    getSaveHandlers = (url) => IORouterRegistry.getSaveHandlers(url);
    getLoadHandlers = (url, loadOptions) => IORouterRegistry.getLoadHandlers(url, loadOptions);
  }
});

// node_modules/@tensorflow/tfjs-core/dist/io/indexed_db.js
function getIndexedDBFactory() {
  if (!env().getBool("IS_BROWSER")) {
    throw new Error("Failed to obtain IndexedDB factory because the current environmentis not a web browser.");
  }
  const theWindow = typeof window === "undefined" ? self : window;
  const factory = theWindow.indexedDB || theWindow.mozIndexedDB || theWindow.webkitIndexedDB || theWindow.msIndexedDB || theWindow.shimIndexedDB;
  if (factory == null) {
    throw new Error("The current browser does not appear to support IndexedDB.");
  }
  return factory;
}
function setUpDatabase(openRequest) {
  const db = openRequest.result;
  db.createObjectStore(MODEL_STORE_NAME, {
    keyPath: "modelPath"
  });
  db.createObjectStore(INFO_STORE_NAME, {
    keyPath: "modelPath"
  });
}
function browserIndexedDB(modelPath) {
  return new BrowserIndexedDB(modelPath);
}
function maybeStripScheme(key) {
  return key.startsWith(BrowserIndexedDB.URL_SCHEME) ? key.slice(BrowserIndexedDB.URL_SCHEME.length) : key;
}
var DATABASE_NAME, DATABASE_VERSION, MODEL_STORE_NAME, INFO_STORE_NAME, BrowserIndexedDB, indexedDBRouter, BrowserIndexedDBManager;
var init_indexed_db = __esm({
  "node_modules/@tensorflow/tfjs-core/dist/io/indexed_db.js"() {
    init_flags();
    init_environment();
    init_io_utils();
    init_router_registry();
    init_composite_array_buffer();
    DATABASE_NAME = "tensorflowjs";
    DATABASE_VERSION = 1;
    MODEL_STORE_NAME = "models_store";
    INFO_STORE_NAME = "model_info_store";
    BrowserIndexedDB = class {
      constructor(modelPath) {
        this.indexedDB = getIndexedDBFactory();
        if (modelPath == null || !modelPath) {
          throw new Error("For IndexedDB, modelPath must not be null, undefined or empty.");
        }
        this.modelPath = modelPath;
      }
      save(modelArtifacts) {
        return __async(this, null, function* () {
          if (modelArtifacts.modelTopology instanceof ArrayBuffer) {
            throw new Error("BrowserLocalStorage.save() does not support saving model topology in binary formats yet.");
          }
          return this.databaseAction(this.modelPath, modelArtifacts);
        });
      }
      load() {
        return __async(this, null, function* () {
          return this.databaseAction(this.modelPath);
        });
      }
      /**
       * Perform database action to put model artifacts into or read model artifacts
       * from IndexedDB object store.
       *
       * Whether the action is put or get depends on whether `modelArtifacts` is
       * specified. If it is specified, the action will be put; otherwise the action
       * will be get.
       *
       * @param modelPath A unique string path for the model.
       * @param modelArtifacts If specified, it will be the model artifacts to be
       *   stored in IndexedDB.
       * @returns A `Promise` of `SaveResult`, if the action is put, or a `Promise`
       *   of `ModelArtifacts`, if the action is get.
       */
      databaseAction(modelPath, modelArtifacts) {
        return new Promise((resolve, reject) => {
          const openRequest = this.indexedDB.open(DATABASE_NAME, DATABASE_VERSION);
          openRequest.onupgradeneeded = () => setUpDatabase(openRequest);
          openRequest.onsuccess = () => {
            const db = openRequest.result;
            if (modelArtifacts == null) {
              const modelTx = db.transaction(MODEL_STORE_NAME, "readonly");
              const modelStore = modelTx.objectStore(MODEL_STORE_NAME);
              const getRequest = modelStore.get(this.modelPath);
              getRequest.onsuccess = () => {
                if (getRequest.result == null) {
                  db.close();
                  return reject(new Error(`Cannot find model with path '${this.modelPath}' in IndexedDB.`));
                } else {
                  resolve(getRequest.result.modelArtifacts);
                }
              };
              getRequest.onerror = (error) => {
                db.close();
                return reject(getRequest.error);
              };
              modelTx.oncomplete = () => db.close();
            } else {
              modelArtifacts.weightData = CompositeArrayBuffer.join(modelArtifacts.weightData);
              const modelArtifactsInfo = getModelArtifactsInfoForJSON(modelArtifacts);
              const infoTx = db.transaction(INFO_STORE_NAME, "readwrite");
              let infoStore = infoTx.objectStore(INFO_STORE_NAME);
              let putInfoRequest;
              try {
                putInfoRequest = infoStore.put({
                  modelPath: this.modelPath,
                  modelArtifactsInfo
                });
              } catch (error) {
                return reject(error);
              }
              let modelTx;
              putInfoRequest.onsuccess = () => {
                modelTx = db.transaction(MODEL_STORE_NAME, "readwrite");
                const modelStore = modelTx.objectStore(MODEL_STORE_NAME);
                let putModelRequest;
                try {
                  putModelRequest = modelStore.put({
                    modelPath: this.modelPath,
                    modelArtifacts,
                    modelArtifactsInfo
                  });
                } catch (error) {
                  return reject(error);
                }
                putModelRequest.onsuccess = () => resolve({
                  modelArtifactsInfo
                });
                putModelRequest.onerror = (error) => {
                  infoStore = infoTx.objectStore(INFO_STORE_NAME);
                  const deleteInfoRequest = infoStore.delete(this.modelPath);
                  deleteInfoRequest.onsuccess = () => {
                    db.close();
                    return reject(putModelRequest.error);
                  };
                  deleteInfoRequest.onerror = (error2) => {
                    db.close();
                    return reject(putModelRequest.error);
                  };
                };
              };
              putInfoRequest.onerror = (error) => {
                db.close();
                return reject(putInfoRequest.error);
              };
              infoTx.oncomplete = () => {
                if (modelTx == null) {
                  db.close();
                } else {
                  modelTx.oncomplete = () => db.close();
                }
              };
            }
          };
          openRequest.onerror = (error) => reject(openRequest.error);
        });
      }
    };
    BrowserIndexedDB.URL_SCHEME = "indexeddb://";
    indexedDBRouter = (url) => {
      if (!env().getBool("IS_BROWSER")) {
        return null;
      } else {
        if (!Array.isArray(url) && url.startsWith(BrowserIndexedDB.URL_SCHEME)) {
          return browserIndexedDB(url.slice(BrowserIndexedDB.URL_SCHEME.length));
        } else {
          return null;
        }
      }
    };
    IORouterRegistry.registerSaveRouter(indexedDBRouter);
    IORouterRegistry.registerLoadRouter(indexedDBRouter);
    BrowserIndexedDBManager = class {
      constructor() {
        this.indexedDB = getIndexedDBFactory();
      }
      listModels() {
        return __async(this, null, function* () {
          return new Promise((resolve, reject) => {
            const openRequest = this.indexedDB.open(DATABASE_NAME, DATABASE_VERSION);
            openRequest.onupgradeneeded = () => setUpDatabase(openRequest);
            openRequest.onsuccess = () => {
              const db = openRequest.result;
              const tx = db.transaction(INFO_STORE_NAME, "readonly");
              const store = tx.objectStore(INFO_STORE_NAME);
              const getAllInfoRequest = store.getAll();
              getAllInfoRequest.onsuccess = () => {
                const out = {};
                for (const item of getAllInfoRequest.result) {
                  out[item.modelPath] = item.modelArtifactsInfo;
                }
                resolve(out);
              };
              getAllInfoRequest.onerror = (error) => {
                db.close();
                return reject(getAllInfoRequest.error);
              };
              tx.oncomplete = () => db.close();
            };
            openRequest.onerror = (error) => reject(openRequest.error);
          });
        });
      }
      removeModel(path) {
        return __async(this, null, function* () {
          path = maybeStripScheme(path);
          return new Promise((resolve, reject) => {
            const openRequest = this.indexedDB.open(DATABASE_NAME, DATABASE_VERSION);
            openRequest.onupgradeneeded = () => setUpDatabase(openRequest);
            openRequest.onsuccess = () => {
              const db = openRequest.result;
              const infoTx = db.transaction(INFO_STORE_NAME, "readwrite");
              const infoStore = infoTx.objectStore(INFO_STORE_NAME);
              const getInfoRequest = infoStore.get(path);
              let modelTx;
              getInfoRequest.onsuccess = () => {
                if (getInfoRequest.result == null) {
                  db.close();
                  return reject(new Error(`Cannot find model with path '${path}' in IndexedDB.`));
                } else {
                  const deleteInfoRequest = infoStore.delete(path);
                  const deleteModelData = () => {
                    modelTx = db.transaction(MODEL_STORE_NAME, "readwrite");
                    const modelStore = modelTx.objectStore(MODEL_STORE_NAME);
                    const deleteModelRequest = modelStore.delete(path);
                    deleteModelRequest.onsuccess = () => resolve(getInfoRequest.result.modelArtifactsInfo);
                    deleteModelRequest.onerror = (error) => reject(getInfoRequest.error);
                  };
                  deleteInfoRequest.onsuccess = deleteModelData;
                  deleteInfoRequest.onerror = (error) => {
                    deleteModelData();
                    db.close();
                    return reject(getInfoRequest.error);
                  };
                }
              };
              getInfoRequest.onerror = (error) => {
                db.close();
                return reject(getInfoRequest.error);
              };
              infoTx.oncomplete = () => {
                if (modelTx == null) {
                  db.close();
                } else {
                  modelTx.oncomplete = () => db.close();
                }
              };
            };
            openRequest.onerror = (error) => reject(openRequest.error);
          });
        });
      }
    };
  }
});

// node_modules/@tensorflow/tfjs-core/dist/io/local_storage.js
function getModelKeys(path) {
  return {
    info: [PATH_PREFIX, path, INFO_SUFFIX].join(PATH_SEPARATOR),
    topology: [PATH_PREFIX, path, MODEL_TOPOLOGY_SUFFIX].join(PATH_SEPARATOR),
    weightSpecs: [PATH_PREFIX, path, WEIGHT_SPECS_SUFFIX].join(PATH_SEPARATOR),
    weightData: [PATH_PREFIX, path, WEIGHT_DATA_SUFFIX].join(PATH_SEPARATOR),
    modelMetadata: [PATH_PREFIX, path, MODEL_METADATA_SUFFIX].join(PATH_SEPARATOR)
  };
}
function removeItems(keys) {
  for (const key of Object.values(keys)) {
    window.localStorage.removeItem(key);
  }
}
function getModelPathFromKey(key) {
  const items = key.split(PATH_SEPARATOR);
  if (items.length < 3) {
    throw new Error(`Invalid key format: ${key}`);
  }
  return items.slice(1, items.length - 1).join(PATH_SEPARATOR);
}
function maybeStripScheme2(key) {
  return key.startsWith(BrowserLocalStorage.URL_SCHEME) ? key.slice(BrowserLocalStorage.URL_SCHEME.length) : key;
}
function browserLocalStorage(modelPath) {
  return new BrowserLocalStorage(modelPath);
}
var PATH_SEPARATOR, PATH_PREFIX, INFO_SUFFIX, MODEL_TOPOLOGY_SUFFIX, WEIGHT_SPECS_SUFFIX, WEIGHT_DATA_SUFFIX, MODEL_METADATA_SUFFIX, BrowserLocalStorage, localStorageRouter, BrowserLocalStorageManager;
var init_local_storage = __esm({
  "node_modules/@tensorflow/tfjs-core/dist/io/local_storage.js"() {
    init_flags();
    init_environment();
    init_util();
    init_io_utils();
    init_composite_array_buffer();
    init_router_registry();
    PATH_SEPARATOR = "/";
    PATH_PREFIX = "tensorflowjs_models";
    INFO_SUFFIX = "info";
    MODEL_TOPOLOGY_SUFFIX = "model_topology";
    WEIGHT_SPECS_SUFFIX = "weight_specs";
    WEIGHT_DATA_SUFFIX = "weight_data";
    MODEL_METADATA_SUFFIX = "model_metadata";
    BrowserLocalStorage = class {
      constructor(modelPath) {
        if (!env().getBool("IS_BROWSER") || typeof window === "undefined" || typeof window.localStorage === "undefined") {
          throw new Error("The current environment does not support local storage.");
        }
        this.LS = window.localStorage;
        if (modelPath == null || !modelPath) {
          throw new Error("For local storage, modelPath must not be null, undefined or empty.");
        }
        this.modelPath = modelPath;
        this.keys = getModelKeys(this.modelPath);
      }
      /**
       * Save model artifacts to browser local storage.
       *
       * See the documentation to `browserLocalStorage` for details on the saved
       * artifacts.
       *
       * @param modelArtifacts The model artifacts to be stored.
       * @returns An instance of SaveResult.
       */
      save(modelArtifacts) {
        return __async(this, null, function* () {
          if (modelArtifacts.modelTopology instanceof ArrayBuffer) {
            throw new Error("BrowserLocalStorage.save() does not support saving model topology in binary formats yet.");
          } else {
            const topology = JSON.stringify(modelArtifacts.modelTopology);
            const weightSpecs = JSON.stringify(modelArtifacts.weightSpecs);
            const modelArtifactsInfo = getModelArtifactsInfoForJSON(modelArtifacts);
            const weightBuffer = CompositeArrayBuffer.join(modelArtifacts.weightData);
            try {
              this.LS.setItem(this.keys.info, JSON.stringify(modelArtifactsInfo));
              this.LS.setItem(this.keys.topology, topology);
              this.LS.setItem(this.keys.weightSpecs, weightSpecs);
              this.LS.setItem(this.keys.weightData, arrayBufferToBase64String(weightBuffer));
              const metadata = {
                format: modelArtifacts.format,
                generatedBy: modelArtifacts.generatedBy,
                convertedBy: modelArtifacts.convertedBy,
                signature: modelArtifacts.signature != null ? modelArtifacts.signature : void 0,
                userDefinedMetadata: modelArtifacts.userDefinedMetadata != null ? modelArtifacts.userDefinedMetadata : void 0,
                modelInitializer: modelArtifacts.modelInitializer != null ? modelArtifacts.modelInitializer : void 0,
                initializerSignature: modelArtifacts.initializerSignature != null ? modelArtifacts.initializerSignature : void 0,
                trainingConfig: modelArtifacts.trainingConfig != null ? modelArtifacts.trainingConfig : void 0
              };
              this.LS.setItem(this.keys.modelMetadata, JSON.stringify(metadata));
              return {
                modelArtifactsInfo
              };
            } catch (err) {
              removeItems(this.keys);
              throw new Error(`Failed to save model '${this.modelPath}' to local storage: size quota being exceeded is a possible cause of this failure: modelTopologyBytes=${modelArtifactsInfo.modelTopologyBytes}, weightSpecsBytes=${modelArtifactsInfo.weightSpecsBytes}, weightDataBytes=${modelArtifactsInfo.weightDataBytes}.`);
            }
          }
        });
      }
      /**
       * Load a model from local storage.
       *
       * See the documentation to `browserLocalStorage` for details on the saved
       * artifacts.
       *
       * @returns The loaded model (if loading succeeds).
       */
      load() {
        return __async(this, null, function* () {
          const info = JSON.parse(this.LS.getItem(this.keys.info));
          if (info == null) {
            throw new Error(`In local storage, there is no model with name '${this.modelPath}'`);
          }
          if (info.modelTopologyType !== "JSON") {
            throw new Error("BrowserLocalStorage does not support loading non-JSON model topology yet.");
          }
          const out = {};
          const topology = JSON.parse(this.LS.getItem(this.keys.topology));
          if (topology == null) {
            throw new Error(`In local storage, the topology of model '${this.modelPath}' is missing.`);
          }
          out.modelTopology = topology;
          const weightSpecs = JSON.parse(this.LS.getItem(this.keys.weightSpecs));
          if (weightSpecs == null) {
            throw new Error(`In local storage, the weight specs of model '${this.modelPath}' are missing.`);
          }
          out.weightSpecs = weightSpecs;
          const metadataString = this.LS.getItem(this.keys.modelMetadata);
          if (metadataString != null) {
            const metadata = JSON.parse(metadataString);
            out.format = metadata.format;
            out.generatedBy = metadata.generatedBy;
            out.convertedBy = metadata.convertedBy;
            if (metadata.signature != null) {
              out.signature = metadata.signature;
            }
            if (metadata.userDefinedMetadata != null) {
              out.userDefinedMetadata = metadata.userDefinedMetadata;
            }
            if (metadata.modelInitializer != null) {
              out.modelInitializer = metadata.modelInitializer;
            }
            if (metadata.initializerSignature != null) {
              out.initializerSignature = metadata.initializerSignature;
            }
            if (metadata.trainingConfig != null) {
              out.trainingConfig = metadata.trainingConfig;
            }
          }
          const weightDataBase64 = this.LS.getItem(this.keys.weightData);
          if (weightDataBase64 == null) {
            throw new Error(`In local storage, the binary weight values of model '${this.modelPath}' are missing.`);
          }
          out.weightData = base64StringToArrayBuffer(weightDataBase64);
          return out;
        });
      }
    };
    BrowserLocalStorage.URL_SCHEME = "localstorage://";
    localStorageRouter = (url) => {
      if (!env().getBool("IS_BROWSER")) {
        return null;
      } else {
        if (!Array.isArray(url) && url.startsWith(BrowserLocalStorage.URL_SCHEME)) {
          return browserLocalStorage(url.slice(BrowserLocalStorage.URL_SCHEME.length));
        } else {
          return null;
        }
      }
    };
    IORouterRegistry.registerSaveRouter(localStorageRouter);
    IORouterRegistry.registerLoadRouter(localStorageRouter);
    BrowserLocalStorageManager = class {
      constructor() {
        assert(env().getBool("IS_BROWSER"), () => "Current environment is not a web browser");
        assert(typeof window === "undefined" || typeof window.localStorage !== "undefined", () => "Current browser does not appear to support localStorage");
        this.LS = window.localStorage;
      }
      listModels() {
        return __async(this, null, function* () {
          const out = {};
          const prefix = PATH_PREFIX + PATH_SEPARATOR;
          const suffix = PATH_SEPARATOR + INFO_SUFFIX;
          for (let i = 0; i < this.LS.length; ++i) {
            const key = this.LS.key(i);
            if (key.startsWith(prefix) && key.endsWith(suffix)) {
              const modelPath = getModelPathFromKey(key);
              out[modelPath] = JSON.parse(this.LS.getItem(key));
            }
          }
          return out;
        });
      }
      removeModel(path) {
        return __async(this, null, function* () {
          path = maybeStripScheme2(path);
          const keys = getModelKeys(path);
          if (this.LS.getItem(keys.info) == null) {
            throw new Error(`Cannot find model at path '${path}'`);
          }
          const info = JSON.parse(this.LS.getItem(keys.info));
          removeItems(keys);
          return info;
        });
      }
    };
  }
});

// node_modules/@tensorflow/tfjs-core/dist/io/browser_files.js
function defer(f) {
  return new Promise((resolve) => setTimeout(resolve)).then(f);
}
function browserDownloads(fileNamePrefix = "model") {
  return new BrowserDownloads(fileNamePrefix);
}
function browserFiles(files) {
  return new BrowserFiles(files);
}
var DEFAULT_FILE_NAME_PREFIX, DEFAULT_JSON_EXTENSION_NAME, DEFAULT_WEIGHT_DATA_EXTENSION_NAME, BrowserDownloads, BrowserFiles, browserDownloadsRouter;
var init_browser_files = __esm({
  "node_modules/@tensorflow/tfjs-core/dist/io/browser_files.js"() {
    init_flags();
    init_environment();
    init_io_utils();
    init_router_registry();
    init_composite_array_buffer();
    DEFAULT_FILE_NAME_PREFIX = "model";
    DEFAULT_JSON_EXTENSION_NAME = ".json";
    DEFAULT_WEIGHT_DATA_EXTENSION_NAME = ".weights.bin";
    BrowserDownloads = class _BrowserDownloads {
      constructor(fileNamePrefix) {
        if (!env().getBool("IS_BROWSER")) {
          throw new Error("browserDownloads() cannot proceed because the current environment is not a browser.");
        }
        if (fileNamePrefix.startsWith(_BrowserDownloads.URL_SCHEME)) {
          fileNamePrefix = fileNamePrefix.slice(_BrowserDownloads.URL_SCHEME.length);
        }
        if (fileNamePrefix == null || fileNamePrefix.length === 0) {
          fileNamePrefix = DEFAULT_FILE_NAME_PREFIX;
        }
        this.modelJsonFileName = fileNamePrefix + DEFAULT_JSON_EXTENSION_NAME;
        this.weightDataFileName = fileNamePrefix + DEFAULT_WEIGHT_DATA_EXTENSION_NAME;
      }
      save(modelArtifacts) {
        return __async(this, null, function* () {
          if (typeof document === "undefined") {
            throw new Error("Browser downloads are not supported in this environment since `document` is not present");
          }
          const weightBuffer = CompositeArrayBuffer.join(modelArtifacts.weightData);
          const weightsURL = window.URL.createObjectURL(new Blob([weightBuffer], {
            type: "application/octet-stream"
          }));
          if (modelArtifacts.modelTopology instanceof ArrayBuffer) {
            throw new Error("BrowserDownloads.save() does not support saving model topology in binary formats yet.");
          } else {
            const weightsManifest = [{
              paths: ["./" + this.weightDataFileName],
              weights: modelArtifacts.weightSpecs
            }];
            const modelJSON = getModelJSONForModelArtifacts(modelArtifacts, weightsManifest);
            const modelJsonURL = window.URL.createObjectURL(new Blob([JSON.stringify(modelJSON)], {
              type: "application/json"
            }));
            const jsonAnchor = this.modelJsonAnchor == null ? document.createElement("a") : this.modelJsonAnchor;
            jsonAnchor.download = this.modelJsonFileName;
            jsonAnchor.href = modelJsonURL;
            yield defer(() => jsonAnchor.dispatchEvent(new MouseEvent("click")));
            if (modelArtifacts.weightData != null) {
              const weightDataAnchor = this.weightDataAnchor == null ? document.createElement("a") : this.weightDataAnchor;
              weightDataAnchor.download = this.weightDataFileName;
              weightDataAnchor.href = weightsURL;
              yield defer(() => weightDataAnchor.dispatchEvent(new MouseEvent("click")));
            }
            return {
              modelArtifactsInfo: getModelArtifactsInfoForJSON(modelArtifacts)
            };
          }
        });
      }
    };
    BrowserDownloads.URL_SCHEME = "downloads://";
    BrowserFiles = class {
      constructor(files) {
        if (files == null || files.length < 1) {
          throw new Error(`When calling browserFiles, at least 1 file is required, but received ${files}`);
        }
        this.jsonFile = files[0];
        this.weightsFiles = files.slice(1);
      }
      load() {
        return __async(this, null, function* () {
          return new Promise((resolve, reject) => {
            const jsonReader = new FileReader();
            jsonReader.onload = (event) => {
              const modelJSON = JSON.parse(event.target.result);
              const modelTopology = modelJSON.modelTopology;
              if (modelTopology == null) {
                reject(new Error(`modelTopology field is missing from file ${this.jsonFile.name}`));
                return;
              }
              const weightsManifest = modelJSON.weightsManifest;
              if (weightsManifest == null) {
                reject(new Error(`weightManifest field is missing from file ${this.jsonFile.name}`));
                return;
              }
              if (this.weightsFiles.length === 0) {
                resolve({
                  modelTopology
                });
                return;
              }
              const modelArtifactsPromise = getModelArtifactsForJSON(modelJSON, (weightsManifest2) => this.loadWeights(weightsManifest2));
              resolve(modelArtifactsPromise);
            };
            jsonReader.onerror = (error) => reject(`Failed to read model topology and weights manifest JSON from file '${this.jsonFile.name}'. BrowserFiles supports loading Keras-style tf.Model artifacts only.`);
            jsonReader.readAsText(this.jsonFile);
          });
        });
      }
      loadWeights(weightsManifest) {
        const weightSpecs = [];
        const paths = [];
        for (const entry of weightsManifest) {
          weightSpecs.push(...entry.weights);
          paths.push(...entry.paths);
        }
        const pathToFile = this.checkManifestAndWeightFiles(weightsManifest);
        const promises = paths.map((path) => this.loadWeightsFile(path, pathToFile[path]));
        return Promise.all(promises).then((buffers) => [weightSpecs, buffers]);
      }
      loadWeightsFile(path, file) {
        return new Promise((resolve, reject) => {
          const weightFileReader = new FileReader();
          weightFileReader.onload = (event) => {
            const weightData = event.target.result;
            resolve(weightData);
          };
          weightFileReader.onerror = (error) => reject(`Failed to weights data from file of path '${path}'.`);
          weightFileReader.readAsArrayBuffer(file);
        });
      }
      /**
       * Check the compatibility between weights manifest and weight files.
       */
      checkManifestAndWeightFiles(manifest) {
        const basenames = [];
        const fileNames = this.weightsFiles.map((file) => basename(file.name));
        const pathToFile = {};
        for (const group of manifest) {
          group.paths.forEach((path) => {
            const pathBasename = basename(path);
            if (basenames.indexOf(pathBasename) !== -1) {
              throw new Error(`Duplicate file basename found in weights manifest: '${pathBasename}'`);
            }
            basenames.push(pathBasename);
            if (fileNames.indexOf(pathBasename) === -1) {
              throw new Error(`Weight file with basename '${pathBasename}' is not provided.`);
            } else {
              pathToFile[path] = this.weightsFiles[fileNames.indexOf(pathBasename)];
            }
          });
        }
        if (basenames.length !== this.weightsFiles.length) {
          throw new Error(`Mismatch in the number of files in weights manifest (${basenames.length}) and the number of weight files provided (${this.weightsFiles.length}).`);
        }
        return pathToFile;
      }
    };
    browserDownloadsRouter = (url) => {
      if (!env().getBool("IS_BROWSER")) {
        return null;
      } else {
        if (!Array.isArray(url) && url.startsWith(BrowserDownloads.URL_SCHEME)) {
          return browserDownloads(url.slice(BrowserDownloads.URL_SCHEME.length));
        } else {
          return null;
        }
      }
    };
    IORouterRegistry.registerSaveRouter(browserDownloadsRouter);
  }
});

// node_modules/@tensorflow/tfjs-core/dist/io/progress.js
function monitorPromisesProgress(promises, onProgress, startFraction, endFraction) {
  checkPromises(promises);
  startFraction = startFraction == null ? 0 : startFraction;
  endFraction = endFraction == null ? 1 : endFraction;
  checkFraction(startFraction, endFraction);
  let resolvedPromise = 0;
  const registerMonitor = (promise) => {
    promise.then((value) => {
      const fraction = startFraction + ++resolvedPromise / promises.length * (endFraction - startFraction);
      onProgress(fraction);
      return value;
    });
    return promise;
  };
  function checkPromises(promises2) {
    assert(promises2 != null && Array.isArray(promises2) && promises2.length > 0, () => "promises must be a none empty array");
  }
  function checkFraction(startFraction2, endFraction2) {
    assert(startFraction2 >= 0 && startFraction2 <= 1, () => `Progress fraction must be in range [0, 1], but got startFraction ${startFraction2}`);
    assert(endFraction2 >= 0 && endFraction2 <= 1, () => `Progress fraction must be in range [0, 1], but got endFraction ${endFraction2}`);
    assert(endFraction2 >= startFraction2, () => `startFraction must be no more than endFraction, but got startFraction ${startFraction2} and endFraction ${endFraction2}`);
  }
  return Promise.all(promises.map(registerMonitor));
}
var init_progress = __esm({
  "node_modules/@tensorflow/tfjs-core/dist/io/progress.js"() {
    init_util();
  }
});

// node_modules/@tensorflow/tfjs-core/dist/io/weights_loader.js
function loadWeightsAsArrayBuffer(fetchURLs, loadOptions) {
  return __async(this, null, function* () {
    if (loadOptions == null) {
      loadOptions = {};
    }
    const fetchFunc = loadOptions.fetchFunc == null ? env().platform.fetch : loadOptions.fetchFunc;
    const requests = fetchURLs.map((fetchURL) => fetchFunc(fetchURL, loadOptions.requestInit, {
      isBinary: true
    }));
    const fetchStartFraction = 0;
    const fetchEndFraction = 0.5;
    const responses = loadOptions.onProgress == null ? yield Promise.all(requests) : yield monitorPromisesProgress(requests, loadOptions.onProgress, fetchStartFraction, fetchEndFraction);
    const bufferPromises = responses.map((response) => response.arrayBuffer());
    const bufferStartFraction = 0.5;
    const bufferEndFraction = 1;
    const buffers = loadOptions.onProgress == null ? yield Promise.all(bufferPromises) : yield monitorPromisesProgress(bufferPromises, loadOptions.onProgress, bufferStartFraction, bufferEndFraction);
    return buffers;
  });
}
function streamWeights(fetchURLs, loadOptions) {
  var _a;
  const fetchFunc = loadOptions.fetchFunc == null ? env().platform.fetch : loadOptions.fetchFunc;
  let fetchIndex = 0;
  let chunkReader;
  (_a = loadOptions.onProgress) === null || _a === void 0 ? void 0 : _a.call(loadOptions, 0);
  return new ReadableStream({
    pull: (controller) => __async(null, null, function* () {
      var _a2;
      while (fetchIndex < fetchURLs.length) {
        if (!chunkReader) {
          const body = (yield fetchFunc(fetchURLs[fetchIndex], loadOptions.requestInit, {
            isBinary: true
          })).body;
          chunkReader = body.getReader();
        }
        const {
          done,
          value
        } = yield chunkReader.read();
        if (done) {
          fetchIndex++;
          chunkReader = void 0;
          (_a2 = loadOptions.onProgress) === null || _a2 === void 0 ? void 0 : _a2.call(loadOptions, fetchIndex / fetchURLs.length);
          continue;
        }
        controller.enqueue(value);
        return;
      }
      controller.close();
    })
  });
}
function loadWeights(manifest, filePathPrefix = "", weightNames, requestInit) {
  return __async(this, null, function* () {
    const fetchWeights = (fetchUrls) => loadWeightsAsArrayBuffer(fetchUrls, {
      requestInit
    });
    const loadWeights2 = weightsLoaderFactory(fetchWeights);
    return loadWeights2(manifest, filePathPrefix, weightNames);
  });
}
function weightsLoaderFactory(fetchWeightsFunction) {
  return (manifest, filePathPrefix = "", weightNames) => __async(null, null, function* () {
    const groupIndicesToFetchMap = manifest.map(() => false);
    const groupWeightsToFetch = {};
    const weightsFound = weightNames != null ? weightNames.map(() => false) : [];
    const allManifestWeightNames = [];
    manifest.forEach((manifestGroupConfig, groupIndex) => {
      let groupOffset = 0;
      manifestGroupConfig.weights.forEach((weightsEntry) => {
        const rawDtype = "quantization" in weightsEntry ? weightsEntry.quantization.dtype : weightsEntry.dtype;
        const weightsBytes = DTYPE_VALUE_SIZE_MAP[rawDtype] * sizeFromShape(weightsEntry.shape);
        const enqueueWeightsForFetchingFn = () => {
          groupIndicesToFetchMap[groupIndex] = true;
          if (groupWeightsToFetch[groupIndex] == null) {
            groupWeightsToFetch[groupIndex] = [];
          }
          groupWeightsToFetch[groupIndex].push({
            manifestEntry: weightsEntry,
            groupOffset,
            sizeBytes: weightsBytes
          });
        };
        if (weightNames != null) {
          weightNames.forEach((weightName, weightIndex) => {
            if (weightName === weightsEntry.name) {
              enqueueWeightsForFetchingFn();
              weightsFound[weightIndex] = true;
            }
          });
        } else {
          enqueueWeightsForFetchingFn();
        }
        allManifestWeightNames.push(weightsEntry.name);
        groupOffset += weightsBytes;
      });
    });
    if (!weightsFound.every((found) => found)) {
      const weightsNotFound = weightNames.filter((_, i) => !weightsFound[i]);
      throw new Error(`Could not find weights in manifest with names: ${weightsNotFound.join(", ")}. 
Manifest JSON has weights with names: ${allManifestWeightNames.join(", ")}.`);
    }
    const groupIndicesToFetch = groupIndicesToFetchMap.reduce((accumulator, shouldFetch, i) => {
      if (shouldFetch) {
        accumulator.push(i);
      }
      return accumulator;
    }, []);
    const fetchUrls = [];
    groupIndicesToFetch.forEach((i) => {
      manifest[i].paths.forEach((filepath) => {
        const fetchUrl = filePathPrefix + (!filePathPrefix.endsWith("/") ? "/" : "") + filepath;
        fetchUrls.push(fetchUrl);
      });
    });
    const buffers = yield fetchWeightsFunction(fetchUrls);
    const weightsTensorMap = {};
    let bufferIndexOffset = 0;
    groupIndicesToFetch.forEach((i) => {
      const numBuffers = manifest[i].paths.length;
      const weightsBuffer = new CompositeArrayBuffer(buffers.slice(bufferIndexOffset, bufferIndexOffset + numBuffers));
      const weightsEntries = groupWeightsToFetch[i];
      weightsEntries.forEach((weightsEntry) => {
        const byteBuffer = weightsBuffer.slice(weightsEntry.groupOffset, weightsEntry.groupOffset + weightsEntry.sizeBytes);
        const nameToTensorMap = decodeWeights(byteBuffer, [weightsEntry.manifestEntry]);
        for (const name in nameToTensorMap) {
          weightsTensorMap[name] = nameToTensorMap[name];
        }
      });
      bufferIndexOffset += numBuffers;
    });
    return weightsTensorMap;
  });
}
var init_weights_loader = __esm({
  "node_modules/@tensorflow/tfjs-core/dist/io/weights_loader.js"() {
    init_environment();
    init_util();
    init_composite_array_buffer();
    init_io_utils();
    init_progress();
    init_types2();
  }
});

// node_modules/@tensorflow/tfjs-core/dist/io/http.js
function parseUrl(url) {
  const lastSlash = url.lastIndexOf("/");
  const lastSearchParam = url.lastIndexOf("?");
  const prefix = url.substring(0, lastSlash);
  const suffix = lastSearchParam > lastSlash ? url.substring(lastSearchParam) : "";
  return [prefix + "/", suffix];
}
function isHTTPScheme(url) {
  return url.match(HTTPRequest.URL_SCHEME_REGEX) != null;
}
function http(path, loadOptions) {
  return new HTTPRequest(path, loadOptions);
}
function browserHTTPRequest(path, loadOptions) {
  return http(path, loadOptions);
}
var OCTET_STREAM_MIME_TYPE, JSON_TYPE, HTTPRequest, httpRouter;
var init_http = __esm({
  "node_modules/@tensorflow/tfjs-core/dist/io/http.js"() {
    init_environment();
    init_util();
    init_io_utils();
    init_composite_array_buffer();
    init_router_registry();
    init_weights_loader();
    OCTET_STREAM_MIME_TYPE = "application/octet-stream";
    JSON_TYPE = "application/json";
    HTTPRequest = class {
      constructor(path, loadOptions) {
        this.DEFAULT_METHOD = "POST";
        if (loadOptions == null) {
          loadOptions = {};
        }
        this.weightPathPrefix = loadOptions.weightPathPrefix;
        this.weightUrlConverter = loadOptions.weightUrlConverter;
        if (loadOptions.fetchFunc != null) {
          assert(typeof loadOptions.fetchFunc === "function", () => "Must pass a function that matches the signature of `fetch` (see https://developer.mozilla.org/en-US/docs/Web/API/Fetch_API)");
          this.fetch = loadOptions.fetchFunc;
        } else {
          this.fetch = env().platform.fetch;
        }
        assert(path != null && path.length > 0, () => "URL path for http must not be null, undefined or empty.");
        if (Array.isArray(path)) {
          assert(path.length === 2, () => `URL paths for http must have a length of 2, (actual length is ${path.length}).`);
        }
        this.path = path;
        if (loadOptions.requestInit != null && loadOptions.requestInit.body != null) {
          throw new Error("requestInit is expected to have no pre-existing body, but has one.");
        }
        this.requestInit = loadOptions.requestInit || {};
        this.loadOptions = loadOptions;
      }
      save(modelArtifacts) {
        return __async(this, null, function* () {
          if (modelArtifacts.modelTopology instanceof ArrayBuffer) {
            throw new Error("BrowserHTTPRequest.save() does not support saving model topology in binary formats yet.");
          }
          const init = Object.assign({
            method: this.DEFAULT_METHOD
          }, this.requestInit);
          init.body = new FormData();
          const weightsManifest = [{
            paths: ["./model.weights.bin"],
            weights: modelArtifacts.weightSpecs
          }];
          const modelTopologyAndWeightManifest = getModelJSONForModelArtifacts(modelArtifacts, weightsManifest);
          init.body.append("model.json", new Blob([JSON.stringify(modelTopologyAndWeightManifest)], {
            type: JSON_TYPE
          }), "model.json");
          if (modelArtifacts.weightData != null) {
            const weightBuffer = CompositeArrayBuffer.join(modelArtifacts.weightData);
            init.body.append("model.weights.bin", new Blob([weightBuffer], {
              type: OCTET_STREAM_MIME_TYPE
            }), "model.weights.bin");
          }
          const response = yield this.fetch(this.path, init);
          if (response.ok) {
            return {
              modelArtifactsInfo: getModelArtifactsInfoForJSON(modelArtifacts),
              responses: [response]
            };
          } else {
            throw new Error(`BrowserHTTPRequest.save() failed due to HTTP response status ${response.status}.`);
          }
        });
      }
      loadModelJSON() {
        return __async(this, null, function* () {
          const modelConfigRequest = yield this.fetch(this.path, this.requestInit);
          if (!modelConfigRequest.ok) {
            throw new Error(`Request to ${this.path} failed with status code ${modelConfigRequest.status}. Please verify this URL points to the model JSON of the model to load.`);
          }
          let modelJSON;
          try {
            modelJSON = yield modelConfigRequest.json();
          } catch (e) {
            let message = `Failed to parse model JSON of response from ${this.path}.`;
            if (this.path.endsWith(".pb")) {
              message += " Your path contains a .pb file extension. Support for .pb models have been removed in TensorFlow.js 1.0 in favor of .json models. You can re-convert your Python TensorFlow model using the TensorFlow.js 1.0 conversion scripts or you can convert your.pb models with the 'pb2json'NPM script in the tensorflow/tfjs-converter repository.";
            } else {
              message += " Please make sure the server is serving valid JSON for this request.";
            }
            throw new Error(message);
          }
          const modelTopology = modelJSON.modelTopology;
          const weightsManifest = modelJSON.weightsManifest;
          if (modelTopology == null && weightsManifest == null) {
            throw new Error(`The JSON from HTTP path ${this.path} contains neither model topology or manifest for weights.`);
          }
          return modelJSON;
        });
      }
      /**
       * Load model artifacts via HTTP request(s).
       *
       * See the documentation to `tf.io.http` for details on the saved
       * artifacts.
       *
       * @returns The loaded model artifacts (if loading succeeds).
       */
      load() {
        return __async(this, null, function* () {
          if (this.loadOptions.streamWeights) {
            return this.loadStream();
          }
          const modelJSON = yield this.loadModelJSON();
          return getModelArtifactsForJSON(modelJSON, (weightsManifest) => this.loadWeights(weightsManifest));
        });
      }
      loadStream() {
        return __async(this, null, function* () {
          const modelJSON = yield this.loadModelJSON();
          const fetchURLs = yield this.getWeightUrls(modelJSON.weightsManifest);
          const weightSpecs = getWeightSpecs(modelJSON.weightsManifest);
          const stream = () => streamWeights(fetchURLs, this.loadOptions);
          return Object.assign(Object.assign({}, modelJSON), {
            weightSpecs,
            getWeightStream: stream
          });
        });
      }
      getWeightUrls(weightsManifest) {
        return __async(this, null, function* () {
          const weightPath = Array.isArray(this.path) ? this.path[1] : this.path;
          const [prefix, suffix] = parseUrl(weightPath);
          const pathPrefix = this.weightPathPrefix || prefix;
          const fetchURLs = [];
          const urlPromises = [];
          for (const weightsGroup of weightsManifest) {
            for (const path of weightsGroup.paths) {
              if (this.weightUrlConverter != null) {
                urlPromises.push(this.weightUrlConverter(path));
              } else {
                fetchURLs.push(pathPrefix + path + suffix);
              }
            }
          }
          if (this.weightUrlConverter) {
            fetchURLs.push(...yield Promise.all(urlPromises));
          }
          return fetchURLs;
        });
      }
      loadWeights(weightsManifest) {
        return __async(this, null, function* () {
          const fetchURLs = yield this.getWeightUrls(weightsManifest);
          const weightSpecs = getWeightSpecs(weightsManifest);
          const buffers = yield loadWeightsAsArrayBuffer(fetchURLs, this.loadOptions);
          return [weightSpecs, buffers];
        });
      }
    };
    HTTPRequest.URL_SCHEME_REGEX = /^https?:\/\//;
    httpRouter = (url, loadOptions) => {
      if (typeof fetch === "undefined" && (loadOptions == null || loadOptions.fetchFunc == null)) {
        return null;
      } else {
        let isHTTP = true;
        if (Array.isArray(url)) {
          isHTTP = url.every((urlItem) => isHTTPScheme(urlItem));
        } else {
          isHTTP = isHTTPScheme(url);
        }
        if (isHTTP) {
          return http(url, loadOptions);
        }
      }
      return null;
    };
    IORouterRegistry.registerSaveRouter(httpRouter);
    IORouterRegistry.registerLoadRouter(httpRouter);
  }
});

// node_modules/@tensorflow/tfjs-core/dist/io/passthrough.js
function fromMemory(modelArtifacts, weightSpecs, weightData, trainingConfig) {
  const args = arguments;
  return new PassthroughAsync(fromMemorySync(...args));
}
function fromMemorySync(modelArtifacts, weightSpecs, weightData, trainingConfig) {
  if (arguments.length === 1) {
    const isModelArtifacts = modelArtifacts.modelTopology != null || modelArtifacts.weightSpecs != null;
    if (isModelArtifacts) {
      return new PassthroughLoader(modelArtifacts);
    } else {
      console.warn("Please call tf.io.fromMemory() with only one argument. The argument should be of type ModelArtifacts. The multi-argument signature of tf.io.fromMemory() has been deprecated and will be removed in a future release.");
      return new PassthroughLoader({
        modelTopology: modelArtifacts
      });
    }
  } else {
    console.warn("Please call tf.io.fromMemory() with only one argument. The argument should be of type ModelArtifacts. The multi-argument signature of tf.io.fromMemory() has been deprecated and will be removed in a future release.");
    return new PassthroughLoader({
      modelTopology: modelArtifacts,
      weightSpecs,
      weightData,
      trainingConfig
    });
  }
}
function withSaveHandler(saveHandler) {
  return new PassthroughSaver(saveHandler);
}
function withSaveHandlerSync(saveHandler) {
  return new PassthroughSaver(saveHandler);
}
var PassthroughLoader, PassthroughSaver, PassthroughAsync;
var init_passthrough = __esm({
  "node_modules/@tensorflow/tfjs-core/dist/io/passthrough.js"() {
    PassthroughLoader = class {
      constructor(modelArtifacts) {
        this.modelArtifacts = modelArtifacts;
      }
      load() {
        return this.modelArtifacts;
      }
    };
    PassthroughSaver = class {
      constructor(saveHandler) {
        this.saveHandler = saveHandler;
      }
      save(modelArtifacts) {
        return this.saveHandler(modelArtifacts);
      }
    };
    PassthroughAsync = class {
      constructor(handler) {
        if (handler.load) {
          this.load = () => Promise.resolve(handler.load());
        }
        if (handler.save) {
          this.save = (modelArtifacts) => Promise.resolve(handler.save(modelArtifacts));
        }
      }
    };
  }
});

// node_modules/@tensorflow/tfjs-core/dist/io/model_management.js
function parseURL(url) {
  if (url.indexOf(URL_SCHEME_SUFFIX) === -1) {
    throw new Error(`The url string provided does not contain a scheme. Supported schemes are: ${ModelStoreManagerRegistry.getSchemes().join(",")}`);
  }
  return {
    scheme: url.split(URL_SCHEME_SUFFIX)[0],
    path: url.split(URL_SCHEME_SUFFIX)[1]
  };
}
function cloneModelInternal(sourceURL, destURL, deleteSource = false) {
  return __async(this, null, function* () {
    assert(sourceURL !== destURL, () => `Old path and new path are the same: '${sourceURL}'`);
    const loadHandlers = IORouterRegistry.getLoadHandlers(sourceURL);
    assert(loadHandlers.length > 0, () => `Copying failed because no load handler is found for source URL ${sourceURL}.`);
    assert(loadHandlers.length < 2, () => `Copying failed because more than one (${loadHandlers.length}) load handlers for source URL ${sourceURL}.`);
    const loadHandler = loadHandlers[0];
    const saveHandlers = IORouterRegistry.getSaveHandlers(destURL);
    assert(saveHandlers.length > 0, () => `Copying failed because no save handler is found for destination URL ${destURL}.`);
    assert(saveHandlers.length < 2, () => `Copying failed because more than one (${loadHandlers.length}) save handlers for destination URL ${destURL}.`);
    const saveHandler = saveHandlers[0];
    const sourceScheme = parseURL(sourceURL).scheme;
    const sourcePath = parseURL(sourceURL).path;
    const sameMedium = sourceScheme === parseURL(sourceURL).scheme;
    const modelArtifacts = yield loadHandler.load();
    if (deleteSource && sameMedium) {
      yield ModelStoreManagerRegistry.getManager(sourceScheme).removeModel(sourcePath);
    }
    const saveResult = yield saveHandler.save(modelArtifacts);
    if (deleteSource && !sameMedium) {
      yield ModelStoreManagerRegistry.getManager(sourceScheme).removeModel(sourcePath);
    }
    return saveResult.modelArtifactsInfo;
  });
}
function listModels() {
  return __async(this, null, function* () {
    const schemes = ModelStoreManagerRegistry.getSchemes();
    const out = {};
    for (const scheme of schemes) {
      const schemeOut = yield ModelStoreManagerRegistry.getManager(scheme).listModels();
      for (const path in schemeOut) {
        const url = scheme + URL_SCHEME_SUFFIX + path;
        out[url] = schemeOut[path];
      }
    }
    return out;
  });
}
function removeModel(url) {
  return __async(this, null, function* () {
    const schemeAndPath = parseURL(url);
    const manager = ModelStoreManagerRegistry.getManager(schemeAndPath.scheme);
    return manager.removeModel(schemeAndPath.path);
  });
}
function copyModel(sourceURL, destURL) {
  return __async(this, null, function* () {
    const deleteSource = false;
    return cloneModelInternal(sourceURL, destURL, deleteSource);
  });
}
function moveModel(sourceURL, destURL) {
  return __async(this, null, function* () {
    const deleteSource = true;
    return cloneModelInternal(sourceURL, destURL, deleteSource);
  });
}
var URL_SCHEME_SUFFIX, ModelStoreManagerRegistry;
var init_model_management = __esm({
  "node_modules/@tensorflow/tfjs-core/dist/io/model_management.js"() {
    init_util();
    init_router_registry();
    URL_SCHEME_SUFFIX = "://";
    ModelStoreManagerRegistry = class _ModelStoreManagerRegistry {
      constructor() {
        this.managers = {};
      }
      static getInstance() {
        if (_ModelStoreManagerRegistry.instance == null) {
          _ModelStoreManagerRegistry.instance = new _ModelStoreManagerRegistry();
        }
        return _ModelStoreManagerRegistry.instance;
      }
      /**
       * Register a save-handler router.
       *
       * @param saveRouter A function that maps a URL-like string onto an instance
       * of `IOHandler` with the `save` method defined or `null`.
       */
      static registerManager(scheme, manager) {
        assert(scheme != null, () => "scheme must not be undefined or null.");
        if (scheme.endsWith(URL_SCHEME_SUFFIX)) {
          scheme = scheme.slice(0, scheme.indexOf(URL_SCHEME_SUFFIX));
        }
        assert(scheme.length > 0, () => "scheme must not be an empty string.");
        const registry = _ModelStoreManagerRegistry.getInstance();
        assert(registry.managers[scheme] == null, () => `A model store manager is already registered for scheme '${scheme}'.`);
        registry.managers[scheme] = manager;
      }
      static getManager(scheme) {
        const manager = _ModelStoreManagerRegistry.getInstance().managers[scheme];
        if (manager == null) {
          throw new Error(`Cannot find model manager for scheme '${scheme}'`);
        }
        return manager;
      }
      static getSchemes() {
        return Object.keys(_ModelStoreManagerRegistry.getInstance().managers);
      }
    };
  }
});

// node_modules/@tensorflow/tfjs-core/dist/io/io.js
var io_exports = {};
__export(io_exports, {
  CompositeArrayBuffer: () => CompositeArrayBuffer,
  browserFiles: () => browserFiles,
  browserHTTPRequest: () => browserHTTPRequest,
  concatenateArrayBuffers: () => concatenateArrayBuffers,
  copyModel: () => copyModel,
  decodeWeights: () => decodeWeights,
  decodeWeightsStream: () => decodeWeightsStream,
  encodeWeights: () => encodeWeights,
  fromMemory: () => fromMemory,
  fromMemorySync: () => fromMemorySync,
  getLoadHandlers: () => getLoadHandlers,
  getModelArtifactsForJSON: () => getModelArtifactsForJSON,
  getModelArtifactsForJSONSync: () => getModelArtifactsForJSONSync,
  getModelArtifactsInfoForJSON: () => getModelArtifactsInfoForJSON,
  getSaveHandlers: () => getSaveHandlers,
  getWeightSpecs: () => getWeightSpecs,
  http: () => http,
  isHTTPScheme: () => isHTTPScheme,
  listModels: () => listModels,
  loadWeights: () => loadWeights,
  moveModel: () => moveModel,
  registerLoadRouter: () => registerLoadRouter,
  registerSaveRouter: () => registerSaveRouter,
  removeModel: () => removeModel,
  weightsLoaderFactory: () => weightsLoaderFactory,
  withSaveHandler: () => withSaveHandler,
  withSaveHandlerSync: () => withSaveHandlerSync
});
var init_io = __esm({
  "node_modules/@tensorflow/tfjs-core/dist/io/io.js"() {
    init_indexed_db();
    init_local_storage();
    init_browser_files();
    init_http();
    init_io_utils();
    init_passthrough();
    init_router_registry();
    init_weights_loader();
    init_composite_array_buffer();
    init_model_management();
  }
});

// node_modules/@tensorflow/tfjs-core/dist/ops/confusion_matrix.js
function confusionMatrix_(labels, predictions, numClasses) {
  const $labels = convertToTensor(labels, "labels", "confusionMatrix");
  const $predictions = convertToTensor(predictions, "predictions", "confusionMatrix");
  assert(numClasses == null || numClasses > 0 && Number.isInteger(numClasses), () => `If provided, numClasses must be a positive integer, but got ${numClasses}`);
  assert($labels.rank === 1, () => `Expected the rank of labels to be 1, but got ${$labels.rank}`);
  assert($predictions.rank === 1, () => `Expected the rank of predictions to be 1, but got ${$predictions.rank}`);
  assert($labels.shape[0] === $predictions.shape[0], () => `Mismatch in the number of examples: ${$labels.shape[0]} vs. ${$predictions.shape[0]}. Labels and predictions should have the same number of elements.`);
  assert(numClasses > 0 && Number.isInteger(numClasses), () => `numClasses is required to be a positive integer, but got ${numClasses}`);
  const oneHotLabels = oneHot(cast($labels, "int32"), numClasses);
  const oneHotPredictions = oneHot(cast($predictions, "int32"), numClasses);
  const oneHotLabelsT = transpose(oneHotLabels);
  const product = matMul(oneHotLabelsT, oneHotPredictions);
  return cast(product, "int32");
}
var confusionMatrix;
var init_confusion_matrix = __esm({
  "node_modules/@tensorflow/tfjs-core/dist/ops/confusion_matrix.js"() {
    init_tensor_util_env();
    init_util();
    init_cast();
    init_mat_mul();
    init_one_hot();
    init_operation();
    init_transpose();
    confusionMatrix = op({
      confusionMatrix_
    });
  }
});

// node_modules/@tensorflow/tfjs-core/dist/math.js
var math_exports = {};
__export(math_exports, {
  confusionMatrix: () => confusionMatrix
});
var init_math = __esm({
  "node_modules/@tensorflow/tfjs-core/dist/math.js"() {
    init_confusion_matrix();
  }
});

// node_modules/@tensorflow/tfjs-core/dist/ops/browser.js
var browser_exports = {};
__export(browser_exports, {
  draw: () => draw,
  fromPixels: () => fromPixels,
  fromPixelsAsync: () => fromPixelsAsync,
  toPixels: () => toPixels
});
function fromPixels_(pixels, numChannels = 3) {
  if (numChannels > 4) {
    throw new Error("Cannot construct Tensor with more than 4 channels from pixels.");
  }
  if (pixels == null) {
    throw new Error("pixels passed to tf.browser.fromPixels() can not be null");
  }
  let isPixelData2 = false;
  let isImageData = false;
  let isVideo = false;
  let isImage = false;
  let isCanvasLike = false;
  let isImageBitmap = false;
  if (pixels.data instanceof Uint8Array) {
    isPixelData2 = true;
  } else if (typeof ImageData !== "undefined" && pixels instanceof ImageData) {
    isImageData = true;
  } else if (typeof HTMLVideoElement !== "undefined" && pixels instanceof HTMLVideoElement) {
    isVideo = true;
  } else if (typeof HTMLImageElement !== "undefined" && pixels instanceof HTMLImageElement) {
    isImage = true;
  } else if (pixels.getContext != null) {
    isCanvasLike = true;
  } else if (typeof ImageBitmap !== "undefined" && pixels instanceof ImageBitmap) {
    isImageBitmap = true;
  } else {
    throw new Error(`pixels passed to tf.browser.fromPixels() must be either an HTMLVideoElement, HTMLImageElement, HTMLCanvasElement, ImageData in browser, or OffscreenCanvas, ImageData in webworker or {data: Uint32Array, width: number, height: number}, but was ${pixels.constructor.name}`);
  }
  const kernel = getKernel(FromPixels, ENGINE.backendName);
  if (kernel != null) {
    const inputs = {
      pixels
    };
    const attrs = {
      numChannels
    };
    return ENGINE.runKernel(FromPixels, inputs, attrs);
  }
  const [width, height] = isVideo ? [pixels.videoWidth, pixels.videoHeight] : [pixels.width, pixels.height];
  let vals;
  if (isCanvasLike) {
    vals = // tslint:disable-next-line:no-any
    pixels.getContext("2d").getImageData(0, 0, width, height).data;
  } else if (isImageData || isPixelData2) {
    vals = pixels.data;
  } else if (isImage || isVideo || isImageBitmap) {
    if (fromPixels2DContext == null) {
      if (typeof document === "undefined") {
        if (typeof OffscreenCanvas !== "undefined" && typeof OffscreenCanvasRenderingContext2D !== "undefined") {
          fromPixels2DContext = new OffscreenCanvas(1, 1).getContext("2d");
        } else {
          throw new Error("Cannot parse input in current context. Reason: OffscreenCanvas Context2D rendering is not supported.");
        }
      } else {
        fromPixels2DContext = document.createElement("canvas").getContext("2d", {
          willReadFrequently: true
        });
      }
    }
    fromPixels2DContext.canvas.width = width;
    fromPixels2DContext.canvas.height = height;
    fromPixels2DContext.drawImage(pixels, 0, 0, width, height);
    vals = fromPixels2DContext.getImageData(0, 0, width, height).data;
  }
  let values;
  if (numChannels === 4) {
    values = new Int32Array(vals);
  } else {
    const numPixels = width * height;
    values = new Int32Array(numPixels * numChannels);
    for (let i = 0; i < numPixels; i++) {
      for (let channel = 0; channel < numChannels; ++channel) {
        values[i * numChannels + channel] = vals[i * 4 + channel];
      }
    }
  }
  const outShape = [height, width, numChannels];
  return tensor3d(values, outShape, "int32");
}
function isPixelData(pixels) {
  return pixels != null && pixels.data instanceof Uint8Array;
}
function isImageBitmapFullySupported() {
  return typeof window !== "undefined" && typeof ImageBitmap !== "undefined" && window.hasOwnProperty("createImageBitmap");
}
function isNonEmptyPixels(pixels) {
  return pixels != null && pixels.width !== 0 && pixels.height !== 0;
}
function canWrapPixelsToImageBitmap(pixels) {
  return isImageBitmapFullySupported() && !(pixels instanceof ImageBitmap) && isNonEmptyPixels(pixels) && !isPixelData(pixels);
}
function fromPixelsAsync(pixels, numChannels = 3) {
  return __async(this, null, function* () {
    let inputs = null;
    if (env().getBool("WRAP_TO_IMAGEBITMAP") && canWrapPixelsToImageBitmap(pixels)) {
      let imageBitmap;
      try {
        imageBitmap = yield createImageBitmap(pixels, {
          premultiplyAlpha: "none"
        });
      } catch (e) {
        imageBitmap = null;
      }
      if (imageBitmap != null && imageBitmap.width === pixels.width && imageBitmap.height === pixels.height) {
        inputs = imageBitmap;
      } else {
        inputs = pixels;
      }
    } else {
      inputs = pixels;
    }
    return fromPixels_(inputs, numChannels);
  });
}
function validateImgTensor(img) {
  if (img.rank !== 2 && img.rank !== 3) {
    throw new Error(`toPixels only supports rank 2 or 3 tensors, got rank ${img.rank}.`);
  }
  const depth = img.rank === 2 ? 1 : img.shape[2];
  if (depth > 4 || depth === 2) {
    throw new Error(`toPixels only supports depth of size 1, 3 or 4 but got ${depth}`);
  }
  if (img.dtype !== "float32" && img.dtype !== "int32") {
    throw new Error(`Unsupported type for toPixels: ${img.dtype}. Please use float32 or int32 tensors.`);
  }
}
function validateImageOptions(imageOptions) {
  const alpha = (imageOptions === null || imageOptions === void 0 ? void 0 : imageOptions.alpha) || 1;
  if (alpha > 1 || alpha < 0) {
    throw new Error(`Alpha value ${alpha} is suppoed to be in range [0 - 1].`);
  }
}
function toPixels(img, canvas) {
  return __async(this, null, function* () {
    let $img = convertToTensor(img, "img", "toPixels");
    if (!(img instanceof Tensor)) {
      const originalImgTensor = $img;
      $img = cast(originalImgTensor, "int32");
      originalImgTensor.dispose();
    }
    validateImgTensor($img);
    const [height, width] = $img.shape.slice(0, 2);
    const depth = $img.rank === 2 ? 1 : $img.shape[2];
    const data = yield $img.data();
    const multiplier = $img.dtype === "float32" ? 255 : 1;
    const bytes = new Uint8ClampedArray(width * height * 4);
    for (let i = 0; i < height * width; ++i) {
      const rgba = [0, 0, 0, 255];
      for (let d = 0; d < depth; d++) {
        const value = data[i * depth + d];
        if ($img.dtype === "float32") {
          if (value < 0 || value > 1) {
            throw new Error(`Tensor values for a float32 Tensor must be in the range [0 - 1] but encountered ${value}.`);
          }
        } else if ($img.dtype === "int32") {
          if (value < 0 || value > 255) {
            throw new Error(`Tensor values for a int32 Tensor must be in the range [0 - 255] but encountered ${value}.`);
          }
        }
        if (depth === 1) {
          rgba[0] = value * multiplier;
          rgba[1] = value * multiplier;
          rgba[2] = value * multiplier;
        } else {
          rgba[d] = value * multiplier;
        }
      }
      const j = i * 4;
      bytes[j + 0] = Math.round(rgba[0]);
      bytes[j + 1] = Math.round(rgba[1]);
      bytes[j + 2] = Math.round(rgba[2]);
      bytes[j + 3] = Math.round(rgba[3]);
    }
    if (canvas != null) {
      if (!hasToPixelsWarned) {
        const kernel = getKernel(Draw, ENGINE.backendName);
        if (kernel != null) {
          console.warn("tf.browser.toPixels is not efficient to draw tensor on canvas. Please try tf.browser.draw instead.");
          hasToPixelsWarned = true;
        }
      }
      canvas.width = width;
      canvas.height = height;
      const ctx = canvas.getContext("2d");
      const imageData = new ImageData(bytes, width, height);
      ctx.putImageData(imageData, 0, 0);
    }
    if ($img !== img) {
      $img.dispose();
    }
    return bytes;
  });
}
function draw(image2, canvas, options) {
  let $img = convertToTensor(image2, "img", "draw");
  if (!(image2 instanceof Tensor)) {
    const originalImgTensor = $img;
    $img = cast(originalImgTensor, "int32");
    originalImgTensor.dispose();
  }
  validateImgTensor($img);
  validateImageOptions(options === null || options === void 0 ? void 0 : options.imageOptions);
  const inputs = {
    image: $img
  };
  const attrs = {
    canvas,
    options
  };
  ENGINE.runKernel(Draw, inputs, attrs);
}
var fromPixels2DContext, hasToPixelsWarned, fromPixels;
var init_browser = __esm({
  "node_modules/@tensorflow/tfjs-core/dist/ops/browser.js"() {
    init_engine();
    init_environment();
    init_kernel_names();
    init_kernel_registry();
    init_tensor();
    init_tensor_util_env();
    init_cast();
    init_operation();
    init_tensor3d();
    hasToPixelsWarned = false;
    fromPixels = op({
      fromPixels_
    });
  }
});

// node_modules/@tensorflow/tfjs-core/dist/ops/gather_nd_util.js
var gather_nd_util_exports = {};
__export(gather_nd_util_exports, {
  prepareAndValidate: () => prepareAndValidate
});
function prepareAndValidate(tensor2, indices) {
  const tensorRank = tensor2.shape.length;
  const indicesRank = indices.shape.length;
  if (tensorRank < 1) {
    throw new Error(`tf.gatherND() expects the input to be rank 1 or higher, but the rank was ${tensorRank}.`);
  }
  if (indicesRank < 1) {
    throw new Error(`tf.gatherND() expects the indices to be rank 1 or higher, but the rank was ${indicesRank}.`);
  }
  if (indices.dtype !== "int32") {
    throw new Error(`tf.gatherND() expects the indices to be int32 type, but the dtype was ${indices.dtype}.`);
  }
  if (indices.shape[indicesRank - 1] > tensorRank) {
    throw new Error(`index innermost dimension length must be <= tensor rank; saw: ${indices.shape[indicesRank - 1]} vs. ${tensorRank}`);
  }
  if (sizeFromShape(tensor2.shape) === 0) {
    throw new Error(`Requested more than 0 entries, but input is empty. Input shape: ${tensor2.shape}.`);
  }
  const indicesShape = indices.shape;
  const sliceRank = indicesShape[indicesShape.length - 1];
  let nResult = 1;
  for (let i = 0; i < indicesShape.length - 1; ++i) {
    nResult *= indicesShape[i];
  }
  const inputShape = tensor2.shape;
  const resultShape = indicesShape.slice();
  resultShape.pop();
  let sliceSize = 1;
  for (let i = sliceRank; i < tensorRank; ++i) {
    sliceSize *= inputShape[i];
    resultShape.push(inputShape[i]);
  }
  const strides = [...computeStrides(tensor2.shape).map((stride) => stride / sliceSize), 1].slice(0, sliceRank);
  return [resultShape, nResult, sliceSize, strides];
}
var init_gather_nd_util = __esm({
  "node_modules/@tensorflow/tfjs-core/dist/ops/gather_nd_util.js"() {
    init_util();
  }
});

// node_modules/@tensorflow/tfjs-core/dist/ops/slice_util.js
var slice_util_exports = {};
__export(slice_util_exports, {
  assertParamsValid: () => assertParamsValid,
  computeFlatOffset: () => computeFlatOffset,
  computeOutShape: () => computeOutShape,
  getNormalizedAxes: () => getNormalizedAxes,
  isSliceContinous: () => isSliceContinous,
  maskToAxes: () => maskToAxes,
  parseSliceParams: () => parseSliceParams,
  sliceInfo: () => sliceInfo,
  startForAxis: () => startForAxis,
  startIndicesWithElidedDims: () => startIndicesWithElidedDims,
  stopForAxis: () => stopForAxis,
  stopIndicesWithElidedDims: () => stopIndicesWithElidedDims,
  stridesForAxis: () => stridesForAxis,
  stridesWithElidedDims: () => stridesWithElidedDims
});
function assertParamsValid(input, begin, size) {
  const inputRank = input.shape.length;
  assert(inputRank === begin.length, () => `Error in slice${inputRank}D: Length of begin ${begin} must match the rank of the array (${inputRank}).`);
  assert(inputRank === size.length, () => `Error in slice${inputRank}D: Length of size ${size} must match the rank of the array (${inputRank}).`);
  for (let i = 0; i < inputRank; ++i) {
    assert(begin[i] + size[i] <= input.shape[i], () => `Error in slice${inputRank}D: begin[${i}] + size[${i}] (${begin[i] + size[i]}) would overflow input.shape[${i}] (${input.shape[i]})`);
  }
}
function maskToAxes(mask) {
  const axes = [];
  let axis = 0;
  while (mask > 0) {
    if (mask & 1) {
      axes.push(axis);
    }
    mask /= 2;
    axis++;
  }
  return axes;
}
function computeOutShape(begin, end, strides) {
  const size = [];
  for (let axis = 0; axis < begin.length; axis++) {
    size[axis] = Math.ceil((end[axis] - begin[axis]) / strides[axis]);
  }
  return size;
}
function stridesWithElidedDims(strides, ellipsisInsertionIndex, numElidedAxes, inputShape) {
  const newStrides = [...strides];
  for (let i = newStrides.length; i < inputShape.length; i++) {
    newStrides.push(1);
  }
  for (let i = 0; i < numElidedAxes; i++) {
    if (i === 0) {
      newStrides[ellipsisInsertionIndex] = 1;
    } else {
      newStrides.splice(
        ellipsisInsertionIndex,
        0,
        1
        /* element to add */
      );
      newStrides.pop();
    }
  }
  return newStrides;
}
function unnormalizeAxis(ellipsisInsertionIndex, numElidedAxes, normalizedAxis) {
  if (normalizedAxis <= ellipsisInsertionIndex) {
    return normalizedAxis;
  }
  return normalizedAxis - (numElidedAxes - 1);
}
function getElidedAxes(numElidedAxes, ellipsisInsertionIndex) {
  const elidedAxes = [];
  for (let i = 0; i < numElidedAxes; i++) {
    elidedAxes.push(ellipsisInsertionIndex + i);
  }
  return elidedAxes;
}
function getNormalizedAxes(inputShape, ellipsisAxes, numInterpolatedAxes, begin, end, strides, beginMask, endMask, ellipsisMask) {
  const inputRank = inputShape.length;
  let normalizedBegin = new Array(inputRank), normalizedEnd = new Array(inputRank), normalizedStrides = new Array(inputRank);
  if (ellipsisAxes.length && numInterpolatedAxes > 0) {
    const fullIndex = ellipsisAxes[0];
    const numElidedAxes = numInterpolatedAxes + 1;
    normalizedBegin = startIndicesWithElidedDims(beginMask, fullIndex, numElidedAxes, begin, inputShape);
    normalizedEnd = stopIndicesWithElidedDims(endMask, fullIndex, numElidedAxes, end, inputShape);
    normalizedStrides = stridesWithElidedDims(strides, fullIndex, numElidedAxes, inputShape);
  } else {
    for (let axis = 0; axis < inputRank; axis++) {
      normalizedBegin[axis] = startForAxis(beginMask, begin, strides, inputShape, axis, ellipsisMask);
      normalizedEnd[axis] = stopForAxis(endMask, end, strides, inputShape, axis, ellipsisMask);
      normalizedStrides[axis] = stridesForAxis(strides, axis, ellipsisMask);
    }
  }
  return {
    begin: normalizedBegin,
    end: normalizedEnd,
    strides: normalizedStrides
  };
}
function startIndicesWithElidedDims(beginMask, ellipsisInsertionIndex, numElidedAxes, originalBegin, inputShape) {
  const newIndices = [...inputShape];
  const elidedAxes = getElidedAxes(numElidedAxes, ellipsisInsertionIndex);
  for (let axis = 0; axis < newIndices.length; axis++) {
    if (elidedAxes.indexOf(axis) > -1) {
      newIndices[axis] = 0;
    } else {
      const originalAxis = unnormalizeAxis(ellipsisInsertionIndex, numElidedAxes, axis);
      let originalValue = originalBegin[originalAxis];
      if (beginMask & 1 << originalAxis) {
        originalValue = 0;
      }
      newIndices[axis] = originalValue;
    }
  }
  return newIndices;
}
function stopIndicesWithElidedDims(endMask, ellipsisInsertionIndex, numElidedAxes, originalEnd, inputShape) {
  const newIndices = [...inputShape];
  const elidedAxes = getElidedAxes(numElidedAxes, ellipsisInsertionIndex);
  for (let axis = 0; axis < newIndices.length; axis++) {
    if (elidedAxes.indexOf(axis) > -1) {
      newIndices[axis] = Number.MAX_SAFE_INTEGER;
    } else {
      const originalAxis = unnormalizeAxis(ellipsisInsertionIndex, numElidedAxes, axis);
      let originalValue = originalEnd[originalAxis];
      if (endMask & 1 << originalAxis) {
        originalValue = Number.MAX_SAFE_INTEGER;
      }
      newIndices[axis] = originalValue;
    }
  }
  for (let i = 0; i < newIndices.length; i++) {
    const axisSize = inputShape[i];
    if (newIndices[i] < 0) {
      newIndices[i] += axisSize;
    }
    newIndices[i] = clamp(0, newIndices[i], inputShape[i]);
  }
  return newIndices;
}
function stridesForAxis(strides, axis, ellipsisMask) {
  let stride = strides[axis];
  if (ellipsisMask & 1 << axis || stride == null) {
    stride = 1;
  }
  return stride;
}
function startForAxis(beginMask, startIndices, strides, inputShape, axis, ellipsisMask) {
  let start = startIndices[axis];
  const stride = strides[axis] || 1;
  if (beginMask & 1 << axis || ellipsisMask & 1 << axis || start == null) {
    if (stride > 0) {
      start = Number.MIN_SAFE_INTEGER;
    } else {
      start = Number.MAX_SAFE_INTEGER;
    }
  }
  const axisSize = inputShape[axis];
  if (start < 0) {
    start += axisSize;
  }
  start = clamp(0, start, axisSize - 1);
  return start;
}
function stopForAxis(endMask, stopIndices, strides, inputShape, axis, ellipsisMask) {
  let stop = stopIndices[axis];
  const stride = strides[axis] || 1;
  if (endMask & 1 << axis || ellipsisMask & 1 << axis || stop == null) {
    if (stride > 0) {
      stop = Number.MAX_SAFE_INTEGER;
    } else {
      stop = Number.MIN_SAFE_INTEGER;
    }
  }
  const axisSize = inputShape[axis];
  if (stop < 0) {
    stop += axisSize;
  }
  if (stride > 0) {
    stop = clamp(0, stop, axisSize);
  } else {
    stop = clamp(-1, stop, axisSize - 1);
  }
  return stop;
}
function isSliceContinous(shape, begin, size) {
  let firstNonOneAxis = size.length;
  for (let i = 0; i < size.length; i++) {
    if (size[i] > 1) {
      firstNonOneAxis = i;
      break;
    }
  }
  for (let i = firstNonOneAxis + 1; i < size.length; i++) {
    if (begin[i] > 0 || size[i] !== shape[i]) {
      return false;
    }
  }
  return true;
}
function computeFlatOffset(begin, strides) {
  let flatOffset = begin.length > 0 ? begin[begin.length - 1] : 1;
  for (let i = 0; i < begin.length - 1; i++) {
    flatOffset += begin[i] * strides[i];
  }
  return flatOffset;
}
function parseSliceParams(x, begin, size) {
  let begin_;
  const xRank = x.shape.length;
  if (typeof begin === "number") {
    begin_ = [begin, ...new Array(xRank - 1).fill(0)];
  } else if (begin.length < xRank) {
    begin_ = begin.concat(new Array(xRank - begin.length).fill(0));
  } else {
    begin_ = begin.slice();
  }
  begin_.forEach((d) => {
    assert(d !== -1, () => "slice() does not support negative begin indexing.");
  });
  let size_;
  if (size == null) {
    size_ = new Array(xRank).fill(-1);
  } else if (typeof size === "number") {
    size_ = [size, ...new Array(xRank - 1).fill(-1)];
  } else if (size.length < xRank) {
    size_ = size.concat(new Array(xRank - size.length).fill(-1));
  } else {
    size_ = size;
  }
  size_ = size_.map((d, i) => {
    if (d >= 0) {
      return d;
    } else {
      assert(d === -1, () => `Negative size values should be exactly -1 but got ${d} for the slice() size at index ${i}.`);
      return x.shape[i] - begin_[i];
    }
  });
  return [begin_, size_];
}
function sliceInfo(xShape, begin, end, strides, beginMask, endMask, ellipsisMask, newAxisMask, shrinkAxisMask) {
  let stridesNonNull;
  if (strides == null) {
    stridesNonNull = new Array(begin.length);
    stridesNonNull.fill(1);
  } else {
    stridesNonNull = strides;
  }
  if (ellipsisMask != null && (ellipsisMask & ellipsisMask - 1) !== 0) {
    throw new Error("Multiple ellipses in slice is not allowed.");
  }
  let ellipsisSeen = false;
  const sparseSpec = {
    dims: stridesNonNull.length,
    numAddAxisAfterEllipsis: 0,
    begin: begin.slice(),
    end: end.slice(),
    strides: stridesNonNull.slice(),
    beginMask,
    endMask,
    ellipsisMask,
    newAxisMask,
    shrinkAxisMask
  };
  for (let i = 0; i < sparseSpec.dims; i++) {
    if (ellipsisSeen && (1 << i & newAxisMask) !== 0) {
      sparseSpec.numAddAxisAfterEllipsis++;
    }
    if (1 << i & ellipsisMask) {
      ellipsisSeen = true;
    }
  }
  if (!ellipsisSeen) {
    sparseSpec.ellipsisMask |= 1 << sparseSpec.dims;
    sparseSpec.dims++;
  }
  const denseSpec = {
    dims: xShape.length,
    beginMask: 0,
    endMask: 0,
    beginValid: false,
    endValid: false
  };
  buildDenseSpec(sparseSpec, denseSpec);
  let isIdentity = true;
  let sliceDim0 = true;
  let isSimpleSlice = true;
  const processingShape = [];
  const finalShape = [];
  for (let i = 0; i < xShape.length; ++i) {
    if (denseSpec.strides[i] === 0) {
      throw Error(`strides[${i}] must be non-zero`);
    }
    const shrinkI = !!(denseSpec.shrinkAxisMask & 1 << i);
    const dimI = xShape[i];
    if (dimI === -1) {
      processingShape.push(shrinkI ? 1 : -1);
      continue;
    }
    const masks = [denseSpec.beginMask & 1 << i, denseSpec.endMask & 1 << i];
    const validRange = [denseSpec.strides[i] > 0 ? 0 : -1, denseSpec.strides[i] > 0 ? dimI : dimI - 1];
    if (shrinkI && denseSpec.strides[i] <= 0) {
      throw Error("only stride 1 allowed on non-range indexing.");
    }
    isSimpleSlice = isSimpleSlice && denseSpec.strides[i] === 1;
    const beginAndEndMasked = !!(denseSpec.beginMask & 1 << i && denseSpec.endMask & 1 << i);
    if (denseSpec.beginValid && denseSpec.endValid) {
      if (shrinkI) {
        const xFwd = denseSpec.begin[i] < 0 ? dimI + denseSpec.begin[i] : denseSpec.begin[i];
        denseSpec.begin[i] = xFwd;
        denseSpec.end[i] = denseSpec.begin[i] + 1;
        if (xFwd < 0 || xFwd >= dimI) {
          throw Error(`slice index ${denseSpec.begin[i]} of dimension ${i} out of bounds.`);
        }
      } else {
        denseSpec.begin[i] = canonical(denseSpec.begin[i], 0, denseSpec.strides[i], dimI, masks, validRange);
        denseSpec.end[i] = canonical(denseSpec.end[i], 1, denseSpec.strides[i], dimI, masks, validRange);
      }
      const takeAllInDimension = denseSpec.strides[i] === 1 && denseSpec.begin[i] === 0 && denseSpec.end[i] === dimI;
      isIdentity = isIdentity && takeAllInDimension;
      sliceDim0 = sliceDim0 && (i === 0 && denseSpec.strides[i] === 1 || takeAllInDimension);
    } else {
      isIdentity = isIdentity && denseSpec.strides[i] === 1 && beginAndEndMasked;
      sliceDim0 = sliceDim0 && (i === 0 && denseSpec.strides[i] === 1 || beginAndEndMasked);
    }
    let intervalLength;
    let knownInterval = false;
    if (denseSpec.beginValid && denseSpec.endValid) {
      intervalLength = denseSpec.end[i] - denseSpec.begin[i];
      knownInterval = true;
    } else if (shrinkI) {
      intervalLength = 1;
      knownInterval = true;
    } else if (beginAndEndMasked) {
      if (dimI >= 0) {
        if (denseSpec.strides[i] < 0) {
          intervalLength = -dimI;
        } else {
          intervalLength = dimI;
        }
        knownInterval = true;
      }
    }
    if (knownInterval) {
      let sizeI;
      if (intervalLength === 0 || intervalLength < 0 !== denseSpec.strides[i] < 0) {
        sizeI = 0;
      } else {
        sizeI = Math.trunc(intervalLength / denseSpec.strides[i]) + (intervalLength % denseSpec.strides[i] !== 0 ? 1 : 0);
      }
      processingShape.push(sizeI);
    } else {
      processingShape.push(-1);
    }
  }
  for (let denseDim = 0; denseDim < denseSpec.finalShapeGatherIndices.length; ++denseDim) {
    const gatherIndex = denseSpec.finalShapeGatherIndices[denseDim];
    if (gatherIndex >= 0) {
      finalShape.push(processingShape[gatherIndex]);
    } else if (gatherIndex === NEW_AXIS) {
      finalShape.push(1);
    }
  }
  const finalShapeSparse = finalShape.filter((dim, i) => denseSpec.finalShapeGatherIndices[i] !== NEW_AXIS);
  return {
    finalShapeSparse,
    finalShape,
    isIdentity,
    sliceDim0,
    isSimpleSlice,
    begin: denseSpec.begin,
    end: denseSpec.end,
    strides: denseSpec.strides
  };
}
function buildDenseSpec(sparse2, dense) {
  dense.beginMask = 0;
  dense.endMask = 0;
  dense.shrinkAxisMask = 0;
  let fullIndex = 0;
  dense.beginValid = sparse2.begin != null;
  dense.endValid = sparse2.end != null;
  dense.begin = new Array(dense.dims);
  dense.end = new Array(dense.dims);
  dense.strides = new Array(dense.dims);
  dense.finalShapeGatherIndices = [];
  dense.finalShapeGatherIndicesSparse = [];
  dense.inputShapeGatherIndicesSparse = new Array(dense.dims);
  for (let i = 0; i < sparse2.dims; i++) {
    if (1 << i & sparse2.ellipsisMask) {
      const nextIndex = Math.min(dense.dims - (sparse2.dims - i) + 1 + sparse2.numAddAxisAfterEllipsis, dense.dims);
      for (; fullIndex < nextIndex; fullIndex++) {
        dense.begin[fullIndex] = 0;
        dense.end[fullIndex] = 0;
        dense.strides[fullIndex] = 1;
        dense.beginMask |= 1 << fullIndex;
        dense.endMask |= 1 << fullIndex;
        dense.finalShapeGatherIndices.push(fullIndex);
        dense.finalShapeGatherIndicesSparse.push(-1);
        dense.inputShapeGatherIndicesSparse[fullIndex] = i;
      }
    } else if (1 << i & sparse2.newAxisMask) {
      dense.finalShapeGatherIndices.push(NEW_AXIS);
      dense.finalShapeGatherIndicesSparse.push(-1);
    } else {
      if (fullIndex === dense.begin.length) {
        throw Error(`Index out of range using input dim ${fullIndex}; input has only ${dense.dims} dims, ${dense.begin.length}.`);
      }
      if (sparse2.begin != null) {
        dense.begin[fullIndex] = sparse2.begin[i];
      }
      if (sparse2.end != null) {
        dense.end[fullIndex] = sparse2.end[i];
      }
      dense.strides[fullIndex] = sparse2.strides[i];
      if (sparse2.beginMask & 1 << i) {
        dense.beginMask |= 1 << fullIndex;
      }
      if (sparse2.endMask & 1 << i) {
        dense.endMask |= 1 << fullIndex;
      }
      if (sparse2.shrinkAxisMask & 1 << i) {
        dense.finalShapeGatherIndices.push(SHRINK_AXIS);
        dense.finalShapeGatherIndicesSparse.push(-1);
        dense.shrinkAxisMask |= 1 << fullIndex;
      } else {
        dense.finalShapeGatherIndices.push(fullIndex);
        dense.finalShapeGatherIndicesSparse.push(i);
      }
      dense.inputShapeGatherIndicesSparse[fullIndex] = i;
      fullIndex++;
    }
  }
}
function canonical(x, c, strideI, dimI, masks, validRange) {
  if (masks[c]) {
    return strideI > 0 ? validRange[c] : validRange[c + 1 & 1];
  } else {
    const xFwd = x < 0 ? dimI + x : x;
    return xFwd < validRange[0] ? validRange[0] : xFwd > validRange[1] ? validRange[1] : xFwd;
  }
}
var NEW_AXIS, SHRINK_AXIS;
var init_slice_util = __esm({
  "node_modules/@tensorflow/tfjs-core/dist/ops/slice_util.js"() {
    init_util();
    NEW_AXIS = -2;
    SHRINK_AXIS = -1;
  }
});

// node_modules/@tensorflow/tfjs-core/dist/version.js
var version;
var init_version = __esm({
  "node_modules/@tensorflow/tfjs-core/dist/version.js"() {
    version = "4.22.0";
  }
});

// node_modules/@tensorflow/tfjs-core/dist/optimizers/optimizer_constructors.js
var OptimizerConstructors;
var init_optimizer_constructors = __esm({
  "node_modules/@tensorflow/tfjs-core/dist/optimizers/optimizer_constructors.js"() {
    init_adadelta_optimizer();
    init_adagrad_optimizer();
    init_adam_optimizer();
    init_adamax_optimizer();
    init_momentum_optimizer();
    init_rmsprop_optimizer();
    init_sgd_optimizer();
    OptimizerConstructors = class {
      /**
       * Constructs a `tf.SGDOptimizer` that uses stochastic gradient descent.
       *
       * ```js
       * // Fit a quadratic function by learning the coefficients a, b, c.
       * const xs = tf.tensor1d([0, 1, 2, 3]);
       * const ys = tf.tensor1d([1.1, 5.9, 16.8, 33.9]);
       *
       * const a = tf.scalar(Math.random()).variable();
       * const b = tf.scalar(Math.random()).variable();
       * const c = tf.scalar(Math.random()).variable();
       *
       * // y = a * x^2 + b * x + c.
       * const f = x => a.mul(x.square()).add(b.mul(x)).add(c);
       * const loss = (pred, label) => pred.sub(label).square().mean();
       *
       * const learningRate = 0.01;
       * const optimizer = tf.train.sgd(learningRate);
       *
       * // Train the model.
       * for (let i = 0; i < 10; i++) {
       *   optimizer.minimize(() => loss(f(xs), ys));
       * }
       *
       * // Make predictions.
       * console.log(
       *     `a: ${a.dataSync()}, b: ${b.dataSync()}, c: ${c.dataSync()}`);
       * const preds = f(xs).dataSync();
       * preds.forEach((pred, i) => {
       *   console.log(`x: ${i}, pred: ${pred}`);
       * });
       * ```
       *
       * @param learningRate The learning rate to use for the SGD algorithm.
       *
       * @doc {heading: 'Training', subheading: 'Optimizers', namespace: 'train'}
       */
      static sgd(learningRate) {
        return new SGDOptimizer(learningRate);
      }
      /**
       * Constructs a `tf.MomentumOptimizer` that uses momentum gradient
       * descent.
       *
       * See
       * [http://proceedings.mlr.press/v28/sutskever13.pdf](
       * http://proceedings.mlr.press/v28/sutskever13.pdf)
       *
       * @param learningRate The learning rate to use for the Momentum gradient
       * descent algorithm.
       * @param momentum The momentum to use for the momentum gradient descent
       * algorithm.
       *
       * @doc {heading: 'Training', subheading: 'Optimizers', namespace: 'train'}
       */
      static momentum(learningRate, momentum, useNesterov = false) {
        return new MomentumOptimizer(learningRate, momentum, useNesterov);
      }
      /**
       * Constructs a `tf.RMSPropOptimizer` that uses RMSProp gradient
       * descent. This implementation uses plain momentum and is not centered
       * version of RMSProp.
       *
       * See
       * [http://www.cs.toronto.edu/~tijmen/csc321/slides/lecture_slides_lec6.pdf](
       * http://www.cs.toronto.edu/~tijmen/csc321/slides/lecture_slides_lec6.pdf)
       *
       * @param learningRate The learning rate to use for the RMSProp gradient
       * descent algorithm.
       * @param decay The discounting factor for the history/coming gradient.
       * @param momentum The momentum to use for the RMSProp gradient descent
       * algorithm.
       * @param epsilon Small value to avoid zero denominator.
       * @param centered If true, gradients are normalized by the estimated
       * variance of the gradient.
       *
       * @doc {heading: 'Training', subheading: 'Optimizers', namespace: 'train'}
       */
      static rmsprop(learningRate, decay = 0.9, momentum = 0, epsilon = null, centered = false) {
        return new RMSPropOptimizer(learningRate, decay, momentum, epsilon, centered);
      }
      /**
       * Constructs a `tf.AdamOptimizer` that uses the Adam algorithm.
       * See [https://arxiv.org/abs/1412.6980](https://arxiv.org/abs/1412.6980)
       *
       * @param learningRate The learning rate to use for the Adam gradient
       * descent algorithm.
       * @param beta1 The exponential decay rate for the 1st moment estimates.
       * @param beta2 The exponential decay rate for the 2nd moment estimates.
       * @param epsilon A small constant for numerical stability.
       *
       * @doc {heading: 'Training', subheading: 'Optimizers', namespace: 'train'}
       */
      static adam(learningRate = 1e-3, beta1 = 0.9, beta2 = 0.999, epsilon = null) {
        return new AdamOptimizer(learningRate, beta1, beta2, epsilon);
      }
      /**
       * Constructs a `tf.AdadeltaOptimizer` that uses the Adadelta algorithm.
       * See [https://arxiv.org/abs/1212.5701](https://arxiv.org/abs/1212.5701)
       *
       * @param learningRate The learning rate to use for the Adadelta gradient
       * descent algorithm.
       * @param rho The learning rate decay over each update.
       * @param epsilon A constant epsilon used to better condition the grad
       * update.
       *
       * @doc {heading: 'Training', subheading: 'Optimizers', namespace: 'train'}
       */
      static adadelta(learningRate = 1e-3, rho = 0.95, epsilon = null) {
        return new AdadeltaOptimizer(learningRate, rho, epsilon);
      }
      /**
       * Constructs a `tf.AdamaxOptimizer` that uses the Adamax algorithm.
       * See [https://arxiv.org/abs/1412.6980](https://arxiv.org/abs/1412.6980)
       *
       * @param learningRate The learning rate to use for the Adamax gradient
       * descent algorithm.
       * @param beta1 The exponential decay rate for the 1st moment estimates.
       * @param beta2 The exponential decay rate for the 2nd moment estimates.
       * @param epsilon A small constant for numerical stability.
       * @param decay The learning rate decay over each update.
       *
       * @doc {heading: 'Training', subheading: 'Optimizers', namespace: 'train'}
       */
      static adamax(learningRate = 2e-3, beta1 = 0.9, beta2 = 0.999, epsilon = null, decay = 0) {
        return new AdamaxOptimizer(learningRate, beta1, beta2, epsilon, decay);
      }
      /**
       * Constructs a `tf.AdagradOptimizer` that uses the Adagrad algorithm.
       * See
       * [http://www.jmlr.org/papers/volume12/duchi11a/duchi11a.pdf](
       * http://www.jmlr.org/papers/volume12/duchi11a/duchi11a.pdf)
       * or
       * [http://ruder.io/optimizing-gradient-descent/index.html#adagrad](
       * http://ruder.io/optimizing-gradient-descent/index.html#adagrad)
       *
       * @param learningRate The learning rate to use for the Adagrad gradient
       * descent algorithm.
       * @param initialAccumulatorValue Starting value for the accumulators, must be
       * positive.
       *
       * @doc {heading: 'Training', subheading: 'Optimizers', namespace: 'train'}
       */
      static adagrad(learningRate, initialAccumulatorValue = 0.1) {
        return new AdagradOptimizer(learningRate, initialAccumulatorValue);
      }
    };
  }
});

// node_modules/@tensorflow/tfjs-core/dist/train.js
var train;
var init_train = __esm({
  "node_modules/@tensorflow/tfjs-core/dist/train.js"() {
    init_optimizer_constructors();
    train = OptimizerConstructors;
  }
});

// node_modules/@tensorflow/tfjs-core/dist/browser_util.js
function nextFrame() {
  return new Promise((resolve) => delayCallback(() => resolve()));
}
var delayCallback;
var init_browser_util = __esm({
  "node_modules/@tensorflow/tfjs-core/dist/browser_util.js"() {
    delayCallback = (() => {
      if (typeof requestAnimationFrame !== "undefined") {
        return requestAnimationFrame;
      } else if (typeof setImmediate !== "undefined") {
        return setImmediate;
      }
      return (f) => f();
    })();
  }
});

// node_modules/@tensorflow/tfjs-core/dist/ops/concat_util.js
function assertParamsConsistent(shapes, axis) {
  const rank = shapes[0].length;
  shapes.forEach((shape, i) => {
    assert(shape.length === rank, () => `Error in concat${rank}D: rank of tensors[${i}] must be the same as the rank of the rest (${rank})`);
  });
  assert(axis >= 0 && axis < rank, () => `Error in concat${rank}D: axis must be between 0 and ${rank - 1}.`);
  const firstShape = shapes[0];
  shapes.forEach((shape, i) => {
    for (let r = 0; r < rank; r++) {
      assert(r === axis || shape[r] === firstShape[r], () => `Error in concat${rank}D: Shape of tensors[${i}] (${shape}) does not match the shape of the rest (${firstShape}) along the non-concatenated axis ${i}.`);
    }
  });
}
function computeOutShape2(shapes, axis) {
  const outputShape = shapes[0].slice();
  for (let i = 1; i < shapes.length; i++) {
    outputShape[axis] += shapes[i][axis];
  }
  return outputShape;
}
var init_concat_util = __esm({
  "node_modules/@tensorflow/tfjs-core/dist/ops/concat_util.js"() {
    init_util();
  }
});

// node_modules/@tensorflow/tfjs-core/dist/ops/fused_types.js
var init_fused_types = __esm({
  "node_modules/@tensorflow/tfjs-core/dist/ops/fused_types.js"() {
  }
});

// node_modules/@tensorflow/tfjs-core/dist/ops/ragged_to_dense_util.js
function combineRaggedTensorToTensorShapes(raggedRank, shape, valueShape) {
  let outputShape = new Array();
  if (valueShape == null && shape == null) {
    return outputShape;
  }
  if (shape == null) {
    while (outputShape.length < raggedRank + valueShape.length) {
      outputShape.push(-1);
    }
  } else {
    outputShape = shape.slice();
  }
  if (valueShape == null) {
    return outputShape;
  }
  if (raggedRank + valueShape.length !== outputShape.length) {
    throw new Error(`rt input.shape and shape=${shape} are incompatible: rt input.rank = ${raggedRank + valueShape.length}, but shape.rank = ${outputShape.length}`);
  }
  for (let i = 1; i < valueShape.length; ++i) {
    const valueDim = valueShape[i];
    const outputShapeDimIndex = outputShape[outputShape.length - valueShape.length + i];
    const outputShapeDim = outputShape[outputShapeDimIndex];
    if (valueDim >= 0) {
      if (outputShapeDim >= 0) {
        if (outputShapeDim !== valueDim) {
          throw new Error(`rt input.shape and shape=${shape} are incompatible: rt input.shape[${i + raggedRank}] = ${valueDim} but shape[${i + raggedRank}] = ${outputShapeDim}`);
        }
      } else {
        outputShape[outputShapeDimIndex] = valueDim;
      }
    }
  }
  return outputShape;
}
function getRowPartitionTypesHelper(rowPartitionTypeStrings) {
  const stringToType = {
    "FIRST_DIM_SIZE": RowPartitionType.FIRST_DIM_SIZE,
    "VALUE_ROWIDS": RowPartitionType.VALUE_ROWIDS,
    "ROW_LENGTHS": RowPartitionType.ROW_LENGTHS,
    "ROW_SPLITS": RowPartitionType.ROW_SPLITS,
    "ROW_LIMITS": RowPartitionType.ROW_LIMITS,
    "ROW_STARTS": RowPartitionType.ROW_STARTS
  };
  const result = [];
  for (const typeStr of rowPartitionTypeStrings) {
    if (typeStr in stringToType) {
      result.push(stringToType[typeStr]);
    } else {
      break;
    }
  }
  return result;
}
function getRaggedRank(rowPartitionTypes) {
  if (rowPartitionTypes.length === 0) {
    return 0;
  }
  if (rowPartitionTypes[0] === RowPartitionType.FIRST_DIM_SIZE) {
    return rowPartitionTypes.length - 1;
  }
  return rowPartitionTypes.length;
}
function validateDefaultValueShape(defaultValueShape, valueShape) {
  if (defaultValueShape == null || valueShape == null) {
    return;
  }
  const defaultNDims = defaultValueShape.length;
  const valuesNDims = valueShape.length;
  if (defaultNDims >= valuesNDims) {
    throw new Error(`defaultValue.shape=${defaultValueShape} and ragged tensor flatValues.shape=${valueShape}, are incompatible: defaultValue.rank = ${defaultNDims} must be less than ragged tensor input flatValues.rank = ${valuesNDims})`);
  }
  for (let i = 0; i < Math.min(defaultNDims, valuesNDims - 1); ++i) {
    const defaultDim = defaultValueShape[i];
    const valueDim = valueShape[i + 1];
    if (defaultDim >= 0 && valueDim >= 0 && defaultDim !== 1 && defaultDim !== valueDim) {
      throw new Error(`defaultValue.shape=${defaultValueShape}, and ragged tensor input flatValues.shape=${valueShape} are incompatible: defaultValue.shape[${i - defaultValueShape.length}] = ${defaultDim} but ragged tensor input.flatValues.shape[${i - defaultValueShape.length}] = ${valueDim}`);
    }
  }
}
var RowPartitionType;
var init_ragged_to_dense_util = __esm({
  "node_modules/@tensorflow/tfjs-core/dist/ops/ragged_to_dense_util.js"() {
    (function(RowPartitionType3) {
      RowPartitionType3[RowPartitionType3["FIRST_DIM_SIZE"] = 0] = "FIRST_DIM_SIZE";
      RowPartitionType3[RowPartitionType3["VALUE_ROWIDS"] = 1] = "VALUE_ROWIDS";
      RowPartitionType3[RowPartitionType3["ROW_LENGTHS"] = 2] = "ROW_LENGTHS";
      RowPartitionType3[RowPartitionType3["ROW_SPLITS"] = 3] = "ROW_SPLITS";
      RowPartitionType3[RowPartitionType3["ROW_LIMITS"] = 4] = "ROW_LIMITS";
      RowPartitionType3[RowPartitionType3["ROW_STARTS"] = 5] = "ROW_STARTS";
    })(RowPartitionType || (RowPartitionType = {}));
  }
});

// node_modules/@tensorflow/tfjs-core/dist/ops/reduce_util.js
function computeOptimalWindowSize(inSize) {
  if (inSize <= PARALLELIZE_THRESHOLD) {
    return inSize;
  }
  return nearestDivisor(inSize, Math.floor(Math.sqrt(inSize)));
}
var PARALLELIZE_THRESHOLD;
var init_reduce_util = __esm({
  "node_modules/@tensorflow/tfjs-core/dist/ops/reduce_util.js"() {
    init_util();
    PARALLELIZE_THRESHOLD = 30;
  }
});

// node_modules/@tensorflow/tfjs-core/dist/ops/rotate_util.js
function getImageCenter(center, imageHeight, imageWidth) {
  const centerX = imageWidth * (typeof center === "number" ? center : center[0]);
  const centerY = imageHeight * (typeof center === "number" ? center : center[1]);
  return [centerX, centerY];
}
var init_rotate_util = __esm({
  "node_modules/@tensorflow/tfjs-core/dist/ops/rotate_util.js"() {
  }
});

// node_modules/@tensorflow/tfjs-core/dist/ops/array_ops_util.js
function getReshaped(inputShape, blockShape, prod3, batchToSpace = true) {
  let reshaped = [];
  if (batchToSpace) {
    reshaped = reshaped.concat(blockShape.slice(0));
    reshaped.push(inputShape[0] / prod3);
    reshaped = reshaped.concat(inputShape.slice(1));
  } else {
    reshaped = reshaped.concat(inputShape[0]);
    const spatialLength = blockShape.length;
    for (let i = 0; i < spatialLength; ++i) {
      reshaped = reshaped.concat([inputShape[i + 1] / blockShape[i], blockShape[i]]);
    }
    reshaped = reshaped.concat(inputShape.slice(spatialLength + 1));
  }
  return reshaped;
}
function getPermuted(reshapedRank, blockShapeRank, batchToSpace = true) {
  const permuted = [];
  if (batchToSpace) {
    permuted.push(blockShapeRank);
    for (let i = blockShapeRank + 1; i < reshapedRank; ++i) {
      if (i <= 2 * blockShapeRank) {
        permuted.push(i);
        permuted.push(i - (blockShapeRank + 1));
      } else {
        permuted.push(i);
      }
    }
  } else {
    const permutedBeforeBatch = [];
    const permutedAfterBatch = [];
    for (let i = 1; i < reshapedRank; ++i) {
      if (i >= blockShapeRank * 2 + 1 || i % 2 === 1) {
        permutedAfterBatch.push(i);
      } else {
        permutedBeforeBatch.push(i);
      }
    }
    permuted.push(...permutedBeforeBatch);
    permuted.push(0);
    permuted.push(...permutedAfterBatch);
  }
  return permuted;
}
function getReshapedPermuted(inputShape, blockShape, prod3, batchToSpace = true) {
  const reshapedPermuted = [];
  if (batchToSpace) {
    reshapedPermuted.push(inputShape[0] / prod3);
  } else {
    reshapedPermuted.push(inputShape[0] * prod3);
  }
  for (let i = 1; i < inputShape.length; ++i) {
    if (i <= blockShape.length) {
      if (batchToSpace) {
        reshapedPermuted.push(blockShape[i - 1] * inputShape[i]);
      } else {
        reshapedPermuted.push(inputShape[i] / blockShape[i - 1]);
      }
    } else {
      reshapedPermuted.push(inputShape[i]);
    }
  }
  return reshapedPermuted;
}
function getSliceBeginCoords(crops, blockShape) {
  const sliceBeginCoords = [0];
  for (let i = 0; i < blockShape; ++i) {
    sliceBeginCoords.push(crops[i][0]);
  }
  return sliceBeginCoords;
}
function getSliceSize(uncroppedShape, crops, blockShape) {
  const sliceSize = uncroppedShape.slice(0, 1);
  for (let i = 0; i < blockShape; ++i) {
    sliceSize.push(uncroppedShape[i + 1] - crops[i][0] - crops[i][1]);
  }
  return sliceSize;
}
var init_array_ops_util = __esm({
  "node_modules/@tensorflow/tfjs-core/dist/ops/array_ops_util.js"() {
  }
});

// node_modules/@tensorflow/tfjs-core/dist/ops/selu_util.js
var SELU_SCALEALPHA, SELU_SCALE;
var init_selu_util = __esm({
  "node_modules/@tensorflow/tfjs-core/dist/ops/selu_util.js"() {
    SELU_SCALEALPHA = 1.7580993408473768;
    SELU_SCALE = 1.0507009873554805;
  }
});

// node_modules/@tensorflow/tfjs-core/dist/ops/erf_util.js
var ERF_P, ERF_A1, ERF_A2, ERF_A3, ERF_A4, ERF_A5;
var init_erf_util = __esm({
  "node_modules/@tensorflow/tfjs-core/dist/ops/erf_util.js"() {
    ERF_P = 0.3275911;
    ERF_A1 = 0.254829592;
    ERF_A2 = -0.284496736;
    ERF_A3 = 1.421413741;
    ERF_A4 = -1.453152027;
    ERF_A5 = 1.061405429;
  }
});

// node_modules/@tensorflow/tfjs-core/dist/backends/complex_util.js
function mergeRealAndImagArrays(real3, imag2) {
  if (real3.length !== imag2.length) {
    throw new Error(`Cannot merge real and imag arrays of different lengths. real:${real3.length}, imag: ${imag2.length}.`);
  }
  const result = new Float32Array(real3.length * 2);
  for (let i = 0; i < result.length; i += 2) {
    result[i] = real3[i / 2];
    result[i + 1] = imag2[i / 2];
  }
  return result;
}
function splitRealAndImagArrays(complex3) {
  const real3 = new Float32Array(complex3.length / 2);
  const imag2 = new Float32Array(complex3.length / 2);
  for (let i = 0; i < complex3.length; i += 2) {
    real3[i / 2] = complex3[i];
    imag2[i / 2] = complex3[i + 1];
  }
  return {
    real: real3,
    imag: imag2
  };
}
function complexWithEvenIndex(complex3) {
  const len = Math.ceil(complex3.length / 4);
  const real3 = new Float32Array(len);
  const imag2 = new Float32Array(len);
  for (let i = 0; i < complex3.length; i += 4) {
    real3[Math.floor(i / 4)] = complex3[i];
    imag2[Math.floor(i / 4)] = complex3[i + 1];
  }
  return {
    real: real3,
    imag: imag2
  };
}
function complexWithOddIndex(complex3) {
  const len = Math.floor(complex3.length / 4);
  const real3 = new Float32Array(len);
  const imag2 = new Float32Array(len);
  for (let i = 2; i < complex3.length; i += 4) {
    real3[Math.floor(i / 4)] = complex3[i];
    imag2[Math.floor(i / 4)] = complex3[i + 1];
  }
  return {
    real: real3,
    imag: imag2
  };
}
function getComplexWithIndex(complex3, index) {
  const real3 = complex3[index * 2];
  const imag2 = complex3[index * 2 + 1];
  return {
    real: real3,
    imag: imag2
  };
}
function assignToTypedArray(data, real3, imag2, index) {
  data[index * 2] = real3;
  data[index * 2 + 1] = imag2;
}
function exponents(n, inverse) {
  const real3 = new Float32Array(n / 2);
  const imag2 = new Float32Array(n / 2);
  for (let i = 0; i < Math.ceil(n / 2); i++) {
    const x = (inverse ? 2 : -2) * Math.PI * (i / n);
    real3[i] = Math.cos(x);
    imag2[i] = Math.sin(x);
  }
  return {
    real: real3,
    imag: imag2
  };
}
function exponent(k, n, inverse) {
  const x = (inverse ? 2 : -2) * Math.PI * (k / n);
  const real3 = Math.cos(x);
  const imag2 = Math.sin(x);
  return {
    real: real3,
    imag: imag2
  };
}
var init_complex_util = __esm({
  "node_modules/@tensorflow/tfjs-core/dist/backends/complex_util.js"() {
  }
});

// node_modules/@tensorflow/tfjs-core/dist/backends/einsum_util.js
function decodeEinsumEquation(equation, numTensors) {
  equation = equation.replace(/\s/g, "");
  const numArrows = (equation.length - equation.replace(ARROW_REGEX, "").length) / ARROW.length;
  if (numArrows < 1) {
    throw new Error("Equations without an arrow are not supported.");
  } else if (numArrows > 1) {
    throw new Error(`Equation must contain exactly one arrow ("${ARROW}").`);
  }
  const [inputString, outputString] = equation.split(ARROW);
  assert(inputString.indexOf(ELLIPSIS) === -1, () => `The ellipsis notation ("${ELLIPSIS}") is not supported yet.`);
  const inputTerms = inputString.split(COMMA);
  const numInputs = inputTerms.length;
  if (numTensors !== numInputs) {
    throw new Error(`Expected ${numInputs} input tensors, received ${numTensors}`);
  }
  if (numInputs > 2) {
    throw new Error("Support for more than 2 input tensors is not implemented yet.");
  }
  const allDims = [];
  for (let i = 0; i < outputString.length; ++i) {
    const dimName = outputString[i];
    if (!inputTerms.some((inputTerm) => inputTerm.indexOf(dimName) !== -1)) {
      throw new Error(`Output subscripts contain the label ${dimName} not present in the input subscripts.`);
    }
    if (allDims.indexOf(dimName) === -1) {
      allDims.push(dimName);
    }
  }
  for (let i = 0; i < inputString.length; ++i) {
    const dimName = inputString[i];
    if (allDims.indexOf(dimName) === -1 && dimName !== COMMA) {
      allDims.push(dimName);
    }
  }
  const idDims = new Array(inputTerms.length);
  for (let i = 0; i < numInputs; ++i) {
    if (new Set(inputTerms[i].split("")).size !== inputTerms[i].length) {
      throw new Error(`Found duplicate axes in input component ${inputTerms[i]}. Support for duplicate axes in input is not implemented yet.`);
    }
    idDims[i] = [];
    for (let j = 0; j < inputTerms[i].length; ++j) {
      idDims[i].push(allDims.indexOf(inputTerms[i][j]));
    }
  }
  const numDims = allDims.length;
  const numOutDims = outputString.length;
  const summedDims = [];
  for (let i = numOutDims; i < numDims; ++i) {
    summedDims.push(i);
  }
  return {
    allDims,
    summedDims,
    idDims
  };
}
function getEinsumPermutation(nDims, idDims) {
  let permutationIndices = new Array(nDims);
  permutationIndices.fill(-1);
  for (let i = 0; i < idDims.length; ++i) {
    permutationIndices[idDims[i]] = i;
  }
  const expandDims2 = [];
  for (let i = 0; i < nDims; ++i) {
    if (permutationIndices[i] === -1) {
      expandDims2.push(i);
    }
  }
  permutationIndices = permutationIndices.filter((d) => d !== -1);
  return {
    permutationIndices,
    expandDims: expandDims2
  };
}
function checkEinsumDimSizes(nDims, idDims, tensors) {
  const dimSizes = new Array(nDims);
  for (let i = 0; i < tensors.length; ++i) {
    const shape = tensors[i].shape;
    for (let j = 0; j < idDims[i].length; ++j) {
      if (dimSizes[idDims[i][j]] === void 0) {
        dimSizes[idDims[i][j]] = shape[j];
      } else {
        assert(dimSizes[idDims[i][j]] === shape[j], () => `Expected dimension ${dimSizes[idDims[i][j]]} at axis ${j} of input shaped ${JSON.stringify(shape)}, but got dimension ${shape[j]}`);
      }
    }
  }
}
function getEinsumComputePath(summedDims, idDims) {
  const path = summedDims;
  const steps = [];
  let nSteps = 0;
  if (summedDims.length === 0) {
    path.push(-1);
  }
  nSteps = summedDims.length + 1;
  for (let i = 0; i < nSteps; ++i) {
    steps.push([]);
  }
  const computedTermIndices = [];
  for (let i = 0; i < path.length; ++i) {
    const summedDim = path[i];
    const termIndices = findTermsWithDim(idDims, summedDim);
    for (const termIndex of termIndices) {
      if (computedTermIndices.indexOf(termIndex) === -1) {
        steps[i].push(termIndex);
        computedTermIndices.push(termIndex);
      }
    }
  }
  return {
    path,
    steps
  };
}
function isIdentityPermutation(perm) {
  return perm.every((dim, index) => dim === index);
}
function findTermsWithDim(idDims, dim) {
  const termIndices = [];
  for (let i = 0; i < idDims.length; ++i) {
    if (idDims[i].length === 0 || idDims[i].indexOf(dim) !== -1 || dim === -1) {
      termIndices.push(i);
    }
  }
  return termIndices;
}
var ARROW, ARROW_REGEX, COMMA, ELLIPSIS;
var init_einsum_util = __esm({
  "node_modules/@tensorflow/tfjs-core/dist/backends/einsum_util.js"() {
    init_util_base();
    ARROW = "->";
    ARROW_REGEX = /->/g;
    COMMA = ",";
    ELLIPSIS = "...";
  }
});

// node_modules/@tensorflow/tfjs-core/dist/ops/split_util.js
function prepareSplitSize(x, numOrSizeSplits, axis = 0) {
  let splitSizes = [];
  if (typeof numOrSizeSplits === "number") {
    assert(x.shape[axis] % numOrSizeSplits === 0, () => "Number of splits must evenly divide the axis.");
    splitSizes = new Array(numOrSizeSplits).fill(x.shape[axis] / numOrSizeSplits);
  } else {
    const numOfNegs = numOrSizeSplits.reduce((count, value) => {
      if (value === -1) {
        count += 1;
      }
      return count;
    }, 0);
    assert(numOfNegs <= 1, () => "There should be only one negative value in split array.");
    const negIndex = numOrSizeSplits.indexOf(-1);
    if (negIndex !== -1) {
      const total = numOrSizeSplits.reduce((a, b) => b > 0 ? a + b : a);
      numOrSizeSplits[negIndex] = x.shape[axis] - total;
    }
    assert(x.shape[axis] === numOrSizeSplits.reduce((a, b) => a + b), () => "The sum of sizes must match the size of the axis dimension.");
    splitSizes = numOrSizeSplits;
  }
  return splitSizes;
}
var init_split_util = __esm({
  "node_modules/@tensorflow/tfjs-core/dist/ops/split_util.js"() {
    init_util();
  }
});

// node_modules/@tensorflow/tfjs-core/dist/ops/sparse/sparse_fill_empty_rows_util.js
function getSparseFillEmptyRowsIndicesDenseShapeMismatch(indicesLength) {
  return `Received SparseTensor with denseShape[0] = 0 but
  indices.shape[0] = ${indicesLength}`;
}
function getSparseFillEmptyRowsNegativeIndexErrorMessage(index, value) {
  return `indices(${index}, 0) is invalid: ${value} < 0`;
}
function getSparseFillEmptyRowsOutOfRangeIndexErrorMessage(index, value, limit) {
  return `indices(${index}, 0) is invalid: ${value} >= ${limit}`;
}
var init_sparse_fill_empty_rows_util = __esm({
  "node_modules/@tensorflow/tfjs-core/dist/ops/sparse/sparse_fill_empty_rows_util.js"() {
  }
});

// node_modules/@tensorflow/tfjs-core/dist/ops/sparse/sparse_reshape_util.js
function getSparseReshapeMultipleNegativeOneOutputDimErrorMessage(dim1, dim2) {
  return `only one output dimension may be -1, not both ${dim1} and ${dim2}`;
}
function getSparseReshapeNegativeOutputDimErrorMessage(dim, value) {
  return `size ${dim} must be non-negative, not ${value}`;
}
function getSparseReshapeEmptyTensorZeroOutputDimErrorMessage() {
  return "reshape cannot infer the missing input size for an empty tensor unless all specified input sizes are non-zero";
}
function getSparseReshapeInputOutputMultipleErrorMessage(inputShape, outputShape) {
  const inputSize = sizeFromShape(inputShape);
  const outputSize = sizeFromShape(outputShape);
  return `Input to reshape is a SparseTensor with ${inputSize}
  dense values, but the requested shape requires a multiple of ${outputSize}. inputShape=${inputShape} outputShape= ${outputShape}`;
}
function getSparseReshapeInputOutputMismatchErrorMessage(inputShape, outputShape) {
  const inputSize = sizeFromShape(inputShape);
  const outputSize = sizeFromShape(outputShape);
  return `Input to reshape is a tensor with ${inputSize} dense values, but the requested shape has ${outputSize}. inputShape=${inputShape} outputShape=${outputShape}`;
}
var init_sparse_reshape_util = __esm({
  "node_modules/@tensorflow/tfjs-core/dist/ops/sparse/sparse_reshape_util.js"() {
    init_util();
  }
});

// node_modules/@tensorflow/tfjs-core/dist/ops/sparse/sparse_segment_reduction_util.js
function getSparseSegmentReductionNegativeSegmentIdsErrorMessage() {
  return `segment ids must be >= 0`;
}
function getSparseSegmentReductionNonIncreasingSegmentIdsErrorMessage() {
  return `segment ids are not increasing`;
}
function getSparseSegmentReductionSegmentIdOutOfRangeErrorMessage(segmentId, outputRows) {
  return `Segment id ${segmentId} out of range [0, ${outputRows}), possibly because segmentIds input is not sorted.`;
}
function getSparseSegmentReductionIndicesOutOfRangeErrorMessage(index, indexValue, inputRows) {
  return `Bad: indices[${index}] == ${indexValue} out of range [0, ${inputRows})`;
}
var init_sparse_segment_reduction_util = __esm({
  "node_modules/@tensorflow/tfjs-core/dist/ops/sparse/sparse_segment_reduction_util.js"() {
  }
});

// node_modules/@tensorflow/tfjs-core/dist/ops/segment_util.js
var segment_util_exports = {};
__export(segment_util_exports, {
  collectGatherOpShapeInfo: () => collectGatherOpShapeInfo,
  computeOutShape: () => computeOutShape3,
  segOpComputeOptimalWindowSize: () => segOpComputeOptimalWindowSize
});
function segOpComputeOptimalWindowSize(inSize, numSegments) {
  let done = false;
  let res;
  if (inSize <= PARALLELIZE_THRESHOLD) {
    res = inSize;
    done = true;
  } else {
    res = nearestDivisor(inSize, Math.floor(Math.sqrt(inSize)));
  }
  while (!done) {
    if (res > numSegments || res === inSize) {
      done = true;
    } else {
      res = nearestDivisor(inSize, res + 1);
    }
  }
  return res;
}
function computeOutShape3(aShape, axis, numSegments) {
  const outShape = [];
  const rank = aShape.length;
  for (let dim = 0; dim < rank; dim++) {
    if (dim !== axis) {
      outShape.push(aShape[dim]);
    } else {
      outShape.push(numSegments);
    }
  }
  return outShape;
}
function collectGatherOpShapeInfo(x, indices, axis, batchDims) {
  const indicesRank = indices.shape.length;
  const xRank = x.shape.length;
  if (batchDims !== 0) {
    if (batchDims < -indicesRank || batchDims > indicesRank) {
      throw new Error(`Expect batchDims in the range of [-${indicesRank}, ${indicesRank}], but got ${batchDims}`);
    }
  }
  if (batchDims < 0) {
    batchDims += indicesRank;
  }
  if (batchDims > xRank) {
    throw new Error(`batchDims (${batchDims}) must be less than rank(x) (
    ${xRank}).`);
  }
  if (axis < batchDims) {
    throw new Error(`batchDims (${batchDims}) must be less than or equal to axis (${axis}).`);
  }
  for (let i = 0; i < batchDims; ++i) {
    if (x.shape[i] !== indices.shape[i]) {
      throw new Error(`x.shape[${i}]: ${x.shape[i]} should be equal to indices.shape[${i}]: ${indices.shape[i]}.`);
    }
  }
  const dimSize = x.shape[axis];
  const outputShape = [];
  let batchSize = 1;
  let outerSize = 1;
  let sliceSize = 1;
  for (let i = 0; i < batchDims; ++i) {
    outputShape.push(x.shape[i]);
    batchSize *= x.shape[i];
  }
  for (let i = batchDims; i < axis; i++) {
    outputShape.push(x.shape[i]);
    outerSize *= x.shape[i];
  }
  for (let i = batchDims; i < indicesRank; i++) {
    outputShape.push(indices.shape[i]);
  }
  for (let i = axis + 1; i < xRank; i++) {
    outputShape.push(x.shape[i]);
    sliceSize *= x.shape[i];
  }
  return {
    batchSize,
    sliceSize,
    outerSize,
    dimSize,
    outputShape
  };
}
var init_segment_util = __esm({
  "node_modules/@tensorflow/tfjs-core/dist/ops/segment_util.js"() {
    init_util();
    init_reduce_util();
  }
});

// node_modules/@tensorflow/tfjs-core/dist/backends/backend_util.js
var backend_util_exports = {};
__export(backend_util_exports, {
  ERF_A1: () => ERF_A1,
  ERF_A2: () => ERF_A2,
  ERF_A3: () => ERF_A3,
  ERF_A4: () => ERF_A4,
  ERF_A5: () => ERF_A5,
  ERF_P: () => ERF_P,
  PARALLELIZE_THRESHOLD: () => PARALLELIZE_THRESHOLD,
  RowPartitionType: () => RowPartitionType,
  SELU_SCALE: () => SELU_SCALE,
  SELU_SCALEALPHA: () => SELU_SCALEALPHA,
  applyActivation: () => applyActivation,
  assertAndGetBroadcastShape: () => assertAndGetBroadcastShape,
  assertAxesAreInnerMostDims: () => assertAxesAreInnerMostDims,
  assertParamsConsistent: () => assertParamsConsistent,
  assignToTypedArray: () => assignToTypedArray,
  axesAreInnerMostDims: () => axesAreInnerMostDims,
  calculateShapes: () => calculateShapes,
  checkEinsumDimSizes: () => checkEinsumDimSizes,
  checkPadOnDimRoundingMode: () => checkPadOnDimRoundingMode,
  combineLocations: () => combineLocations,
  combineRaggedTensorToTensorShapes: () => combineRaggedTensorToTensorShapes,
  complexWithEvenIndex: () => complexWithEvenIndex,
  complexWithOddIndex: () => complexWithOddIndex,
  computeConv2DInfo: () => computeConv2DInfo,
  computeConv3DInfo: () => computeConv3DInfo,
  computeDefaultPad: () => computeDefaultPad,
  computeDilation2DInfo: () => computeDilation2DInfo,
  computeOptimalWindowSize: () => computeOptimalWindowSize,
  computeOutAndReduceShapes: () => computeOutAndReduceShapes,
  computeOutShape: () => computeOutShape2,
  computePool2DInfo: () => computePool2DInfo,
  computePool3DInfo: () => computePool3DInfo,
  convertConv2DDataFormat: () => convertConv2DDataFormat,
  decodeEinsumEquation: () => decodeEinsumEquation,
  eitherStridesOrDilationsAreOne: () => eitherStridesOrDilationsAreOne,
  expandShapeToKeepDim: () => expandShapeToKeepDim,
  exponent: () => exponent,
  exponents: () => exponents,
  fromStringArrayToUint8: () => fromStringArrayToUint8,
  fromUint8ToStringArray: () => fromUint8ToStringArray,
  getAxesPermutation: () => getAxesPermutation,
  getBroadcastDims: () => getBroadcastDims,
  getComplexWithIndex: () => getComplexWithIndex,
  getEinsumComputePath: () => getEinsumComputePath,
  getEinsumPermutation: () => getEinsumPermutation,
  getFusedBiasGradient: () => getFusedBiasGradient,
  getFusedDyActivation: () => getFusedDyActivation,
  getImageCenter: () => getImageCenter,
  getInnerMostAxes: () => getInnerMostAxes,
  getPermuted: () => getPermuted,
  getRaggedRank: () => getRaggedRank,
  getReductionAxes: () => getReductionAxes,
  getReshaped: () => getReshaped,
  getReshapedPermuted: () => getReshapedPermuted,
  getRowPartitionTypesHelper: () => getRowPartitionTypesHelper,
  getSliceBeginCoords: () => getSliceBeginCoords,
  getSliceSize: () => getSliceSize,
  getSparseFillEmptyRowsIndicesDenseShapeMismatch: () => getSparseFillEmptyRowsIndicesDenseShapeMismatch,
  getSparseFillEmptyRowsNegativeIndexErrorMessage: () => getSparseFillEmptyRowsNegativeIndexErrorMessage,
  getSparseFillEmptyRowsOutOfRangeIndexErrorMessage: () => getSparseFillEmptyRowsOutOfRangeIndexErrorMessage,
  getSparseReshapeEmptyTensorZeroOutputDimErrorMessage: () => getSparseReshapeEmptyTensorZeroOutputDimErrorMessage,
  getSparseReshapeInputOutputMismatchErrorMessage: () => getSparseReshapeInputOutputMismatchErrorMessage,
  getSparseReshapeInputOutputMultipleErrorMessage: () => getSparseReshapeInputOutputMultipleErrorMessage,
  getSparseReshapeMultipleNegativeOneOutputDimErrorMessage: () => getSparseReshapeMultipleNegativeOneOutputDimErrorMessage,
  getSparseReshapeNegativeOutputDimErrorMessage: () => getSparseReshapeNegativeOutputDimErrorMessage,
  getSparseSegmentReductionIndicesOutOfRangeErrorMessage: () => getSparseSegmentReductionIndicesOutOfRangeErrorMessage,
  getSparseSegmentReductionNegativeSegmentIdsErrorMessage: () => getSparseSegmentReductionNegativeSegmentIdsErrorMessage,
  getSparseSegmentReductionNonIncreasingSegmentIdsErrorMessage: () => getSparseSegmentReductionNonIncreasingSegmentIdsErrorMessage,
  getSparseSegmentReductionSegmentIdOutOfRangeErrorMessage: () => getSparseSegmentReductionSegmentIdOutOfRangeErrorMessage,
  getUndoAxesPermutation: () => getUndoAxesPermutation,
  isIdentityPermutation: () => isIdentityPermutation,
  log: () => log,
  mergeRealAndImagArrays: () => mergeRealAndImagArrays,
  prepareAndValidate: () => prepareAndValidate,
  prepareSplitSize: () => prepareSplitSize,
  segment_util: () => segment_util_exports,
  shouldFuse: () => shouldFuse,
  slice_util: () => slice_util_exports,
  splitRealAndImagArrays: () => splitRealAndImagArrays,
  stridesOrDilationsArePositive: () => stridesOrDilationsArePositive,
  tupleValuesAreOne: () => tupleValuesAreOne,
  upcastType: () => upcastType,
  validateDefaultValueShape: () => validateDefaultValueShape,
  validateInput: () => validateInput,
  validateUpdateShape: () => validateUpdateShape,
  warn: () => warn
});
function fromUint8ToStringArray(vals) {
  try {
    return vals.map((val) => decodeString(val));
  } catch (err) {
    throw new Error(`Failed to decode encoded string bytes into utf-8, error: ${err}`);
  }
}
function fromStringArrayToUint8(strings) {
  return strings.map((s) => encodeString(s));
}
var init_backend_util = __esm({
  "node_modules/@tensorflow/tfjs-core/dist/backends/backend_util.js"() {
    init_util();
    init_axis_util();
    init_broadcast_util();
    init_concat_util();
    init_conv_util();
    init_fused_util();
    init_fused_types();
    init_ragged_to_dense_util();
    init_reduce_util();
    init_slice_util();
    init_types();
    init_rotate_util();
    init_array_ops_util();
    init_gather_nd_util();
    init_scatter_nd_util();
    init_selu_util();
    init_fused_util();
    init_erf_util();
    init_log();
    init_complex_util();
    init_einsum_util();
    init_split_util();
    init_sparse_fill_empty_rows_util();
    init_sparse_reshape_util();
    init_sparse_segment_reduction_util();
    init_segment_util();
  }
});

// node_modules/@tensorflow/tfjs-core/dist/backends/kernel_impls.js
var kernel_impls_exports = {};
__export(kernel_impls_exports, {
  nonMaxSuppressionV3Impl: () => nonMaxSuppressionV3Impl,
  nonMaxSuppressionV4Impl: () => nonMaxSuppressionV4Impl,
  nonMaxSuppressionV5Impl: () => nonMaxSuppressionV5Impl,
  whereImpl: () => whereImpl
});
var init_kernel_impls = __esm({
  "node_modules/@tensorflow/tfjs-core/dist/backends/kernel_impls.js"() {
    init_non_max_suppression_impl();
    init_where_impl();
  }
});

// node_modules/@tensorflow/tfjs-core/dist/base.js
var init_base = __esm({
  "node_modules/@tensorflow/tfjs-core/dist/base.js"() {
    init_io();
    init_math();
    init_broadcast_util();
    init_browser();
    init_gather_nd_util();
    init_scatter_nd_util();
    init_slice_util();
    init_serialization();
    init_tensor_util();
    init_test_util();
    init_util();
    init_version();
    init_adadelta_optimizer();
    init_adagrad_optimizer();
    init_adam_optimizer();
    init_adamax_optimizer();
    init_momentum_optimizer();
    init_optimizer();
    init_optimizer_constructors();
    init_rmsprop_optimizer();
    init_sgd_optimizer();
    init_tensor();
    init_types();
    init_ops();
    init_loss_ops_utils();
    init_train();
    init_globals();
    init_kernel_registry();
    init_gradients();
    init_environment();
    init_browser_util();
    init_backend_util();
    init_device_util();
    init_kernel_impls();
    init_backend();
    init_kernel_names();
  }
});

// node_modules/@tensorflow/tfjs-core/dist/platforms/platform_browser.js
var PlatformBrowser;
var init_platform_browser = __esm({
  "node_modules/@tensorflow/tfjs-core/dist/platforms/platform_browser.js"() {
    init_flags();
    init_environment();
    init_indexed_db();
    init_local_storage();
    init_model_management();
    init_is_typed_array_browser();
    PlatformBrowser = class {
      constructor() {
        this.messageName = "setTimeoutCustom";
        this.functionRefs = [];
        this.handledMessageCount = 0;
        this.hasEventListener = false;
      }
      fetch(path, init) {
        return fetch(path, init);
      }
      now() {
        return performance.now();
      }
      encode(text, encoding) {
        if (encoding !== "utf-8" && encoding !== "utf8") {
          throw new Error(`Browser's encoder only supports utf-8, but got ${encoding}`);
        }
        if (this.textEncoder == null) {
          this.textEncoder = new TextEncoder();
        }
        return this.textEncoder.encode(text);
      }
      decode(bytes, encoding) {
        return new TextDecoder(encoding).decode(bytes);
      }
      // If the setTimeout nesting level is greater than 5 and timeout is less
      // than 4ms, timeout will be clamped to 4ms, which hurts the perf.
      // Interleaving window.postMessage and setTimeout will trick the browser and
      // avoid the clamp.
      setTimeoutCustom(functionRef, delay) {
        if (typeof window === "undefined" || !env().getBool("USE_SETTIMEOUTCUSTOM")) {
          setTimeout(functionRef, delay);
          return;
        }
        this.functionRefs.push(functionRef);
        setTimeout(() => {
          window.postMessage({
            name: this.messageName,
            index: this.functionRefs.length - 1
          }, "*");
        }, delay);
        if (!this.hasEventListener) {
          this.hasEventListener = true;
          window.addEventListener("message", (event) => {
            if (event.source === window && event.data.name === this.messageName) {
              event.stopPropagation();
              const functionRef2 = this.functionRefs[event.data.index];
              functionRef2();
              this.handledMessageCount++;
              if (this.handledMessageCount === this.functionRefs.length) {
                this.functionRefs = [];
                this.handledMessageCount = 0;
              }
            }
          }, true);
        }
      }
      isTypedArray(a) {
        return isTypedArrayBrowser(a);
      }
    };
    if (env().get("IS_BROWSER")) {
      env().setPlatform("browser", new PlatformBrowser());
      try {
        ModelStoreManagerRegistry.registerManager(BrowserLocalStorage.URL_SCHEME, new BrowserLocalStorageManager());
      } catch (err) {
      }
      try {
        ModelStoreManagerRegistry.registerManager(BrowserIndexedDB.URL_SCHEME, new BrowserIndexedDBManager());
      } catch (err) {
      }
    }
  }
});

// browser-external:node-fetch
var require_node_fetch = __commonJS({
  "browser-external:node-fetch"(exports, module) {
    module.exports = Object.create(new Proxy({}, {
      get(_, key) {
        if (key !== "__esModule" && key !== "__proto__" && key !== "constructor" && key !== "splice") {
          console.warn(`Module "node-fetch" has been externalized for browser compatibility. Cannot access "node-fetch.${key}" in client code. See https://vite.dev/guide/troubleshooting.html#module-externalized-for-browser-compatibility for more details.`);
        }
      }
    }));
  }
});

// browser-external:util
var require_util = __commonJS({
  "browser-external:util"(exports, module) {
    module.exports = Object.create(new Proxy({}, {
      get(_, key) {
        if (key !== "__esModule" && key !== "__proto__" && key !== "constructor" && key !== "splice") {
          console.warn(`Module "util" has been externalized for browser compatibility. Cannot access "util.${key}" in client code. See https://vite.dev/guide/troubleshooting.html#module-externalized-for-browser-compatibility for more details.`);
        }
      }
    }));
  }
});

// node_modules/@tensorflow/tfjs-core/dist/platforms/platform_node.js
var getNodeFetch, systemFetch, PlatformNode;
var init_platform_node = __esm({
  "node_modules/@tensorflow/tfjs-core/dist/platforms/platform_node.js"() {
    init_environment();
    getNodeFetch = {
      // tslint:disable-next-line:no-require-imports
      importFetch: () => require_node_fetch()
    };
    PlatformNode = class {
      constructor() {
        this.util = require_util();
        this.textEncoder = new this.util.TextEncoder();
      }
      fetch(path, requestInits) {
        if (env().global.fetch != null) {
          return env().global.fetch(path, requestInits);
        }
        if (systemFetch == null) {
          systemFetch = getNodeFetch.importFetch();
        }
        return systemFetch(path, requestInits);
      }
      now() {
        const time2 = process.hrtime();
        return time2[0] * 1e3 + time2[1] / 1e6;
      }
      encode(text, encoding) {
        if (encoding !== "utf-8" && encoding !== "utf8") {
          throw new Error(`Node built-in encoder only supports utf-8, but got ${encoding}`);
        }
        return this.textEncoder.encode(text);
      }
      decode(bytes, encoding) {
        if (bytes.length === 0) {
          return "";
        }
        return new this.util.TextDecoder(encoding).decode(bytes);
      }
      isTypedArray(a) {
        return this.util.types.isFloat32Array(a) || this.util.types.isInt32Array(a) || this.util.types.isUint8Array(a) || this.util.types.isUint8ClampedArray(a);
      }
    };
    if (env().get("IS_NODE") && !env().get("IS_BROWSER")) {
      env().setPlatform("node", new PlatformNode());
    }
  }
});

// node_modules/@tensorflow/tfjs-core/dist/base_side_effects.js
var opHandler2;
var init_base_side_effects = __esm({
  "node_modules/@tensorflow/tfjs-core/dist/base_side_effects.js"() {
    init_engine();
    init_flags();
    init_platform_browser();
    init_platform_node();
    init_buffer();
    init_cast();
    init_clone();
    init_print();
    init_tensor();
    getOrMakeEngine();
    opHandler2 = {
      buffer,
      cast,
      clone,
      print
    };
    setOpHandler(opHandler2);
  }
});

// node_modules/@tensorflow/tfjs-core/dist/optimizers/register_optimizers.js
function registerOptimizers() {
  for (const optimizer of OPTIMIZERS) {
    registerClass(optimizer);
  }
}
var OPTIMIZERS;
var init_register_optimizers = __esm({
  "node_modules/@tensorflow/tfjs-core/dist/optimizers/register_optimizers.js"() {
    init_adadelta_optimizer();
    init_adagrad_optimizer();
    init_adam_optimizer();
    init_adamax_optimizer();
    init_momentum_optimizer();
    init_rmsprop_optimizer();
    init_sgd_optimizer();
    init_serialization();
    OPTIMIZERS = [AdadeltaOptimizer, AdagradOptimizer, AdamOptimizer, AdamaxOptimizer, MomentumOptimizer, RMSPropOptimizer, SGDOptimizer];
  }
});

// node_modules/@tensorflow/tfjs-core/dist/index.js
var init_dist = __esm({
  "node_modules/@tensorflow/tfjs-core/dist/index.js"() {
    init_base_side_effects();
    init_register_optimizers();
    init_base();
    registerOptimizers();
  }
});

// node_modules/@tensorflow/tfjs-backend-cpu/dist/shared.js
var shared_exports = {};
__export(shared_exports, {
  addImpl: () => addImpl,
  bincountImpl: () => bincountImpl,
  bincountReduceImpl: () => bincountReduceImpl,
  bitwiseAndImpl: () => bitwiseAndImpl,
  castImpl: () => castImpl,
  ceilImpl: () => ceilImpl,
  concatImpl: () => concatImpl,
  equalImpl: () => equalImpl,
  expImpl: () => expImpl,
  expm1Impl: () => expm1Impl,
  floorDivImpl: () => floorDivImpl,
  floorImpl: () => floorImpl,
  gatherNdImpl: () => gatherNdImpl,
  gatherV2Impl: () => gatherV2Impl,
  greaterEqualImpl: () => greaterEqualImpl,
  greaterImpl: () => greaterImpl,
  lessEqualImpl: () => lessEqualImpl,
  lessImpl: () => lessImpl,
  linSpaceImpl: () => linSpaceImpl,
  logImpl: () => logImpl,
  maxImpl: () => maxImpl,
  maximumImpl: () => maximumImpl,
  minimumImpl: () => minimumImpl,
  multiplyImpl: () => multiplyImpl,
  negImpl: () => negImpl,
  notEqualImpl: () => notEqualImpl,
  prodImpl: () => prodImpl,
  raggedGatherImpl: () => raggedGatherImpl,
  raggedRangeImpl: () => raggedRangeImpl,
  raggedTensorToTensorImpl: () => raggedTensorToTensorImpl,
  rangeImpl: () => rangeImpl,
  rsqrtImpl: () => rsqrtImpl,
  scatterImpl: () => scatterImpl,
  sigmoidImpl: () => sigmoidImpl,
  simpleAbsImpl: () => simpleAbsImpl,
  sliceImpl: () => sliceImpl,
  sparseFillEmptyRowsImpl: () => sparseFillEmptyRowsImpl,
  sparseReshapeImpl: () => sparseReshapeImpl,
  sparseSegmentReductionImpl: () => sparseSegmentReductionImpl,
  sqrtImpl: () => sqrtImpl,
  squaredDifferenceImpl: () => squaredDifferenceImpl,
  staticRegexReplaceImpl: () => staticRegexReplaceImpl,
  stridedSliceImpl: () => stridedSliceImpl,
  stringNGramsImpl: () => stringNGramsImpl,
  stringSplitImpl: () => stringSplitImpl,
  stringToHashBucketFastImpl: () => stringToHashBucketFastImpl,
  subImpl: () => subImpl,
  tileImpl: () => tileImpl,
  topKImpl: () => topKImpl,
  transposeImpl: () => transposeImpl,
  uniqueImpl: () => uniqueImpl
});

// node_modules/@tensorflow/tfjs-backend-cpu/dist/kernels/Abs.js
init_dist();

// node_modules/@tensorflow/tfjs-backend-cpu/dist/cpu_util.js
init_dist();
function assertNotComplex(tensor2, opName) {
  if (!Array.isArray(tensor2)) {
    tensor2 = [tensor2];
  }
  tensor2.forEach((t) => {
    if (t != null) {
      util_exports.assert(t.dtype !== "complex64", () => `${opName} does not support complex64 tensors in the CPU backend.`);
    }
  });
}

// node_modules/@tensorflow/tfjs-backend-cpu/dist/kernels/Abs.js
function simpleAbsImpl(vals) {
  const resultValues = new Float32Array(vals.length);
  for (let i = 0; i < vals.length; ++i) {
    resultValues[i] = Math.abs(vals[i]);
  }
  return resultValues;
}
var abs2 = (args) => {
  const {
    x
  } = args.inputs;
  const cpuBackend = args.backend;
  assertNotComplex(x, "abs");
  let resultValues = new Float32Array(util_exports.sizeFromShape(x.shape));
  const values = cpuBackend.data.get(x.dataId).values;
  resultValues = simpleAbsImpl(values);
  return cpuBackend.makeOutput(resultValues, x.shape, x.dtype);
};
var absConfig = {
  kernelName: Abs,
  backendName: "cpu",
  kernelFunc: abs2
};

// node_modules/@tensorflow/tfjs-backend-cpu/dist/kernels/Add.js
init_dist();

// node_modules/@tensorflow/tfjs-backend-cpu/dist/utils/binary_impl.js
init_dist();
function createSimpleBinaryKernelImpl(op2) {
  return (aShape, bShape, aVals, bVals, dtype) => {
    const newShape = backend_util_exports.assertAndGetBroadcastShape(aShape, bShape);
    const resultRank = newShape.length;
    const resultStrides = util_exports.computeStrides(newShape);
    const resultSize = util_exports.sizeFromShape(newShape);
    const result = util_exports.getTypedArrayFromDType(dtype, resultSize);
    const aRank = aShape.length;
    const bRank = bShape.length;
    const aStrides = util_exports.computeStrides(aShape);
    const bStrides = util_exports.computeStrides(bShape);
    const aBroadcastDims = backend_util_exports.getBroadcastDims(aShape, newShape);
    const bBroadcastDims = backend_util_exports.getBroadcastDims(bShape, newShape);
    if (aBroadcastDims.length + bBroadcastDims.length === 0) {
      for (let i = 0; i < result.length; ++i) {
        result[i] = op2(aVals[i % aVals.length], bVals[i % bVals.length]);
      }
    } else {
      for (let i = 0; i < result.length; ++i) {
        const loc = util_exports.indexToLoc(i, resultRank, resultStrides);
        const aLoc = loc.slice(-aRank);
        aBroadcastDims.forEach((d) => aLoc[d] = 0);
        const aIndex = util_exports.locToIndex(aLoc, aRank, aStrides);
        const bLoc = loc.slice(-bRank);
        bBroadcastDims.forEach((d) => bLoc[d] = 0);
        const bIndex = util_exports.locToIndex(bLoc, bRank, bStrides);
        result[i] = op2(aVals[aIndex], bVals[bIndex]);
      }
    }
    return [result, newShape];
  };
}

// node_modules/@tensorflow/tfjs-backend-cpu/dist/utils/binary_utils.js
init_dist();

// node_modules/@tensorflow/tfjs-backend-cpu/dist/kernels/Cast.js
init_dist();

// node_modules/@tensorflow/tfjs-backend-cpu/dist/utils/zeros_impl.js
init_dist();

// node_modules/@tensorflow/tfjs-backend-cpu/dist/kernels/Complex.js
init_dist();
function complex2(args) {
  const {
    inputs,
    backend: backend2
  } = args;
  const {
    real: real3,
    imag: imag2
  } = inputs;
  const realVals = backend2.data.get(real3.dataId).values;
  const imagVals = backend2.data.get(imag2.dataId).values;
  const complexInfo = backend2.makeTensorInfo(real3.shape, "complex64");
  const complex3 = backend2.data.get(complexInfo.dataId);
  complex3.complexTensorInfos = {
    real: backend2.makeTensorInfo(real3.shape, "float32", realVals),
    imag: backend2.makeTensorInfo(imag2.shape, "float32", imagVals)
  };
  return complexInfo;
}
var complexConfig = {
  kernelName: Complex,
  backendName: "cpu",
  kernelFunc: complex2
};

// node_modules/@tensorflow/tfjs-backend-cpu/dist/utils/zeros_impl.js
function zeros2(backend2, shape, dtype = "float32") {
  if (dtype === "complex64") {
    const real3 = zeros2(backend2, shape, "float32");
    const imag2 = zeros2(backend2, shape, "float32");
    return complex2({
      inputs: {
        real: real3,
        imag: imag2
      },
      backend: backend2
    });
  }
  const values = util_exports.makeZerosTypedArray(util_exports.sizeFromShape(shape), dtype);
  return backend2.makeTensorInfo(shape, dtype, values);
}

// node_modules/@tensorflow/tfjs-backend-cpu/dist/kernels/Identity.js
init_dist();
function identity(args) {
  const {
    inputs,
    backend: backend2
  } = args;
  const {
    x
  } = inputs;
  backend2.incRef(x.dataId);
  return {
    dataId: x.dataId,
    shape: x.shape,
    dtype: x.dtype
  };
}
var identityConfig = {
  kernelName: Identity,
  backendName: "cpu",
  kernelFunc: identity
};

// node_modules/@tensorflow/tfjs-backend-cpu/dist/kernels/Real.js
init_dist();
function real2(args) {
  const {
    inputs,
    backend: backend2
  } = args;
  const {
    input
  } = inputs;
  const real3 = backend2.data.get(input.dataId).complexTensorInfos.real;
  const realVal = backend2.data.get(real3.dataId).values;
  return backend2.makeTensorInfo(real3.shape, real3.dtype, realVal);
}
var realConfig = {
  kernelName: Real,
  backendName: "cpu",
  kernelFunc: real2
};

// node_modules/@tensorflow/tfjs-backend-cpu/dist/kernels/Cast.js
function castImpl(values, shape, inputType, dtype) {
  if (dtype === "int32") {
    const resultValues = Int32Array.from(values);
    return [shape, "int32", resultValues];
  }
  if (dtype === "bool") {
    const zero = util_exports.toTypedArray([0], inputType);
    const [resultData, resultShape] = createSimpleBinaryKernelImpl((a, b) => a !== b ? 1 : 0)(shape, [], values, zero, "bool");
    return [resultShape, "bool", resultData];
  }
  throw new Error(`Error in Cast: failed to cast ${inputType} to ${dtype}`);
}
function cast2(args) {
  const {
    inputs,
    backend: backend2,
    attrs
  } = args;
  const {
    x
  } = inputs;
  const {
    dtype
  } = attrs;
  if (dtype === "complex64") {
    if (x.dtype === "complex64") {
      return identity({
        inputs: {
          x
        },
        backend: backend2
      });
    }
    const zerosTensorInfo = zeros2(backend2, x.shape, x.dtype);
    const floatX = cast2({
      inputs: {
        x
      },
      backend: backend2,
      attrs: {
        dtype: "float32"
      }
    });
    const result = complex2({
      inputs: {
        real: floatX,
        imag: zerosTensorInfo
      },
      backend: backend2
    });
    backend2.disposeIntermediateTensorInfo(zerosTensorInfo);
    backend2.disposeIntermediateTensorInfo(floatX);
    return result;
  }
  if (x.dtype === "complex64") {
    const realPart = real2({
      inputs: {
        input: x
      },
      backend: backend2
    });
    const result = cast2({
      inputs: {
        x: realPart
      },
      backend: backend2,
      attrs: {
        dtype
      }
    });
    backend2.disposeIntermediateTensorInfo(realPart);
    return result;
  }
  if (!util_exports.hasEncodingLoss(x.dtype, dtype)) {
    const result = identity({
      inputs: {
        x
      },
      backend: backend2
    });
    return {
      dataId: result.dataId,
      shape: result.shape,
      dtype
    };
  }
  const values = backend2.data.get(x.dataId).values;
  const [resultShape, resultType, resultData] = castImpl(values, x.shape, x.dtype, dtype);
  return backend2.makeTensorInfo(resultShape, resultType, resultData);
}
var castConfig = {
  kernelName: Cast,
  backendName: "cpu",
  kernelFunc: cast2
};

// node_modules/@tensorflow/tfjs-backend-cpu/dist/utils/binary_utils.js
function binaryKernelFunc(name, simpleImpl, complexImpl, dtype) {
  if (complexImpl == null) {
    return ({
      inputs,
      backend: backend2
    }) => {
      const {
        a,
        b
      } = inputs;
      const cpuBackend = backend2;
      assertNotComplex([a, b], name);
      const aVals = cpuBackend.data.get(a.dataId).values;
      const bVals = cpuBackend.data.get(b.dataId).values;
      const decodedAVals = a.dtype === "string" ? (
        // tslint:disable-next-line: no-any
        backend_util_exports.fromUint8ToStringArray(aVals)
      ) : aVals;
      const decodedBVals = a.dtype === "string" ? (
        // tslint:disable-next-line: no-any
        backend_util_exports.fromUint8ToStringArray(bVals)
      ) : bVals;
      const $dtype = dtype || a.dtype;
      const [resultData, resultShape] = simpleImpl(a.shape, b.shape, decodedAVals, decodedBVals, $dtype);
      return cpuBackend.makeTensorInfo(resultShape, $dtype, resultData);
    };
  }
  return ({
    inputs,
    backend: backend2
  }) => {
    const {
      a,
      b
    } = inputs;
    const cpuBackend = backend2;
    if (a.dtype === "complex64" || b.dtype === "complex64") {
      const $aComplex = cast2({
        inputs: {
          x: a
        },
        backend: cpuBackend,
        attrs: {
          dtype: "complex64"
        }
      });
      const $aComplexVals = cpuBackend.data.get($aComplex.dataId);
      const aReal = $aComplexVals.complexTensorInfos.real;
      const aImag = $aComplexVals.complexTensorInfos.imag;
      const aRealVals = cpuBackend.data.get(aReal.dataId).values;
      const aImagVals = cpuBackend.data.get(aImag.dataId).values;
      const $bComplex = cast2({
        inputs: {
          x: b
        },
        backend: cpuBackend,
        attrs: {
          dtype: "complex64"
        }
      });
      const $bComplexVals = cpuBackend.data.get($bComplex.dataId);
      const bReal = $bComplexVals.complexTensorInfos.real;
      const bImag = $bComplexVals.complexTensorInfos.imag;
      const bRealVals = cpuBackend.data.get(bReal.dataId).values;
      const bImagVals = cpuBackend.data.get(bImag.dataId).values;
      const [resultRealData, resultImagData, resultShape] = complexImpl(a.shape, b.shape, aRealVals, aImagVals, bRealVals, bImagVals);
      const resultReal = cpuBackend.makeTensorInfo(resultShape, "float32", resultRealData);
      const resultImag = cpuBackend.makeTensorInfo(resultShape, "float32", resultImagData);
      const result = complex2({
        inputs: {
          real: resultReal,
          imag: resultImag
        },
        backend: cpuBackend
      });
      cpuBackend.disposeIntermediateTensorInfo($aComplex);
      cpuBackend.disposeIntermediateTensorInfo($bComplex);
      cpuBackend.disposeIntermediateTensorInfo(resultReal);
      cpuBackend.disposeIntermediateTensorInfo(resultImag);
      return result;
    } else {
      const aVals = cpuBackend.data.get(a.dataId).values;
      const bVals = cpuBackend.data.get(b.dataId).values;
      const $dtype = dtype || a.dtype;
      const [resultData, resultShape] = simpleImpl(a.shape, b.shape, aVals, bVals, $dtype);
      return cpuBackend.makeTensorInfo(resultShape, $dtype, resultData);
    }
  };
}
function createComplexBinaryKernelImpl(op2) {
  return (aShape, bShape, aRealVals, aImagVals, bRealVals, bImagVals) => {
    const resultShape = backend_util_exports.assertAndGetBroadcastShape(aShape, bShape);
    const resultSize = util_exports.sizeFromShape(resultShape);
    const resultRank = resultShape.length;
    const resultStrides = util_exports.computeStrides(resultShape);
    const resultRealVals = util_exports.getTypedArrayFromDType("float32", resultSize);
    const resultImagVals = util_exports.getTypedArrayFromDType("float32", resultSize);
    const aBroadcastDims = backend_util_exports.getBroadcastDims(aShape, resultShape);
    const bBroadcastDims = backend_util_exports.getBroadcastDims(bShape, resultShape);
    const aVals = backend_util_exports.mergeRealAndImagArrays(aRealVals, aImagVals);
    const bVals = backend_util_exports.mergeRealAndImagArrays(bRealVals, bImagVals);
    const aRank = aShape.length;
    const aStrides = util_exports.computeStrides(aShape);
    const bRank = bShape.length;
    const bStrides = util_exports.computeStrides(bShape);
    if (aBroadcastDims.length + bBroadcastDims.length === 0) {
      for (let i = 0; i < resultRealVals.length; i++) {
        const aIdx = i % aVals.length;
        const bIdx = i % bVals.length;
        const result = op2(aVals[aIdx * 2], aVals[aIdx * 2 + 1], bVals[bIdx * 2], bVals[bIdx * 2 + 1]);
        resultRealVals[i] = result.real;
        resultImagVals[i] = result.imag;
      }
    } else {
      for (let i = 0; i < resultRealVals.length; i++) {
        const loc = util_exports.indexToLoc(i, resultRank, resultStrides);
        const aLoc = loc.slice(-aRank);
        aBroadcastDims.forEach((d) => aLoc[d] = 0);
        const aIndex = util_exports.locToIndex(aLoc, aRank, aStrides);
        const bLoc = loc.slice(-bRank);
        bBroadcastDims.forEach((d) => bLoc[d] = 0);
        const bIndex = util_exports.locToIndex(bLoc, bRank, bStrides);
        const opResult = op2(aVals[aIndex * 2], aVals[aIndex * 2 + 1], bVals[bIndex * 2], bVals[bIndex * 2 + 1]);
        resultRealVals[i] = opResult.real;
        resultImagVals[i] = opResult.imag;
      }
    }
    return [resultRealVals, resultImagVals, resultShape];
  };
}

// node_modules/@tensorflow/tfjs-backend-cpu/dist/kernels/Add.js
var addImpl = createSimpleBinaryKernelImpl((a, b) => a + b);
var addComplexImpl = createComplexBinaryKernelImpl((aReal, aImag, bReal, bImag) => {
  return {
    real: aReal + bReal,
    imag: aImag + bImag
  };
});
var add3 = binaryKernelFunc(Add, addImpl, addComplexImpl);
var addConfig = {
  kernelName: Add,
  backendName: "cpu",
  kernelFunc: add3
};

// node_modules/@tensorflow/tfjs-backend-cpu/dist/kernels/Bincount_impl.js
init_dist();
function bincountImpl(xVals, weightsVals, weightsDtype, weightsShape, size) {
  const weightsSize = util_exports.sizeFromShape(weightsShape);
  const outVals = util_exports.makeZerosTypedArray(size, weightsDtype);
  for (let i = 0; i < xVals.length; i++) {
    const value = xVals[i];
    if (value < 0) {
      throw new Error("Input x must be non-negative!");
    }
    if (value >= size) {
      continue;
    }
    if (weightsSize > 0) {
      outVals[value] += weightsVals[i];
    } else {
      outVals[value] += 1;
    }
  }
  return outVals;
}
function bincountReduceImpl(xBuf, weightsBuf, size, binaryOutput = false) {
  const numRows = xBuf.shape[0];
  const numCols = xBuf.shape[1];
  const outBuf = buffer([numRows, size], weightsBuf.dtype);
  for (let i = 0; i < numRows; i++) {
    for (let j = 0; j < numCols; j++) {
      const value = xBuf.get(i, j);
      if (value < 0) {
        throw new Error("Input x must be non-negative!");
      }
      if (value >= size) {
        continue;
      }
      if (binaryOutput) {
        outBuf.set(1, i, value);
      } else {
        if (weightsBuf.size > 0) {
          outBuf.set(outBuf.get(i, value) + weightsBuf.get(i, j), i, value);
        } else {
          outBuf.set(outBuf.get(i, value) + 1, i, value);
        }
      }
    }
  }
  return outBuf;
}

// node_modules/@tensorflow/tfjs-backend-cpu/dist/kernels/BitwiseAnd.js
init_dist();
var bitwiseAndImpl = createSimpleBinaryKernelImpl((a, b) => a & b);
var bitwiseAnd2 = binaryKernelFunc(BitwiseAnd, bitwiseAndImpl);
var bitwiseAndConfig = {
  kernelName: BitwiseAnd,
  backendName: "cpu",
  kernelFunc: bitwiseAnd2
};

// node_modules/@tensorflow/tfjs-backend-cpu/dist/kernels/Ceil.js
init_dist();

// node_modules/@tensorflow/tfjs-backend-cpu/dist/utils/unary_impl.js
init_dist();
function createSimpleUnaryImpl(op2) {
  return (values, dtype, attrs) => {
    const newValues = util_exports.getArrayFromDType(dtype, values.length);
    for (let i = 0; i < values.length; ++i) {
      newValues[i] = op2(values[i], attrs);
    }
    return newValues;
  };
}

// node_modules/@tensorflow/tfjs-backend-cpu/dist/utils/unary_utils.js
init_dist();
function unaryKernelFunc(name, op2, dtype) {
  const impl = createSimpleUnaryImpl(op2);
  return unaryKernelFuncFromImpl(name, impl, dtype);
}
function unaryKernelFuncFromImpl(name, unaryImpl, dtype) {
  return ({
    inputs,
    attrs,
    backend: backend2
  }) => {
    const {
      x
    } = inputs;
    assertNotComplex(x, name);
    const cpuBackend = backend2;
    const values = cpuBackend.data.get(x.dataId).values;
    let decoded;
    if (x.dtype === "string") {
      if (!Array.isArray(values)) {
        throw new Error("String tensor's value was not an instance of Array");
      }
      decoded = backend_util_exports.fromUint8ToStringArray(values);
    } else {
      decoded = values;
    }
    const $dtype = dtype || x.dtype;
    const newValues = unaryImpl(decoded, $dtype, attrs);
    return cpuBackend.makeTensorInfo(x.shape, $dtype, newValues);
  };
}

// node_modules/@tensorflow/tfjs-backend-cpu/dist/kernels/Ceil.js
var ceilImpl = createSimpleUnaryImpl((xi) => Math.ceil(xi));
var ceil2 = unaryKernelFuncFromImpl(Ceil, ceilImpl);
var ceilConfig = {
  kernelName: Ceil,
  backendName: "cpu",
  kernelFunc: ceil2
};

// node_modules/@tensorflow/tfjs-backend-cpu/dist/kernels/Concat_impl.js
init_dist();
function concatImpl(inputs, outShape, dtype, simplyConcat) {
  const outVals = util_exports.getArrayFromDType(dtype, util_exports.sizeFromShape(outShape));
  if (simplyConcat && dtype !== "string") {
    let offset = 0;
    inputs.forEach((input) => {
      const size = util_exports.sizeFromShape(input.shape);
      outVals.set(input.vals, offset);
      offset += size;
    });
  } else {
    let colOffset = 0;
    inputs.forEach((input) => {
      const decodedData = dtype === "string" ? backend_util_exports.fromUint8ToStringArray(input.vals) : input.vals;
      let tIdx = 0;
      for (let row = 0; row < input.shape[0]; ++row) {
        const resIdx = row * outShape[1] + colOffset;
        for (let col = 0; col < input.shape[1]; ++col) {
          outVals[resIdx + col] = decodedData[tIdx++];
        }
      }
      colOffset += input.shape[1];
    });
  }
  return outVals;
}

// node_modules/@tensorflow/tfjs-backend-cpu/dist/kernels/Equal.js
init_dist();
var equalImpl = createSimpleBinaryKernelImpl((a, b) => a === b ? 1 : 0);
var equal2 = binaryKernelFunc(Equal, equalImpl, null, "bool");
var equalConfig = {
  kernelName: Equal,
  backendName: "cpu",
  kernelFunc: equal2
};

// node_modules/@tensorflow/tfjs-backend-cpu/dist/kernels/Exp.js
init_dist();
var expImpl = createSimpleUnaryImpl((xi) => Math.exp(xi));
var exp2 = unaryKernelFuncFromImpl(Exp, expImpl, "float32");
var expConfig = {
  kernelName: Exp,
  backendName: "cpu",
  kernelFunc: exp2
};

// node_modules/@tensorflow/tfjs-backend-cpu/dist/kernels/Expm1.js
init_dist();
var expm1Impl = createSimpleUnaryImpl((xi) => Math.expm1(xi));
var expm12 = unaryKernelFuncFromImpl(Expm1, expm1Impl);
var expm1Config = {
  kernelName: Expm1,
  backendName: "cpu",
  kernelFunc: expm12
};

// node_modules/@tensorflow/tfjs-backend-cpu/dist/kernels/Floor.js
init_dist();
var floorImpl = createSimpleUnaryImpl((xi) => Math.floor(xi));
var floor2 = unaryKernelFuncFromImpl(Floor, floorImpl);
var floorConfig = {
  kernelName: Floor,
  backendName: "cpu",
  kernelFunc: floor2
};

// node_modules/@tensorflow/tfjs-backend-cpu/dist/kernels/FloorDiv.js
init_dist();
var floorDivImpl = createSimpleBinaryKernelImpl((a, b) => Math.floor(a / b));
var floorDiv2 = binaryKernelFunc(FloorDiv, floorDivImpl, null, "int32");
var floorDivConfig = {
  kernelName: FloorDiv,
  backendName: "cpu",
  kernelFunc: floorDiv2
};

// node_modules/@tensorflow/tfjs-backend-cpu/dist/kernels/GatherNd_Impl.js
init_dist();
function gatherNdImpl(indicesData, paramsBuf, dtype, numSlices, sliceRank, sliceSize, strides, paramsShape, paramsSize) {
  const outBuf = buffer([numSlices, sliceSize], dtype);
  for (let i = 0; i < numSlices; i++) {
    const index = [];
    let flattenIndex = 0;
    for (let j = 0; j < sliceRank; j++) {
      const dim = indicesData[i * sliceRank + j];
      flattenIndex += dim * strides[j];
      index.push(dim);
    }
    if (flattenIndex < 0 || flattenIndex >= paramsSize / sliceSize) {
      throw new Error(`Invalid indices: ${index} does not index into ${paramsShape}`);
    }
    for (let k = 0; k < sliceSize; k++) {
      outBuf.values[i * sliceSize + k] = paramsBuf.get(...paramsBuf.indexToLoc(flattenIndex * sliceSize + k));
    }
  }
  return outBuf;
}

// node_modules/@tensorflow/tfjs-backend-cpu/dist/kernels/GatherV2_impl.js
init_dist();
function gatherV2Impl(xBuf, indicesBuf, flattenOutputShape) {
  const outBuf = buffer(flattenOutputShape, xBuf.dtype);
  for (let i = 0; i < outBuf.size; ++i) {
    const newLoc = outBuf.indexToLoc(i);
    const originalLoc = newLoc.slice();
    const batchIdx = originalLoc[0];
    const indicesIdx = originalLoc[2];
    const indicesIndex = indicesBuf.locToIndex([batchIdx, indicesIdx]);
    originalLoc[2] = indicesBuf.values[indicesIndex];
    const originalIndex = xBuf.locToIndex(originalLoc);
    if (0 <= originalIndex && originalIndex < xBuf.values.length) {
      outBuf.values[i] = xBuf.values[originalIndex];
    }
  }
  return outBuf;
}

// node_modules/@tensorflow/tfjs-backend-cpu/dist/kernels/Greater.js
init_dist();
var greaterImpl = createSimpleBinaryKernelImpl((a, b) => a > b ? 1 : 0);
var greater2 = binaryKernelFunc(Greater, greaterImpl, null, "bool");
var greaterConfig = {
  kernelName: Greater,
  backendName: "cpu",
  kernelFunc: greater2
};

// node_modules/@tensorflow/tfjs-backend-cpu/dist/kernels/GreaterEqual.js
init_dist();
var greaterEqualImpl = createSimpleBinaryKernelImpl((a, b) => a >= b ? 1 : 0);
var greaterEqual2 = binaryKernelFunc(GreaterEqual, greaterEqualImpl, null, "bool");
var greaterEqualConfig = {
  kernelName: GreaterEqual,
  backendName: "cpu",
  kernelFunc: greaterEqual2
};

// node_modules/@tensorflow/tfjs-backend-cpu/dist/kernels/Less.js
init_dist();
var lessImpl = createSimpleBinaryKernelImpl((a, b) => a < b ? 1 : 0);
var less2 = binaryKernelFunc(Less, lessImpl, null, "bool");
var lessConfig = {
  kernelName: Less,
  backendName: "cpu",
  kernelFunc: less2
};

// node_modules/@tensorflow/tfjs-backend-cpu/dist/kernels/LessEqual.js
init_dist();
var lessEqualImpl = createSimpleBinaryKernelImpl((a, b) => a <= b ? 1 : 0);
var lessEqual2 = binaryKernelFunc(LessEqual, lessEqualImpl, null, "bool");
var lessEqualConfig = {
  kernelName: LessEqual,
  backendName: "cpu",
  kernelFunc: lessEqual2
};

// node_modules/@tensorflow/tfjs-backend-cpu/dist/kernels/LinSpace_impl.js
init_dist();
function linSpaceImpl(start, stop, num) {
  const step2 = (stop - start) / (num - 1);
  const values = util_exports.makeZerosTypedArray(num, "float32");
  values[0] = start;
  for (let i = 1; i < values.length; i++) {
    values[i] = values[i - 1] + step2;
  }
  return values;
}

// node_modules/@tensorflow/tfjs-backend-cpu/dist/kernels/Log.js
init_dist();
var logImpl = createSimpleUnaryImpl((xi) => Math.log(xi));
var log3 = unaryKernelFuncFromImpl(Log, logImpl);
var logConfig = {
  kernelName: Log,
  backendName: "cpu",
  kernelFunc: log3
};

// node_modules/@tensorflow/tfjs-backend-cpu/dist/kernels/Max_impl.js
init_dist();
function maxImpl(aVals, reduceSize, outShape, dtype) {
  const vals = util_exports.getTypedArrayFromDType(dtype, util_exports.sizeFromShape(outShape));
  for (let i = 0; i < vals.length; ++i) {
    const offset = i * reduceSize;
    let max2 = aVals[offset];
    for (let j = 0; j < reduceSize; ++j) {
      const value = aVals[offset + j];
      if (Number.isNaN(value) || value > max2) {
        max2 = value;
      }
    }
    vals[i] = max2;
  }
  return vals;
}

// node_modules/@tensorflow/tfjs-backend-cpu/dist/kernels/Maximum.js
init_dist();
var maximumImpl = createSimpleBinaryKernelImpl((aValue, bValue) => Math.max(aValue, bValue));
var maximum2 = binaryKernelFunc(Maximum, maximumImpl);
var maximumConfig = {
  kernelName: Maximum,
  backendName: "cpu",
  kernelFunc: maximum2
};

// node_modules/@tensorflow/tfjs-backend-cpu/dist/kernels/Minimum.js
init_dist();
var minimumImpl = createSimpleBinaryKernelImpl((aValue, bValue) => Math.min(aValue, bValue));
var minimum2 = binaryKernelFunc(Minimum, minimumImpl);
var minimumConfig = {
  kernelName: Minimum,
  backendName: "cpu",
  kernelFunc: minimum2
};

// node_modules/@tensorflow/tfjs-backend-cpu/dist/kernels/Multiply.js
init_dist();
var multiplyImpl = createSimpleBinaryKernelImpl((aValue, bValue) => aValue * bValue);
var multiplyComplexImpl = createComplexBinaryKernelImpl((aReal, aImag, bReal, bImag) => {
  return {
    real: aReal * bReal - aImag * bImag,
    imag: aReal * bImag + aImag * bReal
  };
});
var multiply = binaryKernelFunc(Multiply, multiplyImpl, multiplyComplexImpl);
var multiplyConfig = {
  kernelName: Multiply,
  backendName: "cpu",
  kernelFunc: multiply
};

// node_modules/@tensorflow/tfjs-backend-cpu/dist/kernels/Neg.js
init_dist();
function negImpl(xVals, xShape, xDtype) {
  const minusOne = util_exports.createScalarValue(-1, xDtype);
  return multiplyImpl([], xShape, minusOne, xVals, xDtype);
}
function neg2(args) {
  const {
    inputs,
    backend: backend2
  } = args;
  const {
    x
  } = inputs;
  assertNotComplex(x, "neg");
  const xVals = backend2.data.get(x.dataId).values;
  const [res, newShape] = negImpl(xVals, x.shape, x.dtype);
  return backend2.makeTensorInfo(newShape, x.dtype, res);
}
var negConfig = {
  kernelName: Neg,
  backendName: "cpu",
  kernelFunc: neg2
};

// node_modules/@tensorflow/tfjs-backend-cpu/dist/kernels/NotEqual.js
init_dist();
var notEqualImpl = createSimpleBinaryKernelImpl((a, b) => a !== b ? 1 : 0);
var notEqual2 = binaryKernelFunc(NotEqual, notEqualImpl, null, "bool");
var notEqualConfig = {
  kernelName: NotEqual,
  backendName: "cpu",
  kernelFunc: notEqual2
};

// node_modules/@tensorflow/tfjs-backend-cpu/dist/kernels/Prod.js
init_dist();

// node_modules/@tensorflow/tfjs-backend-cpu/dist/kernels/Transpose.js
init_dist();

// node_modules/@tensorflow/tfjs-backend-cpu/dist/kernels/Transpose_impl.js
init_dist();
function transposeImpl(xVals, xShape, dtype, perm, newShape) {
  const xRank = xShape.length;
  const xSize = util_exports.sizeFromShape(xShape);
  const xStrides = util_exports.computeStrides(xShape);
  const newStrides = util_exports.computeStrides(newShape);
  const result = util_exports.getTypedArrayFromDType(dtype, util_exports.sizeFromShape(newShape));
  for (let i = 0; i < xSize; ++i) {
    const loc = util_exports.indexToLoc(i, xRank, xStrides);
    const newLoc = new Array(loc.length);
    for (let i2 = 0; i2 < newLoc.length; i2++) {
      newLoc[i2] = loc[perm[i2]];
    }
    const newIndex = util_exports.locToIndex(newLoc, xRank, newStrides);
    result[newIndex] = xVals[i];
  }
  return result;
}

// node_modules/@tensorflow/tfjs-backend-cpu/dist/kernels/Transpose.js
function transpose2(args) {
  const {
    inputs,
    attrs,
    backend: backend2
  } = args;
  const {
    x
  } = inputs;
  const {
    perm
  } = attrs;
  assertNotComplex(x, "transpose");
  const xRank = x.shape.length;
  const newShape = new Array(xRank);
  for (let i = 0; i < newShape.length; i++) {
    newShape[i] = x.shape[perm[i]];
  }
  const values = backend2.data.get(x.dataId).values;
  const result = transposeImpl(values, x.shape, x.dtype, perm, newShape);
  const dataId = backend2.write(result, newShape, x.dtype);
  return {
    dataId,
    shape: newShape,
    dtype: x.dtype
  };
}
var transposeConfig = {
  kernelName: Transpose,
  backendName: "cpu",
  kernelFunc: transpose2
};

// node_modules/@tensorflow/tfjs-backend-cpu/dist/kernels/Prod.js
function prodImpl(xShape, xDtype, xVals, reductionAxes) {
  const [outShape, reduceShape] = backend_util_exports.computeOutAndReduceShapes(xShape, reductionAxes);
  const outDtype = upcastType(xDtype, "int32");
  const outVals = util_exports.makeZerosTypedArray(util_exports.sizeFromShape(outShape), outDtype);
  const reduceSize = util_exports.sizeFromShape(reduceShape);
  for (let i = 0; i < outVals.length; ++i) {
    const offset = i * reduceSize;
    let prod3 = 1;
    for (let j = 0; j < reduceSize; ++j) {
      prod3 *= xVals[offset + j];
    }
    outVals[i] = prod3;
  }
  return {
    outVals,
    outShape,
    outDtype
  };
}
function prod2(args) {
  const {
    inputs,
    backend: backend2,
    attrs
  } = args;
  const {
    x
  } = inputs;
  const {
    axis,
    keepDims
  } = attrs;
  assertNotComplex(x, "prod");
  const xRank = x.shape.length;
  const axes = util_exports.parseAxisParam(axis, x.shape);
  const permutation = backend_util_exports.getAxesPermutation(axes, xRank);
  let reductionAxes = axes;
  let permutedX = x;
  const intermediateTensorInfos = [];
  if (permutation != null) {
    permutedX = transpose2({
      inputs: {
        x
      },
      backend: backend2,
      attrs: {
        perm: permutation
      }
    });
    intermediateTensorInfos.push(permutedX);
    reductionAxes = backend_util_exports.getInnerMostAxes(reductionAxes.length, xRank);
  }
  const xVals = backend2.data.get(permutedX.dataId).values;
  const {
    outVals,
    outShape,
    outDtype
  } = prodImpl(permutedX.shape, permutedX.dtype, xVals, reductionAxes);
  let resultShape = outShape;
  if (keepDims) {
    resultShape = backend_util_exports.expandShapeToKeepDim(outShape, axes);
  }
  intermediateTensorInfos.forEach((t) => backend2.disposeIntermediateTensorInfo(t));
  return backend2.makeTensorInfo(resultShape, outDtype, outVals);
}
var prodConfig = {
  kernelName: Prod,
  backendName: "cpu",
  kernelFunc: prod2
};

// node_modules/@tensorflow/tfjs-backend-cpu/dist/kernels/RaggedGather_impl.js
init_dist();
function validateIndices(indices, indicesShape, numParams) {
  indices.forEach((index, i) => {
    if (index < 0 || index >= numParams) {
      const locString = util_exports.indexToLoc(i, indicesShape.length, util_exports.computeStrides(indicesShape)).join(",");
      throw new Error(`indices[${locString}] = ${index} is not in [0, ${numParams})`);
    }
  });
}
function validateSplits(paramsNestedSplits, numParamsDenseValues) {
  for (let dim = 0; dim < paramsNestedSplits.length; ++dim) {
    const splits = paramsNestedSplits[dim];
    const lastSplit = dim === paramsNestedSplits.length - 1 ? numParamsDenseValues : paramsNestedSplits[dim + 1].length;
    if (splits.length === 0) {
      throw new Error("Ragged splits may not be empty");
    }
    if (splits[0] < 0) {
      throw new Error("Ragged splits must be non-negative");
    }
    if (splits[splits.length - 1] > lastSplit) {
      throw new Error("Ragged splits must not point past values");
    }
    for (let i = 1; i < splits.length; ++i) {
      if (splits[i - 1] > splits[i]) {
        throw new Error("Ragged splits must be sorted in ascending order");
      }
    }
  }
}
function makeSplits(indices, indicesShape, paramsNestedSplits, numParamsDenseValues) {
  const valueSlices = [];
  let numValues = 0;
  const numSplits = indicesShape.length - 1 + paramsNestedSplits.length;
  const outSplits = new Array(numSplits).fill(null).map(() => [0]);
  validateSplits(paramsNestedSplits, numParamsDenseValues);
  let nrows = 1;
  for (let dim = 0; dim < indicesShape.length - 1; ++dim) {
    nrows *= indicesShape[dim];
    const rowLength = indicesShape[dim + 1];
    for (let i = 1; i < nrows + 1; ++i) {
      outSplits[dim].push(i * rowLength);
    }
  }
  for (let i = 0; i < indices.length; ++i) {
    let start = indices[i];
    let limit = indices[i] + 1;
    for (let dim = 0; dim < paramsNestedSplits.length; ++dim) {
      const splits = paramsNestedSplits[dim];
      const outDim = dim + indicesShape.length - 1;
      if (outDim >= 0) {
        const outSplitsOutDim = outSplits[outDim];
        const delta = outSplitsOutDim[outSplitsOutDim.length - 1] - splits[start];
        for (let j = start; j < limit; ++j) {
          outSplits[outDim].push(splits[j + 1] + delta);
        }
      }
      start = splits[start];
      limit = splits[limit];
    }
    if (limit !== start) {
      valueSlices.push([start, limit]);
      numValues += limit - start;
    }
  }
  return {
    outSplits,
    valueSlices,
    numValues
  };
}
function getSplits(outSplits) {
  const splitsOut = [];
  for (let i = 0; i < outSplits.length; ++i) {
    const numSplits = outSplits[i].length;
    const splits = util_exports.getArrayFromDType("int32", numSplits);
    splitsOut.push(splits);
    outSplits[i].forEach((value, j) => splits[j] = value);
  }
  return splitsOut;
}
function computeFlatOuterDims(orig, numOutDims) {
  const outDims = orig.slice(0, numOutDims);
  while (outDims.length < numOutDims) {
    outDims.push(1);
  }
  for (let inDim = numOutDims; inDim < orig.length; inDim++) {
    outDims[numOutDims - 1] *= orig[inDim];
  }
  return outDims;
}
function writeValueSlices(paramsDenseValues, paramsDenseValuesShape, valueSlices, valueSize, values, valuesShape) {
  const denseM = computeFlatOuterDims(paramsDenseValuesShape, 2)[1];
  const valuesM = computeFlatOuterDims(valuesShape, 2)[1];
  let outPos = 0;
  for (const slice3 of valueSlices) {
    for (let i = slice3[0]; i < slice3[1]; ++i) {
      for (let j = 0; j < valueSize; ++j) {
        values[outPos * valuesM + j] = paramsDenseValues[i * denseM + j];
      }
      ++outPos;
    }
  }
}
function getValues(paramsDenseValues, paramsDenseValuesShape, paramsDenseValuesDType, valueSlices, numValues) {
  const valuesShape = paramsDenseValuesShape.slice();
  valuesShape[0] = numValues;
  const valuesOut = util_exports.getArrayFromDType(paramsDenseValuesDType, util_exports.sizeFromShape(valuesShape));
  const numElements = paramsDenseValues.length;
  const valueSize = numElements === 0 ? 0 : numElements / paramsDenseValuesShape[0];
  writeValueSlices(paramsDenseValues, paramsDenseValuesShape, valueSlices, valueSize, valuesOut, valuesShape);
  return [valuesOut, valuesShape];
}
function raggedGatherImpl(paramsNestedSplits, paramsNestedSplitsShapes, paramsDenseValues, paramsDenseValuesShape, paramsDenseValuesDType, indices, indicesShape, outputRaggedRank) {
  if (paramsNestedSplits.length === 0) {
    throw new Error("paramsNestedSplits must be non empty");
  }
  if (paramsNestedSplitsShapes[0].length === 0) {
    throw new Error("Split tensors must not be scalars");
  }
  const numParams = paramsNestedSplitsShapes[0][0] - 1;
  validateIndices(indices, indicesShape, numParams);
  if (paramsDenseValuesShape.length === 0) {
    throw new Error("params.rank must be nonzero");
  }
  const numParamsDenseValues = paramsDenseValuesShape[0];
  const {
    outSplits,
    valueSlices,
    numValues
  } = makeSplits(indices, indicesShape, paramsNestedSplits, numParamsDenseValues);
  const outputNestedSplits = getSplits(outSplits);
  const outputDenseValues = getValues(paramsDenseValues, paramsDenseValuesShape, paramsDenseValuesDType, valueSlices, numValues);
  return [outputNestedSplits, outputDenseValues[0], outputDenseValues[1]];
}

// node_modules/@tensorflow/tfjs-backend-cpu/dist/kernels/RaggedRange_impl.js
init_dist();
var INT32_MAX2 = 2147483647;
function raggedRangeImpl(starts, startsShape, startsDType, limits, limitsShape, deltas, deltasShape) {
  if (startsShape.length > 1) {
    throw new Error("starts must be a scalar or vector");
  }
  if (limitsShape.length > 1) {
    throw new Error("limits must be a scalar or vector");
  }
  if (deltasShape.length > 1) {
    throw new Error("deltas must be a scalar or vector");
  }
  const broadcastStarts = startsShape.length === 0;
  const broadcastLimits = limitsShape.length === 0;
  const broadcastDeltas = deltasShape.length === 0;
  const inSizes = [];
  if (!broadcastStarts) {
    inSizes.push(startsShape[0]);
  }
  if (!broadcastLimits) {
    inSizes.push(limitsShape[0]);
  }
  if (!broadcastDeltas) {
    inSizes.push(deltasShape[0]);
  }
  for (let i = 1; i < inSizes.length; ++i) {
    if (inSizes[i] !== inSizes[i - 1]) {
      throw new Error("starts, limits, and deltas must have the same shape");
    }
  }
  const nRows = inSizes.length === 0 ? 1 : inSizes[0];
  const rtNestedSplits = util_exports.getArrayFromDType("int32", nRows + 1);
  rtNestedSplits[0] = 0;
  for (let row = 0; row < nRows; ++row) {
    const start = broadcastStarts ? starts[0] : starts[row];
    const limit = broadcastLimits ? limits[0] : limits[row];
    const delta = broadcastDeltas ? deltas[0] : deltas[row];
    if (delta === 0) {
      throw new Error("Requires delta != 0");
    }
    let size;
    if (delta > 0 && limit < start || delta < 0 && limit > start) {
      size = 0;
    } else {
      size = Math.ceil(Math.abs((limit - start) / delta));
      if (size > INT32_MAX2) {
        throw new Error(`Requires ((limit - start) / delta) <= ${INT32_MAX2}`);
      }
    }
    rtNestedSplits[row + 1] = rtNestedSplits[row] + size;
  }
  const nVals = rtNestedSplits[nRows];
  const rtDenseValues = util_exports.getArrayFromDType(startsDType, nVals);
  let valueIndex = 0;
  for (let row = 0; row < nRows; ++row) {
    const rowSize = rtNestedSplits[row + 1] - rtNestedSplits[row];
    let value = broadcastStarts ? starts[0] : starts[row];
    const delta = broadcastDeltas ? deltas[0] : deltas[row];
    for (let i = 0; i < rowSize; ++i) {
      rtDenseValues[valueIndex++] = value;
      value += delta;
    }
  }
  return [rtNestedSplits, rtDenseValues];
}

// node_modules/@tensorflow/tfjs-backend-cpu/dist/kernels/RaggedTensorToTensor_impl.js
init_dist();
var RowPartitionType2 = backend_util_exports.RowPartitionType;
var RaggedTensorToTensorOp = class _RaggedTensorToTensorOp {
  constructor(shape, shapeShape, values, valuesShape, valuesDType, defaultValue, defaultValueShape, rowPartitionValues, rowPartitionValuesShapes, rowPartitionTypeStrings) {
    this.shape = shape;
    this.shapeShape = shapeShape;
    this.values = values;
    this.valuesShape = valuesShape;
    this.valuesDType = valuesDType;
    this.defaultValue = defaultValue;
    this.defaultValueShape = defaultValueShape;
    this.rowPartitionValues = rowPartitionValues;
    this.rowPartitionValuesShapes = rowPartitionValuesShapes;
    this.rowPartitionTypes = backend_util_exports.getRowPartitionTypesHelper(rowPartitionTypeStrings);
    this.raggedRank = backend_util_exports.getRaggedRank(this.rowPartitionTypes);
  }
  getRowPartitionTypeByDimension(dimension) {
    if (this.rowPartitionTypes[0] === RowPartitionType2.FIRST_DIM_SIZE) {
      return this.rowPartitionTypes[dimension + 1];
    } else {
      return this.rowPartitionTypes[dimension];
    }
  }
  // Returns the relationship between dimension and dimension + 1.
  getRowPartitionTensor(dimension) {
    if (this.rowPartitionTypes[0] === RowPartitionType2.FIRST_DIM_SIZE) {
      return this.rowPartitionValues[dimension + 1];
    } else {
      return this.rowPartitionValues[dimension];
    }
  }
  getMaxWidth(dimension) {
    const rowPartitionTensor = this.getRowPartitionTensor(dimension - 1);
    switch (this.getRowPartitionTypeByDimension(dimension - 1)) {
      case RowPartitionType2.VALUE_ROWIDS:
        return _RaggedTensorToTensorOp.getMaxWidthValueRowID(rowPartitionTensor);
      case RowPartitionType2.ROW_SPLITS:
        return _RaggedTensorToTensorOp.getMaxWidthRowSplit(rowPartitionTensor);
      default:
        throw new Error(`Cannot handle partition type ${RowPartitionType2[this.getRowPartitionTypeByDimension(dimension - 1)]}`);
    }
  }
  static getMaxWidthRowSplit(rowSplit) {
    const tensorLength = rowSplit.length;
    if (tensorLength === 0 || tensorLength === 1) {
      return 0;
    }
    let maxWidth = 0;
    for (let i = 0; i < tensorLength - 1; ++i) {
      const currentWidth = rowSplit[i + 1] - rowSplit[i];
      if (currentWidth > maxWidth) {
        maxWidth = currentWidth;
      }
    }
    return maxWidth;
  }
  static getMaxWidthValueRowID(valueRowIds) {
    const indexLength = valueRowIds.length;
    if (indexLength === 0) {
      return 0;
    }
    let firstEqualIndex = 0;
    let firstEqualIndexValue = valueRowIds[0];
    let maxWidth = 0;
    for (let i = 1; i < indexLength; ++i) {
      const value = valueRowIds[i];
      if (value !== firstEqualIndexValue) {
        firstEqualIndexValue = value;
        maxWidth = Math.max(i - firstEqualIndex, maxWidth);
        firstEqualIndex = i;
      }
    }
    return Math.max(indexLength - firstEqualIndex, maxWidth);
  }
  tensorShapeFromTensor(t, tShape, isPartial = true) {
    if (tShape.length === 0) {
      if (t[0] === -1) {
        return [];
      }
      throw new Error(`The only valid scalar shape tensor is the fully unknown shape specified as -1.`);
    }
    return makeShape(t, isPartial);
  }
  calculateOutputSize(firstDim) {
    const valueShape = this.valuesShape;
    const defaultValueShape = this.defaultValueShape;
    backend_util_exports.validateDefaultValueShape(defaultValueShape, valueShape);
    const shape = this.tensorShapeFromTensor(this.shape, this.shapeShape);
    const outputShape = backend_util_exports.combineRaggedTensorToTensorShapes(this.raggedRank, shape, valueShape);
    const result = outputShape;
    if (result[0] < 0) {
      result[0] = firstDim;
    }
    for (let i = 1; i <= this.raggedRank; ++i) {
      if (result[i] < 0) {
        result[i] = this.getMaxWidth(i);
      }
    }
    return result;
  }
  /**
   * The outputIndex represents the index in the output tensor
   * where the first element of a particular dimension would be written.
   * If it is -1, it indicates that the index is out of scope.
   * Example, given firstDimension = 10, firstDimensionOutput = 6,
   * and outputIndexMultiplier = 100:
   * result = [0 100 200 300 400 500 -1 -1 -1 -1]
   * If firstDimensionOutput = 11 instead, then:
   * result = [0 100 200 300 400 500 600 700 800 900]
   */
  calculateFirstParentOutputIndex(firstDimension, outputIndexMultiplier, firstDimensionOutput) {
    const minDimension = Math.min(firstDimension, firstDimensionOutput);
    const result = [];
    let currentOutputIndex = 0;
    for (let i = 0; i < minDimension; ++i, currentOutputIndex += outputIndexMultiplier) {
      result.push(currentOutputIndex);
    }
    for (let i = minDimension; i < firstDimension; ++i) {
      result.push(-1);
    }
    util_exports.assert(result.length === firstDimension, () => "Final length of result must be equal to firstDimension.");
    return result;
  }
  calculateOutputIndexRowSplit(rowSplit, parentOutputIndex, outputIndexMultiplier, outputSize) {
    const rowSplitSize = rowSplit.length;
    const result = [];
    for (let i = 0; i < rowSplitSize - 1; ++i) {
      const rowLength = rowSplit[i + 1] - rowSplit[i];
      let realLength = Math.min(outputSize, rowLength);
      let parentOutputIndexCurrent = parentOutputIndex[i];
      if (parentOutputIndexCurrent === -1) {
        realLength = 0;
      }
      for (let j = 0; j < realLength; ++j) {
        result.push(parentOutputIndexCurrent);
        parentOutputIndexCurrent += outputIndexMultiplier;
      }
      for (let j = 0; j < rowLength - realLength; ++j) {
        result.push(-1);
      }
    }
    if (rowSplitSize > 0 && result.length !== rowSplit[rowSplitSize - 1]) {
      throw new Error("Invalid row split size.");
    }
    return result;
  }
  // Calculate the output index of the first element of a list.
  // The parentOutputIndex is the same computation for the previous list.
  // -1 indicates an element or list that is out of range.
  // The outputIndexMultiplier is the number of output indices one moves
  // forward for each column.
  // E.g., given:
  // valueRowIds:[0 1 2 2 2 3 5 5 6]
  // parentOutputIndex:[1000 1100 2000 2100 -1 3000 4000]
  // outputIndexMultiplier: 10
  // outputSize: 2
  // You get:
  // result = [1000 1100 2000 2010 -1 2100 -1 -1 3000]
  // result[0] = parentOutputIndex[valueRowIds[0]]
  // result[1] = parentOutputIndex[valueRowIds[1]]
  // result[2] = parentOutputIndex[valueRowIds[2]]
  // result[3] = parentOutputIndex[valueRowIds[2] + 10]
  // result[4] = -1 because it is the third element the size is 2.
  // result[5] = parentOutputIndex[valueRowIds[3]]
  // result[6] = -1 because parentOutputIndex[valueRowIds[6]] == -1
  // result[7] = -1 because parentOutputIndex[valueRowIds[6]] == -1
  // result[8] = parentOutputIndex[valueRowIds[7]]
  calculateOutputIndexValueRowID(valueRowIds, parentOutputIndex, outputIndexMultiplier, outputSize) {
    const indexSize = valueRowIds.length;
    const result = [];
    if (indexSize === 0) {
      return [];
    }
    let currentOutputColumn = 0;
    let currentValueRowId = valueRowIds[0];
    if (currentValueRowId >= parentOutputIndex.length) {
      throw new Error(`Got currentValueRowId=${currentValueRowId}, which is not less than ${parentOutputIndex.length}`);
    }
    let currentOutputIndex = parentOutputIndex[currentValueRowId];
    result.push(currentOutputIndex);
    for (let i = 1; i < indexSize; ++i) {
      const nextValueRowId = valueRowIds[i];
      if (nextValueRowId === currentValueRowId) {
        if (currentOutputIndex >= 0) {
          ++currentOutputColumn;
          if (currentOutputColumn < outputSize) {
            currentOutputIndex += outputIndexMultiplier;
          } else {
            currentOutputIndex = -1;
          }
        }
      } else {
        currentOutputColumn = 0;
        currentValueRowId = nextValueRowId;
        if (nextValueRowId >= parentOutputIndex.length) {
          throw new Error(`Got nextValueRowId=${nextValueRowId} which is not less than ${parentOutputIndex.length}`);
        }
        currentOutputIndex = parentOutputIndex[nextValueRowId];
      }
      result.push(currentOutputIndex);
    }
    if (result.length !== valueRowIds.length) {
      throw new Error("Invalid row ids.");
    }
    return result;
  }
  calculateOutputIndex(dimension, parentOutputIndex, outputIndexMultiplier, outputSize) {
    const rowPartitionTensor = this.getRowPartitionTensor(dimension);
    const partitionType = this.getRowPartitionTypeByDimension(dimension);
    switch (partitionType) {
      case RowPartitionType2.VALUE_ROWIDS:
        return this.calculateOutputIndexValueRowID(rowPartitionTensor, parentOutputIndex, outputIndexMultiplier, outputSize);
      case RowPartitionType2.ROW_SPLITS:
        if (rowPartitionTensor.length - 1 > parentOutputIndex.length) {
          throw new Error(`Row partition size is greater than output size: ${rowPartitionTensor.length - 1} > ${parentOutputIndex.length}`);
        }
        return this.calculateOutputIndexRowSplit(rowPartitionTensor, parentOutputIndex, outputIndexMultiplier, outputSize);
      default:
        throw new Error(`Unsupported partition type: ${RowPartitionType2[partitionType]}`);
    }
  }
  getFirstDimensionSize() {
    const firstPartitionTensor = this.rowPartitionValues[0];
    if (this.rowPartitionTypes.length === 0) {
      throw new Error("No row_partition_types given.");
    }
    const firstPartitionType = this.rowPartitionTypes[0];
    switch (firstPartitionType) {
      case RowPartitionType2.FIRST_DIM_SIZE:
        return firstPartitionTensor[0];
      case RowPartitionType2.VALUE_ROWIDS:
        throw new Error("Cannot handle VALUE_ROWIDS in first dimension.");
      case RowPartitionType2.ROW_SPLITS:
        return this.rowPartitionValuesShapes[0][0] - 1;
      default:
        throw new Error(`Cannot handle type ${RowPartitionType2[firstPartitionType]}`);
    }
  }
  compute() {
    const firstPartitionTensor = this.rowPartitionValues[0];
    if (firstPartitionTensor.length <= 0) {
      throw new Error("Invalid first partition input. Tensor requires at least one element.");
    }
    const firstDimension = this.getFirstDimensionSize();
    const outputSize = this.calculateOutputSize(firstDimension);
    const multiplier = new Array(this.raggedRank + 1);
    multiplier[multiplier.length - 1] = 1;
    for (let i = multiplier.length - 2; i >= 0; --i) {
      multiplier[i] = multiplier[i + 1] * outputSize[i + 1];
    }
    const outputShape = makeShape(outputSize, false);
    const outputTensor = util_exports.getArrayFromDType(this.valuesDType, util_exports.sizeFromShape(outputShape));
    const fullSize = multiplier[0] * outputSize[0];
    if (fullSize > 0) {
      let outputIndex = this.calculateFirstParentOutputIndex(firstDimension, multiplier[0], outputSize[0]);
      for (let i = 1; i <= this.raggedRank; ++i) {
        const newOutputIndex = this.calculateOutputIndex(i - 1, outputIndex, multiplier[i], outputSize[i]);
        outputIndex = newOutputIndex;
      }
      this.setOutput(this.raggedRank, outputIndex, outputTensor, outputShape);
    }
    return [outputShape, outputTensor];
  }
  setOutput(raggedRank, outputIndex, outputTensor, outputShape) {
    if (outputTensor.length === 0) {
      return;
    }
    const valuesBase = this.values;
    const outputBase = outputTensor;
    let elementShape = outputShape.slice();
    elementShape = elementShape.slice(raggedRank + 1);
    const valueElementSize = util_exports.sizeFromShape(elementShape);
    const outputIndexSize = outputIndex.length;
    let defaultValue = this.defaultValue;
    if (defaultValue.length !== valueElementSize && defaultValue.length !== 1) {
      const srcShape = this.defaultValueShape;
      tidy(() => {
        const defaultValueTensor = reshape(defaultValue, srcShape);
        const bCastDefault = broadcastTo(defaultValueTensor, elementShape);
        defaultValue = bCastDefault.dataSync();
      });
    }
    let srcStart = 0;
    let dstStart = 0;
    let dstEnd = 0;
    for (let srcI = 0; srcI <= outputIndexSize; ++srcI) {
      let dstI = srcI < outputIndexSize ? outputIndex[srcI] : -1;
      if (dstI === dstEnd) {
        ++dstEnd;
        continue;
      }
      if (dstStart < dstEnd) {
        const src = valuesBase.subarray(srcStart * valueElementSize);
        const dst = outputBase.subarray(dstStart * valueElementSize);
        const nVals = (dstEnd - dstStart) * valueElementSize;
        copyArray(dst, src, nVals);
      }
      if (srcI >= outputIndexSize) {
        const outputSize = outputTensor.length;
        dstI = Math.floor(outputSize / valueElementSize);
      }
      if (dstI > dstEnd) {
        if (this.defaultValue.length === 1) {
          outputBase.subarray(dstEnd * valueElementSize, dstI * valueElementSize).fill(this.defaultValue[0]);
          dstEnd = dstI;
        } else {
          while (dstI > dstEnd) {
            const dst = outputBase.slice(dstEnd * valueElementSize);
            copyArray(dst, defaultValue, valueElementSize);
            ++dstEnd;
          }
        }
      }
      if (dstI < 0) {
        srcStart = srcI + 1;
        dstStart = dstEnd;
      } else {
        srcStart = srcI;
        dstStart = dstEnd;
        dstEnd = dstStart + 1;
      }
    }
  }
};
function copyArray(dst, src, size) {
  for (let i = 0; i < size; i++) {
    dst[i] = src[i];
  }
}
function makeShape(shape, isPartial) {
  const out = [];
  for (let dim of shape) {
    if (dim < 0) {
      if (!isPartial) {
        throw new Error(`Dimension ${dim} must be >= 0`);
      }
      if (dim < -1) {
        throw new Error(`Dimension ${dim} must be >= -1`);
      }
      dim = -1;
    }
    out.push(dim);
  }
  return out;
}
function raggedTensorToTensorImpl(shape, shapesShape, values, valuesShape, valuesDType, defaultValue, defaultValueShape, rowPartitionValues, rowPartitionValuesShapes, rowPartitionTypes) {
  return new RaggedTensorToTensorOp(shape, shapesShape, values, valuesShape, valuesDType, defaultValue, defaultValueShape, rowPartitionValues, rowPartitionValuesShapes, rowPartitionTypes).compute();
}

// node_modules/@tensorflow/tfjs-backend-cpu/dist/kernels/Range_impl.js
init_dist();
function rangeImpl(start, stop, step2, dtype) {
  const sameStartStop = start === stop;
  const increasingRangeNegativeStep = start < stop && step2 < 0;
  const decreasingRangePositiveStep = stop < start && step2 > 1;
  if (sameStartStop || increasingRangeNegativeStep || decreasingRangePositiveStep) {
    return util_exports.makeZerosTypedArray(0, dtype);
  }
  const numElements = Math.abs(Math.ceil((stop - start) / step2));
  const values = util_exports.makeZerosTypedArray(numElements, dtype);
  if (stop < start && step2 === 1) {
    step2 = -1;
  }
  values[0] = start;
  for (let i = 1; i < values.length; i++) {
    values[i] = values[i - 1] + step2;
  }
  return values;
}

// node_modules/@tensorflow/tfjs-backend-cpu/dist/kernels/Rsqrt.js
init_dist();
var rsqrtImpl = createSimpleUnaryImpl((xi) => 1 / Math.sqrt(xi));
var rsqrt2 = unaryKernelFuncFromImpl(Rsqrt, rsqrtImpl);
var rsqrtConfig = {
  kernelName: Rsqrt,
  backendName: "cpu",
  kernelFunc: rsqrt2
};

// node_modules/@tensorflow/tfjs-backend-cpu/dist/kernels/Scatter_impl.js
init_dist();
function scatterImpl(indices, updates, shape, outputSize, sliceSize, numUpdates, sliceRank, strides, defaultValue, sumDupeIndices) {
  const flattenShape = [outputSize / sliceSize, sliceSize];
  const indicesData = indices.values;
  const updatesData = updates.values;
  if (outputSize === 0) {
    return buffer(shape, updates.dtype);
  }
  const outBuf = defaultValue instanceof TensorBuffer ? defaultValue : buffer(flattenShape, updates.dtype);
  if (typeof defaultValue === "string") {
    outBuf.values.fill(defaultValue);
  } else if (typeof defaultValue === "number") {
    outBuf.values.fill(defaultValue);
  } else if (typeof defaultValue === "boolean") {
    outBuf.values.fill(+defaultValue);
  }
  for (let i = 0; i < numUpdates; i++) {
    const index = [];
    let flattenIndex = 0;
    for (let j = 0; j < sliceRank; j++) {
      const dim = indicesData[i * sliceRank + j];
      index.push(dim);
      flattenIndex += dim * strides[j];
    }
    if (flattenIndex < 0 || flattenIndex >= outputSize / sliceSize) {
      throw new Error(`Invalid indices: ${index} does not index into ${shape}`);
    }
    for (let k = 0; k < sliceSize; k++) {
      if (sumDupeIndices) {
        outBuf.values[flattenIndex * sliceSize + k] += updatesData[i * sliceSize + k];
      } else {
        outBuf.values[flattenIndex * sliceSize + k] = updates.rank === 0 ? updatesData[0] : updatesData[i * sliceSize + k];
      }
    }
  }
  return outBuf;
}

// node_modules/@tensorflow/tfjs-backend-cpu/dist/kernels/Sigmoid.js
init_dist();
var sigmoidImpl = createSimpleUnaryImpl((xi) => 1 / (1 + Math.exp(-xi)));
var sigmoid2 = unaryKernelFunc(Sigmoid, (xi) => 1 / (1 + Math.exp(-xi)));
var sigmoidConfig = {
  kernelName: Sigmoid,
  backendName: "cpu",
  kernelFunc: sigmoid2
};

// node_modules/@tensorflow/tfjs-backend-cpu/dist/kernels/Slice.js
init_dist();
function sliceImpl(vals, begin, size, shape, dtype) {
  const isContinous = slice_util_exports.isSliceContinous(shape, begin, size);
  const length = util_exports.sizeFromShape(size);
  const xStrides = util_exports.computeStrides(shape);
  if (isContinous) {
    const flatOffset = slice_util_exports.computeFlatOffset(begin, xStrides);
    if (dtype === "string") {
      return vals.slice(flatOffset, flatOffset + length);
    }
    return vals.subarray(flatOffset, flatOffset + length);
  }
  const decodedData = dtype === "string" ? backend_util_exports.fromUint8ToStringArray(vals) : vals;
  const inBuf = buffer(shape, dtype, decodedData);
  const outBuf = buffer(size, dtype);
  for (let i = 0; i < outBuf.size; ++i) {
    const outLoc = outBuf.indexToLoc(i);
    const inLoc = outLoc.map((idx, j) => idx + begin[j]);
    outBuf.set(inBuf.get(...inLoc), ...outLoc);
  }
  if (dtype === "string") {
    return backend_util_exports.fromStringArrayToUint8(outBuf.values);
  }
  return outBuf.values;
}
function slice2(args) {
  const {
    inputs,
    backend: backend2,
    attrs
  } = args;
  const {
    x
  } = inputs;
  const {
    begin,
    size
  } = attrs;
  assertNotComplex(x, "slice");
  const [$begin, $size] = slice_util_exports.parseSliceParams(x, begin, size);
  slice_util_exports.assertParamsValid(x, $begin, $size);
  const vals = backend2.data.get(x.dataId).values;
  const outVals = sliceImpl(vals, $begin, $size, x.shape, x.dtype);
  return backend2.makeTensorInfo($size, x.dtype, outVals);
}
var sliceConfig = {
  kernelName: Slice,
  backendName: "cpu",
  kernelFunc: slice2
};

// node_modules/@tensorflow/tfjs-backend-cpu/dist/kernels/SparseFillEmptyRows_impl.js
init_dist();
function sparseFillEmptyRowsImpl(indices, indicesShape, indicesDType, values, valuesDType, denseShape, defaultValue) {
  const indicesCount = indicesShape[0];
  const denseRows = denseShape[0];
  const emptyRowIndicator = new Array(denseRows);
  const reverseIndexMap = new Array(indicesCount);
  const rank = indicesShape[1];
  if (denseRows === 0) {
    if (indicesCount !== 0) {
      throw new Error(backend_util_exports.getSparseFillEmptyRowsIndicesDenseShapeMismatch(indicesCount));
    }
    const outputIndices = util_exports.getArrayFromDType(indicesDType, 0);
    const outputValues = util_exports.getArrayFromDType(valuesDType, 0);
    return [outputIndices, [0, rank], outputValues, emptyRowIndicator, reverseIndexMap];
  }
  let rowsAreOrdered = true;
  let lastIndicesRow = 0;
  const csrOffset = new Array(denseRows).fill(0);
  for (let i = 0; i < indicesCount; ++i) {
    const row = indices[i * rank];
    if (row < 0) {
      throw new Error(backend_util_exports.getSparseFillEmptyRowsNegativeIndexErrorMessage(i, row));
    }
    if (row >= denseRows) {
      throw new Error(backend_util_exports.getSparseFillEmptyRowsOutOfRangeIndexErrorMessage(i, row, denseRows));
    }
    ++csrOffset[row];
    rowsAreOrdered = rowsAreOrdered && row >= lastIndicesRow;
    lastIndicesRow = row;
  }
  let allRowsFull = true;
  for (let row = 0; row < denseRows; ++row) {
    const rowEmpty = csrOffset[row] === 0;
    emptyRowIndicator[row] = rowEmpty;
    allRowsFull = allRowsFull && !rowEmpty;
    csrOffset[row] = Math.max(csrOffset[row], 1);
    if (row > 0) {
      csrOffset[row] += csrOffset[row - 1];
    }
  }
  if (allRowsFull && rowsAreOrdered) {
    const outputIndices = indices;
    const outputValues = values;
    for (let i = 0; i < indicesCount; ++i) {
      reverseIndexMap[i] = i;
    }
    return [outputIndices, [indicesCount, rank], outputValues, emptyRowIndicator, reverseIndexMap];
  } else {
    const fullIndicesCount = csrOffset[denseRows - 1];
    const outputIndices = util_exports.getArrayFromDType(indicesDType, fullIndicesCount * rank);
    const outputValues = util_exports.getArrayFromDType(valuesDType, fullIndicesCount);
    const filledCount = new Array(denseRows).fill(0);
    for (let i = 0; i < indicesCount; ++i) {
      const row = indices[i * rank];
      const offset = filledCount[row];
      const outputI = (row === 0 ? 0 : csrOffset[row - 1]) + offset;
      filledCount[row]++;
      for (let j = 0; j < rank; ++j) {
        outputIndices[outputI * rank + j] = indices[i * rank + j];
      }
      outputValues[outputI] = values[i];
      reverseIndexMap[i] = outputI;
    }
    for (let row = 0; row < denseRows; ++row) {
      const rowCount = filledCount[row];
      if (rowCount === 0) {
        const startingIndex = row === 0 ? 0 : csrOffset[row - 1];
        outputIndices[startingIndex * rank + 0] = row;
        for (let col = 1; col < rank; ++col) {
          outputIndices[startingIndex * rank + col] = 0;
        }
        outputValues[startingIndex] = defaultValue;
      }
    }
    return [outputIndices, [fullIndicesCount, rank], outputValues, emptyRowIndicator, reverseIndexMap];
  }
}

// node_modules/@tensorflow/tfjs-backend-cpu/dist/kernels/SparseReshape_impl.js
init_dist();
function sparseReshapeImpl(inputIndices, inputIndicesShape, inputDType, inputShape, targetShape) {
  const denseSize = util_exports.sizeFromShape(inputShape);
  const nnz = inputIndicesShape[0];
  const outputRank = targetShape.length;
  const outputShape = [];
  let product = 1;
  let unknownIndex = -1;
  for (let d = 0; d < outputRank; ++d) {
    const size = targetShape[d];
    if (size === -1) {
      if (unknownIndex !== -1) {
        throw new Error(backend_util_exports.getSparseReshapeMultipleNegativeOneOutputDimErrorMessage(unknownIndex, d));
      }
      unknownIndex = d;
      outputShape.push(1);
    } else {
      if (size < 0) {
        throw new Error(backend_util_exports.getSparseReshapeNegativeOutputDimErrorMessage(d, size));
      }
      product *= size;
      outputShape.push(size);
    }
  }
  if (unknownIndex !== -1) {
    if (product <= 0) {
      throw new Error(backend_util_exports.getSparseReshapeEmptyTensorZeroOutputDimErrorMessage());
    }
    const missing = Math.trunc(denseSize / product);
    if (product * missing !== denseSize) {
      throw new Error(backend_util_exports.getSparseReshapeInputOutputMultipleErrorMessage(inputShape, outputShape));
    }
    outputShape[unknownIndex] = missing;
  }
  const outputSize = util_exports.sizeFromShape(outputShape);
  if (outputSize !== denseSize) {
    throw new Error(backend_util_exports.getSparseReshapeInputOutputMismatchErrorMessage(inputShape, outputShape));
  }
  const inputRank = inputShape.length;
  const inputStrides = [];
  if (inputRank > 0) {
    inputStrides[inputRank - 1] = 1;
    for (let d = inputRank - 2; d >= 0; --d) {
      inputStrides[d] = inputStrides[d + 1] * inputShape[d + 1];
    }
  }
  const outputStrides = [];
  if (outputRank > 0) {
    outputStrides[outputRank - 1] = 1;
    for (let d = outputRank - 2; d >= 0; --d) {
      outputStrides[d] = outputStrides[d + 1] * outputShape[d + 1];
    }
  }
  const newIndices = util_exports.getArrayFromDType(inputDType, nnz * outputRank);
  for (let i = 0; i < nnz; ++i) {
    let id = 0;
    for (let j = 0; j < inputRank; ++j) {
      id += inputIndices[i * inputRank + j] * inputStrides[j];
    }
    for (let j = 0; j < outputRank; ++j) {
      newIndices[i * outputRank + j] = Math.trunc(id / outputStrides[j]);
      id %= outputStrides[j];
    }
  }
  return [newIndices, [nnz, outputRank], outputShape];
}

// node_modules/@tensorflow/tfjs-backend-cpu/dist/kernels/SparseSegmentReduction_impl.js
init_dist();
function sparseSegmentReductionImpl(input, inputShape, inputDType, indices, segmentIds, isMean = false, defaultValue = 0) {
  const numIndices = indices.length;
  const inputFlat = [inputShape[0], input.length / inputShape[0]];
  const numCol = inputFlat[1];
  const lastSegmentIdPlusOne = numIndices > 0 ? segmentIds[numIndices - 1] + 1 : 0;
  const outputRows = lastSegmentIdPlusOne;
  if (outputRows < 0) {
    throw new Error(backend_util_exports.getSparseSegmentReductionNegativeSegmentIdsErrorMessage());
  }
  const outputShape = inputShape.slice();
  outputShape[0] = outputRows;
  const outputLength = outputShape.reduce((product, value) => product * value, 1);
  const output = util_exports.getArrayFromDType(inputDType, outputLength);
  if (numIndices === 0) {
    if (outputRows > 0) {
      output.fill(defaultValue);
    }
    return [output, outputShape];
  }
  if (outputRows <= 0) {
    throw new Error(backend_util_exports.getSparseSegmentReductionNegativeSegmentIdsErrorMessage());
  }
  let start = 0, end = 1;
  let uninitializedIndex = 0;
  let outIndex = segmentIds[start];
  while (true) {
    let nextIndex = 0;
    if (end < numIndices) {
      nextIndex = segmentIds[end];
      if (outIndex === nextIndex) {
        ++end;
        continue;
      }
      if (outIndex >= nextIndex) {
        throw new Error(backend_util_exports.getSparseSegmentReductionNonIncreasingSegmentIdsErrorMessage());
      }
    }
    if (outIndex < 0 || outIndex >= outputRows) {
      throw new Error(backend_util_exports.getSparseSegmentReductionSegmentIdOutOfRangeErrorMessage(outIndex, outputRows));
    }
    if (outIndex > uninitializedIndex) {
      output.fill(defaultValue, uninitializedIndex * numCol, outIndex * numCol);
    }
    for (let i = start; i < end; ++i) {
      const index = indices[i];
      if (index < 0 || index >= inputFlat[0]) {
        throw new Error(backend_util_exports.getSparseSegmentReductionIndicesOutOfRangeErrorMessage(i, indices[i], inputFlat[0]));
      }
      for (let j = 0; j < numCol; j++) {
        output[outIndex * numCol + j] += input[index * numCol + j];
      }
    }
    if (isMean) {
      for (let j = 0; j < numCol; j++) {
        output[outIndex * numCol + j] /= end - start;
      }
    }
    start = end;
    ++end;
    uninitializedIndex = outIndex + 1;
    outIndex = nextIndex;
    if (end > numIndices) {
      break;
    }
  }
  if (uninitializedIndex < outputRows) {
    output.fill(defaultValue, uninitializedIndex * numCol, outputRows * numCol);
  }
  return [output, outputShape];
}

// node_modules/@tensorflow/tfjs-backend-cpu/dist/kernels/Sqrt.js
init_dist();
var sqrtImpl = createSimpleUnaryImpl((xi) => Math.sqrt(xi));
var sqrt2 = unaryKernelFunc(Sqrt, (xi) => Math.sqrt(xi));
var sqrtConfig = {
  kernelName: Sqrt,
  backendName: "cpu",
  kernelFunc: sqrt2
};

// node_modules/@tensorflow/tfjs-backend-cpu/dist/kernels/SquaredDifference.js
init_dist();
var squaredDifferenceImpl = createSimpleBinaryKernelImpl((a, b) => {
  const diff = a - b;
  return diff * diff;
});
var squaredDifference2 = binaryKernelFunc(SquaredDifference, squaredDifferenceImpl);
var squaredDifferenceConfig = {
  kernelName: SquaredDifference,
  backendName: "cpu",
  kernelFunc: squaredDifference2
};

// node_modules/@tensorflow/tfjs-backend-cpu/dist/kernels/StaticRegexReplace.js
init_dist();
var staticRegexReplaceImpl = createSimpleUnaryImpl((x, attrs) => {
  const {
    pattern,
    replaceGlobal,
    rewrite
  } = attrs;
  return x.replace(new RegExp(pattern, replaceGlobal ? "g" : ""), rewrite);
});
var staticRegexReplace2 = unaryKernelFuncFromImpl(StaticRegexReplace, staticRegexReplaceImpl);
var staticRegexReplaceConfig = {
  kernelName: StaticRegexReplace,
  backendName: "cpu",
  kernelFunc: staticRegexReplace2
};

// node_modules/@tensorflow/tfjs-backend-cpu/dist/kernels/StridedSlice_impl.js
init_dist();
function stridedSliceImpl(outShape, xBuf, strides, begin) {
  const outBuf = buffer(outShape, xBuf.dtype);
  for (let i = 0; i < outBuf.size; i++) {
    const loc = outBuf.indexToLoc(i);
    const newLoc = new Array(loc.length);
    for (let j = 0; j < newLoc.length; j++) {
      newLoc[j] = loc[j] * strides[j] + begin[j];
    }
    outBuf.set(xBuf.get(...newLoc), ...loc);
  }
  return outBuf;
}

// node_modules/@tensorflow/tfjs-backend-cpu/dist/kernels/StringNGrams_impl.js
init_dist();
var StringNGramsOp = class {
  constructor(separator, nGramWidths, leftPad, rightPad2, padWidth, preserveShortSequences) {
    this.separator = util_exports.encodeString(separator);
    this.nGramWidths = nGramWidths;
    this.leftPad = util_exports.encodeString(leftPad);
    this.rightPad = util_exports.encodeString(rightPad2);
    this.padWidth = padWidth;
    this.preserveShort = preserveShortSequences;
  }
  getPadWidth(nGramWidth) {
    return Math.min(this.padWidth < 0 ? nGramWidth - 1 : this.padWidth, nGramWidth - 1);
  }
  getNumNGrams(length, nGramWidth) {
    const padWidth = this.getPadWidth(nGramWidth);
    return Math.max(0, length + 2 * padWidth - nGramWidth + 1);
  }
  createNGrams(data, splitIndex, output, outputStartIndex, numNGrams, nGramWidth) {
    for (let nGramIndex = 0; nGramIndex < numNGrams; ++nGramIndex) {
      const padWidth = this.getPadWidth(nGramWidth);
      const leftPadding = Math.max(0, padWidth - nGramIndex);
      const rightPadding = Math.max(0, padWidth - (numNGrams - (nGramIndex + 1)));
      const numTokens = nGramWidth - (leftPadding + rightPadding);
      const dataStartIndex = splitIndex + (leftPadding > 0 ? 0 : nGramIndex - padWidth);
      let nGramSize = 0;
      nGramSize += leftPadding * this.leftPad.length;
      for (let n = 0; n < numTokens; ++n) {
        nGramSize += data[dataStartIndex + n].length;
      }
      nGramSize += rightPadding * this.rightPad.length;
      const numSeparators = leftPadding + rightPadding + numTokens - 1;
      nGramSize += numSeparators * this.separator.length;
      output[outputStartIndex + nGramIndex] = new Uint8Array(nGramSize);
      const nGram = output[outputStartIndex + nGramIndex];
      let nextNGramIndex = 0;
      const appendToNGram = (str) => str.forEach((value) => nGram[nextNGramIndex++] = value);
      for (let n = 0; n < leftPadding; ++n) {
        appendToNGram(this.leftPad);
        appendToNGram(this.separator);
      }
      for (let n = 0; n < numTokens - 1; ++n) {
        appendToNGram(data[dataStartIndex + n]);
        appendToNGram(this.separator);
      }
      if (numTokens > 0) {
        appendToNGram(data[dataStartIndex + numTokens - 1]);
        for (let n = 0; n < rightPadding; ++n) {
          appendToNGram(this.separator);
          appendToNGram(this.rightPad);
        }
      } else {
        for (let n = 0; n < rightPadding - 1; ++n) {
          appendToNGram(this.rightPad);
          appendToNGram(this.separator);
        }
        appendToNGram(this.rightPad);
      }
    }
  }
  // Data and splits together form the definition of the ragged tensor,
  // where data is 1 dimensional and contains the values of the tensor
  // and splits denotes the indices at which each row starts.
  compute(data, splits) {
    const inputDataSize = data.length;
    const splitsSize = splits.length;
    if (splitsSize > 0) {
      let prevSplit = splits[0];
      if (prevSplit !== 0) {
        throw new Error(`First split value must be 0, got ${prevSplit}`);
      }
      for (let i = 1; i < splitsSize; ++i) {
        let validSplits = splits[i] >= prevSplit;
        validSplits = validSplits && splits[i] <= inputDataSize;
        if (!validSplits) {
          throw new Error(`Invalid split value ${splits[i]}, must be in [${prevSplit}, ${inputDataSize}]`);
        }
        prevSplit = splits[i];
      }
      if (prevSplit !== inputDataSize) {
        throw new Error(`Last split value must be data size. Expected ${inputDataSize}, got ${prevSplit}`);
      }
    }
    const numBatchItems = splitsSize - 1;
    const nGramsSplits = util_exports.getArrayFromDType("int32", splitsSize);
    if (inputDataSize === 0 || splitsSize === 0) {
      const empty = new Array(inputDataSize);
      for (let i = 0; i <= numBatchItems; ++i) {
        nGramsSplits[i] = 0;
      }
      return [empty, nGramsSplits];
    }
    nGramsSplits[0] = 0;
    for (let i = 1; i <= numBatchItems; ++i) {
      const length = splits[i] - splits[i - 1];
      let numNGrams = 0;
      this.nGramWidths.forEach((nGramWidth) => {
        numNGrams += this.getNumNGrams(length, nGramWidth);
      });
      if (this.preserveShort && length > 0 && numNGrams === 0) {
        numNGrams = 1;
      }
      nGramsSplits[i] = nGramsSplits[i - 1] + numNGrams;
    }
    const nGrams = new Array(nGramsSplits[numBatchItems]);
    for (let i = 0; i < numBatchItems; ++i) {
      const splitIndex = splits[i];
      let outputStartIdx = nGramsSplits[i];
      this.nGramWidths.forEach((nGramWidth) => {
        const length = splits[i + 1] - splits[i];
        const numNGrams = this.getNumNGrams(length, nGramWidth);
        this.createNGrams(data, splitIndex, nGrams, outputStartIdx, numNGrams, nGramWidth);
        outputStartIdx += numNGrams;
      });
      if (this.preserveShort && outputStartIdx === nGramsSplits[i]) {
        const dataLength = splits[i + 1] - splits[i];
        if (dataLength === 0) {
          continue;
        }
        const nGramWidth = dataLength + 2 * this.padWidth;
        const numNGrams = 1;
        this.createNGrams(data, splitIndex, nGrams, outputStartIdx, numNGrams, nGramWidth);
      }
    }
    return [nGrams, nGramsSplits];
  }
};
function stringNGramsImpl(data, dataSplits, separator, nGramWidths, leftPad, rightPad2, padWidth, preserveShortSequences) {
  return new StringNGramsOp(separator, nGramWidths, leftPad, rightPad2, padWidth, preserveShortSequences).compute(data, dataSplits);
}

// node_modules/@tensorflow/tfjs-backend-cpu/dist/kernels/StringSplit_impl.js
init_dist();
function split2(str, delimiters, skipEmpty, result) {
  if (!str.length) {
    return;
  }
  if (delimiters.length === 0) {
    for (let i = 0; i < str.length; ++i) {
      result.push(str.subarray(i, i + 1));
    }
    return;
  }
  if (delimiters.length === 1) {
    const delimiter = delimiters[0];
    let f = str.indexOf(delimiter);
    while (f !== -1) {
      const token = str.subarray(0, f);
      if (!skipEmpty || token.length !== 0) {
        result.push(token);
      }
      str = str.subarray(f + 1);
      f = str.indexOf(delimiter);
    }
    if (!skipEmpty || str.length !== 0) {
      result.push(str);
    }
    return;
  }
  let tokenStart = 0;
  for (let i = 0; i < str.length + 1; i++) {
    if (i === str.length || delimiters.indexOf(str[i]) !== -1) {
      const token = str.subarray(tokenStart, i);
      if (!skipEmpty || token.length !== 0) {
        result.push(token);
      }
      tokenStart = i + 1;
    }
  }
}
function stringSplitImpl(input, delimiter, skipEmpty) {
  const batchSize = input.length;
  const tokens = [];
  let outputSize = 0;
  let maxNumEntries = 0;
  const numIndices = new Array(batchSize);
  for (let i = 0; i < batchSize; ++i) {
    const prevTokensLength = tokens.length;
    split2(input[i], delimiter, skipEmpty, tokens);
    const nEntries = tokens.length - prevTokensLength;
    numIndices[i] = nEntries;
    outputSize += nEntries;
    maxNumEntries = Math.max(maxNumEntries, nEntries);
  }
  const indices = util_exports.getArrayFromDType("int32", outputSize * 2);
  const values = new Array(outputSize);
  const shape = [batchSize, maxNumEntries];
  let c = 0;
  for (let i = 0; i < batchSize; ++i) {
    for (let j = 0; j < numIndices[i]; ++j) {
      indices[c * 2] = i;
      indices[c * 2 + 1] = j;
      values[c] = tokens[c];
      ++c;
    }
  }
  return [indices, values, shape];
}

// node_modules/@tensorflow/tfjs-backend-cpu/dist/kernels/StringToHashBucketFast_impl.js
init_dist();
function stringToHashBucketFastImpl(input, numBuckets) {
  const output = util_exports.getArrayFromDType("int32", input.length);
  for (let i = 0; i < input.length; ++i) {
    output[i] = util_exports.fingerPrint64(input[i]).modulo(numBuckets).getLowBitsUnsigned();
  }
  return output;
}

// node_modules/@tensorflow/tfjs-backend-cpu/dist/kernels/Sub.js
init_dist();
var subImpl = createSimpleBinaryKernelImpl((aValue, bValue) => aValue - bValue);
var subComplexImpl = createComplexBinaryKernelImpl((aReal, aImag, bReal, bImag) => {
  return {
    real: aReal - bReal,
    imag: aImag - bImag
  };
});
var sub2 = binaryKernelFunc(Sub, subImpl, subComplexImpl);
var subConfig = {
  kernelName: Sub,
  backendName: "cpu",
  kernelFunc: sub2
};

// node_modules/@tensorflow/tfjs-backend-cpu/dist/kernels/Tile_impl.js
init_dist();
function tileImpl(xBuf, reps) {
  const newShape = new Array(xBuf.rank);
  for (let i = 0; i < newShape.length; i++) {
    newShape[i] = xBuf.shape[i] * reps[i];
  }
  const result = buffer(newShape, xBuf.dtype);
  for (let i = 0; i < result.values.length; ++i) {
    const newLoc = result.indexToLoc(i);
    const originalLoc = new Array(xBuf.rank);
    for (let j = 0; j < originalLoc.length; j++) {
      originalLoc[j] = newLoc[j] % xBuf.shape[j];
    }
    const originalIndex = xBuf.locToIndex(originalLoc);
    result.values[i] = xBuf.values[originalIndex];
  }
  return result;
}

// node_modules/@tensorflow/tfjs-backend-cpu/dist/kernels/TopK_impl.js
init_dist();
var comparePair = (a, b) => {
  const valueDiff = b.value - a.value;
  return valueDiff === 0 ? a.index - b.index : valueDiff;
};
function select(array, k, left = 0, right = array.length - 1) {
  while (right > left) {
    if (right - left > 600) {
      const n = right - left + 1;
      const i2 = k - left + 1;
      const z = Math.log(n);
      const s = 0.5 * Math.exp(2 * z / 3);
      const sd = 0.5 * Math.sqrt(z * s * (n - s) / n) * Math.sign(i2 - n / 2);
      const newLeft = Math.max(left, Math.floor(k - i2 * s / n + sd));
      const newRight = Math.min(right, Math.floor(k + (n - i2) * s / n + sd));
      select(array, k, newLeft, newRight);
    }
    const t = array[k];
    let i = left;
    let j = right;
    util_exports.swap(array, left, k);
    if (comparePair(array[right], t) > 0) {
      util_exports.swap(array, left, right);
    }
    while (i < j) {
      util_exports.swap(array, i, j);
      i++;
      j--;
      while (comparePair(array[i], t) < 0) {
        i = i + 1;
      }
      while (comparePair(array[j], t) > 0) {
        j = j - 1;
      }
    }
    if (comparePair(array[left], t) === 0) {
      util_exports.swap(array, left, j);
    } else {
      j = j + 1;
      util_exports.swap(array, j, right);
    }
    if (j <= k) {
      left = j + 1;
    }
    if (k <= j) {
      right = j - 1;
    }
  }
}
function topKImpl(x, xShape, xDtype, k, sorted) {
  const lastDim = xShape[xShape.length - 1];
  const [batch, size] = [x.length / lastDim, lastDim];
  const allTopKVals = util_exports.getTypedArrayFromDType(xDtype, batch * k);
  const allTopKIndices = util_exports.getTypedArrayFromDType("int32", batch * k);
  for (let b = 0; b < batch; b++) {
    const offset = b * size;
    const vals = x.subarray(offset, offset + size);
    let valAndInd = new Array(vals.length);
    vals.forEach((value, index) => valAndInd[index] = {
      value,
      index
    });
    if (k < valAndInd.length) {
      select(valAndInd, k);
      valAndInd = valAndInd.slice(0, k);
    }
    if (sorted) {
      valAndInd.sort(comparePair);
    }
    const outOffset = b * k;
    const topKVals = allTopKVals.subarray(outOffset, outOffset + k);
    const topKIndices = allTopKIndices.subarray(outOffset, outOffset + k);
    for (let i = 0; i < k; i++) {
      topKVals[i] = valAndInd[i].value;
      topKIndices[i] = valAndInd[i].index;
    }
  }
  const outputShape = xShape.slice();
  outputShape[outputShape.length - 1] = k;
  return [buffer(outputShape, xDtype, allTopKVals), buffer(outputShape, "int32", allTopKIndices)];
}

// node_modules/@tensorflow/tfjs-backend-cpu/dist/kernels/Unique_impl.js
init_dist();
function uniqueImpl(values, axis, shape, dtype) {
  const $axis = util_exports.parseAxisParam(axis, shape)[0];
  const newShape = [1, shape[0], 1];
  for (let i = 0; i < $axis; i++) {
    newShape[0] *= shape[i];
  }
  newShape[1] = shape[$axis];
  for (let i = $axis + 1; i < shape.length; i++) {
    newShape[2] *= shape[i];
  }
  const uniqueElements = /* @__PURE__ */ new Map();
  const indices = new Int32Array(shape[$axis]);
  const inputBuffer = new TensorBuffer(newShape, dtype, values);
  const uniqueIndices = [];
  const is1DTensor = newShape[0] === 1 && newShape[2] === 1;
  for (let i = 0; i < shape[$axis]; i++) {
    let element;
    if (is1DTensor) {
      element = values[i].toString();
    } else {
      const axisValues = [];
      for (let m = 0; m < newShape[0]; m++) {
        for (let n = 0; n < newShape[2]; n++) {
          axisValues.push(inputBuffer.get(m, i, n));
        }
      }
      element = axisValues.join(",");
    }
    const existingIndex = uniqueElements.get(element);
    if (existingIndex != null) {
      indices[i] = existingIndex;
    } else {
      const uniqueIndex = uniqueElements.size;
      uniqueElements.set(element, uniqueIndex);
      indices[i] = uniqueIndex;
      uniqueIndices.push(i);
    }
  }
  const outputTmpShape = newShape.slice();
  outputTmpShape[1] = uniqueElements.size;
  const outputBuffer = new TensorBuffer(outputTmpShape, dtype);
  uniqueIndices.forEach((uniqueElementIndex, i) => {
    for (let m = 0; m < newShape[0]; m++) {
      for (let n = 0; n < newShape[2]; n++) {
        outputBuffer.set(inputBuffer.get(m, uniqueElementIndex, n), m, i, n);
      }
    }
  });
  const outputShape = shape.slice();
  outputShape[$axis] = outputTmpShape[1];
  return {
    outputValues: outputBuffer.values,
    outputShape,
    indices
  };
}

export {
  DataStorage,
  KernelBackend,
  assert,
  sizeFromShape,
  parseAxisParam,
  Environment,
  env,
  ENV,
  Abs,
  Acos,
  Acosh,
  Add,
  AddN,
  All,
  Any,
  ArgMax,
  ArgMin,
  Asin,
  Asinh,
  Atan,
  Atanh,
  Atan2,
  AvgPool,
  AvgPoolGrad,
  AvgPool3D,
  AvgPool3DGrad,
  BatchMatMul,
  BatchToSpaceND,
  Bincount,
  BitwiseAnd,
  BroadcastTo,
  BroadcastArgs,
  Cast,
  Ceil,
  ClipByValue,
  Complex,
  ComplexAbs,
  Concat,
  Conv2D,
  Conv2DBackpropFilter,
  Conv2DBackpropInput,
  Conv3D,
  Conv3DBackpropFilterV2,
  Conv3DBackpropInputV2,
  Cos,
  Cosh,
  Cumprod,
  Cumsum,
  CropAndResize,
  DenseBincount,
  DepthToSpace,
  DepthwiseConv2dNative,
  DepthwiseConv2dNativeBackpropFilter,
  DepthwiseConv2dNativeBackpropInput,
  Diag,
  Dilation2D,
  Dilation2DBackpropInput,
  Dilation2DBackpropFilter,
  Draw,
  RealDiv,
  Einsum,
  Elu,
  EluGrad,
  Erf,
  Equal,
  Exp,
  ExpandDims,
  Expm1,
  FFT,
  Fill,
  FlipLeftRight,
  Floor,
  FloorDiv,
  FusedBatchNorm,
  GatherV2,
  GatherNd,
  Greater,
  GreaterEqual,
  Identity,
  IFFT,
  Imag,
  IsFinite,
  IsInf,
  IsNan,
  LeakyRelu,
  Less,
  LessEqual,
  LinSpace,
  Log,
  Log1p,
  LogicalAnd,
  LogicalNot,
  LogicalOr,
  LogicalXor,
  LogSoftmax,
  LowerBound,
  LRN,
  LRNGrad,
  MatrixBandPart,
  Max,
  Maximum,
  MaxPool,
  MaxPoolGrad,
  MaxPool3D,
  MaxPool3DGrad,
  MaxPoolWithArgmax,
  Mean,
  Min,
  Minimum,
  MirrorPad,
  Mod,
  Multinomial,
  Multiply,
  Neg,
  NotEqual,
  NonMaxSuppressionV3,
  NonMaxSuppressionV4,
  NonMaxSuppressionV5,
  OnesLike,
  OneHot,
  Pack,
  PadV2,
  Pool,
  Pow,
  Prelu,
  Prod,
  RaggedGather,
  RaggedRange,
  RaggedTensorToTensor,
  Range,
  Real,
  Reciprocal,
  Relu,
  Reshape,
  ResizeNearestNeighbor,
  ResizeNearestNeighborGrad,
  ResizeBilinear,
  ResizeBilinearGrad,
  Relu6,
  Reverse,
  Round,
  Rsqrt,
  ScatterNd,
  TensorScatterUpdate,
  SearchSorted,
  Select,
  Selu,
  Slice,
  Sin,
  Sinh,
  Sign,
  Sigmoid,
  Softplus,
  Sqrt,
  Sum,
  SpaceToBatchND,
  SplitV,
  Softmax,
  SparseFillEmptyRows,
  SparseReshape,
  SparseSegmentMean,
  SparseSegmentSum,
  SparseToDense,
  SquaredDifference,
  Square,
  StaticRegexReplace,
  StridedSlice,
  StringNGrams,
  StringSplit,
  StringToHashBucketFast,
  Sub,
  Tan,
  Tanh,
  Tile,
  TopK,
  Transform,
  Transpose,
  Unique,
  Unpack,
  UnsortedSegmentSum,
  UpperBound,
  ZerosLike,
  Step,
  FromPixels,
  RotateWithOffset,
  _FusedMatMul,
  FusedConv2D,
  FusedDepthwiseConv2D,
  init_kernel_names,
  getKernel,
  getGradient,
  getKernelsForBackend,
  registerKernel,
  registerGradient,
  unregisterKernel,
  unregisterGradient,
  copyRegisteredKernels,
  init_kernel_registry,
  util_exports,
  init_util,
  TensorBuffer,
  Tensor,
  getGlobalTensorClass,
  Variable,
  init_tensor,
  Rank,
  upcastType,
  sumOutType,
  tensor_util_exports,
  ENGINE,
  init_engine,
  device_util_exports,
  convertToTensor,
  init_tensor_util_env,
  OP_SCOPE_SUFFIX,
  op,
  init_operation,
  complex,
  tensor,
  enableProdMode,
  enableDebugMode,
  disableDeprecationWarnings,
  deprecationWarn,
  disposeVariables,
  engine,
  memory,
  profile,
  tidy,
  dispose,
  keep,
  time,
  setBackend,
  ready,
  getBackend,
  removeBackend,
  findBackend,
  findBackendFactory,
  registerBackend,
  backend,
  setPlatform,
  decodeWeightsStream,
  init_io_utils,
  buffer,
  cast,
  init_cast,
  clone,
  print,
  add2 as add,
  init_add,
  floorDiv,
  init_floorDiv,
  div,
  init_div,
  mul,
  init_mul,
  abs,
  acos,
  acosh,
  addN,
  all,
  init_all,
  any,
  init_any,
  argMax,
  init_arg_max,
  argMin,
  init_arg_min,
  asin,
  asinh,
  atan,
  atan2,
  init_atan2,
  atanh,
  tupleValuesAreOne,
  eitherStridesOrDilationsAreOne,
  checkPadOnDimRoundingMode,
  init_conv_util,
  reshape,
  init_reshape,
  avgPool,
  init_avg_pool,
  avgPool3d,
  concat,
  init_concat,
  matMul,
  init_mat_mul,
  sigmoid,
  init_sigmoid,
  slice,
  init_slice,
  tanh2 as tanh,
  basicLSTMCell,
  batchToSpaceND,
  init_batch_to_space_nd,
  batchNorm,
  init_batchnorm,
  batchNorm2d,
  batchNorm3d,
  batchNorm4d,
  bincount,
  bitwiseAnd,
  broadcastArgs,
  broadcastTo,
  init_broadcast_to,
  ceil,
  fill,
  clipByValue,
  concat1d,
  concat2d,
  concat3d,
  concat4d,
  conv2d,
  init_conv2d,
  conv1d,
  init_conv1d,
  conv2DBackpropInput,
  init_conv2d_backprop_input,
  conv2dTranspose,
  init_conv2d_transpose,
  conv3d,
  conv3DBackpropInput,
  init_conv3d_backprop_input,
  conv3dTranspose,
  cos,
  init_cos,
  cosh,
  init_cosh,
  cumprod,
  init_cumprod,
  cumsum,
  init_cumsum,
  denseBincount,
  depthToSpace,
  init_depth_to_space,
  depthwiseConv2d,
  init_depthwise_conv2d,
  diag,
  dilation2d,
  init_dilation2d,
  getReductionAxes,
  assertAndGetBroadcastShape,
  broadcast_util_exports,
  init_broadcast_util,
  equal,
  init_equal,
  where,
  init_where,
  zerosLike,
  init_zeros_like,
  divNoNan,
  init_div_no_nan,
  dot,
  init_dot,
  einsum,
  elu,
  init_elu,
  ensureShape,
  erf,
  computeOutAndReduceShapes,
  expandShapeToKeepDim,
  getAxesPermutation,
  getUndoAxesPermutation,
  init_axis_util,
  max,
  init_max,
  min,
  init_min,
  pow,
  init_pow,
  scalar,
  init_scalar,
  sqrt,
  init_sqrt,
  square,
  init_square,
  sum2 as sum,
  init_sum,
  norm,
  euclideanNorm,
  init_euclidean_norm,
  exp,
  init_exp,
  expandDims,
  init_expand_dims,
  expm1,
  tile,
  init_tile,
  eye,
  floor,
  init_floor,
  gather,
  init_gather,
  greater,
  init_greater,
  greaterEqual,
  init_greater_equal,
  imag,
  isFinite2 as isFinite,
  isInf,
  isNaN2 as isNaN,
  leakyRelu,
  init_leaky_relu,
  less,
  init_less,
  lessEqual,
  init_less_equal,
  linspace,
  localResponseNormalization,
  init_local_response_normalization,
  log2 as log,
  init_log2 as init_log,
  log1p,
  grad,
  grads,
  valueAndGrad,
  valueAndGrads,
  variableGrads,
  customGrad,
  neg,
  init_neg,
  softplus,
  logSigmoid,
  sub,
  init_sub,
  logSoftmax,
  logSumExp,
  init_log_sum_exp,
  logicalAnd,
  init_logical_and,
  logicalNot,
  init_logical_not,
  logicalOr,
  init_logical_or,
  logicalXor,
  init_logical_xor,
  searchSorted,
  lowerBound,
  maxPool,
  init_max_pool,
  maxPool3d,
  maxPoolWithArgmax,
  maximum,
  init_maximum,
  mean,
  init_mean,
  zeros,
  init_zeros,
  ones2 as ones,
  init_ones,
  meshgrid,
  minimum,
  init_minimum,
  mirrorPad,
  init_mirror_pad,
  mod,
  init_mod,
  moments,
  multiRNNCell,
  multinomial,
  notEqual,
  init_not_equal,
  oneHot,
  init_one_hot,
  onesLike,
  outerProduct,
  pad,
  init_pad,
  pad1d,
  pad2d,
  pad3d,
  pad4d,
  spaceToBatchND,
  init_space_to_batch_nd,
  pool,
  init_pool,
  prelu,
  init_prelu,
  prod,
  init_prod,
  raggedGather,
  raggedRange,
  raggedTensorToTensor,
  rand,
  require_seedrandom2 as require_seedrandom,
  test_util_exports,
  randomGamma,
  randomNormal,
  randomStandardNormal,
  randomUniform,
  randomUniformInt,
  range,
  real,
  reciprocal,
  relu,
  init_relu,
  relu6,
  init_relu6,
  reverse,
  init_reverse,
  reverse1d,
  reverse2d,
  reverse3d,
  reverse4d,
  round2 as round,
  rsqrt,
  init_rsqrt,
  selu,
  init_selu,
  separableConv2d,
  init_separable_conv2d,
  setdiff1dAsync,
  sign,
  sin,
  init_sin,
  sinh,
  init_sinh,
  slice1d,
  slice2d,
  slice3d,
  slice4d,
  softmax,
  fft,
  ifft,
  irfft,
  split,
  init_split,
  rfft,
  squaredDifference,
  init_squared_difference,
  squeeze,
  init_squeeze,
  stack,
  init_stack,
  step,
  init_step,
  stridedSlice,
  tan,
  tensor1d,
  tensor2d,
  tensor3d,
  tensor4d,
  tensor5d,
  tensor6d,
  scatter_nd_util_exports,
  tensorScatterUpdate,
  topk,
  init_topk,
  truncatedNormal,
  unique,
  init_unique,
  unsortedSegmentSum,
  init_unsorted_segment_sum,
  unstack,
  init_unstack,
  upperBound,
  variable,
  whereAsync,
  booleanMaskAsync,
  transpose,
  init_transpose,
  movingAverage,
  scatterND,
  sparseToDense,
  gatherND,
  dropout,
  enclosingPowerOfTwo,
  cosineWindow,
  inTopKAsync,
  conv2DBackpropFilter,
  init_conv2d_backprop_filter,
  depthwiseConv2dNativeBackpropFilter,
  init_depthwise_conv2d_native_backprop_filter,
  depthwiseConv2dNativeBackpropInput,
  init_depthwise_conv2d_native_backprop_input,
  fused_ops_exports,
  resizeBilinear,
  init_resize_bilinear,
  resizeNearestNeighbor,
  init_resize_nearest_neighbor,
  Reduction,
  spectral,
  signal,
  image,
  linalg,
  losses,
  sparse,
  string,
  init_ops,
  serialization_exports,
  Optimizer,
  AdadeltaOptimizer,
  AdagradOptimizer,
  AdamOptimizer,
  AdamaxOptimizer,
  SGDOptimizer,
  MomentumOptimizer,
  RMSPropOptimizer,
  io_exports,
  math_exports,
  browser_exports,
  gather_nd_util_exports,
  parseSliceParams,
  slice_util_exports,
  init_slice_util,
  version,
  OptimizerConstructors,
  train,
  nextFrame,
  SELU_SCALEALPHA,
  SELU_SCALE,
  init_selu_util,
  backend_util_exports,
  kernel_impls_exports,
  init_base,
  init_dist,
  assertNotComplex,
  absConfig,
  createSimpleBinaryKernelImpl,
  complex2,
  complexConfig,
  zeros2,
  identity,
  identityConfig,
  real2,
  realConfig,
  cast2,
  castConfig,
  binaryKernelFunc,
  add3 as add2,
  addConfig,
  bincountImpl,
  bincountReduceImpl,
  bitwiseAndConfig,
  unaryKernelFunc,
  ceilConfig,
  concatImpl,
  equal2,
  equalConfig,
  exp2,
  expConfig,
  expm1Config,
  floorConfig,
  floorDivConfig,
  gatherNdImpl,
  gatherV2Impl,
  greaterConfig,
  greaterEqualConfig,
  lessConfig,
  lessEqualConfig,
  linSpaceImpl,
  logConfig,
  maxImpl,
  maximumConfig,
  minimumConfig,
  multiply,
  multiplyConfig,
  negConfig,
  notEqualConfig,
  transposeImpl,
  transpose2,
  transposeConfig,
  prodConfig,
  raggedGatherImpl,
  raggedRangeImpl,
  raggedTensorToTensorImpl,
  rangeImpl,
  rsqrtConfig,
  scatterImpl,
  sigmoid2,
  sigmoidConfig,
  sliceImpl,
  slice2,
  sliceConfig,
  sparseFillEmptyRowsImpl,
  sparseReshapeImpl,
  sparseSegmentReductionImpl,
  sqrtConfig,
  squaredDifferenceConfig,
  staticRegexReplaceConfig,
  stridedSliceImpl,
  stringNGramsImpl,
  stringSplitImpl,
  stringToHashBucketFastImpl,
  sub2,
  subConfig,
  tileImpl,
  topKImpl,
  uniqueImpl,
  shared_exports
};
/*! Bundled license information:

@tensorflow/tfjs-core/dist/backends/backend.js:
@tensorflow/tfjs-core/dist/util_base.js:
@tensorflow/tfjs-core/dist/global_util.js:
@tensorflow/tfjs-core/dist/ops/complex.js:
@tensorflow/tfjs-core/dist/ops/clone.js:
@tensorflow/tfjs-core/dist/ops/add.js:
@tensorflow/tfjs-core/dist/ops/floorDiv.js:
@tensorflow/tfjs-core/dist/ops/div.js:
@tensorflow/tfjs-core/dist/ops/mul.js:
@tensorflow/tfjs-core/dist/ops/add_n.js:
@tensorflow/tfjs-core/dist/ops/all.js:
@tensorflow/tfjs-core/dist/ops/any.js:
@tensorflow/tfjs-core/dist/ops/atan2.js:
@tensorflow/tfjs-core/dist/ops/reshape.js:
@tensorflow/tfjs-core/dist/ops/conv_util.js:
@tensorflow/tfjs-core/dist/ops/avg_pool.js:
@tensorflow/tfjs-core/dist/ops/avg_pool_3d.js:
@tensorflow/tfjs-core/dist/ops/concat.js:
@tensorflow/tfjs-core/dist/ops/mat_mul.js:
@tensorflow/tfjs-core/dist/ops/basic_lstm_cell.js:
@tensorflow/tfjs-core/dist/ops/batch_to_space_nd.js:
@tensorflow/tfjs-core/dist/ops/batchnorm.js:
@tensorflow/tfjs-core/dist/ops/bincount.js:
@tensorflow/tfjs-core/dist/ops/broadcast_to.js:
@tensorflow/tfjs-core/dist/ops/fill.js:
@tensorflow/tfjs-core/dist/ops/conv2d.js:
@tensorflow/tfjs-core/dist/ops/conv2d_backprop_input.js:
@tensorflow/tfjs-core/dist/ops/conv3d.js:
@tensorflow/tfjs-core/dist/ops/conv3d_backprop_input.js:
@tensorflow/tfjs-core/dist/ops/dense_bincount.js:
@tensorflow/tfjs-core/dist/ops/depth_to_space.js:
@tensorflow/tfjs-core/dist/ops/depthwise_conv2d.js:
@tensorflow/tfjs-core/dist/ops/diag.js:
@tensorflow/tfjs-core/dist/ops/dilation2d.js:
@tensorflow/tfjs-core/dist/ops/equal.js:
@tensorflow/tfjs-core/dist/ops/where.js:
@tensorflow/tfjs-core/dist/ops/div_no_nan.js:
@tensorflow/tfjs-core/dist/ops/dot.js:
@tensorflow/tfjs-core/dist/ops/elu.js:
@tensorflow/tfjs-core/dist/ops/max.js:
@tensorflow/tfjs-core/dist/ops/pow.js:
@tensorflow/tfjs-core/dist/ops/expand_dims.js:
@tensorflow/tfjs-core/dist/ops/tile.js:
@tensorflow/tfjs-core/dist/ops/eye.js:
@tensorflow/tfjs-core/dist/ops/greater.js:
@tensorflow/tfjs-core/dist/ops/greater_equal.js:
@tensorflow/tfjs-core/dist/ops/imag.js:
@tensorflow/tfjs-core/dist/ops/leaky_relu.js:
@tensorflow/tfjs-core/dist/ops/less.js:
@tensorflow/tfjs-core/dist/ops/less_equal.js:
@tensorflow/tfjs-core/dist/ops/local_response_normalization.js:
@tensorflow/tfjs-core/dist/ops/sub.js:
@tensorflow/tfjs-core/dist/ops/log_sum_exp.js:
@tensorflow/tfjs-core/dist/ops/logical_and.js:
@tensorflow/tfjs-core/dist/ops/logical_not.js:
@tensorflow/tfjs-core/dist/ops/logical_or.js:
@tensorflow/tfjs-core/dist/ops/logical_xor.js:
@tensorflow/tfjs-core/dist/ops/max_pool.js:
@tensorflow/tfjs-core/dist/ops/max_pool_3d.js:
@tensorflow/tfjs-core/dist/ops/maximum.js:
@tensorflow/tfjs-core/dist/ops/minimum.js:
@tensorflow/tfjs-core/dist/ops/mirror_pad.js:
@tensorflow/tfjs-core/dist/ops/mod.js:
@tensorflow/tfjs-core/dist/ops/moments.js:
@tensorflow/tfjs-core/dist/ops/multinomial.js:
@tensorflow/tfjs-core/dist/ops/not_equal.js:
@tensorflow/tfjs-core/dist/ops/one_hot.js:
@tensorflow/tfjs-core/dist/ops/pad.js:
@tensorflow/tfjs-core/dist/ops/space_to_batch_nd.js:
@tensorflow/tfjs-core/dist/ops/prelu.js:
@tensorflow/tfjs-core/dist/ops/prod.js:
@tensorflow/tfjs-core/dist/ops/rand.js:
@tensorflow/tfjs-core/dist/ops/random_gamma.js:
@tensorflow/tfjs-core/dist/ops/random_normal.js:
@tensorflow/tfjs-core/dist/ops/random_uniform.js:
@tensorflow/tfjs-core/dist/ops/real.js:
@tensorflow/tfjs-core/dist/ops/relu.js:
@tensorflow/tfjs-core/dist/ops/relu6.js:
@tensorflow/tfjs-core/dist/ops/reverse_1d.js:
@tensorflow/tfjs-core/dist/ops/reverse_2d.js:
@tensorflow/tfjs-core/dist/ops/reverse_3d.js:
@tensorflow/tfjs-core/dist/ops/reverse_4d.js:
@tensorflow/tfjs-core/dist/ops/selu.js:
@tensorflow/tfjs-core/dist/ops/spectral/fft.js:
@tensorflow/tfjs-core/dist/ops/spectral/ifft.js:
@tensorflow/tfjs-core/dist/ops/split.js:
@tensorflow/tfjs-core/dist/ops/squared_difference.js:
@tensorflow/tfjs-core/dist/ops/squeeze.js:
@tensorflow/tfjs-core/dist/ops/stack.js:
@tensorflow/tfjs-core/dist/ops/truncated_normal.js:
@tensorflow/tfjs-core/dist/ops/unique.js:
@tensorflow/tfjs-core/dist/ops/unsorted_segment_sum.js:
@tensorflow/tfjs-core/dist/ops/unstack.js:
@tensorflow/tfjs-core/dist/ops/where_async.js:
@tensorflow/tfjs-core/dist/ops/conv2d_backprop_filter.js:
@tensorflow/tfjs-core/dist/ops/depthwise_conv2d_native_backprop_filter.js:
@tensorflow/tfjs-core/dist/ops/depthwise_conv2d_native_backprop_input.js:
@tensorflow/tfjs-core/dist/ops/loss_ops_utils.js:
@tensorflow/tfjs-core/dist/ops/image/crop_and_resize.js:
@tensorflow/tfjs-core/dist/ops/image/flip_left_right.js:
@tensorflow/tfjs-core/dist/ops/image/rotate_with_offset.js:
@tensorflow/tfjs-core/dist/ops/nonmax_util.js:
@tensorflow/tfjs-core/dist/ops/image/non_max_suppression.js:
@tensorflow/tfjs-core/dist/backends/non_max_suppression_impl.js:
@tensorflow/tfjs-core/dist/ops/image/non_max_suppression_async.js:
@tensorflow/tfjs-core/dist/ops/image/non_max_suppression_with_score.js:
@tensorflow/tfjs-core/dist/ops/image/non_max_suppression_with_score_async.js:
@tensorflow/tfjs-core/dist/ops/image/non_max_suppression_padded.js:
@tensorflow/tfjs-core/dist/ops/image/non_max_suppression_padded_async.js:
@tensorflow/tfjs-core/dist/ops/image/resize_bilinear.js:
@tensorflow/tfjs-core/dist/ops/image/resize_nearest_neighbor.js:
@tensorflow/tfjs-core/dist/ops/linalg/band_part.js:
@tensorflow/tfjs-core/dist/ops/linalg/gram_schmidt.js:
@tensorflow/tfjs-core/dist/ops/linalg/qr.js:
@tensorflow/tfjs-core/dist/ops/losses/absolute_difference.js:
@tensorflow/tfjs-core/dist/ops/losses/huber_loss.js:
@tensorflow/tfjs-core/dist/ops/losses/log_loss.js:
@tensorflow/tfjs-core/dist/ops/losses/mean_squared_error.js:
@tensorflow/tfjs-core/dist/ops/losses/sigmoid_cross_entropy.js:
@tensorflow/tfjs-core/dist/ops/losses/softmax_cross_entropy.js:
@tensorflow/tfjs-core/dist/ops/ops.js:
@tensorflow/tfjs-core/dist/ops/rotate_util.js:
@tensorflow/tfjs-core/dist/backends/kernel_impls.js:
@tensorflow/tfjs-backend-cpu/dist/utils/binary_impl.js:
@tensorflow/tfjs-backend-cpu/dist/kernels/Complex.js:
@tensorflow/tfjs-backend-cpu/dist/utils/zeros_impl.js:
@tensorflow/tfjs-backend-cpu/dist/kernels/Identity.js:
@tensorflow/tfjs-backend-cpu/dist/kernels/Real.js:
@tensorflow/tfjs-backend-cpu/dist/kernels/Cast.js:
@tensorflow/tfjs-backend-cpu/dist/utils/binary_utils.js:
@tensorflow/tfjs-backend-cpu/dist/kernels/Add.js:
@tensorflow/tfjs-backend-cpu/dist/kernels/Bincount_impl.js:
@tensorflow/tfjs-backend-cpu/dist/utils/unary_impl.js:
@tensorflow/tfjs-backend-cpu/dist/utils/unary_utils.js:
@tensorflow/tfjs-backend-cpu/dist/kernels/Concat_impl.js:
@tensorflow/tfjs-backend-cpu/dist/kernels/Equal.js:
@tensorflow/tfjs-backend-cpu/dist/kernels/FloorDiv.js:
@tensorflow/tfjs-backend-cpu/dist/kernels/GatherV2_impl.js:
@tensorflow/tfjs-backend-cpu/dist/kernels/Greater.js:
@tensorflow/tfjs-backend-cpu/dist/kernels/GreaterEqual.js:
@tensorflow/tfjs-backend-cpu/dist/kernels/Less.js:
@tensorflow/tfjs-backend-cpu/dist/kernels/LessEqual.js:
@tensorflow/tfjs-backend-cpu/dist/kernels/LinSpace_impl.js:
@tensorflow/tfjs-backend-cpu/dist/kernels/Max_impl.js:
@tensorflow/tfjs-backend-cpu/dist/kernels/Maximum.js:
@tensorflow/tfjs-backend-cpu/dist/kernels/Minimum.js:
@tensorflow/tfjs-backend-cpu/dist/kernels/Multiply.js:
@tensorflow/tfjs-backend-cpu/dist/kernels/Neg.js:
@tensorflow/tfjs-backend-cpu/dist/kernels/NotEqual.js:
@tensorflow/tfjs-backend-cpu/dist/kernels/Transpose_impl.js:
@tensorflow/tfjs-backend-cpu/dist/kernels/Transpose.js:
@tensorflow/tfjs-backend-cpu/dist/kernels/Prod.js:
@tensorflow/tfjs-backend-cpu/dist/kernels/Range_impl.js:
@tensorflow/tfjs-backend-cpu/dist/kernels/Scatter_impl.js:
@tensorflow/tfjs-backend-cpu/dist/kernels/Slice.js:
@tensorflow/tfjs-backend-cpu/dist/kernels/SquaredDifference.js:
@tensorflow/tfjs-backend-cpu/dist/kernels/StridedSlice_impl.js:
@tensorflow/tfjs-backend-cpu/dist/kernels/Sub.js:
@tensorflow/tfjs-backend-cpu/dist/kernels/TopK_impl.js:
@tensorflow/tfjs-backend-cpu/dist/kernels/Unique_impl.js:
@tensorflow/tfjs-backend-cpu/dist/shared.js:
  (**
   * @license
   * Copyright 2020 Google LLC. All Rights Reserved.
   * Licensed under the Apache License, Version 2.0 (the "License");
   * you may not use this file except in compliance with the License.
   * You may obtain a copy of the License at
   *
   * http://www.apache.org/licenses/LICENSE-2.0
   *
   * Unless required by applicable law or agreed to in writing, software
   * distributed under the License is distributed on an "AS IS" BASIS,
   * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
   * See the License for the specific language governing permissions and
   * limitations under the License.
   * =============================================================================
   *)

@tensorflow/tfjs-core/dist/environment.js:
@tensorflow/tfjs-core/dist/util.js:
@tensorflow/tfjs-core/dist/tensor.js:
@tensorflow/tfjs-core/dist/types.js:
@tensorflow/tfjs-core/dist/device_util.js:
@tensorflow/tfjs-core/dist/tape.js:
@tensorflow/tfjs-core/dist/ops/broadcast_util.js:
@tensorflow/tfjs-core/dist/ops/axis_util.js:
@tensorflow/tfjs-core/dist/test_util.js:
@tensorflow/tfjs-core/dist/browser_util.js:
@tensorflow/tfjs-core/dist/ops/concat_util.js:
@tensorflow/tfjs-core/dist/ops/reduce_util.js:
@tensorflow/tfjs-core/dist/index.js:
  (**
   * @license
   * Copyright 2017 Google LLC. All Rights Reserved.
   * Licensed under the Apache License, Version 2.0 (the "License");
   * you may not use this file except in compliance with the License.
   * You may obtain a copy of the License at
   *
   * http://www.apache.org/licenses/LICENSE-2.0
   *
   * Unless required by applicable law or agreed to in writing, software
   * distributed under the License is distributed on an "AS IS" BASIS,
   * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
   * See the License for the specific language governing permissions and
   * limitations under the License.
   * =============================================================================
   *)

@tensorflow/tfjs-core/dist/log.js:
@tensorflow/tfjs-core/dist/tensor_format.js:
@tensorflow/tfjs-core/dist/tensor_util.js:
@tensorflow/tfjs-core/dist/profiler.js:
@tensorflow/tfjs-core/dist/engine.js:
@tensorflow/tfjs-core/dist/ops/operation.js:
@tensorflow/tfjs-core/dist/tensor_util_env.js:
@tensorflow/tfjs-core/dist/ops/tensor_ops_util.js:
@tensorflow/tfjs-core/dist/ops/tensor.js:
@tensorflow/tfjs-core/dist/globals.js:
@tensorflow/tfjs-core/dist/ops/abs.js:
@tensorflow/tfjs-core/dist/ops/acos.js:
@tensorflow/tfjs-core/dist/ops/acosh.js:
@tensorflow/tfjs-core/dist/ops/asin.js:
@tensorflow/tfjs-core/dist/ops/asinh.js:
@tensorflow/tfjs-core/dist/ops/atan.js:
@tensorflow/tfjs-core/dist/ops/atanh.js:
@tensorflow/tfjs-core/dist/ops/sigmoid.js:
@tensorflow/tfjs-core/dist/ops/slice.js:
@tensorflow/tfjs-core/dist/ops/tanh.js:
@tensorflow/tfjs-core/dist/ops/ceil.js:
@tensorflow/tfjs-core/dist/ops/clip_by_value.js:
@tensorflow/tfjs-core/dist/ops/cos.js:
@tensorflow/tfjs-core/dist/ops/cosh.js:
@tensorflow/tfjs-core/dist/ops/cumsum.js:
@tensorflow/tfjs-core/dist/ops/zeros_like.js:
@tensorflow/tfjs-core/dist/ops/erf.js:
@tensorflow/tfjs-core/dist/ops/scalar.js:
@tensorflow/tfjs-core/dist/ops/sqrt.js:
@tensorflow/tfjs-core/dist/ops/sum.js:
@tensorflow/tfjs-core/dist/ops/norm.js:
@tensorflow/tfjs-core/dist/ops/exp.js:
@tensorflow/tfjs-core/dist/ops/expm1.js:
@tensorflow/tfjs-core/dist/ops/floor.js:
@tensorflow/tfjs-core/dist/ops/gather.js:
@tensorflow/tfjs-core/dist/ops/is_finite.js:
@tensorflow/tfjs-core/dist/ops/is_inf.js:
@tensorflow/tfjs-core/dist/ops/is_nan.js:
@tensorflow/tfjs-core/dist/ops/linspace.js:
@tensorflow/tfjs-core/dist/ops/log.js:
@tensorflow/tfjs-core/dist/ops/log1p.js:
@tensorflow/tfjs-core/dist/gradients.js:
@tensorflow/tfjs-core/dist/ops/neg.js:
@tensorflow/tfjs-core/dist/ops/softplus.js:
@tensorflow/tfjs-core/dist/ops/log_sigmoid.js:
@tensorflow/tfjs-core/dist/ops/max_pool_with_argmax.js:
@tensorflow/tfjs-core/dist/ops/zeros.js:
@tensorflow/tfjs-core/dist/ops/ones.js:
@tensorflow/tfjs-core/dist/ops/ones_like.js:
@tensorflow/tfjs-core/dist/ops/pool.js:
@tensorflow/tfjs-core/dist/ops/rand_util.js:
@tensorflow/tfjs-core/dist/ops/range.js:
@tensorflow/tfjs-core/dist/ops/reciprocal.js:
@tensorflow/tfjs-core/dist/ops/reverse.js:
@tensorflow/tfjs-core/dist/ops/round.js:
@tensorflow/tfjs-core/dist/ops/rsqrt.js:
@tensorflow/tfjs-core/dist/ops/sign.js:
@tensorflow/tfjs-core/dist/ops/sin.js:
@tensorflow/tfjs-core/dist/ops/sinh.js:
@tensorflow/tfjs-core/dist/ops/slice1d.js:
@tensorflow/tfjs-core/dist/ops/slice2d.js:
@tensorflow/tfjs-core/dist/ops/slice3d.js:
@tensorflow/tfjs-core/dist/ops/slice4d.js:
@tensorflow/tfjs-core/dist/ops/softmax.js:
@tensorflow/tfjs-core/dist/ops/spectral/irfft.js:
@tensorflow/tfjs-core/dist/ops/spectral/rfft.js:
@tensorflow/tfjs-core/dist/ops/step.js:
@tensorflow/tfjs-core/dist/ops/strided_slice.js:
@tensorflow/tfjs-core/dist/ops/tan.js:
@tensorflow/tfjs-core/dist/ops/tensor1d.js:
@tensorflow/tfjs-core/dist/ops/tensor2d.js:
@tensorflow/tfjs-core/dist/ops/tensor3d.js:
@tensorflow/tfjs-core/dist/ops/tensor4d.js:
@tensorflow/tfjs-core/dist/ops/tensor5d.js:
@tensorflow/tfjs-core/dist/ops/tensor6d.js:
@tensorflow/tfjs-core/dist/ops/topk.js:
@tensorflow/tfjs-core/dist/ops/variable.js:
@tensorflow/tfjs-core/dist/backends/where_impl.js:
@tensorflow/tfjs-core/dist/ops/boolean_mask.js:
@tensorflow/tfjs-core/dist/ops/transpose.js:
@tensorflow/tfjs-core/dist/ops/moving_average.js:
@tensorflow/tfjs-core/dist/ops/scatter_nd.js:
@tensorflow/tfjs-core/dist/ops/sparse_to_dense.js:
@tensorflow/tfjs-core/dist/ops/gather_nd.js:
@tensorflow/tfjs-core/dist/ops/dropout.js:
@tensorflow/tfjs-core/dist/serialization.js:
@tensorflow/tfjs-core/dist/optimizers/optimizer.js:
@tensorflow/tfjs-core/dist/optimizers/adadelta_optimizer.js:
@tensorflow/tfjs-core/dist/optimizers/adagrad_optimizer.js:
@tensorflow/tfjs-core/dist/optimizers/adam_optimizer.js:
@tensorflow/tfjs-core/dist/optimizers/adamax_optimizer.js:
@tensorflow/tfjs-core/dist/optimizers/sgd_optimizer.js:
@tensorflow/tfjs-core/dist/optimizers/momentum_optimizer.js:
@tensorflow/tfjs-core/dist/optimizers/rmsprop_optimizer.js:
@tensorflow/tfjs-core/dist/io/types.js:
@tensorflow/tfjs-core/dist/io/io_utils.js:
@tensorflow/tfjs-core/dist/io/router_registry.js:
@tensorflow/tfjs-core/dist/io/indexed_db.js:
@tensorflow/tfjs-core/dist/io/local_storage.js:
@tensorflow/tfjs-core/dist/io/browser_files.js:
@tensorflow/tfjs-core/dist/io/weights_loader.js:
@tensorflow/tfjs-core/dist/io/http.js:
@tensorflow/tfjs-core/dist/io/passthrough.js:
@tensorflow/tfjs-core/dist/io/model_management.js:
@tensorflow/tfjs-core/dist/io/io.js:
@tensorflow/tfjs-core/dist/ops/confusion_matrix.js:
@tensorflow/tfjs-core/dist/math.js:
@tensorflow/tfjs-core/dist/optimizers/optimizer_constructors.js:
@tensorflow/tfjs-core/dist/train.js:
@tensorflow/tfjs-core/dist/ops/array_ops_util.js:
@tensorflow/tfjs-core/dist/ops/selu_util.js:
@tensorflow/tfjs-core/dist/ops/erf_util.js:
@tensorflow/tfjs-core/dist/backends/complex_util.js:
@tensorflow/tfjs-core/dist/ops/segment_util.js:
@tensorflow/tfjs-core/dist/backends/backend_util.js:
  (**
   * @license
   * Copyright 2018 Google LLC. All Rights Reserved.
   * Licensed under the Apache License, Version 2.0 (the "License");
   * you may not use this file except in compliance with the License.
   * You may obtain a copy of the License at
   *
   * http://www.apache.org/licenses/LICENSE-2.0
   *
   * Unless required by applicable law or agreed to in writing, software
   * distributed under the License is distributed on an "AS IS" BASIS,
   * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
   * See the License for the specific language governing permissions and
   * limitations under the License.
   * =============================================================================
   *)

@tensorflow/tfjs-core/dist/kernel_registry.js:
@tensorflow/tfjs-core/dist/ops/square.js:
@tensorflow/tfjs-core/dist/ops/dropout_util.js:
@tensorflow/tfjs-core/dist/ops/signal_ops_util.js:
@tensorflow/tfjs-core/dist/ops/in_top_k.js:
@tensorflow/tfjs-core/dist/ops/fused_util.js:
@tensorflow/tfjs-core/dist/ops/fused/conv2d.js:
@tensorflow/tfjs-core/dist/ops/fused/depthwise_conv2d.js:
@tensorflow/tfjs-core/dist/ops/fused/mat_mul.js:
@tensorflow/tfjs-core/dist/ops/fused_ops.js:
@tensorflow/tfjs-core/dist/ops/signal/hamming_window.js:
@tensorflow/tfjs-core/dist/ops/signal/hann_window.js:
@tensorflow/tfjs-core/dist/ops/signal/frame.js:
@tensorflow/tfjs-core/dist/ops/signal/stft.js:
@tensorflow/tfjs-core/dist/backends/non_max_suppression_util.js:
@tensorflow/tfjs-core/dist/flags.js:
@tensorflow/tfjs-core/dist/io/progress.js:
@tensorflow/tfjs-core/dist/ops/browser.js:
@tensorflow/tfjs-core/dist/platforms/platform_browser.js:
@tensorflow/tfjs-core/dist/platforms/platform_node.js:
@tensorflow/tfjs-backend-cpu/dist/cpu_util.js:
@tensorflow/tfjs-backend-cpu/dist/kernels/Tile_impl.js:
  (**
   * @license
   * Copyright 2019 Google LLC. All Rights Reserved.
   * Licensed under the Apache License, Version 2.0 (the "License");
   * you may not use this file except in compliance with the License.
   * You may obtain a copy of the License at
   *
   * http://www.apache.org/licenses/LICENSE-2.0
   *
   * Unless required by applicable law or agreed to in writing, software
   * distributed under the License is distributed on an "AS IS" BASIS,
   * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
   * See the License for the specific language governing permissions and
   * limitations under the License.
   * =============================================================================
   *)

@tensorflow/tfjs-core/dist/platforms/is_typed_array_browser.js:
@tensorflow/tfjs-core/dist/ops/bitwise_and.js:
@tensorflow/tfjs-core/dist/ops/ensure_shape.js:
@tensorflow/tfjs-core/dist/ops/random_uniform_int.js:
@tensorflow/tfjs-core/dist/ops/image/rgb_to_grayscale.js:
@tensorflow/tfjs-core/dist/ops/string/static_regex_replace.js:
@tensorflow/tfjs-backend-cpu/dist/kernels/BitwiseAnd.js:
@tensorflow/tfjs-backend-cpu/dist/kernels/StaticRegexReplace.js:
  (**
   * @license
   * Copyright 2023 Google LLC.
   * Licensed under the Apache License, Version 2.0 (the "License");
   * you may not use this file except in compliance with the License.
   * You may obtain a copy of the License at
   *
   * http://www.apache.org/licenses/LICENSE-2.0
   *
   * Unless required by applicable law or agreed to in writing, software
   * distributed under the License is distributed on an "AS IS" BASIS,
   * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
   * See the License for the specific language governing permissions and
   * limitations under the License.
   * =============================================================================
   *)

@tensorflow/tfjs-core/dist/hash_util.js:
@tensorflow/tfjs-core/dist/ops/broadcast_args.js:
@tensorflow/tfjs-core/dist/ops/einsum.js:
@tensorflow/tfjs-core/dist/ops/meshgrid.js:
@tensorflow/tfjs-core/dist/ops/image/grayscale_to_rgb.js:
@tensorflow/tfjs-core/dist/ops/image/transform.js:
@tensorflow/tfjs-core/dist/ops/sparse/sparse_fill_empty_rows.js:
@tensorflow/tfjs-core/dist/ops/sparse/sparse_reshape.js:
@tensorflow/tfjs-core/dist/ops/sparse/sparse_segment_mean.js:
@tensorflow/tfjs-core/dist/ops/sparse/sparse_segment_sum.js:
@tensorflow/tfjs-core/dist/ops/string/string_n_grams.js:
@tensorflow/tfjs-core/dist/ops/string/string_split.js:
@tensorflow/tfjs-core/dist/ops/string/string_to_hash_bucket_fast.js:
@tensorflow/tfjs-core/dist/ops/slice_util.js:
@tensorflow/tfjs-core/dist/backends/einsum_util.js:
@tensorflow/tfjs-core/dist/ops/sparse/sparse_fill_empty_rows_util.js:
@tensorflow/tfjs-core/dist/ops/sparse/sparse_reshape_util.js:
@tensorflow/tfjs-core/dist/ops/sparse/sparse_segment_reduction_util.js:
@tensorflow/tfjs-backend-cpu/dist/kernels/GatherNd_Impl.js:
@tensorflow/tfjs-backend-cpu/dist/kernels/SparseFillEmptyRows_impl.js:
@tensorflow/tfjs-backend-cpu/dist/kernels/SparseReshape_impl.js:
@tensorflow/tfjs-backend-cpu/dist/kernels/SparseSegmentReduction_impl.js:
@tensorflow/tfjs-backend-cpu/dist/kernels/StringNGrams_impl.js:
@tensorflow/tfjs-backend-cpu/dist/kernels/StringSplit_impl.js:
@tensorflow/tfjs-backend-cpu/dist/kernels/StringToHashBucketFast_impl.js:
  (**
   * @license
   * Copyright 2021 Google LLC. All Rights Reserved.
   * Licensed under the Apache License, Version 2.0 (the "License");
   * you may not use this file except in compliance with the License.
   * You may obtain a copy of the License at
   *
   * http://www.apache.org/licenses/LICENSE-2.0
   *
   * Unless required by applicable law or agreed to in writing, software
   * distributed under the License is distributed on an "AS IS" BASIS,
   * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
   * See the License for the specific language governing permissions and
   * limitations under the License.
   * =============================================================================
   *)

@tensorflow/tfjs-core/dist/ops/buffer.js:
@tensorflow/tfjs-core/dist/ops/cast.js:
@tensorflow/tfjs-core/dist/ops/print.js:
@tensorflow/tfjs-core/dist/ops/arg_max.js:
@tensorflow/tfjs-core/dist/ops/arg_min.js:
@tensorflow/tfjs-core/dist/ops/min.js:
@tensorflow/tfjs-core/dist/ops/log_softmax.js:
@tensorflow/tfjs-core/dist/ops/mean.js:
@tensorflow/tfjs-core/dist/ops/setdiff1d_async.js:
@tensorflow/tfjs-core/dist/ops/fused_types.js:
@tensorflow/tfjs-core/dist/base.js:
@tensorflow/tfjs-core/dist/base_side_effects.js:
  (**
   * @license
   * Copyright 2020 Google Inc. All Rights Reserved.
   * Licensed under the Apache License, Version 2.0 (the "License");
   * you may not use this file except in compliance with the License.
   * You may obtain a copy of the License at
   *
   * http://www.apache.org/licenses/LICENSE-2.0
   *
   * Unless required by applicable law or agreed to in writing, software
   * distributed under the License is distributed on an "AS IS" BASIS,
   * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
   * See the License for the specific language governing permissions and
   * limitations under the License.
   * =============================================================================
   *)

@tensorflow/tfjs-core/dist/ops/cumprod.js:
  (**
   * @license
   * Copyright 2022 Google LLC. All Rights Reserved.
   * Licensed under the Apache License, Version 2.0 (the 'License');
   * you may not use this file except in compliance with the License.
   * You may obtain a copy of the License at
   *
   * http://www.apache.org/licenses/LICENSE-2.0
   *
   * Unless required by applicable law or agreed to in writing, software
   * distributed under the License is distributed on an 'AS IS' BASIS,
   * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
   * See the License for the specific language governing permissions and
   * limitations under the License.
   * =============================================================================
   *)

@tensorflow/tfjs-core/dist/ops/euclidean_norm.js:
@tensorflow/tfjs-core/dist/ops/search_sorted.js:
@tensorflow/tfjs-core/dist/ops/lower_bound.js:
@tensorflow/tfjs-core/dist/ops/ragged_gather.js:
@tensorflow/tfjs-core/dist/ops/ragged_tensor_to_tensor.js:
@tensorflow/tfjs-core/dist/ops/random_standard_normal.js:
@tensorflow/tfjs-core/dist/ops/tensor_scatter_update.js:
@tensorflow/tfjs-core/dist/ops/upper_bound.js:
@tensorflow/tfjs-core/dist/ops/ragged_to_dense_util.js:
@tensorflow/tfjs-backend-cpu/dist/kernels/RaggedGather_impl.js:
@tensorflow/tfjs-backend-cpu/dist/kernels/RaggedTensorToTensor_impl.js:
  (**
   * @license
   * Copyright 2022 Google LLC. All Rights Reserved.
   * Licensed under the Apache License, Version 2.0 (the "License");
   * you may not use this file except in compliance with the License.
   * You may obtain a copy of the License at
   *
   * http://www.apache.org/licenses/LICENSE-2.0
   *
   * Unless required by applicable law or agreed to in writing, software
   * distributed under the License is distributed on an "AS IS" BASIS,
   * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
   * See the License for the specific language governing permissions and
   * limitations under the License.
   * =============================================================================
   *)

@tensorflow/tfjs-core/dist/ops/ragged_range.js:
@tensorflow/tfjs-core/dist/optimizers/register_optimizers.js:
@tensorflow/tfjs-backend-cpu/dist/kernels/RaggedRange_impl.js:
  (**
   * @license
   * Copyright 2022 Google LLC.
   * Licensed under the Apache License, Version 2.0 (the "License");
   * you may not use this file except in compliance with the License.
   * You may obtain a copy of the License at
   *
   * http://www.apache.org/licenses/LICENSE-2.0
   *
   * Unless required by applicable law or agreed to in writing, software
   * distributed under the License is distributed on an "AS IS" BASIS,
   * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
   * See the License for the specific language governing permissions and
   * limitations under the License.
   * =============================================================================
   *)

@tensorflow/tfjs-core/dist/ops/image/threshold.js:
  (**
   * @license
   * Copyright 2021 Google LLC. All Rights Reserved.
   * Licensed under the Apache License, Version 2.0 (the "License");
   * you may not use this file except in compliance with the License.
   * You may obtain a copy of the License at
   *
   * https://www.apache.org/licenses/LICENSE-2.0
   *
   * Unless required by applicable law or agreed to in writing, software
   * distributed under the License is distributed on an "AS IS" BASIS,
   * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
   * See the License for the specific language governing permissions and
   * limitations under the License.
   * =============================================================================
   *)

@tensorflow/tfjs-core/dist/version.js:
  (** @license See the LICENSE file. *)

@tensorflow/tfjs-backend-cpu/dist/kernels/Abs.js:
@tensorflow/tfjs-backend-cpu/dist/kernels/Ceil.js:
@tensorflow/tfjs-backend-cpu/dist/kernels/Exp.js:
@tensorflow/tfjs-backend-cpu/dist/kernels/Expm1.js:
@tensorflow/tfjs-backend-cpu/dist/kernels/Floor.js:
@tensorflow/tfjs-backend-cpu/dist/kernels/Log.js:
@tensorflow/tfjs-backend-cpu/dist/kernels/Rsqrt.js:
@tensorflow/tfjs-backend-cpu/dist/kernels/Sigmoid.js:
@tensorflow/tfjs-backend-cpu/dist/kernels/Sqrt.js:
  (**
   * @license
   * Copyright 2020 Google LLC. All Rights Reserved.
   * Licensed under the Apache License, Version 2.0 (the License);
   * you may not use this file except in compliance with the License.
   * You may obtain a copy of the License at
   *
   * http://www.apache.org/licenses/LICENSE-2.0
   *
   * Unless required by applicable law or agreed to in writing, software
   * distributed under the License is distributed on an AS IS BASIS,
   * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
   * See the License for the specific language governing permissions and
   * limitations under the License.
   * =============================================================================
   *)
*/
//# sourceMappingURL=chunk-Y67JEHGJ.js.map
